{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ef75f2",
   "metadata": {},
   "source": [
    "## AIFFEL Exploration 01 가위 바위 보 프로젝트\n",
    "\n",
    "- 아이펠 강남에 들어와서 처음으로 진행 되었던 Exploration이었고, 이미지 데이터 수집부터 시작해서 데이터를 딥러닝 프레임 워크인 케라스의 모델에 돌려보았던 시간이었다.\n",
    "- 주변의 지인에게 부탁하여 데이터를 계속 추가하는 작업을 진행하였다. 하지만 예제에서 제시되었던 mnist 데이터셋에 비해 데이터의 양이 상대적으로 적다는 한계가 아쉽지만, 데이터를 __수집, 전처리, 모델학습, 평가__ 를 직접 경험하면서 데이터의 중요함을 배워가는 시간이었다. 순서는 다음과 같다. \n",
    "\n",
    "#### 1. 데이터 수집 및 전처리\n",
    "- 이미지 수집 및 사용된 라이브러리\n",
    "- resize_images(), load_data() 함수 코드 설명\n",
    "- 데이터 정규화\n",
    "\n",
    "#### 2. 모델 구성, 하이퍼 파라미터 튜닝 및 평가\n",
    "- 베이스모델 설명\n",
    "- 모델 최적화를 위한 방법\n",
    "- 하이퍼파라미터 튜닝 결과 및 평가\n",
    "\n",
    "#### 3. 회고\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4091a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터에 접근하기 위해서 사용하는 라이브러리\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 데이터 전처리 및 시각화에 쓸 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 모델을 만들기 위한 프레임 워크\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990354c",
   "metadata": {},
   "source": [
    "#### 1. 데이터 수집 및 전처리\n",
    "\n",
    "##### 이미지 수집  및 전처리에 사용된 라이브러리\n",
    "- 구글의 [teachable machine](https://teachablemachine.withgoogle.com/) 웹페이지에 접속해서 웹캠을 이용하여  244 x 244 픽셀 컬러 사진을 수집하였다. 함께 학습하는 5조 조원분들과 이미지를 공유하고, 주변 친구들에게 요청하여서 가위, 바위, 보를 각각 수집하였다. \n",
    "![](https://raw.githubusercontent.com/Asunny2019/AIFFEL_Exploration/cde46562817225c4de94778c233b53781a65213d/img/paper_back_7.jpg)\n",
    "||학습 데이터(train data)|시험데이터(test data)|\n",
    "|-|-|-|\n",
    "|총 사진 갯수|3 class x720(장/class) = 2160 장 |3 class x 150(장/class) = 450장|\n",
    "\n",
    "- 학습 데이터의 손 사진을 찍은 사람과 시험 데이터의 손 사진을 분리하였다.학습데이터에 참여한 사람이 시험 데이터의 이미지에도 넣으면 다른 각도의 이미지이라도 비슷한 손모양이기 때문에 과대평가 될 수 있겠다고 생각해서 이미지를 분리하였다.    \n",
    "\n",
    "- 처음에는 학습데이터를 1800장 테스트 데이터셋을 총150장으로 작업을 진행하다가 테스트 데이터셋이 너무 적고 다양성이 부족해서 모델 성능을 대표하기에는 부족할 것 같아서 지인들에게 부탁을 해서 테스트 데이터 셋과 훈련 데이터 셋을 추가하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f559add",
   "metadata": {},
   "source": [
    "#### 전처리 과정에서 사용된 라이브러리 glob, PIL(pillow),numpy\n",
    "\n",
    "#### glob.glob(pathname, *, root_dir=None, dir_fd=None, recursive=False) 와 glob.iglob\n",
    "- glob모듈은 유닉스 셸이 사용하는 규칙에 따라 지정된 패턴과 일치하는 모든 경로명을 찾아준다. \n",
    "- 그 중에서 glob.glob 함수는 pathname에 일치하는 경로(절대경로 혹은 상대경로)를 찾아서 리스트로 반환해준다. 경로에 와일드카드(* : 문자열 모두, ?: 문자열 한개 등)를 포함할 수 있고, 와일드 카드에 매칭되는 파일의 경로를 모두 찾아주므로 편리하다. __glob.iglob__ 는 glob.glob와 같은 결과를 제너레이터로 반환하므로 메모리를 절약할 수 있다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3acd142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glob.glob 사용시 ['/aiffel/aiffel/rock_scissor_paper/scissor/CLASS_SCISSORS_KIWEON.ZIP (1)_25.jpg']\n",
      "glob.iglob 사용시 <generator object _iglob at 0x7f136fdbe5f0>\n"
     ]
    }
   ],
   "source": [
    "glob_prt=glob.glob( os.getenv(\"HOME\") + '/aiffel/rock_scissor_paper/scissor/*.jpg')\n",
    "iglob_prt=glob.iglob( os.getenv(\"HOME\") + '/aiffel/rock_scissor_paper')\n",
    "\n",
    "print(\"glob.glob 사용시\",glob_prt[:1]) # glob.blob는 리스트,\n",
    "print(\"glob.iglob 사용시\",iglob_prt)   # glob.iglob는 제너레이터를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7cb9b",
   "metadata": {},
   "source": [
    "#### PIL라이브러리의 Image 클래스\n",
    "- __img=Image.open(path)메서드__: 이미지 파일의 path를 open 메서드의 인자로 입력하면 해당 이미지를 변수 __old_img__ 에 이미지를 반환한다.\n",
    "- __new_img=img.resize((50,50), Image.ANTIALIAS)__ :변수 __old_img__ 에 있는 이미지의 사이즈를 50,50사이즈로 변경한다. 두번째 인자는 높은 해상도의 사진을 낮은 해상도로 변환할 때 깨지는 패턴의 형태를 최소화해주는 방법으로 안티엘리어싱이라고 한다. 다음 이미지는 엘리어싱 된 이미지와 ANTIALIAS이미지의 차이이다.\n",
    "![](https://helpx.adobe.com/content/dam/help/en/photoshop/ps-key-concepts/aliasing.png)\n",
    "\n",
    "- __new_img.save(img, \"JPEG\")__ : 이미지 경로img에 new_img 이미지를 JPEG 포멧으로 저장한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5ce5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PILOW 파일을 numpy 로 만든다.:\n",
      "[[255 255 255]\n",
      " [255 255 255]\n",
      " [255 255 255]\n",
      " ...\n",
      " [255 255 255]\n",
      " [255 255 255]\n",
      " [255 255 255]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADHCAYAAADifRM/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADYtUlEQVR4nOy9d7wlR3nn/X2qOpx08+QcNElhJKEEkhAiI3IwGHAAbINzWl6HxbsOu867ttf2rgP2kjEGA4vBiGSyBBICRZTD5HzziR2q6v2j+px77p2gkVAYyff3mTO3T4eq6j5PP/XUE8U5xyIWsYhFLOLpBfVkD2ARi1jEIhbx2GORuS9iEYtYxNMQi8x9EYtYxCKehlhk7otYxCIW8TTEInNfxCIWsYinIRaZ+yIWsYhFPA3xlGbuIvJ3IvJfH+tzH6adDSLiRCQ4yfE7ReTqH7SfRSzikUBEfkREvvgYt7lI609hPKWZu3PuZ5xz//2xPvcHHNM5zrmvPd79PFYQkd8uXuAX9O37nyJyv4jUReQeEfnxBddcICLfE5FW8feCx3hMoyJyTESu69v3TBH5kohMFsf+RURW9h0XEfkTEZkoPn8iIvJYjutMhnPuw865Fz3BfT6laB1ARK4WESsijb7PWxac80YRuVtEmiLyoIg8+6nY71OWuYuIfrLH8FSHiGwGXg8cWnCoCbwCGALeAvyliFxeXBMB/wp8CBgB3g/8a7H/scKfAHcv2DcCvBvYAKwH6sB7+46/A3g1cD6wsxj/Tz+GY3rccTIJeRGPOQ4652p9n/d3D4jIC/H09zZgALgKeOgp2a9z7oz5ADuArwHTwJ3AK/uOvQ/4W+BaPPN5QbHv9/vO+XU8ozoI/BTggLP6rv/9YvtqYD/wTuBocc3b+tp5GXALMAvsA36379iGot3gJPewG3hBsf27wL/gGWEduAPYCvznot99wIv6rn0bnqnVix/2pxe0far7i4H/CewFjgB/B5Qf5nl/Hnhp/5hPct6ngXcW2y8CDgDSd3wv8JITXDdaPOdXFN9rwAPAj5+ir8uBbxfP4rpTnPcMoN73/VvAO/q+/yRww5NN06dB87uB3wBuBxIgAJ5Z3M80cBtwdd/5by1oow7sAn6kb/91fXTS6PtkwPuKY0PA/y3o6ADw+4AujumChsaLPn7+6ULrfe1eDew/xfFvAT95mm39LfCJvu9/Any5/914PPo9bdp6som77+bC4sV/FxABzyt++G3F8fcBM8AV+BVHifkM+yXAYeAcoFIQ2amYew78t6LflwItYKTv+HlFPzsLAnp1cWzDIyT4DvBi/Ev7AfwL+VtFv28HdvVd+zJgMyDAc4oxPeM07+8v8Ex4FD/zfwb4o762p4Er+76/HvjXhWM+wf2U8S/ZS4rvvwp8bsE5/0bB/E9w/YuKcS8D/gH4+CloQAM3AxfRx6xOcu6v0Me8C9q4rO/7xfQx/zP1Uzz7W4G1xbNeDUwUNKmAFxbflwJVvMDRfSdWAucU2yd8XkW7B4Friu//D/j7oq1lwHcoGCvwM8A9xTWjwFefDrS+YMxXAyn+nd5VtFXto78U+E08L9oP/G9OMnEUY7uvePbPxk+Kax7vfk+btp5s4u67+WcXP6jq2/cRCqkZz5w/sOCa9zHHsN+z4Ac+i1Mz93Y/0eKli2eeZGz/C/iLYnvDIyT4L/UdewVekupKSgNFW8MnaetTwC8/3P3hX5AmsLnv+LPoe5kWtDsA3A9sWDjmE5z7fryEL8X3/wr884JzPkzf6uYEbfw1XpI7AIyd4rxfBf622H4rJ2Hu+Al3Enh23z4DbO/7vqV4PsdJUWfSp3j2P9H3/TeADy445wt49VgVz7hex4IX/0TPCz9ZfA/4jeL7cvzqoNx3zpuArxbbXwF+pu/Yi57qtH6CflYAZ+Mnzo3AN4C/L46tKvr5Ln7iXAJcD/zBKdq7rKDFPcCbnqh+T+dzJuncVwH7nHO2b98evCTTxb6Hu/40zwWYcM7lfd9beLUBInKZiHy1MNzN4CWaJQ93AyfBkb7tNjDunDN93+nr9xoRuaEwGk7jpbduv6e6v6V4KeJ7IjJdXPv5Yv+J8Lt4BrL7VAMXkf8BnAu8wRVUiH9hBxecOohfZZ0M7y7aeZ9zbuIkfa0Cfgkv6Z1qTGcBn8Mzgm/2HVo4rkGg0TfuMxn9v+V64PXd37H4La8EVjrnmsAP4+nxkIh8VkS2n6Ld/wvc65z7k762w+Labtt/j5fg4Xga2/MI7+NMpPV5cM4dds7d5ZyzzrldePXP6xaM8a+dc4ecc+PAnxdjO1l7N+LVSgJ87Inq93RwJjH3g8BaEekf0zq8tNfFqV7UQ8Cavu9rf4Cx/BN+2bfWOTeE1+k9rp4XIhIDn8DrEpc754bx9oVuv6e6v3E8gZzjnBsuPkPOudpJuns+8EsiclhEDhdtfUxEfqNvPL8HXIPXk872XXsnsHOBJ8rOYv+J7kvjmfsHgJ8rmPOJcClearmrGNNfApcWY9RFW+uBfwf+u3PugwuuvxNvTO3i/JON6QxEP13vw0+8w32fqnPujwGcc19wzr0Q/6zuwau6joOI/CZe5/2TC9pOgCV9bQ86584pjh9iPl2te0zu7vixPZG0/nBwFHzQOTeFV4m4BcdPdS8/j7cBHMQz7Cek39PBmcTcb8RLz78uImHhP/sK4J9P8/qPAW8TkR0iUsGrDx4tBoBJ51xHRC4F3vwDtHW6iPBEcgzIReQa/LK4i5PeX7Ha+QfgL0RkGYCIrBaRF5+kr+fjJekLis9BvGfJ/ymu/c/4e37BCSTtr+FVIL8kIrGI/EKx/ysn6etdeEL9CeB/AB84iafT5/Aqr+6Yfhtv1L7AOWdEZHXRx/92zv3dCa7/APCfivtehTeWv+8kYzqT8SHgFSLyYhHRIlIq3OjWiMhyEXmViFTxTLoB2IUNFLTzS8BrnHNdqRDn3CHgi8CficigiCgR2SwizylO+Rj+d10jIiN4HfDjgSeS1udBRJ4rIuvFYy3wx3jvry7eC/yiiCwrnsGv4m1KJ2prK94g/aPAj+F51wWPd7+nizOGuTvnUjwzvwY/O/8N3qvintO8/nPAX+GNQA8ANxSHkkcxnJ8D/puI1PFM5qTLrccKzrk6/oX8GDCFZ66f7jv+cPf3G939IjKLl3C3da8v/GqfXbQ1USwTDzvnDuOZ9ZRzrlGc/od4qe0BmfPJfVdxbYp3OfxxvP73J/DG5nThPYnIRcB/wv+OBu9N4DgB03DOJQvGNANkxTZ4j4lNwO/2janR18Tf4w1rdwDfBz5b7HtKwTm3D3gVflI8hpe2fw3/rir88zyI1/M+B/jZEzTzw3g1xd19z6o7If44nrnehaezj+NXAeCZ5hfwHjo3A598rO8PnlhaPwEuxHumNIu/dxRj6eK/AzfhDaV34wWMP1jYSOG2+iHgT5xztznn7sf/Zh8sViaPS7+PBF0j2dMOIrID/5LHC3TrTws83e9vEYvoYpHWHx3OGMn9sYCIvKZQFYzgpcTPPJ2I4el+f4tYRBeLtP6D43Fh7iLyEhG5V0QeKAw7TxR+Gu/S+CBe1XCiJetTGU/3+1vEIrpYpPUfEI+5WqYwlt2HD77Yj9cjvck5d9dj2tEiFrGIRSzipHg8JPdLgQeccw8VRrZ/xhuIFrGIpzyexFXpIhbxiPB4MPfVzA862M/8QKRFLOIpiWJV+n/wHl1nA28SkbOf3FEtYhEnxpOWhU5E3oHP5Ee1Wr1o+/ZTBdotYhGPHrt372Z8fPyxCELrrUoBRKS7Kj2pynHJkiVuw4YNj0HXi1jE8TgVbT8ezP0A8yPK1jA/yhQA59y78ZGLXHzxxe673/3u4zCURSwCLr744seqqROtSi9beFK/4LJu3ToWadvjVPa9H9Tydzx3m9vzdM7qfyrafjzUMjcBW0Rko/gc32+kL0BhEYt4usM5927n3MXOuYuXLj2tlCf/4dCf4MqeJPGVdQ7rWPA5+bkOep9FPA6Su3MuL0LSv4BPZfke59xTJcfHIhZxKpzWqvQ/Ks7UgMgTjkv6N5+eov3jonN3zl2LTwS0iB4WEtjxBOX6tqTvu+s/23WvFhyOeSf22nVzm6cYynyi7mvk6byO/cHQW5XimfobeWLyDj0l4br/FeTUT1VyGjR24jNOft2Jjsx7NZwDebqy8uOxWNbrTIM7bqPY6idKi3MKxHmCRYEDK57ApbjKOv9mqeOmCgB10uXrfxTif6RYXJWePpybT8oCODkxbT1e9NZT0cz9VzD4p6+03o9F5v6Eo0tUru9/wC2Uo6W3X1tw4kCBFYf03hIBcUhPIvHyvG9UUE5ArJ8EeuYVmZOm5nX49Cf2xwKLq9JHqX4p5AvrbE9Pbmx3m0IQAScyR/v0zRBdSb+vb6EoSCGgRCECSim0UsXKoE/aWThk17/Zf/DpY4hdZO6PM45/Efq/d7O1KjyJzTFmBAwOEfAJcr0cIs6BU3NLXTf3IggWi8OKb9P/uJ6ZO+n2bFBigMC3c8Ixz22LyAlf5tNZVi/iPwacm2OPqqALOU5Kd1gcnSQhzTKyLKfZbJJlGalxtHOLBXLR5MpTrrMGn+G39xIUwotFHMQYIixaK8pxRBgGlKKIwVqVMAhQWqG09lL6CejVMfd+CvKUZ+YLscjcnwR4gnJzwghevSJ4KQZROCcoZ0DwDNsKzkKn1abdmaGZGJLMkKcJBrDiJfUghziOCGJNqRRSrlQpl8poFFo8kTs0Tgni5mSkOUleTjDWRSzixHB9XiqwwD503MmWLM/pJClJkjAzM0unk9A2lnpqyB1kOiRVoW/T5NDP3EW8y4wzKBwVcsoYQq0YqFYoxRF5uUw5jvwkI6D1iUoH9I+/twVPMwa/yNyfIHgmabs2Ha+TLKRuJ11pxOIQMuuYmqlz9OAxdj90H7v37mXPsSn2zSRM5prpMKThNJkLyC2YICQRS4AQZ5oARygdqrQZsTmDGFYPlVm/Ygmr165m09atrFmxlNHBQSKtEWcL86wDF/TG2C+dO2d73xel9v+YOOkKrqtScY48z8BaEmNppobcOdppTivLsMaQt1qYpIM1OXnSwRpDJ3e0M0fmYNIaJm2OEUWmQoyEnu9aizhHmYwBlxCKw2lLEDhMLjhnabY10802x5odlA4I4xJxuYxWiloolLUi0IpyFBBqjWfmqnsj/h56Fq45xv9UpfdF5v44oP8d6CpehK7xU7yOxHpduCksoY1Gi3sffJDv3H0/N9/9AIf37+PY/n2oNGF4oEY8upSpoEx9YDnN1ZfSXHkW9dIw2mmMBmyGE4tTMdpmDE3sI9/1fczR7yOqyX37j3Ljbd+jg0YNjDI0OMiK0WEu23oWl+08mx2bVlIZGkQLCLao/6X7DGGFXkdJYZ/ql/qfmsS/iEcO6+aYX/9kL4Axhk6zQZ4mjLcydk23aWQ5+6eb7J1s4EzOYFqnkrcpBZoltRKlMKBthXoudKzw/aZwZ1ORqJBGbTlJaQjyDNoNMIa10marTFNVlnVVja5ocJZOkpDlhtnMcagDHQvlwWGqI6OUQs1ZAyFrqppqHLJ2dIjBcgkVBEgYI0ph6X9X5/BUpuxF5v64wC9Uezr0rrHUWpxochGcCJ1Wmzvvvo/PXn8D39w1zkFGyJeMMdCIWBEO8GNvfj3PfdZlrF2+jCAIaKYp9zywi3/54o189qb7SC97Hs3KSoxThFjERkDG0L3fYOPB23jzc87nBZe+nbGhIbRTTDc63Hzv/Xzq37/OrRPC/iU7ue5YSPhPX2d1Os5z1q3gxc+9kJ07tjMQV9CisEqwzhI4S6q8fB8VpiyD4OWfRTxdcTpqua4zirGWLMtIkpRGJ2Wi0WY2yTk41WDP+CzOZCzN6wyaNrVSSC0UAnHkVpEZRWaEegJHm9DRwnQgtFQImUU6guSOkjKsVBmiDGkcYi1YY2l3UpI0Zbpj2D+b0TSOSiZUXUQ5Chh0EVUXYIwhqVUwYYATQQd9XjT9mLdq7TPiPoUEmUXm/rjConA4p8mVQlyIJefQ+CG+/PUb+MQN93OHqZCt307rymvQJqF2/ed45eYl/PwbfoyxFaNowatsEGpSZfnoMJeffzaXf+Eb/PHnPsy+Z/8wjYENZKEmzjIGvv9NXuHu5bd+8y2sHluJixSIRuMYHhxg/cplvPRZl/KtG67jv33iK9yz+Wqmr/whpjqw7+DdfPjDX2Gb/hKvu+gcXvK8K1i+bIQIi1URgTFehRMEeBdLFjn7fwCcyJfEmBybZ+TGcqTeYaKV0Mws++sdZhLDZMewpw6dXNBZwEAppKxDtg0Ns6YaUAoChmtl4lCTWaHjFJmFykzK6tmUqVzxnXbOg51pquSsKKdUxLBjoMZlowMMBMLSkma0pLDWkaQpeZ4z1U4ZnW7RSHMO5hF7U8FljrrS3JtH1BrCxnad4ajBcClk9UBMOdAMVkoM1yooEUSp3p26Bff9VMIic3+M0D+7O7wXi7gAKw6rDVjDwfFJPv65b/Av37mLfUs3kOx8GZ3qKlIVUevMsur6j/JrLzyb111zDVGYocQrv23h1iUOlFPoOOb1L38eFef45eu/DJe8miwaIj54Jy9q3MMf/vpPUh1dQuocUWG4teIrHjjnoBxw+dVX8Y8b1/Obf/EhvmFKJJvOYXzz+cRrt3FL0uH2+27l3df9NW+6cB0//NIXsmLFOjQaJ56xe1hAPWUlm0WcHrpGU2HOG8ZmGZ1Wk3aacff+Ce46OstkBrc0Aw6lmqYRpjKFdZrzSwHPqMQsqYRcvG0dO9csRSmFKlwWvSsBWGs5e7bO9MwsB5o5s/c1ODhdZ1kJLhoQlsbChWvGeO6WVQzEIVoJume/8qvl2WabLROTNDoJX9zf5vrdTWZzR5IFpM0SFTLWuSkGXcLmmuaZS0JGY83mFUsYjgNUoEHCHonbpzBtLzL3xxBzblU5FjCiCayhPlPnE1/4Mv9w3d0cWLGd1pU/Rru0DCeKXBki00Tf9nF+7rL1/PDLXkSoNFa0J3yBQtnt+1AOJQqrA1700ufxQ3fu5cOHHiRYtoU1d13Hb/zCyxkdHsZKhtUZyoU48e5gyqme7txJztoNG/jDX/5J3vE//i/fHyvTWHouSVBDR3X0zstJG5fwlw/ezMf+8P381FXbee2Ln89obRjnAqwCMAQL0hM5555yL8EiYF7Q3Ek0MdY5bOGb3spy6p2UZpoz0TGMdwyTuWI8FcYzIbFCy0sTKK0ZKIUMlCIGyiWqlbKnEVF9fRa+76UQlUW0DAxoS4WUmiiGgpDhSBiKNQOliFocnpDOjHUMVkporajEOZGCQIRZJ8waReoUVSukDgZTx3jHYB2MdnLqSUZkLFGkCIK+WJL+p/QUYvaLzP0xQpc4PQTrDLnN+cb3buPPP/4Vvh+tY/aZb6ZdG8ZYhXapjx11itKhPbw8zPmR176EQId0dEbJRkVQEkWEKT1brOAIyNFhxE+99Er+7QNfpJ41eOGOUTZt3UweeLexwIVY6U4LXj/uN10R2KTZtHEV73r9FfzsZ75K84q1GD2AcwG5CI1aSHreFTRbF/D7t32df/vue/nNH3ohl15wNqIVShWePt1mz3BiX8Tpw/uA++2uwbTZSRifmqGTpNw33eGOiRb1zPFgR7M/W0LbaY6WyjRKAaWszcpkhpLLOX9pmavWjTBcClk+XPWuvsx1YIwlyzOccyilqFSrjDjNjlJKI5plWaXE+WNVxqoxy0qapN1G8owoigij0I+3eP/CQDMyNEgtN5zXtEw3mkwkcGMWcGcekIlmIlhOXRwtyZmsJ1Qalq2dNtsn9jMUac5ZMci64QpBEBDFZVQQ9ProPo+nAhaZ+w8Ah+0ZTJ2AFeMzAljF7GSLv/v4Z3jP9/fRPO+FTC/ZhhGFcgYbeEIMMkckHVbe9WXe/hMv8xINQkiMSL8f/FyP4gCnyJVF49i8Yx3PqmV8797reNXPvZFIBQgWcbrruTs3YCnMvOIQF+DEosVxxRVXcvWXb+bfxvczuWIrjhDnNEplJGLJBkdoXfQabjp6H29/7+d528X38bY3vJDBgUG0D7UCFLrrDLQovT/l0Z8+oBsCkaQpRyYmmWm2+d6xlM8f7DBjFBOlJUyHIzgd4EpVXBBSSqZYaqcZImf7aIlLNiylGgUQlIpYC8B6p4PcGNI0xTpHFGjKlQqDxrEpzknDOkvKwtbhkJGBMqVQkaUJNs8QJQShZ2HWWhygg4ChMMQ52NpsY+shxxLL3hnNXQ1NrgOmyxUIQo522tzfmCbIM3bPzLJXplla1lS1YWlkiaKYMIp7Aa4njmM9c7HI3H8gCJbCJ9yBNoKVnPseepDf/sdP8e1wI+3L30yzUsM6C+i5BDAEiCikfoRzhgJ2nL0VpQQrPmlJj7MXfsRdqaFZb3Do0GHGVq5guBYTRyGXnbWKg/fdzpYN60AC0lbCQw89xMDQIKtXr0apQnYXQYkqorodCosQUippfug5F/Fv198DKzf3/O9xGnGCMw5UxNSyTSTP+VH+/I6vcOf/+Bt+7yd+nNXrV6AQrFisKJTTc/ewiKcM5qti5r5Y62ilGbkxHGsk7G1aplpwJNPUdYm2KDId4bQG5SOtsY5QHNUABoBSIGilUUr39Ov9nLLTaTM+Pk6e54RBQBhoWp0E7Qwj1TLVKMBlKUlbkTSaTOU5WmuWLV2KjInX32vtjaFQpOJwhFpTjQNazlJSEDgDTgqXRwGlcDrAAG0XMUUZscL+lmXJdIda2bEqTKg6ejaCp5IXzSJz/wFhAe1AjCHF8o0b7+Z3Pvxp9mx9NlOrLiFTCit1UBqxjlw0gQUQcjEMHNvPM7etpxIHPid1L2udN1Z24Zxj//79/Jd3vYvbb72ds3aczR/+0e9x1qZ17Fy/kgdXLqNWrtCsN/jjP/gDrv3c5xgaHuZdv/UuXviiF/UYPMxlOFBF+0bgnB1nMXbt7TRNRqq81O+sj5AVpcglBxUxWw5JLngpX9l1G3v+8h/40594Ixdt344E1quApM///Skh3yyii/mqGP/rtbOUBw4e5cjULA82Hf9+xHA4ESb1IEdqNXLRoENKOsC6wosmyxhQKevKjqVaMVoKkSD2kj2Ctba3GhAchw4e5Fvf+hb1eh2tFFpr4jhm+arV7Ny0BpNltKammD2aceDAAR584AFEhGc+65lccOGFlOKYoeFhyqXSvHsZKEesHh0k7hhG65Zq3iQjIrUlDAFohVSriLWM2xJNM0QZw+zBGW48fJT1gyVessGwbrBEuVJmYGAArdS8dAtnIlPvYpG5PwIc7/NrCaxnyKkkfObfv8V//dTNjF/4Gppja+hoC8qCicFqRBkIQiS34CwuMMSzh9h+4WoUFuZ5oszv01nHhz/0Ya7/1rdAHHfc9D0+8v6P8Jv/9T8zsmQZq1etIgoCvvjvX+Yzn/kMaZrSaDT4m7/9Wy659FJGR0fnGi08DKTIUeOwjAwPsi407E876DjCiEKUwnnlE0hKZBwWTScocWzjFUwPlfjpv/8X/vJNr+SyZ+0kMNrfrxicmyOtM/kFWMTxnl4wp4oxxjA+U2f/+BQPtjS3zsQcSDW2VsIODiFaE4sjxKGsxWUZGEMshuEQRkOoBApRAYjuebV4DZ7vrT47y66HHmJyctJLyKIYGhpi1YoVrBwZol5vMDsxQaPR4MC+fdxx++0ArF6zmrO2bMFay8DAQI/OuvcQBZrBcolUciq6RexSsIJx1uesUQpREeBo5RGzUiEwCensNPs7TeqdnIvGSiwJLFprXO3kPv9noipykbk/CnR/SGcFIwZjUj7zxRv5nc/exrFnvYzpodVoo5Ei411kfC4X5wy50xgxqCL1qE3rjA7XCs8B1afOmJ+St9Vq8d2bbiKMIl7/w6/ju9+8gZu/813qs23KQyNIqYSzlhtvvBEVBPzs29/OZz79aXY99BB79+6dz9x7EJw4tAMdxAyWQmye4+LuscKjwYKyikw0TgTlMowyuCXb2HV+iZ/54Md5t8247JmXeNWMCBpXpCzoy0a5iDMOPeGh+C749C0zzRbNTofxVsrddct9zYD9eUwnqiJBiIrinorCOsgLgcE6hzUOoyyZMWRiMdaepG/fc57ndNod2q02Wmu0UiRxTJqmZHlOmmUknY7/JB3SJAGBNElIkg5hEGBP0Icfj8VYR2YcSW7JsBjXjcF281Iqae3fwCSuURfLESXcMZ0zmzZZl2nOLZepxCFKa7Q+nnWeaQx+kbmfNubyZ/ReCAFnhWu/ejO/9dnvMHHpy5gdWIPKQowyiHPoPMCIApehnCAqxGqfqlScxoUhs40WTnpKEkB5Juk79GpMY2i32wxUB3jT63+U2elZbv7ezSStBp3ZWZxJscYyPT1NbaDGK175Su644w4OHDpImqYnvqUiKVngoGOEVm5QQVDoRQXrfEZIcQohBHEo51cYJkwhL9NcupVDl7ycX/unz/G/hmqct3MryvVPTM7r8KXrJnrmEP8iPLol6rp+7MZaDk5Ms+vQUQ52HJ8/Itw6WyaLKrSqS5Ag8h404k2NBsiLxHbkFmcMGTltyWnZnMx4x4NuyoKup4xzDmctSZIwOzPLzPQ0QRAQFAy+2WrT7iS0Wm0a9Tr1ep3GbJ1Go4EINBoNGvU6SoQ8z3v3I333lRk/ybQzQyM1GFck4aNwPMD4+1YQKECHNPQS6maEjmmRHTjCsGlxxZqcZRXNkkpEuVJFV4I5w/CCfs8UPB41VJ92cIUUSvES5JKTO4dzHW666RZ+95M3Mn7py2gNrIG8TOD8ktMqh9UZJkhBCiZHG2xAlGUol0NtjL0Hj3mPGyzdSWSBcgYdaGrVKrPT0/z2b/1XvvWN6xkdGaZSi5mpjzN+7DBoxfIVK5k4OsH/9yu/yk3fvZFypcRArXbcHYEj974KOKeodxrsSwOyUHdfV1AG8PpR7UBhioAqhaDJtfE+z6Pnct95r+Y/v/cTHNq1C+PAGZ+y2FlfB9MsdDdYxJOGefVHmf+zOOe8ETXJmGi0GW8mHEngcBYwZUPyIIIwBq3phR91BZ4is6l2PjW1s7bnF9/fy3HSbSFhW+v77tVPtZY8NxhjsNZiTTcFcDFu59v3UvvxxNW9F99moQotkuQp102fPSesedIWch2RhhUaEnO449jbzDnWymklPsVBbszC4Z+RWJTcTwOekLy3eS45Otc4HA/t281vfeCzHD7/5dSHV6LzAC0JaZxhnSLISlixKDKsKgL2VYp2AS5I0dZio0HuvOc7mCxHRV1r/EL5ViiXK1xxxRXcetutfO+O76FRvO6H3kCtOsKB3eMc2HWQrN3iqquu4F8+9lHuuvsurHM86/LLWbd23XE3VNT+wAHGwn0P3ItxGdXMkoSKVIXY3KIxaAy5znFOQ5FiSRmNNg4nhlxCZlau5p7GM/jDf/xX/ujX3sbw0AiCwilBubmkTIs4c7AwtL6TeCm5mebcMdnhuklh0gZMBgOooSoSeKMpeQ55gmQJ4iwDLqNMTohlWBlKkWWFarFcUoYwRCYhTRKUMygd+BzrUniriDAyOsqOHTuYWTWDDgJ0GFAqlQhLJWYbDVJrGRgbozQ4SIYXN5QIW87aysqVKymXK8Rx6bj7S9OURr1Op52zwnW4sJySKkvTTJAlTToWZq2QO3BB5CcuUYjSBFpwYUS9PEInLPNg7rj+wCxLYsXZqzU7ymW0VjgpUhWcQeqYLhaZ++nAeRWMcgbtHI6AemOWP3zvp7h307OYXrEdaw0Oh+gMZwLizII0MSomzCN0lhC7JnpmL6V9B4imH2LUGLYMKmYn93HgwH7Wb1hH71VbYLwVEd74pjdx3333ccstt3DOeefyo2/5EawYHjrwIAOjgxw5coxLLr2Un/7pt/Pxj32CZctX8M53/hqVavUkNyZAgDjHzdddz+CxfeQ3vI/Z0ihmbDMMriQdHqNVrmAlJs4zFIYkUGTKq+O1C3GS48Qxu/EKrr1lkq2f+DS/8GNvJA5K5FqIulkmFxeKZwxOVGCj00k4OjHJdDvjlmNtvjgOHR3QHh1CV0Zw1mDyDJdn0OkgnTqBNQzSYCltalrYUFEMh8KAS1hqO5TFEecpadJBXEipJChd5GYv+l2yZAk7d+6k3W4jYYAKQ5xzZGnG9OwsQRQxvGwpOgyoDg6wZGwMJcKOHTtYs3ptEWwUHXePaZIyMzNLq5OxipxLK4a2Szlmclq5ZsJo8iyg7RRZPEAWD4DWBJFCa8ERM1tdgjOGe9NJoj2HGAsMcanE1mWD3kKmQ28o5sxTyywy95Ngng9r4RMOIC4gsx0+8pkv8JV0LdMbduJyS4SQabAuBiy51jgUocuotHZTuee7LJvdx7kry7zk/HPZed7LWbt8OWEl5rpv3MCX//3fecvb3lK4LC6IhBNQWrF0+TL+55//GdOT0wyMDFEulTh68BB5q82LXvISvnPLbazfvIV3vP1necMP/TBRpUytVi0Cn9x8H13prkiE3bt3kTY7fOIvfp9mJ+Hg0cN8/567uOnu7/G9O4Ujo+th3bl0BpbRDmvgBE2GFYuzMSIZYi2JjtE7r+YfrvsgV+z8PpdevBNtY5zybp2y4LnOu8czCCLyHuDlwFHn3LnFvlHgo8AGYDfwBufc1JM1xkeKU2V37B5Lc8NMJ2OqkzGbQ1NCEgn81CwgzhGaDKwhJCNWhkgMSzUsF0U1gKUlzXAkVGzIgI2IxREIZFnqRYkgRGvbp7OHMAqpDQwQhEWRDhzGGPIkwbbbuDhGohBlLSWtGRwcJNA+2CkIAnSg5zxlnOupcYwx4EAJDESapWg6VhCjaFlB59DG0baOljI0XebVSFaB9fYmKxqnFR0TMJ0L4oR6ZmmnGdY6gjhAB2em7/sicz8F5nLFOMTlGEIycdx91/384/UPMvXsN2NVCSEnVYI2Alb7IgIupza+j4F7ruOceIbXX34pz7vopSxdPkikIjIlKOewTnP55Zdz4w3f5o47vs+FF17IccydriAvxKUSy1YvI0dI2h2+8Kl/o2w0cSfhy//+WZ5zxWUsW72WoSVLUGLnjFgL6EyMoLE02y0+9olP8MJXvZIlSwZZKpYN65Zw5TPO5u2p4cixGa777q188puf4dt2EH32VSSja8lUke7XgriQLMpQeYKRYSbOeyF/+i9f5t1nrWfJ4FJsUd9SzkTx5sR4H/C/gQ/07ftN4MvOuT8Wkd8svv/GkzC2xwRdFuScxZkcZy17Z1p8eV+d8U7Offkw7aFBTOG+6Jp1KqbNWDJNyaZsqAhbh6AaCOsGaqyojhBpzWA5Ig402maEeYKyBmsyjhw5QqADxsZGGRgYRGtNFEYorRioDbBx4wayNGX20GFmDx8mazZJH3yI7MgRKJXIh4dxUczAujWs2raVqFJhbGyMMAx7pSCNMXQ6HWZnZ8myjHa7RakcE5VLDK+osTOuYBy0c19EZLqTc7Ce0s4tuxptHqjXaWWKvfkAxyhBEKJKFdABdVvlARmhZnO2Tuds3HuEgVLE2uVLGRmcS4EAFEFUTz4WmfsJsFDK8RkGAqxTmPoUf/Wxa9m347m0BkoEVnCmhNNtDBBIk1pzlvj73+TybDc/96oXcNnFFxNVQrQTnBacUwQOkATtHEGpzJve/Gb+8R//kVqtxpYtW+ap8Aq7j7fOO8Eay67bb+Zzf/3XNL79PZYawz7lGDOGf/jFX+ZFv/hLXPCcq4i6HjfCPMkGvOtalrT56Ef/iTVrV3HueRf4CD4RxGocAUQ5y9cs4XWrXsjLXvRsbrjxFv7+s5/lpmAFrfOupl4ewUqOkYgobWOU0A4D0iVncdOeu/js57/Kj73h9WgUYJ8qjB3n3DdEZMOC3a8Cri623w98jacoc58fjOpwJseanCONhFuONTnScRwYiEhrY55eOk1I24R5gyWdCQZch3NrJa4aLjMUB6xfVmHlyIDXp8clJPAutXmWYk3OgUOH2X/0KKKUzwcTRoRBiNYapRTlcplKpYLJM9TUNJ1mC6am0bv3oHbvhriEGR7GxSXKoyOsWbmSaGiQOIwIAq8SMcYb95MkYXp6mk6n0+svCAKWL1vCyOgI4izkCc7m1Fsdjk7WaaUZtxxuEczOMGUUk7nlsDVIXCIo15AwopWWqcsAJZuxu9Fm17FpRisxY8NDdJ2Me8U+FqySnywsMvfTgrfeizN89frv8IV8gM6qLQiO3GpCa9CZJTAB5cN7WH/b53nH83byhpe9loFaCZHABwz1OG233QiUD1DasGEDb3zjG3nf+97Ha17zGi688EKCYE5F09WRWuf49te/ydd/47e5rN1ixVmbqWqN3rWH2kyDXXc9xA2/8P8x8bu/yotf+wZcoMAdnwxgcmKcD33og4wMD/P6H/oh4kAhRRFiPz7ns0g633dcjrjy6iu45KKz+afPfJ6/uOFjyLnXMLVyA5oEk1dxzmB1jtiY2bOv5B+vfz8vevbzWLl6ELHar4+7Vel58petjxDLnXOHiu3DwPKTnSgi7wDeAbBu3bqTnfakoF+6BMitpdX2RatnUsMsEXWBxCmwBm0tNZcQ02ZZmLOlXGJYBawbiRkZKFOLNKU4QgcBorRPqQGIEpRWgCaKIiqVSiGcOJJOhzzIfS4YneKyDJMkmDSlc2wcmZ4h6HSojY0SBxrSDNVoIe0ZOHyU+q7dBEODlEZGiAYHAQpPGt92NwFZEIY95h6EQZEAzRtyRTRhEFIpxygdsHTQsCFxDGcw2VTkSUaqNTMmIU2LaO0gxDpF3SUcbltyZWllxh/rPdM5+n6y/SQXmftpwDqFcpbxxgzv+fJN5FtfR65yJC2hbUga5YTkhA9+j0v2fZc//KXXsf3sbQSKIgHY3I8+n59JQYg+JPu8885jZGSED3/4w3zzm9/k6uc+l40bNlApV7DW0uq0uefOu/nKf/89Xjk9ydo3/Cgjv/iT2JKj85mvUv/jP2dTo84SZXnfn/457VS49OqrWDIyQhRFZFnG5OQkN9xwA7fccgvPfe5zufrqq3tL2/kjE5+eQEB0kWzMKsLqKD/5hjdwzpY7+cP3foI78hczveJcjAi5cogkKBuTV0Z5YOVOPvOlr/C2H/8hnHbE1rfV7eGpCuecE5GTKrGdc+8G3g1w8cUXnzGecg4vXfazoHaS8eDRKWaaLe6ZUTwkI0wEQmIDXKdD2aVst+Osos7m4Qov2LiM5dWIgThkuByjlaIUdfOgC06U96hBoYIQUQFDwyPoICTPc9qtFuPjxxCl0GGEEkVrfJz6nr3YdpvykSOUjhylXCmz/KJnUFm/jvye++h87JPke/Yx225z/7Gj2MEBahecT/Wcsz3TNgYpAplEKcIwZGBggOHhYbTWhEUyMRBE+6jUuBIxFpUx1lEbGWXbWp/2d9O+ce4/NstBk/CNtuNgHuLCGKoDWIFdSQdpGla1Mzav6rCh0/K5bYqSfWcKZS8y99OAj9UwfOOGG/iuXkd9dA3OJaA0TppUMhi871aek93Gn/zaj7ByzQrEOZ+yV4pHLF0JvL/dOVVJd3v16tX86q/+Kvfeey/Xf+s6/u0znybQoY/6M4bdN93ES/cfYE0ppPL65yJLlmB1TvW5V9P60CdI77uFUdfiOTMVPvh/P8B9u3fjsL3cMkEQcP755/POd77zJFGrC+9dcA60VYhNceIwoeKZF5/N/6rF/PLff4JbVInZlVsIjSUPYkQMuVI0N17OB2/4W17xkuewdOUKnLaFk+eZQv6PCEdEZKVz7pCIrASOPtkDerToN33kxjLT6jBebzPZKTEjZWaVBqcgzwnJGKPNappsjCPOXVJh1VAVdADB8R4qc1mvBUEj2hHHMQBZltFqNWm32/64zhAR6hMTTO7dh202GZuepjw9TSCjDC5fxvC555A1WtSznGxyilklTDlDPjBAtmwZ+do1iNboPEdZSxCGlCuVXn6aSrHdzXLpmDPk6kCjA68vr1b8UqzZSajPTKPqGUHiKGVtXJqDDpAwwilhpq3Z33aI8kXAbZ4BoML5lO36RPcnQwu/yNxPA+Kg0ZnhI1+5lfqm15OFhsAGxFlOEmpqu77L82Zu5n++820ML13qg36U9413fW2c7Pftl5qVUsRxzM6dO9m58zzy3JAkqY/xdpa//tlf4hxzgLhlUAcmUGdDbBVJaxLXqhM5TWhStjrNplDz0+94G5XBYayxRGFIHMfH6d9Pph6Z89YRctEoycHmBLaEE8VZ27fwZ29/NW/5+0+zq1yhObga7UoErkWGIinX2Du4lS9/+0be/KpXerWU4pR9nsH4NPAW4I+Lv//65A7n0UPAF2jH0c4MB1qGgw3DsUyR65LP7ULKoLRZog1n1yK2loZYPhCTdDpMikUFAbqIVA2CAF34rnvVTFft5nvT2qtmlFLe06Uo0+hzFwlqZoYkDDFaUekklCeniYzFPfAQaVzC7NqNbrdBoOQcVWPJrWWwVGJoZASlNaG1KOd8X3Hce4/m6MynAsE5MmuKACfb09UbazHGkmQZZbGsqMUkgbC1kxOLZVrHHDU5udW0CZnRVWoijLdzjs42KcUlhsMSkdLd7voe9pODReZ+AnSt71044NY77+F7+SjZ0FKwDoNFVERlfB87dn+V3/9PP8mS0SV0OnV0PIjF+SRaqDlp9QQL9PkeMcfnpgjDkCAIsc7Sas4yO3WUUdOmHdaZ+du/YaRjCQZCpj/2CeJ9+wiMKzL1QXmmTqfTZHTZCp+QaWFoVF9fx91z31jEQWjAqhgrEcqBy1NmGpOsXLGUP3j1FfzKZ77EoSteR+4g0zEll2CsZnbLxXzqxk/x2ue/gMpQueeReabl4eiHiHwEbzxdIiL7gd/BM/WPichPAnuANzx5I3z06KYMwORgDfUk5e6ZjPsnM/ZoRRpU0ShW2yZn2QlWxornrqqxc3SE1BhajTr1WUcYBsRRhNaaSrlMHMeFtFxCB/NtPEEQEAQBzjlKpVIvD0zXjlSu18nKJfJ2i6Fmk8EDh1ATk7jKTbQPHEYOHiSo1wkEqtYynOVYY1lSqzG6ahVBGBAjBMX99STzwmDb7YvCoyZJEowxZFlGp9Px+9KMTpYhzlFTjuGxCgMtw0zaZpM23EPEdJ6ROkedmHY4glKWPfWUXarNyGCNSrVG1HPnLJ43Tx5/f1jm/kh8fsU/1b8EXgq0gLc6525+fIb+2MPhjmPAzoG1Of/29dupr9uGVQE4i5YAzTSrbvk0v/MjL2PF+vXMzNZ573veT5Z12LzpLLZuP4v169cxUBtEq8AHORVMdCEzPTEKCbuYF0QrSrUK1gbU0irx7buov+u3iXPrk5GZDpn2UaNx7rBRTBiVfK3KhyGxhYx9/l9LvT3NxPgM9993P3v27ObggQPEusSlz7yUK69+Fm++/UH+7oHvMLHtORixKONAaZKBEW5Oatz74H1c8Izzva+7Xxz759C9zzOIzzvn3nSSQ89/QgfyA+K4mILegYKxWkNmLI3MMZNBG3CBZ45lDEOkDKuAkUgzUolodFIabUua+1TQShTWWrIwRAfdohkGa08sRIgIYRjOG59zrvCgCSAI0NYhiY98dVPTmLiEmppBFYxXiRAohVW6WIlG6CAk4nhm1pXO/bhsT1I3xpDnOXmek2VZj9FnaYoSoRwHVEJNLXSMBI5UWwasITB5L9o6VQEJhlZuaSQZpczMq7d6JuB0JPf3cfo+v9cAW4rPZcDfFn+fWnBgiqpKoJmYmOBbu8fpXHENuXYIBm1g7I7v8yPbl/Gsiy8iEMPA0AA/+7M/zdTEBPfefx/XffN6PvHxTxLHMVu2bGH79u2sX7+earXaKw4MzGP4JxuQdY5Ix6zauoN7b76Xi5KANGhTSjIcmqoVrAoRZ7A4DmtBztpAbWTZSZp03Vs9bqJJkoTZ2Vn27NnDAw88wK5du0izlFrVu2k+85nPYs2aNdRqA0RKkemUt77hxXz+f3yA+voddCobyFQCYoAys2vO5Ss33cqF5+/EKQXSx9QX8YTDOke73SFNOky0Ug7kEfscNFKDSo8SimN5PMPWKGEsdJS1kEmAhEK1CrGxhX+uz/fSajZpt1qISE9aFpHe367kLiJExUSgRLyHjQjhQI3KuvWkg4Oku/cy4Ry63WZg1x7Kh4+Qt1q0Z2YxaUqzWsFuXA+jI6jhYS+tW0OaZqS5wVhDmmU46zDW9NQu3Rw3C7e7dB9FIWEUoUQoRQGBVlRch5WlJiVrmWrWWdXMqBhNQ8U0VEwqlsNtw/3OkESGjcYy+GS7yPThYZn7I/T5fRXwAeef2A0iMtw1Qj1mI37c4fUG2imMWMQZ7rj9Hg6U15LWKlgD2kaEnaOMTdzC63/irQQ6KDLqKcrlEpU1q1i1ZjXPfe5zSZKE8fFx7r33Xq677jo+/vGPU6lU2LJlC+eccw5r166lVPLStbV2HsPvhxJBgoCLX/FSPnvtZ9gy1WbAZogNyZUisgkoRyIh2ArfrOU843UvJYijXjmzbvrdOUbuJ40kSTh8+DAPPfQQ99xzD+Pj4yilWLt2LZs3b+aqq65idHSUUl8xBJ/dz6dTFVti9bIR3nLhOv7oru9Q37mUduCw4tAuIl+5hm9873p+upVQq1WKGaVrhFhk8I83uoa9bk1eZy3NdodGo8F403Igj9jrAlSWoJMjlMSwIkjYGiUMhlAOhEyFEAbUdNDzJ+90OlhrabfbvcyjXWaqte4x9DiOKZVKaK2pVio9FY4qJoJgYIDyhvXomREat9zOlLOE7TbRsQlKnYRMhFklpEqRViuYTRtQS8ZQI8OE+LiPdrtNlqSkWUar3SLPDVmekWVZj6F336/uBBQEQe/di6OIMIpRStA6QGtF1Qmryooha5lsNVjdHKeUCYfipTTipSRYDrYs5cygy4bE+LxLPbp+kkn70ercT+bzuxrY13fe/mLfccz9jPUFliJS3wpGg8ozvnbr95ledxGS1whNRjUZp3zzv7Fu6k6+8JlPcvvSZVx88SWsXr8OUd0ABukR9urVq1m9ejVXX301Weaj9e69916++MUvcuTIEcbGxti6dSvnnHMOK1euJAzDOcneMRe27xznXnARd/zk2/nk3/wtL+vEVJ2lnCc04oxyFjEVVrmBnPiVL+byq1+ARnxQBRQZ9aDZbHLw4EHuvuce7n/gfqamphgeHuass87iec97HqtXr6ZWq/Wkry6OVycJxmTc8b3b+Or1X2ff/qOcO23YM7OH8cGV2M3PZHZoFWl5GfeZCvv372Pbti2+1N+T4j/wHxeumEul2E6N99Hu5BZrDWIsFbEMxjCghJFYU41DSlEI+DqnSnxeGIF5Ko5+HboqKhV1y9J1deBdBpvleU+aV1r39O5hHEOlTDA8jFq+DGk0ydQUHdUg05q8FGOCABkbJSqkdgm9e6XPHpmT5XkxudCjXV300R1Xt+/+FYXWmiAMCbu+8L33VxEGmjgKGIxhZdVSysBoIdWGsvLpjZsY2nmRt94VFdQWCGf9E+wThR/YoPpwPr+nuO4M9AXuGj2tdwVzlmarzQ2HpkkuXk8pT6nuvp5N+2/hrZdu5cJz/xPVKGLf3kO87/0fYOv2Lbz2ta8mjksnVLl0Lfjr1q1j3bp1PP/5zydJEg4dOsSdd97Jxz72MRqNBuvWreO8885j27ZtDA0M+uAf3xhBoHnD297KZ6IS//SeD3DW+DgbVQXEcTjKuWtIWPbDb+D17/g5SuUBn9TX5Bw5cpQ77ridu+68i9nZWYaHhznn3HN4zWtew4oVK3oSzEID77yns2BVkXVy3v/hf2J26ggve8UrWLF2A2WrmKrP8uVbbub/fP5feXDTc2iu3smxpeu57e572LZtM3MJxJ586ebpjm5aoX5nrcw5jrRzDswmHJnNUc0WA23DeSMBz15RYiQSNlcD1lVVUXPXUa/PUC6VGBoaJgpDjDHUarV5uVyAeaqPLuPtTgLGGOqzdZyzaB1QLpd7zHVwZAQGBwiefTnBklHy2TrT993PscOHUeUy4bKlqHKJytatDFz0DHS1ggtDpiYnsdaRJh3yPEcp75kjSuatHvonmv5P18tHFTnk/arEFwlRSlEbHKJUqXLBsLB+jdC2jjunMu6ebpLkhnqjwd4kZUklIkkzbJ4jKkB0Ubf4SfnVPR4tcz+Zz+8BYG3feWuKfU8dOIeTogQXjgP7j7LHRTgVUb3vel7cvoXf/423smL5KpTyM/HW7edyxbOv5CMf+SBf+9o3eNGLXlwkvZuvS1+oatFaUy6X2bRpE5s2beJlL3sZs7OzPPTQQ9x6661ce+21DNUGeM7VV7PzogsLKcQSVENe+9a3cvAFV/P9b36dr3z5m8wkbS56wbN587OuZPW2HSgd+ZzaxvD/PvUp7r33Xs477zxe9epXs3LlCsrlis8GqI4nv4cbt39MjkOHDqJ0wE///K9QCxVOO7ABy0tjvPlFz+fSbdv5lb96D9+JKuQjm7ntwa/xQ86g0d5K3OdAtMjjHz8slJyMdcwkhsOtnOl2gkpalNOMDVGN5yyrsaQcUi2VqJRKniE3m3TabQKtCYOg57d+KvR7orTbbVqt1jwVjtaaPM8JgoCBgQEqI8NopbDbt2OXLaMzO8tkrcLUQ4PEg4MMrV9HNFAjWr+e0e3bUFHE9Pg4M9PT2MJAaq0liiJK5RJBEBCXYsrlslfBaD+JPBystWSZz7UjSiiXqzhnWRKFnFeOMc4xvPcY5bTOVCfne1nCeDNluu0nBF93WJ0R+U8fLXM/mc/vp4FfEJF/xhtSZ55a+vbiReiTdPbt2U9zcDml+hHOn/4Ov/+rv8TKFSNYbRFbOG6LUKqUePOb30S7lZ3Sb/xk0nB36Tg8PMyFF17IhRdeSJIk7Nuzl8OHD3s/dy34OpQarXLWrF/Pso1vJd64hfrENNe88uUoHFqp3iRlA3jJNdfwqle/mrCQYqCXAGAeEz+ZF8/JvHrWrFvNj//IGwgkmnP/0pA5g84VmzZs4L/82Kv48Q99ic6O1/L9YzMkaUpQjnpeM4VF95H+TIv4AeCco5PlNDoJ1hiWloRIApbXIgarFaqlkFIUeQOjscR5Xqwag55E/nDo6t6Bnp+7MQZnHUordCFha63nXCdFCMKQUqUC1lJasoRSu0NpoEZ16VLiWpVSreZ19Xg34VJRXjIvVDJhOJezBkdvVeGsmzfuk9G0Z+4ZxuTdISGifJ9ag4OhSonVIzVKrZSByTahzVA2J81zOpkhQBPpObLu8pTC7f8Jw+m4Qj4Sn99r8W6QD+BdId/2OIz5cYTDiPhkYPhotrsefJDO6HaiB6/jF190OauWL0F1qyYVqQU04JxQLg9QLj86XnWiCaFUKrFl21a2bNs6P9BJgML1LHKOoPCpD4rxeJVhESHoHLVq9fj2e0x+fkDTvKfxMOlLtQ5QRdCG6xKvg9hpssCgjHDRedt47sjX+Hh7ikNZxNR0g3J5AF/irNt+sCi5P4Ew1jHZaHNgYhatFReMBASB4ryVg6xZvoxaXJTRUwprLDoMybMMpZSva5plJ237RHEbcRwTRRHOObKKdz1UPd23Iir6AyhVK0SlmGRwgASHXr2KSqXCsmVLKZXKhFFEFPgSd7VqlTgMsYVqyJ2gjmrSSXBFRbCF3jLdMfaP3TmHLSYE1Rd8FQQhEsaESrFpuWL5cI3DM012HZ3m0JEWYVam2UqYbCbUyoowLASlx+pHexQ4HW+Z0/b5Lbxkfv4HHdSTBkfBKH1puCy13DORECwJODc9wjMveY1PjCUan/HLe6F0iXhhUFD/34X7T9h9X8ToiaTohZGl3X39fS3U9Z/oOhHp6Ui7hqZTMffu+f3tZNncCqXbVhT5l9QJhGgfxKUrvOTiC/nct/cwRcCx8WOsXrFizmg1L0h7EY8P5tOcdY4ky2kmGbVYMxaH1GJfH7RaKlGOo56u3ipvcFUyl1b3ZFLvQvrrGuO7xtXutjHGC0XF/n51SRB4f3e0pjQyQikMKJXLVEZGKcVxf5CzN8r2javLtHtRp8bM2+4enyvNd4pYAObeG6WUzxmjNKIUtXJMreRXMbVACJ1B2ZzMGJLcEFt7RtD0YoRqH6RPlhRxmCRhfytBsgbPWjlArTaMFMbW/vzoSZJw4MCBE1ZgfzToJzitNatXr6ZcLh83iTx8ENRce92AjU6nQ7PZpNls0mq1fOX5Toc0TWk2mxhjmJ2dBbxXTZIkAPOKbHcng/5xbNy4kde+9rVzId8OjMpQJmTHxhUMful26tVlHB6fQPWUXove7k8EipjUOTiHMT4lr4pKDJZjRiox1UKCdnSDfvx5nXabJEmO8w0/rp8FQsY85lhsd5mtKtLxakD1t+cKbzNrcXmOTVOcDjBZhi0qOHn1iMMUHjK2iDpdqC5aGMR0qvEfJ3R1x9H92vfpetKgNGEYUAoDtFJ0MkMzySjFhnldPEmGpUXm3oc5729vTM07bSY6LYLWFFu2bQAVoqx35dLicD4eh2azyXXXXddjhHBqCf2UY1gQzGSM4XnPex5bt249aZsPlyOmXq/znve8h8nJyV4ypWq1SrlcJgxDyuUyURQxOjqKUorNmzfPS7wEhZTU594W9OvvRYiiqCe5A1gBg6CcMDw2RJzPMF3bzoHxCYwzKNFzrL3flWMRjylOpOd1OEyWkSYdVCVkrFpm+XCNoUrJS8LWqyZyY8jSjEazSavZPL3+TrJ6XSiQ9NPPcYZO54truzTFtTtYUZjE+7uHQeAD4Zwjz7IeU280GiRJ0lsJdFcKj+Q9lAXMHPofnSsiULvvp0aUJg4DqqWQUCtaac50O6VS6lvdPIki/CJzXwDPZ3xRjHqzRSuIUa02y0ZXoLE46SbDNbhigTg2NsZb3vIW4MRG0x9oPKeMXD01utdVq1V+6qd+qhdIsvCcU6lwFrZ1euPx6QVCNAiEUUQlCDDhIEemD3p+3otS7fXwqO7xPzIeCZ3NrZMA51UztvAx11oRFq6A3XOc6/0HPyg9uznV24l03f1jnH+Z77snbff9LW7juLQC3VXBiQICTzTxzOt/gb2gp46RvqfXL4gU744SX+jbOoexc8+119YJ7u2JwCJzXwDpenA4mGo06IQVbJIzXK4QSAcjsY9Bc56B+aCn+Yxxof79ZDidl3OhW+Kjgda655N8Kk+e0+n31OPwZGxxiC1eCDG4zJJmhiyq0GxnOLp6077ImkU8Jlj4my3we8LL7ZbMQdsIqRVA+QAl8b+FiGf4IkHPg6t60iLrx8Or5eYYsCsYcE/3bQw6CIjC0AcSqcJ1sN+WhKcREen97X2KdlWht3dKEWiN0RqtNKEOUEp6Hi5df/buqrPr237CcTP3XnZXAV0/+IXXOAepE1pW6BghtZA7hznBa/1kMPhF5n4cBCsWhZAlHdKghFMxM602GZrAKUQMuQiBBVGnx8jh5Mx8of76sUS/pPRwE8XCY6e6r/nHFsgpheeMEYdy0Ki3aesSthTQGTfY3BFEFMZUtaiWeQzQTzcnVtPNaY2dc2QWEitkTvw6S4ogH/r15AqtvaH8UY+psPfkRRqALE3J89y7RxYBTFqd2Ctcigmn+1cVjB3xUdfSz9yVwhTMOAg0ShRBGPg8NkXxjqAoStMNnHqk99Iro0eXXB2pFdpWkTghc5BbODPMqYvMfR4EPxv7LIyOpNkhlzLJ8FLu2X+Aq1yMVrZw4wt4JJEKJ1uOdiURv+QE57why1pLu+MDPkZGRk4qbZwOkiTh05/+NJOTkwwMDDA2NsayZcsYHBxicHCQwcGBeZF83XHOS5e6YMzzMf+7QkAcSiyWgPv3HqZRXYYTgxGLU91XYxGPBiczCJ6WYFCoDIwoctFe8swtzTSnmpu+zKVde6KbR7uu6wnSZ5jsfp/XTd/2PK+VgkkKeN25Oj5Uv/vdiWD7/lq8tO6654j4YEOtEa1RQYAoBeLb7a6wnbWIMb0kedbauXb6u13Qf7+U7/r2G2PAWbLckBhH2wpJb5Kc11Lf03jipZf/sMz9hC6G9OnyxCHOYYhIlq7le/ffgbSbUIlxBL3Azh9E0u5mX5yanOTggYMcOnSIycnJXoHfuFxi2bJlvOlNb2JgYOCEY194TydaAYRhyBVXXMHs7Cz12VmOHjnKrbfexuzsLK1Wi1arRRiGjIyMMDw8xKpVq1i1ahWjo6PUarVelN/Jnt9x/RdCohGHMinfvuVWppefh1Mhln5XusX8Mo8Up6K3E6oa5m15FulwdFREPagwYQMemm7TyAxGBawac0TM8Vsf2p/0goSyJPGBTEVU6HGuhX1jkV4Bj/lM3AFh1+slDL0HzILUF0YpcqXItPa5ZYq/dFU4Irgw9H0Yg3YQRGmvfYOvD+uy1E9ELYMrsln2/Nz7Jqh53j3auzyGQUClWi1qKgR+BSNCp9Oh3WoxMdvhYMexNwupmgArQqgFfUKh74ln8P8hmfuJIjB7hCVdXxkAixIwQ0u5YUq46967OP+CC7AIytmezr2/zX4JqivptDsdWq0Whw4d4uDBgxw4cIBDhw5hjCGKIgYHBlm7bi2bztrMJWOXMjY62isV1u8j/LBjP8l+pZRn2CtXzUlYRd1WY3KMsbRaLaamJhkfn+Do0aN84xvfYHJyspdVb2RkhFWrVrFs2TJWrVrF2NgYpVKJuKh64yU8/F8EwYB17D94hC89dJj0yleiG83CDdIWkmExlkUO/4ShG1eQKU2iI5pOM97KcNayfCgr6p/OR9eNNktTOu22d0HMctI09W62xof+918qSvUkaR2G6MKTSgrGCWCVwgXBnFTed71fXQhWKYwIRimsUlgRbHe1W0jsojWqCIzyzNvgnM9YanKfSiBPUmyW+YkpTedcI7t1V/t0+roYdxzHveRmUMRx4FMrtNttWu2EmdQyZQPqVuOksF3MI+gnb336H5K5nxQC1lmU0xggqkRgUyya8bOv5E8/+XX+euNmRoZHsTiUm/OY6YYtNxoNjhw+wqGDB9mzZw9Hjx6lkyQEQcDq1atZuWolF198McuXL5+TirUqmF2/1wrz6KJr/V8Y4NQfcdd/DpxAypt3nUEEgkAThJpSaYiRkSE2btw0585oLWma0m63mZyc5NChQxw9epQ77riDiYkJBAjDgOXLl3PllVdw1pYtxZgVKRmukfHXH/08D6y5FBNVCOwMgRLEzfHzJ8kF+CmHk0ns/SqPbn6Veef3DKVeqowCfywMAkpxhFHCoQRmjGV0ts34xARZKSSKYsIo6pWeSwvG2GXIqpBscY7AFYySPm+WnrcNSJ5DlvtpxVqctWRK0xqfJNUKZR3aFvUTnAXrg+SSiXHyep20VKJ56DBZFPn8NjpAxEv3tvBSyUyRlVEJKMGJ4JQv2I2ALpi2w3tv9dboc0uN3jPtuWgGGls8V5wDa7AO9k822DfV4FDTMGU0eVjGBTFaCaGAFnecpunJwNOauZ9qCXuisGMveAo4i4giLlewzBAaR7J8I984eoQ//YcP8pvveAuDQ1Wc1T6a1To+98Uv8J0bbyAUzdLlS1m5YhUXP+NiVqxYTm1wgKhSQhVqQnGe+LpqCe894nz+GCn07sZhckOr1aRer9NpNmg16rRn6rQnZsg6bdozM2hn2LN7F+PHjjH7vVuwQG1oCB2GIJqBkUHCSpna2CjVkVGiao3ywAAjgwMEYQDKO3Ziu4Yi65e84vWb5VJEqRQyPDrCprPO8pMQYJyl02rRnJ3lyJFjlOKKvxcRciBrZbz3Y5/mU3tSkisvxhIQpR0qlQpKh8U7VayR3KLHzKNFmqa0Wi2MMbRarV6wUXfCV0U6W6UUQ7UyQ7Uib0scMThYo51Zbp3xhS6cmWKjnWZJSTE8uoShkVGsczSThDTLevptAm+ojLqeJEqhVPEOGS8p2yQlb7WwucE0mphGA5fnmEYD225DltNqtiDNcVmK63TAWiTPkTzH5oZWs07S6XjVTBz7iFYdFLQtXqUTaC/Bl0oQhEgcIbUKEgSoWg09OIgKQ6LhIYKBGioICCoVVGFcRbycbQtbgLMWk6aYPPPlNE2O6eQ4k2OzlDS33HiowQ2HmkwZxa6kRqdSw5QUodKUxBFyPDkvukI+Duhn4sYYxsfHufvuu9m3bx/NZpMwDBkaGmLr1q1s2ryJSqWGVxs4RgZHqGZtWsaRaE2y+Rl89l8/RX7sj3jLj7+RHdvP95KowFXPuoKrrnw2UaVCIAqnvAuX6gkynmn6QteemVnxB1utJrPj4xzavZuDDz7IxJ49TO89QOfQIVSzTdhKCFsdgtwQi1AT/8PFCjSWs7Bsd47gppt9wIcDK4JxMIOjDbQddJTCxDGqVKI9Mki8egWjZ21k+ZYtrN2+jaVr1jA4NIwSjXKCWE/wVllUsXDWrki7oIVqrUqlVmP5itU4cb7Un4VD+/fzvve/h/cdCZi56k00qgFkhrDdYnT5IL5oiOsFi51pfF1E1uIrjy3Hz73vds79pZykvOTjNY6Hs+d0XQu7peKSJKHdbs9j7joICIxBaU0lDrFF8i6tFVEY0MwN03lGI3FMtnLqjZRSrihValSy3EvFWebzsCs1p15Rqqe+0EqhtfLGVhGcNZgsx1nnDZlpimm1IUtxs7O4RgObpJipGWySYpME22rhjEXlGZLlOGPI201clmJESLXvS2mNCkI/0UQhhCGiA3StisQxUopRnUEkChFjfSqDKELVqmjnBZYo8GoiRBUqIu++aws1TeocOIvFYjKfWdVkGXmnTSczTDQ67KsnzNqAhlbYIMJp0MrXcV2YaPXJou+nPXMHz9Tvv/9+rr32Wur1Ojt27GDHjh0MDg6SpikTExNcf/31fPSjH+WcnedzzYtfwNDQCLVqjZUdyxFnMUGIiQJq687iNa+9mi986Ut8/nNf4dnPfBbbzjub6kCVWPlln7aFy5mIN8yqIom/VXQ6Kc3mLAd2P8ie27/Pru/eQnPXQ3DoGMsSw5ixrFNwtlIM5zkVC6XcETiw4o1hQV9gicPhxOu5nZOeZd8VS3FtvTui11taTGbImy1mZ2Zp7TpA82vfZUopvhxCc8kgevt2tl70DNZu38GqDRupDg8TlUtIqMmUo2Ssz05ZrDmsNVgDM8069z90H7df/x0mjkyShBnJsstIghXotIlzFhrjrD1vzPst010Ry5noCZkD73TO3SwiA8D3RORLwFs5cXnJJxT9qSI6nU6PoSulqC5IEtcNVgJI2i0m0zYzicU1W5SylMgKVofkUYiNcnSk0KGQG79qzNOU2UNH6MzOEmpFJQh9al6lyLTyKrY8Q3LjpfZmC7IM1+7gZmZxWQbNJqrZhNyg2y1IEsgNrtX2f00OaeZXzMaC9fYak2c4YxD8ZCJ4Xb5ojde1KCiMrMSR3x8GuFLJS/OVMlSquDAkGR4irVWRKKI5NOAngjBE4pK/vrAFWKBlDKm1qDhCDw+j4gjyDIr8NC0JmAyqNK32tVzFEWuhEiiqkRDpOa37Yx3U+EjwtGTu/fkjOp0On/zkJ3nggQd4zWtew7Zt2+aFyXfPu+qqq5iZnuZLX/4yf/Znf8Eb3/x6Nq/bxLpSwC15E+eGsEHAFBVWLVvOL//iL7Nv1z6+/e3r+MLXvkgyOc2O1atZumYpI2PLCcMKDkfe6dCamGD68BFm9uymfnA/zYOHqNWbrO44Lrcho5JSsY6StSiXI5jCPdLrCz2zdn3+Dl3PA/HnOLxU0iOi7l+LE4VFoXAo4wjF62SHshQQDAqDxpiAzoEZjh36Lge+dgPXR46pckAwNsbA0mVEo8sJV44xVhvCIAQISZqzf3KKeqBItWPlsqVc9qzL2L79XP75Mx+ldbiGsaAkwAgEjUNsXHVFoYzqz8NzZrF259NUHyq26yJyN76i2KuAq4vT3s9cecknFEmSMDEx0Qu9z4qMjUNDQ9RqtXnBN2ma0my1vdqmOctsq85M6qDhqGbQsCE2qJHqEBdn6FijI8iMpd6ok9UbTN53H60DhygX0npU6LmNs2Astl6HVguXpDA5Be0OqtVGz8wgWU6YpoRpgnIObSzaWcRBkX5v3uqt59cAKOaqkRW2+p5HW/G1Z8S3xXticRjxi2MjmlxprFIklTJZKcZGEfnwILYUI+UyMjiIFJK8jiOMKOqBpqU04dgotXPPJhwbJbA5oc0wFhoq4lgQ0nGCQRNhKWlFLVIMRIpSMN/zx9/XoivkY4Iuc0+ShA9+8IMEQcA73/nOXpTdyfJfDA8P80OvfQ0XnP8M/vF9f89rXv0aNi2rEDSOwcAQuXM0ggGa9QaBDtmwZRObNq8na6f8z9/5HY695xPUsg5HaWGdt9yHKKpKU9GaVQ5GDIzk4jPHicGqDCOOwDq0FUBjRSPe2Z5cgfFaDLRzKOcwyvogDgfKWZ+CWIrz+iDFcpPuZIHrlS61CEY5rBi0NUR5StU5RtGcpYQ8FfKmpTN5hNb9h2mIph76cmu5CLHRHCwH3LdmNb/+V3/Oyo0biLUiUw7jFMcmGiSDgg1yjI6IO22WmRmWj40W/sa9X6s32jMR4usHXwjcyMnLSy685lGXkDyVm2v3ryncELsG1K7eu1s2rj+/irXWxzDgDZBdqhBr0KZbkwC/8iuSYaGcV4Eo7/1BlmMLXT7GdAeE2MKHvF7HNZtImsLkNLQ7SKeDmq0jWYbKc3SWIc71aFiJoKUbfdr/Hvr/BLx6sFjZ9edqcb1grDnmLoVBV4pVrS3Ufkq8ICR5hnQiL63bHOIYymVv6A1CXBTiwginFaZcJo8jdFJF8NG6PheSQZzDiiITRe4EJRBiCUURKPHRtmcAY4enGXNfqF//5Cc/SRRFvOlNbyLsGlD6sHDJJEqw1rF582Z+7qd/ln9497sZHF5KfOwQzdVbsdpha6McOHiA7eefQ4A3jIblKq96649z7de/xWXjjqqh8OsqPFvIgNRLrM6rTIzy+vgoo9j2krhRkIuXZjSKwHo1jxOHFYsVUNYzcyeFqsZ1TbN95evoM9QWr4P0XhRvytTGEeC9V6xAqqWQ/r0HRGQNsVXURFjpMnTix55pBU7Yaxq89M2vY+2mDaADEFcQlGF8IkWtHyRINc2qpdyaZX2YMzoy3JdR08taXoY78yAiNeATwK8452YX5B45aXlJ9ziUkLTW0ul0yLKMVqvV07PXajUGBgbQWlMqlXrRpL1Q+8I/21pLXi2RDw0SNTtUJ/YR1MfRVBEpgWishVwFGC1UBwcYHajRiUt0BmpkcUw8Pk50z71E9QZaBwSBr6/q0hSyDIxFpan/awzibM8lspvJsZ9C572PXZfiYttTocyt79y8P9A1xPcu90c0DtVj/9Jl91SKic5lGWa6jtNNr4+fmPYBT8ZgrSEvlehs3UyyeiXlUsSypWPUVq7EJB3SdhOXWZh2JM6nGhiSnLJYxgJhoBxRrUQE0fG85snA04q59+Pee+9l165d/Mqv/Mopw6fnq2cERYDBsW7tWl7z6lfzZ3/1d4yU60ztfC7OhWQDo9x/8E5e4HzIdqYcgc3ZuuMcvv2GV3Pde97Pi1oK5xSBFRCDUQ5lNbmyqO4S1AlGwAaeoRrx0gYCQdcjRbmCcXe103N6ailo2xV7/UtxfMph131b+q4tzLuFXr44b25h7FcBPY9oCJyfWFIdEDjB6Q4Hidi7YweveulLQIGSwg3TQdZO2NtsY6MaWQi4HDVxiIvXLiGOy8XqQc1NSE/+e3AcRCTEM/YPO+c+Wew+WXnJxx3OOTqdTu/TldrL5TJLly71edBPgDAMoVQCHCavYPMM4jol2Y1uTfuI62AJKItzQi4aqzXl6gBjY6O0RTFRqdCIQsJWi+DeewmPHCWOSpRKlSLSs2ClRWCSKiJEpdCHO6UK7zBPc/3Kw35mPV/h0lXFzFlkjieTvv2FtO8/c5Teo2rrV7tkOa6TeJfMgtadg6zTJm21SAdqhMuXEKxdSSkOGR0eZnjJEtqtJnUlZEkOQU7qMpyzlDGMSs6wDqlGAeVS5CeNM4Cmz4RSf4858jzn2muv5eUvf3nPwLQwqdeJpPiuNKGVz/S2c+dOtm3fRmPP9wmSGawCBoe451ADl+WIEyIU2juM8/IfeTN7167kiI6wCjSGXHmG25XUu26GInP6Ri+Fd5MiSWGI7ebRKF6Inuuk9Ki2R7yF8RRO8BFZsMud8JAqJB4K3b7Q7ddHmtqCGWtnUHnIN2LFc976NobHlvj8OtAz8tYbDR5MNBKUwTmi3BBN7OKi87YWzx66a43ePZ1BEE8c/xe42zn3532HuuUlYX55yccc/Xaj7veuft05RxiGxHE8L3XuKduDQn2j0TqgGocMlUOqoUY7A7mvAdrKHU3jyAq3XBVo4qEhysuWEo6NYmo10moFE0Vz+nKRIgJVFfQtPcbteqx/Hss+wehOf/cjOW3hRNJ915yS3jukAKs1aSkmL5fQI8OUli0jGhnpeQdZB53c0sktubFdr2XKCgYCR0ULgfYFPRA1ZycocLrJBB9LPC0l98OHD2OMOWUO9BPBC7lFtkfnEwy96uUv4Z+/9GWyww8xsX6YtDbG7eMZs606oyOhnx1NgAscS1Yt45J3/BRf/69/xEszIXQJ2mnEReQqLzwgzyxGdkoU1Omfhy4mq4z7ghr1Zz+LS656Lkq6KpW5nCMHDh3gaGUlTkc4hLjTZkVjDzu2XoUjR6RLdmfss7gC+DHgDhG5tdj3Lk5eXvJxR7fQdL1eJ45jRkdHCYKAcrl8Shp3fd4yIgoVKEpxzLqxQVx7CUFTc8PhDq6d0ajG7GtWSBwszXywUVAuMXruDuIN60hGR5jdtZt8YABpNBmcrqOtwwQaG+h5uvH+Ebk+766e3uX4kZ7i7k92rG+/m1udnqy2l3QnnqK+qnKWoAj66lQGmIwjWDJG+eKLGHr2lZRqNcLBQRzQTHOO1NtMtTNm2gqTCaGClZFjc8mypgxxGEEY01s7FIuOJ4vKn5bM/b777mPLli2nVaV9HoS+ZaCfac/atIGzlwzx7QdvQ625kDQa5oiO2Lt3PwOjw4QoNIWuzwkXvewV3PLVr3PfF7/JpS5AnPer04Veu1+5ckajx9gp0hsbBENDK74+FPLCt/0UtcGBvgsKdY9z3HXvg7SrS7EKrHaER4/wjJESy8eWFj7AZ7YR1Tl3HScf3HHlJZ8IuMLfPE1ToijqpX44kS3pRNcCvdzkQaAZqpRYPljhiPVqRdKcJFXMpJYotCTG+8lLGFBethS9dCmzU1Nky5aStFrkCFJvoTCYbmk8wBVujKcunthn5+LUb8PCOzv5uQ//TnnJXXoqInE+uyRAXoppD1RRI0PUVq2itnEjURig4xIUEbCNJKOeZCRZgLU+SramHGMBDAZeckcVz+EEk9wTjaelWmbv3r1s3LhxXjWW018Wdc/xevAwijh/2zZKh79P1J7EKk17yUZuv+1+tC2SiwWF54rR6EqFl//yL3LjsmGOqiqZVmRBhgChVfQsoV3LppuveTyT0HsSAiawtAPF7YQsfcVLOe8ZF3hPzd5z9ZkEjbF86959MLYGAQJnqOy/mxddci5hEOGc98fv6UvPAMPTUxH9VbEeDv2pfKGIPI5CBitlhssRYxGMhQaNZSJxHO04GqnBmQyxOQEQiSIeGCDevIl4x3bciuU0Qk1DwDiHtg5tvYtj0etp3cfDUb47yfajhUAhjAHWkhhD21ny4WHUWZvRmzYSjQxTCkNiHeBZiCMxjsnEMZE4WrnFOUuAY7SkWVULGSsFRMdlDHty3+unJXNP0/QRFRfowc0ZFp1YnIAOIlatWs/zV1WpHrwfRYfmqp18+e4HyFop3pCUe7270oTOcdambZz7iz/DF6tgnCLAl+azKB/56aRX6LdbHKRfL9nl9/38f95xTkA2fQfmnbNg/wkb6l1TSFx9J3ZfVuUcE0rz3U1refFPvoM41PMG0WXy0zMz3DHRIh1aClYI2x2WzxzkmRefXehldRGhWjCcOX+2RZwmuqlo+wtQnOpcYa7IBfiJYbhaYeXIIKuGKqyvOjaUMwLJeahpubdumWhnuKyDyhNKAtVAU1u2jIErL6f2ohdgzt7ORBwyrhyps0TGEJouc58zdJ7u1H1Sun6MIc57dEV46bqRZczmhmz1KvSVVxBe/iyqa9cwWC5RiUO0AhFHPbfsbjoeqlumOj7wKhLD2lrIeUsqbByKKQWFMMkju/fHC09L5t4Nv35UsJBjECs+1N5YbGZ5xQuvZsWem4gTS3tgiFtmFXsP7sY4QZzBSoooiKyCAK5+zWvoXPN8vhsqxEIuOUYlBDbAisaJQZzGob2hFZ8ywNE1qkKXASonvUnhVCRzoiNzxtG5T9eIpBZc4/Cqo8AKIsYHgxCicGQu5Dpd4qKf+RlWrlmLOMEUnhLe+Ae4lDvu3s2BaCV5XPH69sMP8oLNgyxbsgQRhe4W51jEKXGqleYjXe3Md+EspFftE39FgaKsHRVlUc7RzB2NzJEY67MrWosCNIKOY8LRUcJlS2FogDQKSQOf6tbHXbg+5j7X5/GjnWPjp3Mnj0qJd4rZwqsZCyO1CJkSbLWCXjKGHh1Fl8sEyjtKeLWRI7fFs8khsw6FJRCohIrBSFMJtRfw+sb6ZDP4pyVzHx4eZnx8/BFfJwDKElhdFHh2dIxloj7Fheedz4tWBgRH7sRJxOGV5/PN67/rc28QAmER/AFOFINhhTf+8i9zy1mrOUwN5yJCZ8lVjlXOpwMQsMpH1ykHoXVExqGcj0MVMpAMJJ/7YDiOYhfYqvqdYgr5208Sdm6CyMUHSNkuw3egnaCtYJXFoogNICmZCHcGIa0XX8aVL3sxASBKCIteMxEcFpcHfPPG22itOIc8zFHWUt1zE6+58lkoHSKcaMJ9sl+BMxMLvWVgjuH3699NN6joFO1YZ4ugHu8hZRxMdXIONFImmwmStChlTWzSZKbZZrLZ5li9zeHZDuPNlE7mf7cwihgeGWFs2TIqZ52FvfgismdcSHvJGPUspVV48gQyF7nQvQPNXBS1svQ+UvwNHITO/1XueMGjC1W0FRTtdT+q+HS/B8y1Ib1n5z2+bJZjOglJHFNfv5b6ls3oszYztnkzY+vXUypqJzhrsWmK6bSZ7qTsall2tSzWWVZFOatLlmW1mLGhAQarZV8Virlp68lWOT6tmHv3YW7dupW77757XvrTE70s/ehlhWQuUEiw1OuzfPWee/jEF77GVZdfzvIHv06U5+Rrt/OpW3fTmJny0pBVWAy5cmiETDtWrlrDVe/6z3x6tEZdSiRakQYZoTXEuUI7hziLUUKmIVcWoyyu0IWI04gLcATY4tOV9OUE99SL6Sgkk64vfDdBWTekw3bdHV1X9TLn5a6cKiaXgFwrlBiOac3XVi/hZb/4C1RLZZxyhbubnz4CDGA5Oj3F13Yfo718PcpqwukDPLfa4bztm3EEc8uGbmdngnjzFEG/3aifuXcLZsB8Op+rklQwd9dl715HPtHO2TebMNFsI0mTclrHtptMN1qM19scmW1zYKbDkXqHduYnkCiKGVmyhKUrV1LZtg17+bPILruU1tIl1NOUVpZ6XbRIr9JRN2pUFx8flOc/XeauLYTFJ3BzaQnm3T9z+vLAQdA91x7/CQrmPpfegF6yMwCbZp65l2LqG9dT374VvX0rS7dtY+nmTZQGB/2zs5Y87ZB32ky1Uh5oWO5vOozNWRdnrC9bVg6UWDo8xFC1itZ6bpVxBtD004q5d7Fx40YOHTrEzMzMI07aI4CRxJOks9zynVu5d8VO/uIh4T2f/SobWwco7b0HU61wW7SKb996O4HNfAZF5zDFI9VYrLZcevlVbPyFt/GFsqWlKpRyIbDOZ21UBuWgkgpRXrx4BeMUp7Diev7t2gqxgVJu5+VD7x+3FGKDd0hxhfrFFYVFTPHxGR5D6witrwOrXMEE8P74uQJtfNRsQsTXSprLfuHn2Lh5R+FO1rd2sIKyBmcVN970He4eXoUtK8QKw/d+mzc/91lE1bhIxyCFin1RL/No4OuDem+MPM97kvvpPk9nLdYY8tzQyCxTmWM6F1oS0tExqWjyospSKzPMJjn1xJBZ6+lK5gy5QblMODJCODqCGxggK5fJ4hirxBfAcLbrc4bDrzcNkKn5n1wJeRGVnRWrZUt3cuquO+e85f075vzKE39d71PQbveYD9Tz9y6OOc8YJaRaYUolZGQEPTaGrtUIorBXcxV80rU0N7RTQzszdIwlsY5QwXAkDIVCKdAoXRTUkf4X45E6cjz2eFq6Qg4ODrJ582a+/vWv86pXvapH/AtLxcHxjMZZQZOTS8hMvcV7v/pdGtteSja2lpv23kn6zfdhv/OvuDW/RGvzM3nvV67l6osvpFKNi/Rc3kiqRWFxBIHilW98E++99wG+/akv8SIsVuckyutC4lyTa8EqQTuHtgqcr+ridflSVKRx4KwvbIDCOIeoPn9auoHWhV96we3FCYLG4Hwu0q6+Uegu1ItriiW7WCBExJKK4vogxL3yGp5/zcsxRQCSOK9gCY1XKRklJO2U//fNO2htfSHKCeXJ3VypJnjmM5+BSECABVG9AKZFPDJoranVagRBQJqmTE1NYa3tVcSCE+vpRRS6yLWeJy2STpvJdsZtkwnfPeaYyco8VNpAPXB0Oglps4VzKXumWnwnFpYPlBgbGWLZoJk3OVeXLmXVBeeTz84yPTHJVJoSNRoEe/fDzIzPmx7FiBLaztFyFqsgDYU86K81KijrUIXQEuYQGJ+mIMan0PWTQ1FBSqCjiuA6DVbNXw2KdWA8M4+dUC6cF0JjCKwlUcLkQJVWoFFnbWLkqitRy5czuH6d17O7uQpmncywd6rNbKvN3ukOk62MVmZZPRJx5dKQJdWYpZUIdMSZSNNPS+aulOKaa67hr/7qrzjvvPPYtGmuutDxUo4r/nkdhjMKq2KcSfmXT17L9eVlZMOb6WhLtv5cBob/C+rbH6V873Wk51zDd++OufF7t3Hlc64iQgjoJjDSaBzWGcJKjR/+1d/g7w4f5PvfvIntDsq5xSnwiyeHBqwTpqOAcWU4RMKM84y0QsgQilGJGXQwZHKftwPoatalJ+X4LauEVBRtpWkDqVjygtkHIlQdxDhiA4H1+5Uz3qXNaJpRzn2R4q6zt/P2X3wnulZCMN6wWzD5XFlSsURGc+cdt3NjvUQ2vIwwDRm45wZ+9JVXMFCOESdoleGI5zQyZ8K69QzGwuejtaZcLhMEATMzM9TrdbIso1wuY4zpedAc105fW2mWkbTq1Js5D85m3DwDLRVzJBqmXQpRdhxdbyIm52ijwz0T0Mgdl6QZPX8q56msPDxENDJM1mwyu2s3jfFx4mPjDBw6RJh0iFzsmbsoDJZmYedpR0Iaz0m0gjclqcTXDyhZKOeeMYUU0aPF+2nwjH1WwAgYLZiiMkYvQNsIkjrEwoATQqsInEOMRZsMF4XUKyWmSzGDq1YwvPM84lWrqJRKvhhIlz+IkBjHkXrCeL3N0XpKPc3p5LAkEnaORgyXQ0biwCdbgzmpfU5melLxsMz9kRYuKEK3/xJ4KdAC3uqcu/nxGf5Jx8zY2Bivfe1r+dCHPsTb3/52Vq5cOf8chExyAufABGQKX5BCMjpWuPbaL/KX3zlC/cofJgkMOg+xKFqDowRXvI7gqx9Gr9zBzI7n8N4vfJYLLr6I4WrVL/+krxfxgUxDy8Z4w+/9Nz76yz+P3P0g5zlLpgSwaGsxEvGQVtzgGlTLQm1tlZFa4FUjrZwD9YTvz7ToNHOWuZhzJGS1c4TWIFbjiEAlpCpnXAbYk2fs0h3qcU4pDqlpiLTCCDRzS9J2VJoZWxhgu5SJrSWJGsR5AHQ4FoR8fckSrvm932bJ8qXeJKs0PiOH9YZZgcgZkjzjfV+6jomtl6FcjfDYHVxdaXH1My7GaCF0CkdcGHvPAKp/iqKb+TEMQ0qlUi/rY6PRQGtNGIZzDL5gnLmdK0E3MdNiYjblaMdwzAS0gjIdFeHCGFEBEpWRchVnMlpOmGylVEPNdCthttUm0JooiHrFKBS+mHQ8OkJt/Tp0qUS+ew+tdpvcAc6h8pwkFkyssBrCqiKI1ZzhHyB3uEwQ45DEYlKHs9DOIDcUq0OFFchCQcXKVxALxcdO9TF3Z8FlgAWbOJK293SxVsicolMqIStXEo4OE61cQVQuE0Vzz60bTSsOkjznSDvjYCOjnhlqGkoKhkoBg5WYWikiCLrX9eEMIfHTkdwfaeGCa4Atxecy4G+Lv08I+jM97ty5kyzL+Ju/+Rte+9rXsnPnzt6PKMqhitvPlSNTgnId0maDj/6/G/iLG29l7xWvJa2OICohy0JEGnQCR1xbS3D2c+Hmf4dnv5lv5Ev54te/yRte8kKs0igpCgyIl6oVDqscm9du4Jo/+EP+7Vd+ncH7D7PGJV4fboWHAvhy7SiXX7KCrcMj1GxGSAdBYSQkkQFaSlNPcvYeanD9nlncMctOVWWLEmrGclhXuIE6xyrHWLtpjItXrGSsqiiFmtBZdE9pJDSNZmIm4+b7jvHg4Wlea0PCPCC0MKkH+Vw54Fnv+k0uPPsCbF8epK7qxyGFjl+47/b7+Pdjderb1iBpxvAD1/GzP/ZyShVfi7bH1M8QieapCBEhjuOesTTLsp5Rdd++fYgI5XLZR2X38vdAIzFMtFLaueXOqQ53TSXMGM337TBHyxWsDrBRmUBpRCtUoCFPOdo4Rv3oBPV2wn2HJhgJLIOVMqvHRinHoY9edRYCzdg5OyivXUN64CBTScLU4ADRxBSV3ftRSYd0qEyytoyKFEMDmkqlyGHtujWAIct9ucq07ei0LTZzTE9ZTMtbWFVJkACiqiYaDgi1EIZFMlLo5UkyTkiswlowx1KmDnUgc95TRmJYsgx99XMY2raZwZWrGFy2jKha9V40FG6SJsNZw2SzxQ1HW9x1rIV1jg0VKAWKbUsqbFwxSikMiKLQX9c3hjMFD8vcH0XhglcBH3Cew94gIsPdTHqP/fBPDRHhoosuYmxsjI985CNcf/31PP/5z2fTpk2U4hglOc4qnM1oTk5z04138Z5//zrfjs8ivfxHCaMqiQhBpkBSQmvITAUjKZ0N5xCN34Xc8W2a51zC337hkzzzwgtYvXIV0i2y0eegq/A6wp07LsD88R/xz7/6q7z24DRb8pTMlfiWtLjy/E2cP2zRro2XkTVGHI6cyKWUjGUkcKxeF/CMtWu4bxpuuucYtx5JWF6pcCSbZvP5K3n+2oAhhTeYmsR7S4gvG9atGVmziqHRmNUXL+MTt45z74MJm4OQhgv51xA2/Kdf4FkvvAYXCIai+BKFB46/JayDZtbhbz/zJaY2XwVqiPD+b/C2TaM845yzfPK0Xn3UR+Wt/B8OC9IKz9vfPRaGYU9F0+l0qNfrAJjCGCp9zH22nTNe79DMLLsnc+6czGhIxNFKQCuqIFoThLEPhnJlxOS4PKVVn6DVSilrmGq2mW74Gqa2SM/RzZuulKI0NoYeG6MVBIyvWE57YoI8yfzxLMcEDjOgkVgRDWmqlSKHvDU451PnKgPGOrLYYiIhTxytDqSZRYUQVBQqEGRAUxoOCAIhDCAKQMT18sJnTrBOY6yQtTOS0GKtw+kAjEaXy1TXrCbcsoV4aIioUiYKgl7FKueKHPUmo5PlHGrl7GlmDIeKFSVhMILhUsBgpUQU+NoLOO/4oBb8fk82HpHO/TQLF6wG9vVdtr/YN4+5/yAFDU5zrL2/Gzdu5J3vfCe33347n/vc55ienqY6NMDYwBBp2ub2Xbu5s1ll/8A2Zs99CY3RLTgXoUQRmQ5iA2yQYQS0y3BiSMIBwgteRvClDyFLI3YtuYj/85HP8N9/9sdQZR/AM5f90BuDtLMYbXjGBedj//SP+Py7fpvOwWMMGMPMcsP20bY3fiq/vswVaCsE1udsNMpL3cpqYpVw/nDG1suGue1wznd3TfH8czewY6BBrnyQhRXohAGI4OuVeuOVdoLROWHucGGT8zaVuW93wjIqfLFkWf5zP85L3/R6ypHDiUW7YrXTdQZwhW+Ng5u/fjufa2nqq88mqh/lkn3f4W3/5SdxcakYazGzie1TjC7iB0E3d3sQBFhrUUrRrZfq86ZbTJ7jnGW6k3LvZJuZ1LInqzBRGqQjIVlYQmkFCpzNsa5IwBxG3vBeqkFliHYAD002iU3K+qUpy4aGiLR3dVSFgTwo5qBSpcLwtq2E1Srp0t20shQzM0M8lhPpnEgsIRAV55tiHajwXVoFKlJEOEzk9e9JRaG0EMaCCqBUVlQiH+wcaAiKVWHXruqdhXMMkATQrESYUkBpZC3xwDKiVSuprVlNaXiYUrnshZTCZVoEcuMYr7eZabTYPdlmpp3SSQ2D1YDzllYYLQWsHCihlHd6OJPp+bSZ+6MtXHAyPB4FDfrG2u2j9z2OYy655BIuuugiX6ZsZpLmVAsdGGa+8O9cvztg9rIX0tY1AmOwTsh1jiXEBZk3eeoA5TI0IU4MeTiGPPsazNe/RHzBZXzmgb0855tf4YUveInXSyrdy7siAmiFtmADuPSSy6n8rz/h3379txl5aA9DIzUqApaISp5gUQTGl6fLxYFYAucrwRhlEZUiVjNgFZetinnGqqUELkOLJrAGIwEoS2wzcD761Yr3eU8F4lxwGHQaM6Da7A0rXKsdy37h7bzmx9+KKpKuiRREInPPtqsamJ6a4i/+7VukZ78YkQYjt13Lr7/qOSxduQyULzRiFSAO5VQviGYRPxiCIKBWq3mvlWqV0dFRjLW0222SNMXkGTZLMVnGoXqbbx2c4WjiODI4wtHBtZii2pKWwjfeZFicz8NeKoONYWAEZy2zJuF7B46wa/csz9iwgm0rxqiFQhhGxHGMEh/MFjhHODRMcMXlZGnKkbvv5nAotMaPsiQ7wEC2l1gMZecoO18lKUdj8V5jzufDplZxUAVjoT0IifGrxlB7yThQEKo+OiomJS1d1wSLcylGHJOxZmqojIlqLL34Emrbn0F5eJjRHVupLRnrPU9jDEortCg61vHAeIMHDk+yezbh6GybRpKytFThBeuHWFGLGRuuIjqc7/ro3BlH3Kfl536qwgXF8f7CBQeAtX2Xryn2PanoLmu7Xgdrlq9h246t/3977x0nyXXd937PvZU6TZ6d2byLXSSCyDkQICFSgphEShQpimIwKVHPIi1atJ8k2++Zlp8lU7YpibZlJUsWqUCKQSIpiglgTiKRiEykRVxsnDydqure+/64VT29i11gAWyYhfq3n9oO0111u/vWqXPP+Z3zY/v203jXz76Rc2tt6o/chlOpD2EEXn/USQY29PFlG+JsFeUMolqkYUZ3ZDvq/Gto/uDrtLaewW9++kYeevAhSua4K1RPKTxdozQKTTewnHruubz5v/9Pdlx2HoskZGaY0ChagaWrFVnQxImPyyursc6fDMo6nInJRZHpLtAhIkdhyJwmE8EUCk05QqYUFo1YITBCYKCjA9KwTaqEx5eEO6t1Nr/3bbzm7T9PEFdwRmFU6IuzpKyCLOLt1tLNc/7qU5/hpvFNtMe3MHzXP/KWzTFXX30FWmlC55V4cjGehukGydRniqfSHiil9Mq+7mWHyP6eM0o8dTG1vvFV6hSZCsglwInuBYld0d/Hp1AUTmmcDiFMMDpkMbXMtFLmWimtTkq763u/9wfalBSqT40hkrExwvExGB/DjY9Bvebl7XQAolZqHcpiO4rKU4FQCaGGKIQoFpKKECeKOBLiSIgCCJUjENcrUir8h76aOH8hIAywlQq2VkVGRwim1hCMjxFWq73vqvfdFmGZ3FiWujn7m10Wu371EwpUA8VYJWS8ElIJdLEeX93z+UjYMsJTCxe8nwOFCz4DvFtEPopPpC6ciHg7HJhcPfh5+i66IyNDvO8Xf4Z3//b/olWdYHndVpTRGO3ToagM8LxzBRgXevqWdHEmp7PpLBqtWZbvvo1dW07hfX/8Sf7Hr/4CE6Oj2MAnWJ0IuvSCFcQ2wDnHutNO4V9/8L/zd3/03/jLm7/Mj29oMG0dkGKpoJ1FOe8B9woyrNdtdNbvrKREet/HFymJ8wLBruwIKIKyFnEWpxQiOZYGd7eE77YbvPM//Tuu+dGriYLYL5WlEO9QgkL7OKQ4nFM4sdxyx118+KbdtK95K9G++7hk5h7e9YvvIIwDjCi0UzgFYUGdXKWCSyc9SkMvIlSKUI2zllqSYKzhBUGNlxMw0zHc2DHcuLybrgRk1QYm9KEzigpm8BducQ7iqmdHpVUW0hZtp3igo/j6Dx/l/sdCTt04zdnbNpNEYS+R2O9Bj0xOsv3SS+k2l3G7N5DuWoNJW+xf2sNyew7tLInLCDDoQnu0LMAQ52d17Bye6Sgrxts5SkfJJ2Md1kHmtbrJgph2NIzRIfnEBqZHTkFVG0yedjYjG9YTRhE6CDB57vdcXDzbaUqr22Wm2eWOPQt8Z+cigVacPZ5w4ZTm4rVDjA0NUa1EBGHUU0jzkdfVObOPJCzzTIULPoenQT6Ap0L+s6M54GeKQyY4nMM575lbUWgxnDo1yfvf/kbe/Ycf5876T9IZ2ooiIzCKXEJsKWFXzGJPYgxxgQFlaG1/EaGCxftu4pahcd7/Zx/mN971Nmq1Ud/OoJBiEuXPI1UUljgskyPj/LNf+Q2+dcMlfOiv/ieXVeHS4RpVkxYXhrw4vmf/5sr2TXjxJ4TkOMlxojFob8QBKcSxna+ZLST0FMt5wNefyHlo4nR+9jf/FaeeeS6hcpQDVOpAP9uWTcIQ5vfP83t//Ul2XPgqbNrmlNu/xPt+6bVMTk4DAfpwQbbVeQ6c1Oj37CuVCkm/M+McUVJjLNYsdjK6Dze5b2Y3yxKxFEakUQ2wPhzjCoNZ9KpRcQWp1LHdDoutFtYodLvJN3/4KOMqI0c4dfN6wihA06diVhjokYkJ6hMTGGPY++A0u+8bo7s8T/vBW5DFFolNGbctEpcSBhodakQJOAXOlwMmspKxshTOWFH9WiY+rbXkFpYyH8JpJ1XmK+PkUZ36lvOYPucKwmqd8fFJhoZHAIfJDSYvQjHam8B2N2VmYZFdSx3u2LPIt59YZNtIwuvXN9g+WmHjxBBjQw0qUdjX4oEVFbJViCNhyzwj4YKCJfOu5ziuYwoHPR6wN44BipwLXriN33z9j/BLn/x7dl3+07SqazDae6vlO23p0eIQFyKmhugWKIPZehnaWebvuZkvNQ3jH/4Y//ptbyVOEpz2qtnluecnhy+lcyLEUcSLX/5qTjnvhXzuz/6Yu2+9hRevUWwYqlF1HQJnUb3XF+QrKcqXhIKbq3BO91oOIBbX+4kNqdbMUuWe/Sm3LsW84Lo38n+9/mdoDCdomwGBlw+TshRK+r4wS2CEZtriv/7FJ/jG2IVIdZI13/4U73vVxZx59gswEhK6vCgK80nYQ1UFD/DMcfgivEO/rnhAGGhqsVfEGk06rImggsWQkeZp32sLemKP6loYVqVwYYSLq2R5zlJH0LllrtlhdnaOvJNQrVapxPFKWERAKU2gFEpromqNeGgEoxRuZBLXWQbTwXQ1mel4DV7lzysRel1Sy5CL99WL6thCEBJxGFUIyqMwYYhxGqqjBCNrkKRBNDxGXKsTVmoEUYTSPvEsypbXMkwRjlnspuxebLGv2cUYQ00r6qFmOIkYrcbU4rC3QnIrZeGU58hqYsmUeF5WqD4tih9I8B3kEIVVAblkXP2ii/lPy11+7fq/Y/6S17HQmESkWxQKFUvBgr+uHSi1jHWOjo6Jwjay/TLEjbD3juv58E33UI0+xTve/GoqOibs9csoT1Q/HKd8pz4hYOPG0/iFf/tb3HPbrXzhr/4Y2XEnl49HnFIXajpDY1A28MGY0oCL5/FiFbpcIosiK6KZmYTsM5o793e4a9mw9pIf52ff8HOs37KWgBixshJ6Kr+jIj9U9vjQOaTkfOwf/o6/2akxF17M2M038N6L1vPjL7sUJ0IgvoVqYDW+mtFvq3HiP59RtmHGQRiFjI6OUssNl3YhsRn7UvjywiJ3zrWxYUxWH8UGEViL2Nxzu4zBlCyS0Un08Bjtpf08vGuJpAuVB54gmtvFSDXhjHPOYuv2bQRaUy1CLJ6b5UNGoxNTJHGCSbt01m8gXZzDNhdo79pBc3kB1VlEL+9H8hSVd1F5F3HO57YKFrkr0oNGBVjtcwYmrmOiKkQVGFuHqw4TD48xvO4UdKVOPDRKMjqJCgKiKPKfpci7KQVda2h2u3Ryw/ce289X7n6EbmaIULxkXY3N43XO2TDB5vEGSRShlPi2H5QrplUbkQH+qRp313dHilAECo1GtPCq665mbnGB/3LjZ3CXvZbleMwvDPs63eGEXBsQUxQ+GAwBVoM59Tyq9SbNGz7GX3727+m09/Gut7+DoJoUxy0uLhIghUEsl7YWiw4VZ194PtvP/n0euusOvvsPn+Lrd3yfKdvhtPGQdbFQjwJiLNpmiPNLaSteQiwXzbKFvSk8Mdfi8WbG4sgWTn/xdbz9R36U6Q0b0bq30PWev+gi6VmO0FPEfJLNl45/+dvf5QNfvY/uxW+icsfXeMvGDm/9mTdAGBA45UvFi0SdWs2z/mkgIgnwDSDGnyOfcM69T0S2Ah8FxoGbgTc759LD7+mYjO3pG4W5FQ8/CAKiMKJiLdtHWlS6EbtaOXcttLmvuUye1MlrI6C0n9e2CMEXcW2UQlUbSBCSWcN+V0FlXYb37GNo5y7GahHD02uY3rqFSIRYBQTSL1ohVBvDVBvDWGtZGp+m3e7QXZilpat05/bDwl7ILCJttFlGWefzW46iRTWAn1e5ROSS4FSAjcewtVFUpUG0/gyC0SmCsXFGt24nqdY8u+ZQ36FSxfw2tPKc5W7GgzNLfOfhfSjnuHjdKKeP1dkwWmXjeIO1Y0NY5x0w65yngbI6vfV+/NM07vR8Zx/moFgKWh82CbTiza97Oc3mx/mdWz9PfsFraMcJKIcyqohtC8pohBhwKOcj0lblGOdIw1GufHQntcVdfHLfTlp75/iVX/kXjI6O0N+wCwuBOJzyccSgCGnkEhJHjjPOv4jTzr2A5twsD915Oz+8+R+55aE7WHp8HzrrUNMBUTHxMytkxtHVIWpsDdW1m9l29fm8/IXnsn7zJqJKgiiFpWhORu4NMQ7o4kg8NY0V0QXnvBd366238O8+9mUWz3gZyQ++wNk7vsPPves30EkCTvySWxza2YKrsDLxV/tJcAh0gWudc8sFU+xbIvJ54L3A7zrnPioifwi8A1+BfVxxqO/zUL3feyvD4rk4jhiq1+jqnC2NJvs6hkVteSxvs+zf5B0YKVaFhYzkSgBCiLQi1MLQUpPJ2ScYiTXBfffTqlXJohgZGiKNYwg0EoXekGqN0toXClmL0pogSaiMTaCjCOpVXDWGvIvqNpFuC5xFTI5YA0ih4iWoIEKHCagAVx2GpIHEVaKJKXRjlKha803S8hyxltxaz4QxBme8PJ7LMjCW5VaLhbl5mp0uyY6H2PL4w2ilWFczTNQcI1lAaMv6U4rvoqBXnwThxn+Sxr0sLiolBbw5c7iia6KyAToWfv7Nr2b+Dz/Fn9zxeeTcV9AMKwgKsdb3ukCD8o6bKcqEyGtY1UXteYhXt/Zwvii+tm8PN//l/+G3dtzHW3/5lzjlzDNI6nV/EmnQufJtd2WluN9z2jUgOC0MT0xw3jUv4byrX0KWZnTTLq3mEq2lRbJuB3FCFCVUGnWqtQZhHKPjuJfwsc75DnoFL9iI8XkHZ7EIYiuAV4Q34tuxOmORNOeHt9/Bb//Wb1JnDRtv+0Ou2ncfk1nGd/72Bl7/7k0oUSgCnPOCCCUL4WRFkTdaLh4WSiw44FrgZ4vnPwT8B06AcX869DRTSx679Ynw4UaDWqXCWCflR/PdnBplPNjJ+Pv5WdqpxlXq2MaYN6R5BqQ4J74q1UKEMBwEVIKALfv2cN4t36NuM5K9e9l36w/QjQbz27YRjI6h6lX0+CgqCn174Fq1MOoVgihCh6PE9TrOWazJyLMuzlpc2sWlXbAWlxbNZZRCgoLcHkYQeydFByFaB4jS6ChBBSEOyJ0lb7fI05S83cEZS9Zuk3dSXJpiFuZwnQ6L+2bY8+DDdJebTOx4nOseeJSwErMxOI/J6lYalYxqfio+XGlX9A/kyQ3aViP+SRr3w0HwhT6e2qWIKw3+1dtex/L/+j989K6v0TnnZeAiTNnNUcrQRslR9O+1aMK8Q0CXLZ2Inw0dL40jHrjpNr72jnfx9+vXMnrW2Ww573w2nXU6kxvW0hgZQUKNVooAQVmwOi/CIhSUNX+YII4I4ohqo4FMr0VJwaYvWA897rD1fWtckTzGFt0jnSuSsD7ub53FWYc1lvb8IjN7d7Pn0Yd49K472X33D3ninnu5dN8ip4UPc7qFtXmbBVPjz275Nqn5WSpBvThuWHwPhpN9aok/g28GtgO/DzwIzDvn8uIlZeX1qsDhvXnpeZthGBBHIUpr1tcCVFPoOEfVdtGpYKNi5Sb9vNVSQtEnO0OliLWi1ukwsn8/tbxDVqnSyXLU8DAmrqC7GWqoQagEiSMiYzxjLAhQYYgQoYIAXa0iSvk+7yUrJk0xaQrW4dIMlxlQggSeTSNRhMQxohShyEqFakFLzPOMbruNNTlZp0PabmNzQ7rcJGt3cJ0O+cwMrtWiuWsPzYcfIV1cJnl8F8N7niCsVZhcnmOku4ZK1kEXIc+iNLt3bj3dd78acHKfgUcRZSxTISCWwDqcKOKRCv/3L72e/R/8E66/J2H/GVd6D1+6iIl68fdemAeHJiCbPIPrh8e50O5jY8exziq2mJRmaJl9eCfzD+1k92c+wzd1zv7xadTYGMObNzC8cQPj6zYwMTXFyLq1VOsNoiQhimKiJEZFIVmoCApJPBHp0RQDW1AdRciLzyTGnzBpnpF2U7K0S6fdpj0/x+yePczv2sXirl3M79zJzBNPIPsXiJearGl3WecsZyqoAlVRjLSWsaLItYKgi7RmkayCCRVGyjZsBWX0oL4oJxuccwY4T0RGgL8DzjjS9x7r1hrPBAc3s7IFzXVsuIFWinQx45L2MlNBzi7V5sH2Il3RiNZF0ZF45pXJMaJYrg2T6YCd01v44SlnU+82GYkDGktNJM2J77qLsFpFVxKC0WFfvFSt4Go1bBDQqdZIk8TvP44QrbFKYZTGCXQdpEX4w4jtUw1TiINANJHSRTzd65OJA8mNd1ryHNvx3rrrdKDdQhlD2GyhOx1/wVhahG4XvbiE3rufvJOSdtqk1YS0UuUBE5G1AkaXHGfONxlL5onCkGoS9UQ5+rkyq5U0MDDuB8MVuqLaoawD0YwOr+H9v/QO8t/+M76yo8H+bRd5HrlY78U7PFcYi1KCsjnp9Ba+dc3P8J++8ve8Su3mojxjTBlik7EhT1mP4jQd0HUJatcc7d1zzN+7g1mBReBeYL9WmEAj1QSbhLhKjIQhoY6xlQq60fA8/b6TQSOERnBpTrPZRLsOrtuGrkE6Ga7VxrXbDBlHXRQN51iP5XRnqYkwlBmvd1lskvp9giOTmDyA2aDDV3SVr88OM/U3n+FNP/1ihqrDOO0bnSkX9hqNnexwzs2LyFeBy4EREQkK7/2wldfHsrXGs4Eq2F0+KeibfU1NjLFmbJTG/BJpu8XeOOMfmy12Ljq6LoD6EMRD3rBa6wkDWjM3PImqDfPA5jOpdpcZai3ywl0PUt+3E53PUrn/fipZ6j3zOEKUIksSsiTBaE07SjBh5PsIVGJcEPjWjlGMFUUzCmmGEUYLWV0wiSAGVMcvCCuppdE1KOcIbOopvMbiuinkBmUsOs1QxhKkHcJOGzGGoN1Cul3EGFSagTUMiTAp3jHZm9TYU6/Tqta5zSQ8tBiyPnHo/QtsVIrRoQaVZByltO8vX9I15cme/GrBwLgfBCs+1p2LQitLiBeymBif5v/7l29m+b98mO/GmoWN5+Bc6D14kcLj9zxaQ4oNNHuufB03bL+aW2/+FOfc+m2uXXqCc0XYkHapmAwNNFJNFnQJnWMkEzaLwhSeQZhqLJA323QFUk2hVhqwpDX7AtglOQuB95aHM80UAaNAbHNiawgK1kHgNIGD2Dm0NeCCIo5oCxk+ixLIpJDTtkXhiBZScXQlYGdU4eEs5ssVzbcvfAmLF76K//zgXXzvv32Y//j2n2Tdxg2ecyTGs29OUojIJJAVhr0CvAz4beCrwOvwjJn+quxViX5nsj/fKiJemCIQalHIWKJxqWI0dVTJ6TqHcRZT9mYqYs1OBBuEWBHaSZ35oXFsELI4v4/lcIbcCYkBMoPOLUGWIwKm62PfVhQmijFBAIHGJRFoDUGAi2KcUuTViLwSYQPBBsrTjnNwLYcYMG1L3vRGXPIUTObj890MlxuUMZDmWOsg7ULaQaxFdTuoNPXhpdwnWV0QYOMQqzSdqEKzOsRytc58WGNGEiqEzHUt9XZGGGekuSmq28uckvR9v0d2DT+eHv7AuPdDCmakg6iXdHVY7Z/buH4tv/meN/Avfu9PuCMRFicvRlyA0MVSJbCOjBwXeKmwlCrZ1CnkL/t5vnPhK7n9/u8xfvstXPbYA1yezrBZZ0zqgIpxKFdy5zOUySlb8zpRRAYSC6icnBoPR/B9PUtnY5vtZ9fZNpmASlncaXjwtjbhrhovSmM2ZSlGIkKbgxW6YY52EYENEJsXSeHCM3caQ9lBsksaBDRVwE4lPCDCHUmNG9duYHHbZcy94DLm12whD2Oiddv50gO3seu//hnvf8dPcfa552CdQazFEaKkTDY7yjYIJwHWAh8q4u4K+Jhz7rMicjfwURH5T8Ct+LYcJwkEEVeswjysg0oSccr6KdZOjNLd22Q+X2A2ddzvAnY0FVY0Kop7IRoHoAJmJjfxw7hKnHbZPb2dm+b3Uum2mZrfS73TJOk0aSzOEOYpw1mb0ayJBipKeYWl3KCXWoiDPBS6kWBDCEccjXUOYgjHQNccLgPTFlwOdrdgFxWuA9EiRMveqFp8CMcaSyf3OaSuKDq6ggkUWX0NWRiTa0UzTMh0QDupslAfIQ0iZhrj7B+eoBMl7JpYz+zwBLMhdGZhdKnNmWOWK9Kc4ThgfHiI0aFGoVq5wn1bbaGZgXHvgxfYCECvJKP8c+AwiIMztm7nt3/hZ/jnf/JpHjtvgrmJLYS2Q4rFSIaTEGcqWLpoIxiVshhGNNdsYf/0ZvZe+HIe2/8In3rgZqZ3/IDNux/inMU5tjphsxXGTUhF+9YCiTWELiNXKVb5BmD30+Xbo/Nc8uY6519sqYdthCaODAhZ/skqt9zi+Pxf7ufKmQnOyELECFZrT+G0hlRpTJD7zpEuxDlhXsGeUDHjYIcb5ZGkwiNjkzy+9jS6G06ltekMFibXolSNjgpwSgMZ1gU0t1zAXcOaX/iTj/GB13e54kUXoVAELvMtF8RrTPalnlc1nHO341tbH/z8DuCS4z+iowOhrDz2K0CHp0dump7w9EHZTWtuH/vbGa1WyI5W0UAsCH0rRldQJZ1jbmw9cxObwFrubc2j2ktU0jbrZp+g0V6iMb+XyZ0PUGk32bywh20Lu0isYRyIwMfB2ykqN9jAYpIcE1mCqEs83SWoOBoTlqRhMRl0W4LJhVY7YNFE0FXIQkCw3190bCzYAFILqXFkDuajKjNxQhZELI9N0RoapRPF7G+M0IwT5qvD7BxZSydKWBieZGFkDTaIsHEdF1bY3VnmsdnHCLvL7GulTLomayoBgdaMDTWKIr8Vr31g3E9W+GJPcML5L3wh/+X1TX7lo58gu/TnaA2PEVhDLgKiiSxkKvLKNtiilVeIcSndqEFr3XnYDecwf+kyO1ozfHluJ9MP/CNTt9zAuvl9bKoNUQPGux1GO5ohGWUYw96K4bbJXbzm3aOcsn1fwUJQGJUS5QFGd6lVW7zoClizboq//+As3X1jrMmFJQVtQtpimBOhbRVzOexOqjwxNMm+0Sk6o9PMr52iO76N7uQ6umM1OkEd60YwvZ4zCqOWcZKh8ypGDGlF043OJr1glF/+yCf5r7bJ1Ve/CKcCInLEZSDhCf4B/ymir9agTAEW3ne/6EpJnaxEIeP1BNEBE7kw1slIga7NyHMvVS3OFG8UrASgFCaIPEtGhGZSByDIupiRUWwlQlUc4ZBXAwsFQhHIcsxSC5tmdGnRdAuYMCOOFInSOLGkBiQTjIHUCdYJXa3oxIIzQjBUQbmCYtmooJMQbX3YRVmH1QlZUKGrQxaGxlmoj9IJY2aGxmnHFRYrdZr1ETpBTDeukQeRF/VweNES50h1hA0SFnA80TGkWIbaGRPtNqHWBIFnuB3pivRgAZZjiYFxPwQOjp95wqNCF9l7RcCLrryY/2dhgX/zpb8lvfJ1dOO1XlzatanOP0JneJpM131vF6cJrSULFN0gR2yGk5hmUgPnCHc/QhgFXP2zr+O6yy9h88atLM3MMrN3N/P79rNn3y7ufHgvP/j6F/nxa7fQZpmb7h4hSBM6OSAZ2oIhJghzQm1QYczUSxr8yWeWueiiFzM8PkljdITG5CgbhibYvW+WO++8m9vml9m7ZgsL2y+jOXUmXV0F5zA6AQyh6WIAEy+ishBMHSQkzlIMjiwAsSmBcSyOn4pc9Tr+3d9+nPdJwI9edQW5jgiki1drDHrB39Xm5fxTQ38PF1t0xVgzXOfiUzeznGZ0H5rHpfPMm4C7O45d7RSNJRSLwmGiCnlS9xeLIAIdkIUVZpwwn7ZhZJgN64aISRmqCZM1oaKF4TCkFgSk7Tbzu/bSabaYnX2Ax3d+n8wsMzoeMhYkaAdLS46gVTbM9kVZizHMrnXYPKC6dSsVvYlKtc76rdupT0ygs5y8m5Iag20blluGZav4IQ12uBpZWGF5eJosrpEFAe0wLrQOFBoF1qKzRZTJcUqT1UdJ1QQ/NMu09s3RUIZrzQK226GeRKxfM87oUONE/pSHxcC4HwEUeAoNilAczihsmPDqH38p+/ft57du/gL7L/4ZlA4JuouY275N9cLrWK7XMNrTvHLJUCb24QyBwGga++5h8vbP8pbz1/Jz/+ytrJucgsAzBcY2TLPFvhDlLEuLS/z3D76P4RdYHt6Vs2M+gHCCSpajbUJXRaBSrBi6mRBpDXkHYzLWXzRMe8Mov/R//1uq1QSrIpQBnOGnVM7M7Aw3f/9OPv7NW/nuAz9g/qyX0Rxbi3UdAhtjqaGkRdhJ6OgYbQNEC/Hj96NsSnPruaRKAxbUMouN9Txy8Zv5t3/7t4TW8NJrXoSVqCBIWoKiwOlQFZUDHEOUMYTyYd9TtuBw15KYoUpEJ8t5eP8STwRt9jjNw50Ylxc5IWVQ4kBpbGEA0QFOKYwKWK5YCGPGggSJIwKdk6ypU59uUAk01SQmCUPscpPs0cdpLy6x+HjGfnMnabeDqmli5dA4VLcoJVECgW+Qt6gN88M51kZ0h8Zo1zdRHxpj7dkXEK7dgM1ygnYLmxvcQpvubJNWDntaVR7qxuRhle7wekxcLxY23nXTaRfd7SDOEmRdVNbCRBXS2ggmqrB32TG3vEDV5WyKO5wedhitxkyODK+sj/p6w68GDIz7IXCwoXEF7dGK9m0GAkeAIw00b3ndq3j4Dz/Fn//wszTP/BGilqGbL9GNaxgFQgflEm/QdBeHJrFthnbcyAufuIPffPtPc+652xBd9EEX5xuMOQExOFEs2pxHHn6QUb2E0SlVMQRSoaIsYbVNHohvtGQVJlJ0TRuUo91RJGmH/Y89ROpSaqIRG+G0zx+ELmJqbJqX/9gkL77mKr578+387sc/y11rzmTuzKtoqQClMq/gZECJwQTLODE4lxLuvB/Zcg5iQtIgQ1mFWFgeGmPPxa/hVz/1SX5H4NoXXYVTmkB5BZ4VXrD0nQ+HPiEGRv8o4jDGp6hn83MUEFFMNKqcNjXKUNvy0N6UpU6KEUXX+XlqnTfwohTOZJBZEpczrZrUwpStFcdZozXGItg4XGG4UiHWikoUEgUBJoqoVCs4axgZCpkay8i7KZOjlolhP/87LU2WKrR2hLFFaUcgObFOsc6ha4KqJtTqCdVqQlKpoMMctCYzhrUqxoYJy7kjWxJGWrCEZYdZYr6VYnRAGsa+UtwWBYnOFZ8nBfHEA7G+StYmNTIX8YRNuWM5YzQzRPsXMHmG1oooCNBqpeJFEMIwIAiCvoZlK20LjnWIZmDcjwCC4Ar2ykoWBUQ0leoIv/r2V/LY7/w+n9+1FpiAsIEJFUoZjFJIrolcRic06Dxg4t7buWLxH/mtf/0O1k6v7zUQc2T+R3baeyv4xOrUWJ3LLryC06ce5LytC2hTw+l20dY3gjDDWEdoBOVyurqNcgk2G+GeRzS377mASnUEh29zUFaoKk/HIUeIKyHXXnURZ56+ng/88d/xiTu/TnrOVRiJEVtMk0LqL3XQHt5IdPf3MFajxJJrh7aC0X7ZvlSfwl30Kn79ox/jd6MaV1x2Np2WJc19LNPrgFYIw7DXfXJgyI8/yvbOZRmeRaG1cPrUGBuHKuxaaDG/uAO9bz+zUmGHHqWtIqTikEKfl+UmtJqMBClXVxfZHnbZPDnMhaesZbiakASaJAgK3VUppPmEfHyEWjWmrmLGTAeXLjHScIw0HGmueGJvlbnFiCS2jA5lRKFF00HTAkloRopWOEylNszY+AjDw8M4ByPW92mato4zjSXLDRfOzjO7sMyjrZy/fXwX9yxZWnGDufoach0hNgcMuByXdrHtJs6CylLQIS6IyIcnsM5ya3eOR/fMM64zFpuP88JKTiUOmWjUiMKilM/5dtdDjQb1eg2tNdVq9bi2wB4Y9yOBrCjBOFeKawmBc77vy9g4//7n38ojv/MxHprYRBYkWF30nzYB2lmsUYQ4gpkdnDpzK+9/z//FxPppAlvwZYsy6l4PA8C3OCha/KqUatKk4pYR1cYEGZJXWMgs3/hGhZl5uOpyYdtEi1hyoItEe6nEazDOoJyikI8Cgl6LBYfXN9VFqGT9xDT/zy//M7L/8df87X3fYX77S3F4IcvMQS6KwIFUq9isi1iDDbRvFia+QhYrOJWyNLqGhy97I+/5yN/wqhs+RyCeUyoiWOuTsy94wQu46qorWbNmja8QPgkaMp3sOEj/+EkOvYiikUQ0QsEYw3hgGHUd0kKNzNqy93rB+bYG8i6xZKxRGZvCjA0JrKvHDNUqrLARVhAEmiiKcNYgiUbVLESGoZqlXrV0U00QuIJTDlFgSSJDpAyVIMNJgAoFF4QkSUQUhQSBT9qXqftKcWuMIU5bjBuFsoZR16WapRgdooxBxAuAlBXmOAPG+OWqtX5TChfGGGdZ6IS0u4qOMuxd6jCTtqknERUtuCj0gR4HSiviOCLOokI1yh72NzkWXvzAuD9DHBAvtl6yzhGwffNG3vfTV/GeD/wp+QuupYkGp3yoQlJyHZN0lth0y+f4/37xpWxYPwkmwCnXu2AIqsdEKBd3zi8RqFXHWV5MkanI9/7AIKL5+rcV13//dMKhCo986mb+9ZsjquL3GUjO/KJieHzaj9flxXufzFwpJ54joDGU8O/f+mPc/9/+lO9NvpD22DjKOrQKPEPC4GOgKkClLUwQ+XOioGAYJWgT41zO4vgmdp3zY3z+O5/gL/7VO9l25ha01uR5zuzsLDfffDMf/OAHufjii7nuuuuoVCoDD/44o1Q7gtLIeMMtOqAax5y2ZgRlMu7vhjyyFNLKveNijUOJY4IOw2qZTbFw+tQQp48EjDTqBEFYxPNX2Dpl+YggaB0RhpDrCtZVcK6CqBZhlJKZgOW2sG8uYrieMtrwxt0540NC4kAlBOEIKhxCSjZWr4ulKxfYWOeIK1VEhDW6y9njGRVleBjHoumQGoMojdNRoROo6Slcea6jL4SimN9BTFodpUmXR01K0E7ZGMWcUm8wUU8wDnLrz15jDLNzc4SBN7V5nqO1v7Ada0dm4CYdIfqVcGyx7EO0L9FXBiXClVdcxM9ddTEqSXAu8CeN8qEKdM7Qjn/kLRes5cKzTkfQiHjZPa39UtVz6v1PUvgQlF79ttPOZcdDNdIgx6oMMQGOlMVlCGpjBEMNOq0qeZ6hJUXrLpnAPQ/CKWecjVI5QgBFi+JDfT4RwUmOwjG2bopfftWLGbrnayjJKIWNxQpGeTEOiavovNXz/p2UISwQEyPOEZk2zTVn8PgpF3P7D+9Bex02oihkenqaV7ziFfzar/0ae/fu5f/8n/9Du93uiXwMcPwgZWDG+epNRCFBRK2ScPa6Ma7dPs1568cYTiJC7UOUJrdInjNNi7P0Ai+sdDl7/RjnbN/E5ulJgiAkd4Kx3nnw540tmpAJYZAQhlW0rmGoY1wN0Yoo7qCClMWWYtdMzMxCSJY5HzJxBuusVwwLquh4giAaQVToDbtzWGuw1mKsJc8t1kJSrTEyPsG6yVEumarw0umQcxqOStaCdhNnTGHcI0QFvlVxGbIqjbvJUTbHhhW6jQkWK+Pcb6rcvBzyiEmoDI+wdmKMNeNjjI+PMTIyQp7n7N+3j/379zM/P8/S0hKdTucpvfijhYFxf4boFyR2Ct9xsbBDVYlZs309rpL48n6X4ZSvAY2bM2zdcxuvfeVLCYIIqwJEm168c8WwF0nG0nl1gBW2n/UCds+fw8NzYxgBZSNQmssvyUnsTex/4DZ+5DLHUDUCEXIX8fD+DexrvpBTTj+96AYZ0msHycpSUCnlNxECBO1CFAlXXnoJV+f7qC3OgOe5UF52vL5JQpB3vN6qlWI56sCAUR2yENIgJhVNd2SKxxf3rZzg5X4EhoeHedvb3kaj0eDjH/84WZYdr5/znzz6NVgP+oO/UYo41FSjkCQM0HqF0+2sr0ROxDEcOIZCoVp0ngwC/aQS/YMOgFIKrTWiY9ANnBrCSoIxGmuL44v1YZOeJx5gqGKkhqgqQRijg7jnFB3mUEgh+RcGAY1IMxIH1ANF6CzKmqLFQtHLvr+tAAe7Qv41TjRWaXIUmRMMyksLBpogCHpbmUQV8SGuLMvI85zjgYFxfxYoTwhd9HhWVuGUIw+8dqlvrKsQchwZKteEOx/iR8/YyoY1E3jNVovXGS0n8cEnmsOrvCtEWSqNUV503Tv57PV1lttDYLtYcrZMOn7qxzJedEGTF12638fjnaGZVvnsDcO85FW/SFKv+iQtttBfdU9y3sv4qVVFJ0DdpVarcu2Fp8POB8BplBOsLrpPKghUjOTdoiWsLwF3gBONiEXnCshxkhG2Q4ZV1LuQlJ+5PH2iKOInf/IneeKJJ7j77rt74xp48McRRbJTemHBAkEAUeR7qZebc9BtEWQtNlYU503WOWOsSiMOAY0SjRYhEEEr6f3uIv7ioLUijgMqlYi4volg9FrU6HW07LnsmZ1kbnGIRtJl6/QMUyOLKMlJM6FlN7DA1Syqawka5zC+ZgMj42uIkkqRrhKU8gZVK0UQKAKte8pgUaCZHm6wdXKU9Y0K4ypjxLZJyHHi+fS2ZM04igJEhVUK0YHvZlkW9DlItNAINdVQE4QBEoSEUUQl8dqykxMTbNq0iTVr1mCMYW5ujuXl5eNi4AfG/RngyR6O/6FFCUoUgmJhsYurxCgsRiKU86Z+ePd9vOLSs4lUUDBvVv4d5mh+8yoeKCwXXX0N0y94N3/+6Sn2NicwVqFpU4kWiIOMQCwoYe/CBj78qTG2XvB2zrv8xUQEKAVOlcngA5t6rXwuL/fn2Vz+s1168UVM7noQoYnBgpWiuVqIUdZ3pFQhTjkQg3YgzvoOlc4VavWOyvxDbF6/GVdIGq60bVkR96hUKrzmNa/hi1/4Amn3uKrXDUAx44oVHBTXf/ExaIIAwhDCwN/HQdZBZx2mEuH00YQtQwm1MKBU4vLMGFYuGFKSBcT3Y48C4iQkqq5FNy5G6pfTdqcyMz/K4nKNapyxbnyesaFlz8gyQseuYVkuoKkuRlW3Mzw6xdDwOGEUFx+iPJbqGXitVii3odaMN6qsGx1iTS1mWHIatkvk8qJYaqWlgO8bU7TUFuVFTMo4uQOFI1aKaqBIAu2FQ7RGhyFRHFNJEkZHR5menmZsbAxjDIuLi7RareMSlhkkVJ8hDjDwjiLhCT4dKuTG+HJoZ0mVoKwmdF3WZ3Ns3rqlv+b74D0fcF+KRKpzpTfikDDiJ9/4C3z1yxv4g0/9V04/pcYFpxrmlzJazYiHdlW5617DPY9s5YpXvpuLXnItEpR6piXdrVwpHGop3u/Ra7SDjRNjrCPlkbSNi3283qesvOprnFpC28K4AFziv5MgRUxMpjSBhUpzho1LOzj9vKuL8NPKGPopkEoptm3bRp4b9u3bx4aNG57LTzXAs0X5+5QPy/sOnCt7BHlJxQBHrIVKGJAE2jfTwsfYjTG937ffgXjy1FdESQ0lDpOtxWTbkbyNYgkVtFFaI5FXXAqSzejaWnQ4TBBWvZKTA8wKS7nEAbmbYjXirC04514uMBLXK5oqhxViiTFYlyN5G5sp35vJBT4MmxtUbghJGQ0cU2HAaKwJtSoIC/7LcsVc74U9+1at5fdT/v1YYGDcnwv6IygFKkmMWc5w5ID36vXCDOeOCNXG0GGZIIcOPzz5tVEY8GMveymXnX8h//i9b/PFO7/CwsIiy05YumOUs89+Mb/4tisYGRlH2whnXPErl3S0lcTw4eF6l4J6LWBjxfL9bocsEV/EpcTrzdouOpsjEENGgCLDKW/ktTNo18RooXHvl3nT+VtZO7H2SR+pn30kIgRBwPbt23hox46BcV8lEPAxaecwxaYwVFxOFRiNFVONhEocESjBWEO326XZbGKNRSlFULBFfMhkpYBNRFA6YnR8HdbmdGox7cZpmDzFNmehs+zl9OIaWofEtTVUhzahg4Q4qZNnaTHCMo9Ej/BgjMEYr6QkvVCNkARCGERUIs1oYFnShrZyzFoQ66i7jGHXwRmDaQs2i1gOqsyFwxgUQWeZqLvMSOg4e9px4VCF6dGEehR6bVfAlT0dilBXoDVhGBJFUY8tlmXZkwqbjiYGxv1ooSgOqlUSXJphRFAOcm0JlhbYNl7tTfB+zutTGftD/U2cgFQYXhPy0lf/FD/28tfjTJdcgVYh2hUC3kqRiy3EBATnDnElOvSBEcB6eXeILOvHa6hOGxlRaJeRicI5IcmXmLzrBrK9e6hsu4Sl8VFyXUXbAKOF0Fhq99/N1a3HecNr34rWQf95eEiICBMTE8zNza2scgY47pBD3rpymiOFClIIJFpTiwLiUKOl8EpzQ7fTJc9zgiDoeam6iFl7j7X0bDWVSqPMvpDLJJKnKJlBBUsoHaGSBkpHRPUhasPjaK3B5Vibg3M9AY1+NltpQKGQ+FOaMNAkYYQqPPdEO1/pXdaUOoidpUoO1mGzZZwNyK0DKr5BdtoiaC+RIExFCVsaEcOVgChQuELToSRk+tPIh6F0sfk6D++5r+SfBhWqqwt93q+f9A7BopwgBEU/yAxptZjYMEFprcrf8dZbb+XrX/86U1NTTE1NMTExQbVapVqtEscxcRz3rvT9oQzB4NBoJ55xowNCsQVlywEBjhY4wbnIx8pZ8ZCNyel0OrTbHVqtFs1mk71797Jz504Wl5u85Q1voD4+DC4gU4qxWh3V7XiKoyulwDVDlYQ/+vl3sHd2P3/+lS/wnfsCupvOg/FTUKaD2nEjlzQf5T/8i7cwNLa2l184eB7300ydcyiteyfI4XMSAxwvKOjFzsu1n+o9v+KVKqXJshzjoN1p0263ybKMKIqI4xg/9/Pi9185D3y4wnu8abdLbjKsNSgVEIQVlAoQUTggy1KazSXv/btelLznvPSHYvpDQybNPN89DKmEiiiIEXzCN1DKJx+NV3iqxZpxG1ONQ6aHa1SigCdS4YHWHF0HY3XL2EiFiUSxdbzO+EhEpVJBq6cWqLHWi5WXVNDDMpWOEgbG/TmgVyzRF8tOkgRrllFWYwJL6Awmy2kMjfmka1GdCY677rqLbdu2MT09zZ49e7j55ptpt9ukaUq73e5Rp0ovXmvti3xUiJOMwCmqlaGiV0yIxvgWvM7QaeEVl8jITEank/rJ5RxK+XGGYUQYhtTrdSYnJzn9jDP4yje/xa7duzl9fBhxYFA0wgSVmgM9bucwkhOPhPzIhVdwzYsu57Y77+D//R9/zHy8hqkRxcvPO4M3vOwXGR0ewqGKjpoHxvwPFR5aWlykWqsNDPsqgAho5Q1gUHSE9FwwH6cOEKIgIIliBGh3u+TtDq1mk/mFBfIso1Kp9Faqnu/u5787wDkqqzpWDJ4OErROVgbjHJ1Om3a7dcD4invF4wNzOuX51my3aXe61KoVhmsJlSRGiRBpRaJ9tbnkOQGGiWrM5mqD9Y2IF28aZn095t5dM3z3wcfoZDnbp6c4Ze0ktThiy8Qw4/UqSkmxmugv1pLeAEv+fZ7nWGtXaKAD4756URp4ZRWOnEqtQtydYVFZxOXkLi7Ub0xBTTowobR582bOPffc3uNyyVZuZcywjCG22+2Vi4pxNFtNbJEk6p/UlUrVJ1LFe0aVSqXHtz04ydMrYHKOu+66mzwr1gbiCK2QaVMUJhlyCXxPG52jnCOSAE1AEAsXnXc2P3nJC7nwkks56+yzSKIIpYpK3cJbO+z3WJwUzlh2PLiDl7/85YOQzKqAZ3R5xkuZXHW9dhxSvkIpcOWcteTGYPIcY8xK0R8rxUzQx0jpedu+55DWniKslEakWMU5Ly9ijcEUvdb7efT9c78MdfTqUfAhmjRNicMA64qQKIX9LQkM1tdd+HCNphEHTNciNjQiFueFNSqlozLWxpaNtYAkDhmuRCRx1Ps85X57J7krQ1nugGTvwZ77CWk/ICIJ8A18aWMAfMI59z4R2YrXkhwHbgbe7JxLRSQGPgxcCMwAb3DOPXxURrvK4D1Li0V8ktw5RisVVDsFaSFosEKWRMwtz2L8Mz1DqrUmTT3lr/8HfaokS71eP6If/9mow1hrSbvLRJUQcQqD73M918oxUVwGlRArOGcIlSJJSgoaaBVw7vnnc8dtt3HeeefSK8pSK2M41Hj6J/aePXtYXFxk/fr1RzzuAY4dBAiUEJabeCUlgBSh66BrfUM4H19WBFqIo4harYaxhka9QaPR6M37fhpg76LeK6iTIiYPnjLrFeidW/H8nbMFi6wcYd94D+G5G2Mw1pEbQxh56UdxjtxZWsbRtI5UCU4pyopE5yyIoKMKQaXKyNAQW6fG6KY5k40aSaCJtPRoo+XxDliNOEe326Xb7ZJ2U4zJPW1aKbTSq8Jz7wLXOueWxTdw+JaIfB54L/C7zrmPisgfAu8A/qC4nXPObReRn8ELC7/hGI3/BGPlSu3Ex9sbcUSUg1M52BCN4GoJO/fvxziH7vsxJycn2bdv3yH3fHBzp0M9/1Q4VM/0p/wkzmFMzvz8PEPjIygrGAXG5Ty8dz/5KQ0oetZoF4LLfXWf8ga81JI855zz+PINX+bRRx5h6ynbVjyT8ns6zJjKk/5zX/g8l1x6KdVa7YjHfqwgnox/E7DTOffKwzk0J3KMRxtPYikWYZlIKyJliXBEOK/Q5KDjhK5xdHNDUNR7KOUbZllXwznH8PAwI8MjJ6wpXJ7ntNOUTrdLGPrulDhLbh0t61g2ji70OrG6sp+MKHRcIajUGRlJ2TbVIsszarUaSaAIdLkiXcHB52273WZxcZE8z8mN6VXK6qBcoRw7PO237TyWi4dhsTngWuATxfMfAl5T3P+J4jHF339EnqedoFaihP7W4qgmEaEziNO+8EEEqdS5f988poifg58E69ev57HHHuslfZ4LDpWgeaqv/eBJ6Jxjbm4e5zS1IS9koJ2hs7zAw80OLinUZsRB0R2wJoZKHIOzvf1VqlVe8cpX8ZGP/A3z8wveaBftBsq46sEoj//d736XPXv2cOVVV66WkMx7gHv6Hv823qHZDszhHZnnPfpb9WqhiLvj8ygImbF0s5ws92TzkhHjL9ilR66O+9ZbKRQMMKX989Y533fGOlIrpE56mrLgL2g90nARNw+0Jo4jkjhGK78aKNk45Zbn+QHPpWnae75kxkRR1OvvfqxxRDH3woO5GdgO/D7wIDDvnCtraB8HynX0euAxAOdcLiILeE9n/1Ec9ypBnyF1gAi1epVY2oSpIYu9wIdUJrhnWVhaWCKeGOv9sJs2bWLv3r0sLy8XvagPQ398hhPh2Xr3t99+O6dtO504CrwhzmHHQ3t4QOqga4hzuMAryzubEduUKApxhXEvPbNzzzuP3Xv28L//9//mrW99K2vWrOl5Qgcb7TKX8O1vf5svfelLvPvd76Zerz/rz360ICIbgFcAvwm8t3BQrgV+tnjJh4D/gF+tPm/huzcqCANibaiIoUqOlYimxKQIc+2Mx+c6NJKIdRNVKtUKWZ7TXG6RZhmVpIIbOTD88qTjPMffuXQQ+h2cTqdDs9kkzw3WeEck0Jp2N8e4DnPtnH15wD4jNLXGKRBxRAoSBbHGq04BUZwwPDaByXOWl5eZnZtHlLC03CyYQqrQJljpIWOt7YVlgiBgeHiYJEl6DLhjjSMy7s5nM84TkRHg74AznuuBReSdwDvBG7mTEWUPrrJxmENRqVap0SbJLXmUY5UmCyrsCSe45977uWLi4qKjgFCpVtm8ZTO33noLV199Tc84HmvhikOdYN1ulxtvvJG3vPHnvFasE5zTfOP7P6Q1dSZOa5TkGCc4sYgzVJQrvJCV4ihEEKV56Y++jEqlwgc/+EFe8uIXc9lll1GvNw6Iv+d5zs6dO/nc5z7H0tISv/zLv8zU1FSxmxPuuv8e8KtAKZA5zuEdmucvBC8ArRWhEmIciVjaCJaIHMdSt8PMUhtrYZ1SxLFv5NXudHy8OTswcnWoMONzmfMHx/HL/aRpytLScvE3RxQEKKVIc0NmYSm1LOaKBSOkZVdTAa0gUhDISigxCCNqDY0xOUvLTZaaTZxzhEG7lwSO47iXR+t2uwcQIyqVCtVqleHh4R7z7VjjGbFlnHPzIvJV4HJgRESCYrJvAHYWL9sJbAQeF5EAGMYnVg/e1x8Dfwxw0UUXPbeYxAlCGY4RKQiRLqCSVKm7Ds44DCBWyEJLZ90L+Py3buTiSy8gDBxIgBLFS178Yv78zz/ERRddTK1We1L2/HgYeeccN954I+Pj46xdv77HL59fnOOzdz9Efv4bcEEOuUJZjVUGl+WMVqOVZlB9Y/WMg4BrrrmGM888k8997nP85/e/n8nJSdasWUOlUmFmZoY9e/ZgjOGaa67h8ssvL4zCCTfqiMgrgb3OuZtF5MXP4v0nveOyAuklAZXy1RsB1setVYDVjsUcdrdzjM7pGuupkkoIwxBTGLdWq3VAp0Q4unO7XIU65xk1nhOf001TnLXESUwchmTWMdfJ6OQpMx1LV4WYAKzoQpTDocUnkQNVdmsVRBxKBKc0cZLQaDR6rQzKVWuZIO0vVizHFscxQXFxORqr8yPBkbBlJoGsMOwV4GX42ONXgdfhE0xvBT5dvOUzxePvFn//inuetvY7IFlffEKtNdM1jbPLiIuI8gAb5jTXbefz3/gSb9/xBNtP31yIeGSsX7ueU7Zt4/rrr+fVr371cUs69Rd7zMzMcMMNN/DOd74TCbWvC8HwpW9+k7uGN9Cp1zHWoF0EyksBqk6X0Ub1SZOyP9SjlGJqaoq3vvWttNttdu/ezf79+0nTlFNPPZXJyUnGx8d7k/54XNCOEFcCrxaRlwMJMAR8kMM7NAfg+eC4lBABpTWKkEh3qUpOjYylQCFhlUwcDzZn0UstNnfhtE0ZG5whCBTVeh0dRaRZxq7duwmDgPHx8R5z5uiNcSUUY4whTVOMtSw3l5lbWEAE1jXqjI+Ps3+5zd07d/LY7DJ3ZTXm9SidSohFgc0RcmKBWqhJtOppoirx8oNKKybGxxgeamCNb7NQhmDK3FnpwatiFROGYc+zP5xxPxY4EkuyFviqiNwO3Ahc75z7LPBr+FjkA/gl658Wr/9TYLx4/r3Arx/9Ya8u9BtKrTVr6zE2baPQWCBXGd24zq7Nl/Gn13+BLOtilMEqwQaaV7/61dx9993ccccdT+oWdyAP+OiNE/xJ0W63+Yu/+Ate8pKXsHbtWnIylHPs27WTP/rG7TRPuZRcBRRtJbHiaWhha5nxRu2wrJyDjXytVmPbtm1ccsklXHXVVZx99tlMT0/34pXle1YDnHP/xjm3wTm3BfgZvIPyJlYcGjjQoTnpcUBCvn/D0xt9t0gIxHdU1yKgA6wKWMhhVytnX8d77jjv2YeR76VirKPVbNJqtcjz/JivRo21mDwvPPcuaZqhCtquBCGznZzHF9vs7+R0JcToGCe+AEmc99xDKT13ACnqRQStFEmSMNRoMDQ0RLVaPSCOXvbRieOYJEmo1WoMDQ1Rq9UO8NwP3o4FntZzd87dDpx/iOd3AJcc4vkO8NNHZXQnIZRSTA03oN0FF5KFBqcsYeYw6y/kk9/7Aa/4wQ+4+oJLsNoiKOrVGm9+85v50z/9UyqVCqeeeuox++H7QzGdToePfOQjTE1NceWVV3ovzVnaJuMP/+az3L3mAvLaWgRTdGq3OBQKIe4sMDk5dIBh7ucXl7dHmkBbLYb9afBrwEdF5D8Bt7Li0Dwv4aDIoQigUFoRKSFR4uPR4vufL6qEXWqI2ATct2+JxKZEWpPECUmc0Go1aeUZxjmWlpcxxhAEgS/ZLwzic/ForbV007RXqNRqtshNDs6yZmwUROhkGY/u2c+jSykPtIT7sgp7g5g8DhEJcFkKuUEwhAJJoIhUSXXsJdU8+oZZhmDCMCQMw179SmnIj0ds/XAYVKgeJZSGTERYOz6MfngZ5wRxKZgQMKRhnfmzXsr7/uZL/MX0dtZuHEI7bzDXr1/PW97yFj784Q/zile8ggsvvBBd9Fgp93+04JxjcXGRv/zLv2RkZISf+qmfKo4F1io+8aWv8aHHhPalF5IFDnEWZxWQ4pxn0oTZAqP14WPG5FktcM59Dfhacf+QDs3zEUVPQwBffar8qjTRQlULkfbMEoOwT9WZDaCTZXz/8VkW9nbZsmaci0/dRKOSMCP4dhrWMjM7y35rqSQJk5OTVCqVnqf7jMdYnBt5nrO0tES7aDHg2x7krJkYZdO6aSywY88sT+ya4aG2cNNiwF3dBrmqkQYRWodYk2GND8skCuqBphKoA+pSDjDyhTOTJMmTCrGAJzk6JwIDsY5jgKnJMXRrHinK97UEGA1WCUtT27h/zQW873//Jfvnl8ixdJXDKGHr1i380j9/J1/76pf5yEc+wsLCwgH7Pbhc+5ltFucM1mT88J67+b3f+122bdrGT//UGyCKMCLkLuVr37mRD3zhe8ydfx3dqI7Vac+Dcwo8I1hBZ4Hx0TH8nw5MAh8pjvWydIBnCcdB1l0KY4ZvtCWl4SiMq2i6KqJFwFzXsr+VstjNySyeES8+Vq3Et9bI84ys4ISXbXnLNgUHbH3z15bbQa8p31tyzPM867U9wPkLkihNO7fMtlLmOhmLRlgmpENQ1KKUH7xIBlMkVOUQvef7vqL+ZGrppZfbc12NHA0MPPejgP7wg4hjzfQUleVHWHI5zkUYydAWjFjIIxZPPZsv3L6P5Hf/iv/47jcxNDaOUgYRw/SadfzyL/9LvnjDF/id3/kAV199DRdffDFDQ0O9Y5U4nFf/JCNbxCEffexRPv/5zzO/sMjr3/QmTtuyGaczlLW4XPGV793M//uRL7P3outo1Sd88ZG37L6iTzSKDkJA2F5gbHSo3P1hT4KB4T55Ubab8O3ehFAp6gEMhVDBICYDNCrQqKBK22nuyOvsTDW7ZyzqgSeYiDVjFc1Eo47CkaYZeVHs1G63aLe9GEfJNFF9mqOlrq8rBuNwuEL4mj5D76wlzzKctVSCgMr4CDjoOLjr8X0s547v7O1yx6xmzkXs13WoJRAW9RzOgjO+GA9LEkA9VFQCOchzX8HJMKsHxv0YYKgxzLhZZB8WqwxYULkm1QbtLDk1ls55GZ+461ssf+DP+Y1ffA0bN28mxycX46TKT7z8NVx2yRXccMMNfOADH+CUU07hoosuYtOmTb2l7FOh9GoWFue46557+P6Nt9Bpp7zkRS/i4gsvIkoCEAMuJE3bfPKLX+f9X7mHmQtfx/z4FDgInCNzGucUIhYn4FyAkNPoLjM2XDlO3+gAxxuu79Y3+nUESlEPhaEQEmORLPeJxihARwGdLODuThe6mv2mQ9zaxVRouXjLFKdNThNqTZr7StZON2X/3ALtbndlkSBCGIQERTFQEATogkVVtrcwJifP8l67DGMMSoRqFBEGvpnXSH0IrRX37p3nnif2s79r+eZ8xPeXArIgJB2qQVztfUJnDb6UxyBYYg21SKiET24vQDHOkwED434MUK/WGKeFsykuDBDnm21pbXBaUFlERpX87Gu4/sHb2PGB/82vvP6VXHfpBSRx5KtalWPNmjW88Y1vZHl5mbvuuotvfOMb7Ny5k3q9ztjYGFNTU4yNjREEAVEUkWUZ7Xabffv2sXfvXmZnZwkQTjnlFF77yp9g05ZN6EAhhRaqI2DXrl3897/8DH85B8uXv4ZOso5cHCEOU8YNVY5zRSsFNMp0mdSGahKe4G96gGOD/thy+ZzgzbwrWhAUL+hvlCWCUQFORzQxzJgAEcPujuWJ5Yw4MChnUc6RGofrq2ouecVa+RYHUrQ5UEXbCttreYAXBCmO54rQiHGAdbjMkndyUIrdHcuuVDGbCYsuoKMijAqxRW/43nF7YaiinXHBlFFy9Dz0E7GCHRj3owznHJVKlar2Jfp+8its4GMX1kJbO7TrEpqY+a2Xc9/4Rn7141/im1+7kbe/4Uc5/dRtRIS+kZEIjUaDyy67jMsuu4wsy5idnWXfvn3MzMywb9++Hre3FPdYv3495513HhMTE9QaQ+ggIBCKpadXrVlq7uezX72RP7r+Ru7bcgGLF1xGHoQIXQKnMFZhRfAMGYMX1fanRNhtM1SNqFZOfHOvAY4x+gy8AkIFkfh20FJYRWeNn1oAlRrEFfbZCt8xEUmW8+Auw61zu6gHwvZGyNqKJtbCaBIznCS9oiGhCO8Xhy5j2j0Kr3PYIMAV4ZTcOXLrt4WuodOxzKYdHlpuspw7dnQ197brtJxmj66SDSdFjF1B7i8ATpfV1Q6xOcr69gOVMCAOSknAlWvAyYSBcT/qEL+M1QrrcrRVZAqsyhAboJzgMJgwx1mLtiFLwxtoX/M6/nrnPVz/Pz7Hj6xr8FM/dgXnn34KtVp1Zc/iq/6mp6eZnp4+INZ/OK55juCwWJtjreOJ/Qt8+ds38clv38pdyTrmrngz3Xgcq4raJfFtBxDxmqhWcJL4E89ZHI6o2yWINEEYPemYAzxPcAhLJgK66POvSne3MLrO2qI0OQYRlrKAhVwQkzM7P8/OdIGhwJGtqcJwxFAlZLQWU0lCAiUkuhSw9rHvA+e1FIcpuffe4GZA7qCdW9JOl6U8Z+dyxs27m+zrGh5jiB1SI1Mh1OqQVLxaWZ4VcXYA3bPc4rwYSaA0oRZCLb22gEBfi8CTAwPj/lxwcN6yWD7OzO7msU6EDhJw4sMgRdyyKHWCXEAsRlkkN3SDOt1tl9Dd8AI+sfNBPvsX/8jp8g9cc9ZmXnTu6WzfvplGY4igEBjWIr5cGsGK38rFpvRRxLI0Z/f+vdz5w/u5/pZ7+ObjS8xObKVzzk+zNDyMJcE5Ra4MYnWP3eAlzIoTyXl5NGUCTNjF6IT5jqHdaRPEET0qsBQLlaO4nB3g+OCwRCe3EnrJjGUph4UM2lZWvOCSLQUHzBvRvvthlwqLDGG04+E8wLYVdaOYUzmNyBErqGu/UNVFKKaMYghF7xifUcU6MMVt20HXCh3j2NOCxUyxpxuxWwkLgaMlVZxEoIKVOV3E7qX/80GxZPDSmO3csth1SGAwRR/5fvJQOa7VThYYGPdjgBvvvId9tbWgYx8LxBbecA6iEKd89LKYLVmg0VYRdh2WKosbTmdp03bmmk1u2f0g/+sj32Us+yLbagGnjtfZODnC5PQaRkdHGalVqcYxzkGz1WKp3WbvzCw7987w8O69PLg/Y4eLWByagHWXYjZtoJk0yMTTvhwOqyw4wZUd0LDeUJdMWeeLmMrJnFdrPNyOuf/RhznvrLO9fCC+kvFkW7oO8NQQHK4oCGp3M3a2HI+0YFYrbBCABDgpjW+f2pAIKk4QB8u2QtuOoZ1lV9om6aREGIb3tImwNLRlPLBEApVQUwkDr9KrfFdGB74lr4OusXRSQ+4cc7mwkEOKYt7GtF1EVwU0dUIeKDKlcSpASWGYTV7MTx/vF0CVKwTRWB2TSc5Mp8WjCx0mnWJtbn3nOHfIGqZVjYFxfy4ofuVemT1Cnlm+ePODtDdeCoRYLSjrig6S3ntH8iKk4neijcUK5IFCrMboEKM1ulYl3DpBa8tFzJs2j6cLfKs5h5tbQh5fJlreR5i2sa5FrgwuijBRjCRD2MoUZvIM1JZhWlGM0Qm5ChGKPvPOFQa9/wP1meaS39jjOSqc5OAURmvm153LV75/M+e+4EzvGVF+tpNl6g9wOPSc2b4nnDVe3CJ3LOdCV0rlosIpKPmKJaSQ3kPIVEjX+ZXmUsdAatDWUc0tgc0Y1pY1gSESqMchtcgnM0O1kjw1+NtOZmmlOZl17M+EuRwyNIsKuuJbE1OpgNaIKhTSAKwpVror41tZchafVmmsODrG0UwN9dwrOB3stZ8sGBj3o4Vi9bq0tMyde9t0t23wM1JAFwUY3riDwxZnkBc1sCpHWeuXnFrAaXQmWMlJtQICnK7TjoZQtQ0ol2ML+TFFDqSIC1CmivGSpVgcVgRxghWHttZ71zbzZePK61Q6imRVzyj3GefyLHfOrzjwIiRWoLX+DL5z5zd5VzelWg0LT9+/drUvVwd4epS/oHNef9TmKa3MMG81szagJQFOB4jSiDOIy/veVd76EE3JlEccEoagfJsLYyOcMyyLQ5QX3I5dRtzO0WKpiiHGkiN0UOROyCSgo2oYJTS1ol3IQSIh2pfRFkobZU6g/CC+oKog5ZSBI091dGC1RsIYK5pFo9nThSgVMtcj8hw+dLVKMTDuRwllvH3f/hlmVYwNEkQsYr0xlCKW7QBx3rBCUTmqLcoplAPjvPhwYIRUhSCCLvwWJxrnQnDe0xcRlA3RJkBUTqqbpEGCcyEKIbAGK8bHRaliraBICWwHgy0uEMXp1+/CF15Nv4kWh4/rW4WRHJ1UeSxLmJlZIElqiGKFE/xUVU0DrHr0/3QOSLOMrNtlKc3Zl2t2m5CORLgw8sbddBFTusjS904f+isa54ICiSJEIhxCVlSHdh0sWB8Tl+Ys0pojdI5Rl1Ejp4tiwQVkTmEqNfLaOCjPmiEIAIdyhrBI+PtVqW/766yUmSjKKtt+No4qbtEhLo6wLmPWBDzaFqIqpLYvoXqSTemBcX+WOJCd4nzc0QlLrSZNLT5OHQjKJZgyDFK68gWt0GF9HN46cvGeTbm8NdoROEdOTIZGkaGwODGYQBjqzhI+9kPCPY9Qsx0AluNh8vWn05nYQjusYpVDWcA6lGtiAzDKYUuigLOFUV9hIJSQ0lUpTgaFwzjPPNZYVJCzqBosLbZgfX9zJNdboQ88+NWPg1lWK4s173gY40v6e3JxfW0BvBHtTaa+vfTilUXystxpQZAvxF2cKgT7XLmahQghUhA6qIhQRaGdl8LTDlLxDBkvv+GTuv4C4pOwYq3fVzGkkm1zwDWn3wnpkRzLceDl95wlMxZjfVuE/i6ZJwsGxv0Z4nAnA857AVoEhffCU2IUOaF15IpycdpjAIh4r8aVsT9nvZSdOIyC0Gq0dDAqQNkcJxBnjsqem9l47xd5wwvO4so3XM705Aguddz3+G7+4Zvf44a7b2DfBT9BZ/QUrFIYAadyRAxi6IVWLD4JSpH09fO7ZMe4QtndL2+t0mijMdoS5AaokllNyxhycWgx3j9zBW/45DoPBqCcy76sv9lsFS16M1pLi3Q7HZbncqqdLiOZZaET0VIJVunCuBYsGdF4F92t+AyubzoYS0G6pWTKh1mbuLNI7HLOaVjOGYeKDpisVmhEmtQ4FruGrnE8sJxy2/xOmlaYC4dYCBu+HkMJthcaLD5P/2frpVL9By35Pdb5+e1yizMG51KsWcTYBdLYsLwwx6LOCKOYqFI94f1ingkGxv1ZwNoVQWhrLcvLy9x3333cddfd/PCHP8TOhdTyBZzWGFFoK1gEI16G1zlQaHDe43VSVICUCc6CtZIpATKS1JJLBdEZQztu5eLZ2/nP//KdnLH+FEzkUCoHG7H5lM1ce+W53PT9O3jfX3+O289/BYtTpxDYYv82KIhmyhv7XqqoNMa2xyN2CNaB4D0jJAPpomzgLzbkxG6BWIF2Fl2sAJwtvP2T5AQYoB9Fky5rabWazM7OkWUpzcVF0m6H1pIlTg1DOXS7MULFs2W08slVZCXeLfSK8FasbEmrLL1+7yrrziK1pV3UJOPCsRqvma7SiAOmRhsM1SqkWc5Sq02aGb7x2AJLe/czkzqyMGc+FJxoTBD4eDtyAD3zwKQpveP6YVifaHUO8gyyFOdSjFnCmGWyxNJcWmApMFRqdcI48boGJwkGxv0ZoL9Rl3OOZrPJF77wBX7wgx+wadMmzjnnHF7ykhcjf/tF/u7bf0u87Qqak1vJkhhDVsTLgyJBU3owFrHFidFbBXivWdmQLJAiZKNoLD3C1se+wgd/5S1s3LzOJ0yV9Rr01iDK4GLN5Vecz/tDx9v+4gtw5U/TrAzj0F4cRFkcOcp6D52eiff3Q1OEjJS/0LhirapNBM4S2pRKthe183FGdz3Ox//6Q2w/9XQuvfRyTtm2jSAsPZtj0654gOeOw3XvLIWdyy6LZQvrKI7RWjHiLBvbOXEMVa0JlSWXnFxUL7puxRXhknL+FI5DkdMRWZltShzKQTXIGYktdRwjISRaiLUQBpooCHy4RmucddRDYTLyydduYLBBhhGL0RYnqheq6cXZD/zkxfWnYLeJQ4kP8GjJ0dpQdZb1RExTYawaExSdLMvWHlproqKPzaGwmub6wLg/SywsLPAHf/AHbNmyhV/91V+lXq/3/va+X3wTP/qD2/nsd3/ALTd/hT02Zimsk4+sIWiM4eI6aVjBxFUypbFh5OmJSOG0O5xJqabz6KxFtJSj9z1GvP8WtumUheVFptUmlIIQhxBiAh9+0VZhTc5yu8Wm+Qex3/oo0dA6otFpbH2cNK6RhyGdqIILQmCFDumwPnlrc1SaEnY7RFkG3RZuaRaZ30etO8Mmt8AVp57OW3/rVxgbqnDvvQ/y9//wD2Qm5zU/+WpOO/VUNCvL12Mt+D3A0UG73WZ2drbXPhccURQxNjpKHEdMdA3T6zq0MsvejuHxZkpqYSmzNDOHcdCykDshd46MIjbu6PHKNa5QdPJ94QOBoUqHybojUYrThhRJ4MUudBhDXAHJkDRHI6yvBVw5EdDMDPskYz/L5AjL1idmjYPU9sfki4tK4cIoIBQ/jlCEStHLph5APYSKhq21MabjcWIN9UDopjntdIm5hSVEhPHxccZGRw9QVVqNGBj3Z4hy2fqxj32Mc845h+uuu+5JaitRpcrVl1/CVZdeSNbN2b13lp179vDQzr3s3PMEexeWmOukLHY7dKyl2e4WuR1v3JUI1WqFmlaMVwImxkc5/6ppzjrtF7Ftxyc//jH27Z3h2pdcg2iNFd+SNcoUHTL+4TOfZMeOJ/ij3/wNnLXc+8jD3Pvo4zw68zD75zostDq0Uke7k4Fa6RlDQdGMw4BqFNCIAkbiiImhITZtnWTL5jNZu3aSTRNrqcYVTJiiXMDlV05z0SWXce999/JXf/XXvPIVr+TSi1c0LVbr5B/gQGRZxvLyMlmWHSAZ1xgaol6vM5znTDba5HnOnoUm6/Qindww28lZUJbMOpZyR9dAjqNjvcF3vUWpFIYVIgVDgSbSMCw5UwpiJYzHQljI2YkOQIdI4BCtEWsZjjRba4puZplwhnm6pBbmMkvL+H4zbeepC1CuEfw98Lz5REEg/nj1QBGKMJooRiuaSqDZMFplol4hz3OazRZZlpEWnjsi1KpV7MiIb2Ugsmqdl4FxfxaYnZ1lz549vPGNb+z1oT4ADkARKEEnAVs2rWfL5mkuL57HgTUGY3Ksszi3kmAqO9NprVESEKgIEzqCQrFJsLxrwy/x+7//QabWTvLCF55XVPF1MUHAjjvv5957HuSfv+fdDNXrCMLmrWt5GZ4aZnKLyS3WZiv9QPoSoFJ2f1S+t3aoNErAKgDxlDftwzWapPe+MNScdeaZvPsX38Uf/OEfsnnjpl7/mwFODpSOi3PeY69UKoRhSBD4NgKiFEGheVuvWSatIzWWamoZy6zv81IY2NxBVjSp68vsFIQDCBRUtT9HapIzIjmBOEIFae4rufM89+IeWU6n0yVNuyilGBkdxVhHQsgwIbmDidyRWn/s0nOHA417mQYIhZ5OaqK9KEctUjRCRRQoGrUKcRwTBJ7dZoyh3W6Tm7LxniPtdtFa976f/u+wxIme+wPj/iwwNzfH+Pg4tVrtkD+g59J6oykFvdGh0dBjEGgVEIZB8foyLgm2iLe7goaIw6uWqpV2BcPDw7zqVa/lhhu+wgtecLZfObgQrONb3/kWL7vuOobqQ0XL0pLL7jnF2of9gYTSqD8pMtlfnVpAFaen6PINB79LQDmm105zyaUX873vfY+f+ImfeC5f8wmFiDwMLOGdwNw5d5GIjAF/A2wBHgZe75ybO1FjPNrwKkneoFarVSYnJ3sKQ73+6toLSUeVCmMjw7iiNsMUydGyTQCsGNiSq1IGSEoSjSrOEy0+hu6sYWb/DPv37yfNLY00o5rldDtdFhYW6XQ6DA012LRpEzoIfOte0d5pKS4k/riu78glVlqA9ci/Zf4X3+pAF0SAUKteH/l6o0EpS2kKjQRrDMvLy35V02g8rbbCicLqHNUqh7V2pQ81T32FPoBm+xQXcl/HV9IP+/bZ9x5vb73F37p1K81mk3a7XVxkFHneZWl5iY0bN6CfIqsvhxjMIePjB3yuQ79+5XO63svOOuss/v7v/x5r7aFXNicPXuKc29/3+NeBLzvn3i8iv148/rUTM7Rjg7K9bpk4VAfNozLGrIGYA+mGh9njIZ8tTW2/p2utZWF+AWMtcpDsXp7nZFmGiCIpVhSHjnk/+XgHPiOHe9kBf+6/W65k+jWNjTEHdGVdjTh5eD2rCEmS0G63fXEDKyfEU6FfL/RQ28Gvfbr9KKV6auv9cb/DjeOpjnnw/SPZnmp8cRyTZdlTtiM+SfETwIeK+x8CXnPihnL0Uc4rEenF3z3XPT8ux+/X/KUoSlJK+RChUmitMMbQarVptXws/HihDFmV53ypkbqasbpHt0oxOTnJ0tISMzMzR2TYjybKYzWbTYwxRFHUG4NSikajwWOPPXaIYqtjP8bS6O/evZuJiYlVP/mfBg74kojcLCLvLJ6bcs7tKu7vBqZOzNCODfrFnrvdLktLSywvLz+tcXdHsD0dVl7ri/l87kkOMOxKKYzJaTabLC83SdNnbtyf7Ri9rJ8X44YV476aV6Un9dl3opAkCZdddhmf/exnSdP0KQ38M6FK9b/2UF5yTwneWr71rW9xxhlnEBZ6k+V25ZVXcv3119NsNnvJscN50EebxlU2mbrllls49dRTV/XEPwJc5Zy7APhx4F0icnX/H13pXh4CIvJOEblJRG7at2/fcRjq0cEBcXU8e6bcSnpkqc3bL05Nn8f95I0DN+tw1vX2U3Lq0zQlS1NcEfIsPfbygqO1LmLb0gvRHGp8xliMsVjrelt5TP+LlXqsxb/+seJFR8qtHJvfrzng/DkZjPsg5v4sICJcc801/Nmf/Rmf/OQnee1rX0uSJM/IO+6PcR8J+g30zTffzG233cZ73vOeJ8X+Tz/9dLZt28af//mf88Y3vpHRgo/7dGGbowHnHPfeey87d+7k9a9//aqe+E8H59zO4naviPwdcAmwR0TWOud2ichaYO9h3vvHwB8DXHTRRSdNTCpJEiYmJgoKYJOFhQWUUrTbbaIoIggCkiRBa90ztiWL5mDHpD8Z3y9wbfsuDGma9m5b7TbWGHJjqFarRFHUi/lHUcTo6GivkGh5eQnnHJ1Om4WFqJcfKOmbpcPTHzrpN8SewNA3Nx0HGHpTsnTy3LNk8pxOp9Mr7ArDkFqt1rvorFYMjPszRDlB4jjmbW97Gx//+Mf5wAc+wKtf/WrOPPPMwyYQD5WAPGxSEp5kiJ1zzM/Pc/3113P33Xfz9re/ndHR0SftPwgCXvva13L99dfzO7/zO1xxxRVccskljI6O9sZ28LEP5dEfCgdX6PbDGMOtt97Kpz/9ad761rfSaDSecl+rGSJSA5Rzbqm4/6PAfwQ+A7wVeH9x++kTN8qjC+cccRyjtSbPc1qtFsvLywB0Oh201sRxTKPRIAxDwjAkjmOfXC2Mas/A9xn33mqzuO2vgC0NZqvVYmFhAWMM9Xqder3eu5iUxr1er/fe1263D6gY1Vr3LghBEBDHcc/wlnO+HCPwJI+7f0VcVqPmeU6322VhYYFut9v7e7nf8hirGQPj/gxwcOIySRLe9KY3cffdd/P5z3+eT3/601xwwQWcddZZTExM9CbAAQa1oM+ISK+0v9fUqM/olp5Dq9XioYce4pZbbuHhhx/m/PPP573vfe8BFbEHG+wwDLnuuuu48MIL+da3vsXv//7vU61WOfXUU9myZQvr1q2jXq8TBEHP+zr4+Ae0nCmYPOVr+hkDzWaTBx98kK985SsYY/iFX/gFNm7c2BtX/+1JhCng74pxB8BfO+e+ICI3Ah8TkXcAjwCvP4FjfNY41IW9P1GvlCKOY+r1ei+XU/6tnJfle3uGszDqB/zWZbV1n3EvQzFlWKbcf7nyrVQqJEnSM+wlyvtRFFGtVsnz/IAxl+dA2ULBx+fNAWMXkV4c/2D0c/zLMEx5jPLCUG5RFB02pLma5roc6TJdRDRwE7DTOfdKEdkKfBQYB24G3uycS0UkBj4MXAjMAG9wzj38VPu+6KKL3E033fTsP8VxRn+IpGwiZq1l165d3Hrrrdx7770sLi5Sq9UYHh5mamqKsbExhhpDxFHUWzaCn//WWTqdDt1ul/n5efbu3cvMzAzLy8t0u13Wr1/Pueeey1lnnUW9Xj8ku+XgcfWftGmasnfvXu69914effRRdu/eTbvdJo5jkiTpnchDQ0OMDA1TrVapVCo9DwUgNzndNKXT6TA7O8vOnTuZm5tjcXGR9evX86IXvYjTTjvtgBxA/xhPJC666CJuuummEzKI1T63D5V4d87R7XZJ0xRjDJ1O5wCPu58lBn3sQSnFMKRn2Mv/S+egvOm/kARB0AvBlHNSxIvBl/TD8lhZltHtdnvhnCzLehec8mJxIOvmqT58/133pDGWYxMRkiShVqv1zokoOrQ4/PGe6081t5+J5/4e4B5gqHj828DvOuc+KiJ/CLwD+IPids45t11EfqZ43Rue9ehXIfo95TLmppRi48aNbNiwgVe+8pV0u13m5uaYn59n3759zMzM8Ogjj/iJaVZEd3EOUb45UxzHjIyMcMYZZzA2Nsbo6GivSOJQ4ZRDjetQ9+M4ZuPGjWzcuHElrlh43cvLy7Tb7R4zYmlhkf3799PtdsmNIU27CIJxvrAljmNGR0e59NJLmZiYYHx8/Ck9mQFWNw7+zcrH1Wr1AA9ZKUWapn5e9CVWOYQR9XN15bErGnaVf1Oysjook7i1Wq1n5MMwfNL++r30OI5xztFut+l0OgU9stVbEZQGv3S+cAc6Pr1x9d/vG2M5vv7xVCqVVV2wdCgc0UhFZAPwCuA3gfeKnwHXAj9bvORDwH/AG/efKO4DfAL4nyIi7nlEdobDF/GUzydJwtq1a1m7di1nnnnmU76/f+Id7mQ71DEPZ0yfKmbef6IMDw8zMjLypPE/1U91cGhqtS9NB3huEJHexbtk0vQXF0Exd5xb8dw5wHHHNzwtqI3F3CiNZxnmKL30p5o7B8/LMpFarp77LzqH9OB7N+7A+wd8YHrhG611L4FcfgcnE470MvR7wK+CFwLHh2LmnXMlAfZxYH1xfz3wGIBzLheRheL1/ZV+zzv0G8UjSZ4e/N7+fTyV0T7cMZ7NeA/3+On2fRLH0gd4hlBK9eLghwp3PGOfTVaqU/sN/TNd+ZUXnbKQr1qtHpby6588hCF/mv2XYytvV3sC9WA8rXEXkVcCe51zN4vIi4/WgcUXhrwTYNOmTUdrtycUB8e+D37+mezj2b7/aOHpPPjDvWeA5x9OtFF7qvNqMOcOjyPx3K8EXi0iL8d3mxoCPgiMiEhQeO8bgJ3F63cCG4HHRSQAhvGJ1QNwsnKBjwTHcsI9l30/0/cOTpwBBjh58bSXZOfcv3HObXDObQF+BviKc+5NwFeB1xUv6+f8llxgir9/5fkWbx9ggH+KODiOvRpP6+c6xpPhMx4pnst669fwydUH8DH1Py2e/1NgvHj+vfjOeQMMMMDzDEd7Zdef7O/fDvX3YzXG59Nq9RnxepxzXwO+VtzfgS/JPvg1HeCnj8LYBhhggFWEk8HwHY0xngyf80hwcqV/BxhggAEGOCKcPIz8AQYY4LhjtXqxq3VcqwlH3H7gmA5CZAm490SPow8TrD5e/mob08k0ns3OucnjOZgSIrIPaLK6vqujhdU2B44mTpbPdti5vVqM+03OuYtO9DhKrLbxwOob02A8R47VPLbngufr54Lnx2cbxNwHGGCAAZ6HGBj3AQYYYIDnIVaLcf/jEz2Ag7DaxgOrb0yD8Rw5VvPYnguer58LngefbVXE3AcYYIABBji6WC2e+wADDDDAAEcRJ9y4i8h1InKviDwgIselVYGI/JmI7BWRO/ueGxOR60Xk/uJ2tHheROS/F+O7XUQuOAbj2SgiXxWRu0XkLhF5z4kck4gkIvJ9EbmtGM9vFM9vFZHvFcf9GxGJiufj4vEDxd+3HM3x9I1Li8itIvLZ1TCeIxzzcZ/fxwLPdI6ebDjSuXUy4YQad/HSfb8P/DjwAuCNIvKC43DoPweuO+i5Xwe+7Jw7FfgyKz1xfhw4tdjeiRckOdrIgX/lnHsBcBnwruJ7OFFj6gLXOufOBc4DrhORy1hR39oOzOFVt6BPfQv43eJ1xwKlGliJEz2ep8QJnN/HAs90jp5sONK5dfLgUF3QjtcGXA58se/xvwH+zXE69hbgzr7H9wJri/trgXuL+38EvPFQrzuGY/s08LLVMCagCtwCXIov6ggO/u2ALwKXF/eD4nVylMexAW88rgU+ixdFO2HjOcIxn7D5fRw+21PO0ZNpeyZz62TaTnRYpqfaVKBf0el4Y8o5t6u4vxuYKu4f1zEWIYTzge+dyDEVy9QfAHuB64EHOUL1LaBU3zqa+D28GpgtHh+xGtgxGs+RYDXN76OGI5yjJxN+jyOfWycNTrRxX5Vw/nJ93GlEIlIHPgn8S+fc4okck3POOOfOw3s1lwBnHK9jHwzpUwM7UWMYwGM1zdGjgefz3DrRjcNK1aYS/YpOxxt7RGStc26XiKzFe6xwnMYoIiH+pPkr59zfroYxATjn5kXkq/il6XNS33oOOCZqYMcBq2l+P2c8wzl6suCZzq2TBifac78ROLXITEd4pafPnKCx9CtIHaws9ZaCoXIZsNC3DD0qEBHBi5zc45z7nRM9JhGZFJGR4n4FH1u9hxOkvuVOXjWw1TS/nxOexRw9KfAs5tbJgxMd9AdeDtyHj+n+u+N0zI8Au4AMH097Bz7O9mXgfuAGYKx4reAZDw8CdwAXHYPxXIVfzt4O/KDYXn6ixgScA9xajOdO4N8Xz58CfB94APg4EBfPJ8XjB4q/n3IMf7sXA59dLeNZjfP7GH2OZzRHT8btSObWybQNKlQHGGCAAZ6HONFhmQEGGGCAAY4BBsZ9gAEGGOB5iIFxH2CAAQZ4HmJg3AcYYIABnocYGPcBBhhggOchBsZ9gAEGGOB5iIFxH2CAAQZ4HmJg3AcYYIABnof4/wHEFpq3fIeulAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path=os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/dora.jpg\" # jpg파일의 경로\n",
    "img=Image.open(path)     # img에 이미지 파일을 불러온다.\n",
    "resize=img.resize((56,56),Image.ANTIALIAS)  # 이미지를 48 x 48으로 줄인다. \n",
    "img_to_numpy=np.array(img)  # numpy의 array를 사용하여 이미지 파일을 numpy 배열로 만든다.\n",
    "\n",
    "plt.Figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)    # matplotlib의 imshow메서드를 사용하여 이미지를 출력한다.\n",
    "plt.title(\"original image:%d x %d\"%img.size)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(resize)\n",
    "plt.title(\"resized image: %d x %d\"%resize.size)\n",
    "\n",
    "print(\"PILOW 파일을 numpy 로 만든다.:\")\n",
    "print(img_to_numpy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcab0c",
   "metadata": {},
   "source": [
    "#### numpy 라이브러리의 np.zeros(), np.reshape()\n",
    "- __numpy.zeros(shape, dtype=float)__ : dtype에서 정한 자료형으로 이루어진 0이 shape의 배열로 이룬다.  \n",
    "- __numpy.reshape(a, newshape) 혹은 a.reshape(newshape)__ : 수정할 배열 a를 newshape의 배열로 바꿔준다. \n",
    "----------------\n",
    "\n",
    "- numpy의 shape는 차원에 따라 다음과 같이 달라진다.  \n",
    "__A:__ (channels,rows,columns)의 개수/ __channels__: 2차원 행렬(rows,columns)의 개수/ __rows:__ 행의 개수/ __columns:__ 열의 개수  \n",
    "__1차원__: np.zeros(크기)  \n",
    "__2차원__: np.zeros((rows , columns))  \n",
    "__3차원__: np.zeros((channels,rows,columns))  \n",
    "__4차원__: np.zeros((A,channels,rows,columns))  \n",
    "\n",
    "-----------------------------\n",
    "\n",
    "- 뒤에서 load_data() 함수에서 np.zeros()로 0으로 이루어진 1차원 배열을 만들고, reshape로 학습하기 위한 배열의 형태로 바꿔줄 것이다. 그때 numpy의 4차원 배열로 만들어서 이미지 값을 하나씩 입력할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188d2aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(4) # 1차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139f8fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3,4)) # 2차원 (행,열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd40c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,3,4)) # 3차원 (채널,행,열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe5bf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,2,3,4)) # 3차원 (A,채널,행,열)/ A는 (채널, 행, 열)의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e39d1",
   "metadata": {},
   "source": [
    "#### resize_images(img_path): 이미지 데이터를 작은 사이즈로 변환\n",
    "- 이미지244 x 244 이미지를 그대로 학습을 하면 연산량이 많기 때문에 시간과 컴퓨팅 파워를 줄이기 위해서 이미지를 50 x 50 로 줄였다. \n",
    "- 이 과정에서 glob라이브러리의 glob 함수와 PIL라이브러리의 Image 클래스의 open, resize, save 메서드를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d7fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path): # img_path를 resize_images 함수에 입력하면\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    # *(asterisk:애스터리스트)는 문자열 검색시 모든 것이라는 뜻으로 \n",
    "    #\"/*.jpg\"라는 의미는 디렉터리 아래에 .jpg로 끝나는 모든 문자열. 즉 jpg파일을 반환하라는 뜻이다.\n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(56,56)     # 바꾸고자 하는 이미지 크기\n",
    "    for img in images:      \n",
    "        old_img=Image.open(img)     # img 경로의 이미지를 numpy 배열 형태로 변수 old_img에 반환 시킨다.\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)   #old_img에 있는 이미지를 target_size로 축소 시킨다, \n",
    "                                                              #ANTIALIAS 방법으로 이미지 깨지는 것을 막아준다.\n",
    "        new_img.save(img, \"JPEG\")   # 다시 img 경로에 축소된 이미지를 JPEG파일로 저장한다.\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "    return len(images)     # img_path에 저장된 jpg 이미지 파일이 몇장인지 반환한다. \n",
    "                            # road_data 함수의 number_of_data에 입력시키려고 반환하게 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a7786",
   "metadata": {},
   "source": [
    "#### load_data(img_path, number_of_data=300,datatype=\"train\"): 이미지 데이터를 numpy 배열로 변환\n",
    "- img_path의 이미지 파일들을 딥러닝 학습을 시키기 위해서 numpy 배열로 바꿔준다.  \n",
    "- 이 코드는 feature(이미지 데이터)와 target (label,레이블)이 담길 영행렬을 각각 만들고, 영행렬에 이미지 데이터와 레이블을 차례대로 입력하는 코드이다.  \n",
    "||step|설명|코드|\n",
    "|-|----|:----|:----|\n",
    "|영행렬 만들기|step1|(설명변수,features) 크기가 17498880(2160 x 56 x 56 x 3)인 1차원 영행렬(데이터 타입이 np.int32인 0인)을 만든다.|imgs=np.zeros( number_of_data* img_size * img_size * color, dtype=np.int32)|\n",
    "|영행렬 만들기|step2|(설명변수,features) step1에서 만든 영행렬을 (number_of_data,img_size,img_size,color)의 영행렬로 바꾼다|imgs=imgs.reshape(number_of_data,img_size,img_size,color)|\n",
    "|영행렬 만들기|step3|(레이블,target) 크기가 number_of_data인 1차원 영행렬(데이터 타입이 np.int32인 0인)을 만든다.|labels=np.zeros(number_of_data,dtype=np.int32)|\n",
    "|영행렬에 입력|step4|step1~3 과정에서 만들어진 영행렬에 각 클래스 별로 저장한 이미지 데이터와 레이블을 idx_인덱스 별로 차례대로 입력한다.|아래의 load_data 함수 참조|\n",
    "\n",
    "--------------------------------------------------------------\n",
    "\n",
    "다음 셀의 코드는 load_data 함수의 데이터를 담을 배열이 될 영행렬을 만드는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc96412a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0] np.zeros로 만들어진 1차원 영행렬 imgs의 크기: (17498880,)\n",
      "-------------------------------------------------------\n",
      "배열의 모양을 바꾼후 img 배열의 0번 인덱스의 배열 크기 (56, 56, 3) / img 배열의 전체 크기: (1860, 56, 56, 3)\n",
      "-------------------------------------------------------\n",
      "label의 전체 크기: (1860,)\n"
     ]
    }
   ],
   "source": [
    "number_of_data,img_size,color=2160,56,3 # 함수 안에서 만들어질 영행렬을 정리해보자\n",
    "imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32) # 1차원 0행렬의 크기\n",
    "print(imgs[:5],\"np.zeros로 만들어진 1차원 영행렬 imgs의 크기:\",imgs.shape)\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "imgs=imgs.reshape(number_of_data,img_size,img_size,color)\n",
    "print(\"배열의 모양을 바꾼후 img 배열의 0번 인덱스의 배열 크기\",imgs[0,:,:,:].shape,\"/ img 배열의 전체 크기:\",imgs.shape)\n",
    "print(\"-------------------------------------------------------\")\n",
    "labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "print(\"label의 전체 크기:\",labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cbfaac",
   "metadata": {},
   "source": [
    "이처럼 0으로 채워진 img배열을 만든 후에 이미지를 하나씩 불러와서 데이터를 이 영행렬에 입력한다.  \n",
    "배열의 모양을 바꾼 img 배열의 0번 인덱스의 배열(__img \\[0,:,:,: \\]__)의 크기는 __56(img_size)x56(img_size)x3(color)인 이미지를 numpy 배열의 사이즈와 같다__ 는 것을 알수 있다.  그래서 for반복문을 사용해서\n",
    "\n",
    "첫번째 불러온 이미지를 img[0,:,:,:]에 입력하고,  \n",
    "두번째 불러온 이미지를 img[1,:,:,:]에 입력하고...  \n",
    "\n",
    "idx번째 불러온 이미지를 img[idx,:,:,:]에 입력을 한다. 이렇게 설명변수에 이미지를 입력하는 동안 label에 해당 클래스의 레이블을 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b61fc9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABwCAYAAAC9zaPrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAABwUlEQVR4nO3aMQoDMQwAQTnk/19WPhBSHXsHmWkNRiBYXPjs7gDQeN09AMA/EV2AkOgChEQXICS6AKH3z9NzfG14it1z1VVn7PUpdq7b68zMOWO3D7E7X3frpQsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2A0Nndu2cA+BteugAh0QUIiS5ASHQBQqILEBJdgNAHX7UP25EGcCoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.Figure(figsize=(10,10))\n",
    "imgs[0,:,:,0]=255 # 가장 오른쪽의 인덱스가 color/ 0이 Red\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(imgs[0])\n",
    "plt.axis('off')\n",
    "\n",
    "imgs[1,:,:,1]=255 # 가장 오른쪽의 인덱스가 color/ 1이 green\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(imgs[1])\n",
    "plt.axis('off')\n",
    "\n",
    "imgs[2,:,:,2]=255 # 가장 오른쪽의 인덱스가 color / 1이 blue\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(imgs[2])\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc08ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0]],\n",
       "\n",
       "       [[255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0]],\n",
       "\n",
       "       [[255,   0,   0],\n",
       "        [255,   0,   0],\n",
       "        [255,   0,   0]]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0,:3,:3,:]#red가 보여지는 imgs의 0번 인덱스의 일부를 보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a98963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data=300,datatype=\"train\"):  # 가위바위보 이미지 개수 총합에 주의\n",
    "    # img_path 안에 있는 scissor, rock, paper 폴더의 이미지를 학습하기 위해서 numpy 배열에 저장한다. \n",
    "    \n",
    "    img_size=56\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32)\n",
    "    imgs=imgs.reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'): # iglob를 사용하여 scissor 폴더 안에 있는 jpg 파일을 제너레이터로 가져온다.\n",
    "        img = np.array(Image.open(file),dtype=np.int32) # 이미지 데이터를 불러와서 numpy 배열로 바꿔서 변수 img에 할당한다.\n",
    "        imgs[idx,:,:,:]=img    # 영행렬 imgs의 idx번째 인덱스에 이미지 배열을 저장\n",
    "        labels[idx]=0   # 영행렬labels의 idx번째 인덱스에 가위의 라벨인 0을 입력\n",
    "        idx=idx+1       # idx 하나 증가해서 다음 이미지는 idx+1번째 인덱스에 저장한다.\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'): # 바위에 대해서 가위의 코드와 동일하게 수행\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'): # 보에 대해서 가위의 코드와 동일하게 수행\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "    if datatype==\"train\": # 학습데이터인지 시험데이터 인지에 따라 출력되는 문구가 다르다.\n",
    "        print(\"학습 데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    else:\n",
    "        print(\"시험 데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d386b83a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720  images to be resized.\n",
      "720  images resized.\n",
      "720  images to be resized.\n",
      "720  images resized.\n",
      "720  images to be resized.\n",
      "720  images resized.\n",
      "150  images to be resized.\n",
      "150  images resized.\n",
      "150  images to be resized.\n",
      "150  images resized.\n",
      "150  images to be resized.\n",
      "150  images resized.\n",
      "학습 데이터(x_train)의 이미지 개수는 2160 입니다.\n",
      "시험 데이터(x_test)의 이미지 개수는 450 입니다.\n"
     ]
    }
   ],
   "source": [
    "#  train dataset 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서 사이즈 조절을 한다.\n",
    "train_numbers={\"scissor\":0,\"paper\":0,\"rock\":0} # 학습되는 레이블 각각의 이미지의 갯수를 딕셔너리에 저장한다.\n",
    "\n",
    "# train데이터셋의 이미지 축소\n",
    "for i in train_numbers:# \"scissor\",\"paper\",\"rock\" 차례대로 출력\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/{0}\".format(i) # 가위, 바위, 보 이미지 디렉터리 path\n",
    "    train_numbers[i]=resize_images(image_dir_path)   # resize_images로 이미지 사이즈를 줄이고, 각 클래스 별 이미지를 저장한다.\n",
    "\n",
    "# test 데이터셋 이미지 축소\n",
    "test_numbers={\"scissor\":0,\"paper\":0,\"rock\":0}\n",
    "for i in test_numbers:\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/{0}\".format(i)\n",
    "    test_numbers[i]=resize_images(image_dir_path)\n",
    "\n",
    "# 이미지를 numpy행렬에 \n",
    "image_dir_path = os.getenv(\"HOME\") + '/aiffel/rock_scissor_paper'\n",
    "(x_train, y_train)=load_data(image_dir_path,number_of_data=sum(train_numbers.values())) \n",
    "                                                                # train_number에 저장된 이미지의 개수를 number_of_data에 입력\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + '/aiffel/rock_scissor_paper/test'\n",
    "(x_test, y_test)=load_data(image_dir_path,number_of_data=sum(test_numbers.values()),datatype=\"test\") # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e32452",
   "metadata": {},
   "source": [
    "학습 데이터의 설명변수(feature)는  x_train에 저장되고, 레이블(label/target)은 y_train에 저장된다.  \n",
    "시험 데이터의 설명변수(feature)는  x_test에 저장되고, 레이블(label/target)은 y_test에 저장된다.  \n",
    "\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "### 2. 모델 구성, 하이퍼 파라미터 튜닝 및 평가\n",
    "\n",
    "#### 데이터 정규화 (Normalizing)\n",
    "\n",
    "딥러닝은 설명변수 간의 스케일 차이가 많이 난다면 설명변수의 스케일이 큰 데이터의 feature가 학습에 많이 영향을 미치게 되어서 학습이 불균형적으로 이뤄지게 된다. 그래서 데이터의 스케일을 비슷한 구간으로 맞춰주는 과정이 꼭 필요하다. 이미지 데이터의 경우는 RGB 채널별로 가장 밝으면 255, 가장 어두우면 0이다. 그래서 __이미지 데이터가 담긴 배열을 255.0으로 나누어서 0~1사이의 값 을 갖도록 정규화__ 시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "047020b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train/255.0   # normalizing\n",
    "x_test_norm = x_test/255.0   # normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fae0f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train_norm.max(), x_train_norm.min()) \n",
    "print(x_test_norm.max(), x_test_norm.min()) # 학습데이터셋과 테스트 데이터셋의 최대값은 1이하, 최소값은 0이상임을 알수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71fbecd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습데이터의 일부를 출력해보자.\n",
    "np.random.seed(10)\n",
    "plt.Figure(figsize=(4,20))\n",
    "for i in range(8):\n",
    "    n=np.random.randint(1860)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(x_train_norm[n])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"%d\"%y_train[n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4a4824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160, 56, 56, 3) (2160,)\n"
     ]
    }
   ],
   "source": [
    "x_train_reshaped=x_train_norm.reshape( -1, 56, 56, 3)  \n",
    "x_test_reshaped=x_test_norm.reshape( -1, 56, 56, 3)\n",
    "                                 # reshape의 50,50,3 모양은 유지 시킨채로 첫번째 값인 -1은 알아서 값을 계산해서 입력하라는 뜻이다.\n",
    "\n",
    "print(x_train_reshaped.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930e7f6",
   "metadata": {},
   "source": [
    "### 베이스 모델 설명\n",
    "\n",
    "- exploration에서 제시되었던 LeNet 모델을 베이스 모델로 사용하였다. LeNet은 최초의CNN(convolutional Neural Network)이다.\n",
    "- 1989년 Yann LeCun은 미국의 우편번호를 딥러닝을 이용하여 분류하고자 했다. MNIST데이터셋을 만들고 Yann LeCun이 CNN알고리즘으로 LeNet을 내놓았다. 이 모델을 예시로 배웠고 예시로 배웠던 이 모델을 베이스 모델로 삼아서 최적화를 하고자한다.\n",
    "\n",
    "베이스모델은 \n",
    "    step1.합성곱 레이어에서 합성곱을 한 feature map들을 만들어낸다.\n",
    "    step2.feature map들을 Maxpooling을 하여서 출력해낸다.\n",
    "    step3.이 값을 다시 1-2과정을 한다.(단, filter 사이즈를 달리하고, 1은 이미지 데이터가 입력되는 층이기 때문에 데이터 사이즈가 이미지 데이커 크기이다. 3번은 2에서 연산된 값이 입력된다는 점에서 다르다.)\n",
    "    step4. 은닉층에 학습시키고 flatten을 하여서 soft max(클래스3개를 분류하는 다중분류 문제이기 때문에 soft max 사용)로 입력된 데이터가 어떤 클래스일지 예측하고, cross entropy로 예측한 클래스를 실제 클래스의 loss를 계산해낸다. 그리고 거꾸로 backpropagation을 해서 그레디언트를 계산하여 filter들의 가중치를 학습시킨다.\n",
    "\n",
    "----------------------------------------------\n",
    "\n",
    "- step1. 합성곱 연산을 이용해서 각각의 요소를 서로 곱해서 더한 값(하나의 값)이 출력이 된다.(아래 그림 참조)\n",
    "    ![](https://blog.kakaocdn.net/dn/Ck3Fe/btrci8l9TUb/WR6FUM4tzhQp8KHW4SKFZ0/img.png)\n",
    "\n",
    "- 이렇게 필터가 입력된 이미지를 한픽셀씩 이동하여서 합성곱을 한다. 이 과정에서 filter 하나당 하나의 feature map을 만들어낸다. filter 하나가 이미지 패턴을 잡아내어 feature를 하나 만들어내는 역할을 하기 때문에 이미지의 디테일한 특징을 더 많이 잡아내려면 filter 개수를 늘리고 커널 사이즈를 디테일하게 조절할 필요가 있다.(아래의 움직이는 이미지 참조)\n",
    "- 이 과정을 케라스는 Conv2D를 사용하여 구성한다. 여기에 필터의 개수와 필터 사이즈 그리고 만일 입력층이라면 입력데이터의 모양을 입력한다.\n",
    "\n",
    "![](https://miro.medium.com/max/803/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif)\n",
    "\n",
    "\n",
    "- step2. 합성곱 레이어를 나온 값들을 max pooling의 커널 사이즈만큼 나눠서 각각 가장 큰 값을 반환한다. \n",
    "![](https://production-media.paperswithcode.com/methods/MaxpoolSample2.png)\n",
    "- step3. 또 다시 Conv2D, Max pooling 레이어를 거친다.\n",
    "- step4. 입력된 값을 flatten을 하여서 쭉 늘린 후에 Dense레이어를 통해 은닉층으로 학습한 뒤 soft max로 분류하고 cross entropy를 통해 학습 loss를 계산한 다음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd3f8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(n_channel_1, n_channel_2, n_dense, n_train_epoch):\n",
    "\n",
    "    model=keras.models.Sequential() # 시퀀스형 \n",
    "    model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation=\"relu\", input_shape=(56,56,3))) \n",
    "    model.add(keras.layers.MaxPool2D(2,2))\n",
    "    model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # 모델 훈련\n",
    "    history=model.fit(x_train_reshaped, y_train, validation_data=(x_test_reshaped, y_test), epochs=n_train_epoch)\n",
    "    # 모델 시험\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be06a2",
   "metadata": {},
   "source": [
    "### 베이스라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "103bd9e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,779\n",
      "Trainable params: 150,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1.0913 - accuracy: 0.3981 - val_loss: 1.0720 - val_accuracy: 0.4178\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.9663 - accuracy: 0.5106 - val_loss: 1.0859 - val_accuracy: 0.4956\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.8098 - accuracy: 0.6440 - val_loss: 1.2548 - val_accuracy: 0.4756\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.7106 - val_loss: 1.2431 - val_accuracy: 0.5178\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7917 - val_loss: 1.3795 - val_accuracy: 0.5444\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8273 - val_loss: 1.5907 - val_accuracy: 0.5489\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8569 - val_loss: 1.6755 - val_accuracy: 0.5956\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8880 - val_loss: 1.8200 - val_accuracy: 0.5578\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9157 - val_loss: 2.0420 - val_accuracy: 0.6267\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9222 - val_loss: 2.3365 - val_accuracy: 0.6044\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2099 - accuracy: 0.9296 - val_loss: 2.4337 - val_accuracy: 0.4867\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1864 - accuracy: 0.9389 - val_loss: 2.6512 - val_accuracy: 0.5956\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9505 - val_loss: 2.6534 - val_accuracy: 0.5733\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9579 - val_loss: 3.1905 - val_accuracy: 0.5756\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9662 - val_loss: 3.1057 - val_accuracy: 0.5422\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9731 - val_loss: 3.4294 - val_accuracy: 0.5178\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9699 - val_loss: 3.8567 - val_accuracy: 0.5756\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9769 - val_loss: 3.8993 - val_accuracy: 0.5400\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9639 - val_loss: 3.9460 - val_accuracy: 0.5933\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9662 - val_loss: 4.0256 - val_accuracy: 0.5422\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9833 - val_loss: 4.3585 - val_accuracy: 0.5578\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9861 - val_loss: 4.4545 - val_accuracy: 0.5578\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 4.7689 - val_accuracy: 0.5267\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 4.9294 - val_accuracy: 0.5356\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9903 - val_loss: 5.1034 - val_accuracy: 0.5489\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 5.3454 - val_accuracy: 0.5467\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9926 - val_loss: 5.2291 - val_accuracy: 0.5489\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9944 - val_loss: 5.5178 - val_accuracy: 0.5422\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9917 - val_loss: 5.5852 - val_accuracy: 0.5556\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9963 - val_loss: 5.9769 - val_accuracy: 0.5400\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9963 - val_loss: 5.8135 - val_accuracy: 0.5533\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 6.0427 - val_accuracy: 0.5400\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9977 - val_loss: 6.1462 - val_accuracy: 0.5511\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 6.4627 - val_accuracy: 0.5400\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 6.8099 - val_accuracy: 0.5444\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9995 - val_loss: 6.8222 - val_accuracy: 0.5444\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 7.0465 - val_accuracy: 0.5467\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 7.0439 - val_accuracy: 0.5444\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 7.3568 - val_accuracy: 0.5533\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 7.2462 - val_accuracy: 0.5511\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 7.5411 - val_accuracy: 0.5422\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 7.5977 - val_accuracy: 0.5400\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 7.9550 - val_accuracy: 0.5489\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 7.9774 - val_accuracy: 0.5289\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 7.9512 - val_accuracy: 0.5400\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 8.3003 - val_accuracy: 0.5378\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 8.6087 - val_accuracy: 0.5400\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 8.4724 - val_accuracy: 0.5511\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 8.7592 - val_accuracy: 0.5400\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 8.7532 - val_accuracy: 0.5400\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=10\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=50\n",
    "\n",
    "model=base_model(n_channel_1, n_channel_2, n_dense, n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "489463a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'base model accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 기본 베이스라인이었을때 test 데이터셋과 train 데이터셋의 accuracy와 loss\n",
    "\n",
    "base_m=pd.DataFrame(model.history)\n",
    "plt.Figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(base_m[[\"loss\",\"val_loss\"]])\n",
    "plt.title(\"base model loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(base_m[[\"accuracy\",\"val_accuracy\"]])\n",
    "plt.title(\"base model accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c16c3043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss            1.091340\n",
       "accuracy        1.000000\n",
       "val_loss        8.759213\n",
       "val_accuracy    0.626667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_m.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b3e12",
   "metadata": {},
   "source": [
    "base model accuracy와 같이epoch가 지남에 따라 학습 데이터셋의 성능은 올라가지만 시험데이터셋의 성능은 떨어진 것을 알수 있다. 즉, overfitting이 되었다. \n",
    "\n",
    "그래서 학습데이터셋에 지나치게 학습되는 것을 막기 위해서 최적화 기법으로 Batchnormalization과 dropout, mini batch gredient를 사용했다.activation 함수를 거치기 직전에 BatchNormalization, 그리고 softmax를 거치기 전에 Dropout을 적용하였다.\n",
    "\n",
    "\n",
    "### 모델 최적화를 위한 방법\n",
    "- Dropout: 신경망에서 과대적합을 줄이는 방법중 하나로 무작위로 일부 뉴런을 비활성화시킨다. 무작위로 일부 뉴런을 비활성화시키면 특정 뉴런에 과도하게 의존해서 학습되는 것을 막아줘서 오버피팅을 막아준다. 보통 softmax를 거치기 전에 dropout을 적용한다.\n",
    "- Batch normalization: 레이어 단계마다 출력되는 값들을 정규화 시켜주는 방법이다. 보통 활성화함수를 거치기 전에 정규화를 시켜준다. 논란이 많은 방법이긴 하지만 성능이 개선되기는 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8902f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1은 BatchNormalization과 dropout을 적용\n",
    "\n",
    "\n",
    "def model1(n_channel_1, n_channel_2, n_dense, dropout_rate,n_train_epoch,batch_size,lr):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(n_channel_1, (3,3), input_shape=(56,56,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(n_channel_2, (3,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    history=model.fit(x_train_reshaped, y_train, validation_data=(x_test_reshaped, y_test), epochs=n_train_epoch, batch_size=batch_size)\n",
    "\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef046ef",
   "metadata": {},
   "source": [
    "하이퍼파라미터 평가 및 방법\n",
    "- 다소 무식한 방법이지만 3중 for 반복문을 사용하여서 학습에서 가장 중요한 학습율(learning rate)와 드롭아웃 비율(dropout rate) 그리고 배치사이즈(batch size)의 가장 좋은 조합을 찾고자 했다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e6c920",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.6997 - accuracy: 0.4972 - val_loss: 1.3931 - val_accuracy: 0.4200\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6991 - accuracy: 0.6759 - val_loss: 2.0214 - val_accuracy: 0.4311\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7588 - val_loss: 1.4869 - val_accuracy: 0.2422\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4720 - accuracy: 0.8042 - val_loss: 3.2387 - val_accuracy: 0.4044\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4127 - accuracy: 0.8338 - val_loss: 3.6810 - val_accuracy: 0.4356\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3621 - accuracy: 0.8574 - val_loss: 1.6317 - val_accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3462 - accuracy: 0.8644 - val_loss: 2.9911 - val_accuracy: 0.4711\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2997 - accuracy: 0.8847 - val_loss: 4.6807 - val_accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2820 - accuracy: 0.8912 - val_loss: 6.2857 - val_accuracy: 0.4511\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2721 - accuracy: 0.8981 - val_loss: 5.1941 - val_accuracy: 0.4511\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2569 - accuracy: 0.9046 - val_loss: 4.7897 - val_accuracy: 0.4400\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.9194 - val_loss: 4.4415 - val_accuracy: 0.3756\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2276 - accuracy: 0.9194 - val_loss: 2.6281 - val_accuracy: 0.4667\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1886 - accuracy: 0.9347 - val_loss: 4.0546 - val_accuracy: 0.4178\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2302 - accuracy: 0.9134 - val_loss: 3.5230 - val_accuracy: 0.4556\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2243 - accuracy: 0.9204 - val_loss: 6.0606 - val_accuracy: 0.4844\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9287 - val_loss: 7.0133 - val_accuracy: 0.4956\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9431 - val_loss: 5.4712 - val_accuracy: 0.4622\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9407 - val_loss: 5.3505 - val_accuracy: 0.5133\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1702 - accuracy: 0.9431 - val_loss: 7.8019 - val_accuracy: 0.3800\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9255 - val_loss: 4.1416 - val_accuracy: 0.4111\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1822 - accuracy: 0.9356 - val_loss: 10.4837 - val_accuracy: 0.4622\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9403 - val_loss: 9.9713 - val_accuracy: 0.4244\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9440 - val_loss: 7.9477 - val_accuracy: 0.4489\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9491 - val_loss: 9.1263 - val_accuracy: 0.4400\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9380 - val_loss: 7.8161 - val_accuracy: 0.4600\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1343 - accuracy: 0.9523 - val_loss: 10.1608 - val_accuracy: 0.4578\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1798 - accuracy: 0.9440 - val_loss: 10.0527 - val_accuracy: 0.3978\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9477 - val_loss: 10.0630 - val_accuracy: 0.4156\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.9458 - val_loss: 10.5040 - val_accuracy: 0.4511\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9356 - val_loss: 11.5133 - val_accuracy: 0.4311\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9523 - val_loss: 11.4926 - val_accuracy: 0.4533\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1892 - accuracy: 0.9370 - val_loss: 8.8167 - val_accuracy: 0.4467\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1614 - accuracy: 0.9463 - val_loss: 10.3504 - val_accuracy: 0.3800\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1316 - accuracy: 0.9537 - val_loss: 12.2184 - val_accuracy: 0.4644\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9523 - val_loss: 14.0139 - val_accuracy: 0.4733\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1753 - accuracy: 0.9398 - val_loss: 15.2947 - val_accuracy: 0.3711\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1564 - accuracy: 0.9444 - val_loss: 13.8752 - val_accuracy: 0.3822\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1524 - accuracy: 0.9472 - val_loss: 9.1326 - val_accuracy: 0.4156\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1251 - accuracy: 0.9551 - val_loss: 9.5694 - val_accuracy: 0.4778\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1175 - accuracy: 0.9574 - val_loss: 8.2282 - val_accuracy: 0.4578\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1329 - accuracy: 0.9509 - val_loss: 7.0638 - val_accuracy: 0.3911\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9569 - val_loss: 8.6814 - val_accuracy: 0.4511\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9579 - val_loss: 10.5202 - val_accuracy: 0.4622\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9440 - val_loss: 9.0739 - val_accuracy: 0.4311\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9528 - val_loss: 11.9815 - val_accuracy: 0.4422\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9528 - val_loss: 10.4142 - val_accuracy: 0.4733\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1514 - accuracy: 0.9435 - val_loss: 17.3877 - val_accuracy: 0.3800\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1726 - accuracy: 0.9412 - val_loss: 6.3919 - val_accuracy: 0.4511\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9532 - val_loss: 7.9413 - val_accuracy: 0.4378\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.3864 - accuracy: 0.4102 - val_loss: 1.7195 - val_accuracy: 0.2956\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8902 - accuracy: 0.5259 - val_loss: 1.4612 - val_accuracy: 0.3044\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7925 - accuracy: 0.5940 - val_loss: 5.3190 - val_accuracy: 0.3267\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7247 - accuracy: 0.6301 - val_loss: 6.8989 - val_accuracy: 0.4667\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6671 - accuracy: 0.6662 - val_loss: 5.9546 - val_accuracy: 0.3556\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6485 - accuracy: 0.6653 - val_loss: 10.4868 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7046 - accuracy: 0.6556 - val_loss: 11.6845 - val_accuracy: 0.4911\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6598 - accuracy: 0.6667 - val_loss: 12.1998 - val_accuracy: 0.3933\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6011 - accuracy: 0.7194 - val_loss: 5.4718 - val_accuracy: 0.4378\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6089 - accuracy: 0.7028 - val_loss: 9.1758 - val_accuracy: 0.3222\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5782 - accuracy: 0.7157 - val_loss: 11.5118 - val_accuracy: 0.4511\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5370 - accuracy: 0.7347 - val_loss: 9.1633 - val_accuracy: 0.3889\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5418 - accuracy: 0.7361 - val_loss: 5.9388 - val_accuracy: 0.3911\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4721 - accuracy: 0.7963 - val_loss: 3.1939 - val_accuracy: 0.4644\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4930 - accuracy: 0.7792 - val_loss: 7.8006 - val_accuracy: 0.3956\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 7.1123 - val_accuracy: 0.3844\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8208 - val_loss: 12.8167 - val_accuracy: 0.4156\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3625 - accuracy: 0.8333 - val_loss: 8.6993 - val_accuracy: 0.3511\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3555 - accuracy: 0.8468 - val_loss: 17.1030 - val_accuracy: 0.4000\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3064 - accuracy: 0.8713 - val_loss: 8.7939 - val_accuracy: 0.3400\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2789 - accuracy: 0.8796 - val_loss: 10.8658 - val_accuracy: 0.3867\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.8912 - val_loss: 13.2867 - val_accuracy: 0.3511\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3125 - accuracy: 0.8713 - val_loss: 10.2172 - val_accuracy: 0.3822\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2869 - accuracy: 0.8912 - val_loss: 5.2248 - val_accuracy: 0.4622\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2519 - accuracy: 0.8972 - val_loss: 15.0043 - val_accuracy: 0.4378\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9088 - val_loss: 12.2994 - val_accuracy: 0.4111\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9213 - val_loss: 13.3443 - val_accuracy: 0.4022\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2362 - accuracy: 0.9093 - val_loss: 13.5513 - val_accuracy: 0.3778\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2297 - accuracy: 0.9102 - val_loss: 7.1985 - val_accuracy: 0.4378\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.9236 - val_loss: 7.3815 - val_accuracy: 0.4267\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9264 - val_loss: 5.9624 - val_accuracy: 0.3889\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9148 - val_loss: 10.1522 - val_accuracy: 0.5178\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.9301 - val_loss: 7.7557 - val_accuracy: 0.3600\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9370 - val_loss: 8.1262 - val_accuracy: 0.4200\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2421 - accuracy: 0.9194 - val_loss: 3.7227 - val_accuracy: 0.4644\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9440 - val_loss: 7.8066 - val_accuracy: 0.5333\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9468 - val_loss: 7.0711 - val_accuracy: 0.4911\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9370 - val_loss: 9.0842 - val_accuracy: 0.4667\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1600 - accuracy: 0.9486 - val_loss: 7.6458 - val_accuracy: 0.4489\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9343 - val_loss: 9.5073 - val_accuracy: 0.3978\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1805 - accuracy: 0.9384 - val_loss: 8.7602 - val_accuracy: 0.4600\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9472 - val_loss: 9.0415 - val_accuracy: 0.4156\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1722 - accuracy: 0.9398 - val_loss: 10.2539 - val_accuracy: 0.3644\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9329 - val_loss: 10.8807 - val_accuracy: 0.3600\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9343 - val_loss: 12.0879 - val_accuracy: 0.4467\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1649 - accuracy: 0.9472 - val_loss: 13.0216 - val_accuracy: 0.4111\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1912 - accuracy: 0.9375 - val_loss: 6.1043 - val_accuracy: 0.3978\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9403 - val_loss: 5.1256 - val_accuracy: 0.3978\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9431 - val_loss: 5.1640 - val_accuracy: 0.3733\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9509 - val_loss: 5.5507 - val_accuracy: 0.4133\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.9399 - accuracy: 0.3648 - val_loss: 1.1001 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0247 - accuracy: 0.4231 - val_loss: 1.3928 - val_accuracy: 0.3289\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9518 - accuracy: 0.4861 - val_loss: 1.2826 - val_accuracy: 0.3200\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9516 - accuracy: 0.4755 - val_loss: 1.4914 - val_accuracy: 0.3511\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9128 - accuracy: 0.5102 - val_loss: 2.1472 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9047 - accuracy: 0.4847 - val_loss: 2.2614 - val_accuracy: 0.3222\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8718 - accuracy: 0.5102 - val_loss: 1.3730 - val_accuracy: 0.3289\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8552 - accuracy: 0.5148 - val_loss: 3.9049 - val_accuracy: 0.3911\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8595 - accuracy: 0.5269 - val_loss: 1.2129 - val_accuracy: 0.3889\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8462 - accuracy: 0.5412 - val_loss: 1.9290 - val_accuracy: 0.3178\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7899 - accuracy: 0.5583 - val_loss: 1.5757 - val_accuracy: 0.3422\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8037 - accuracy: 0.5491 - val_loss: 1.2946 - val_accuracy: 0.4111\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.5644 - val_loss: 1.3324 - val_accuracy: 0.4044\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.6000 - val_loss: 3.6235 - val_accuracy: 0.3267\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7151 - accuracy: 0.5940 - val_loss: 3.1247 - val_accuracy: 0.3289\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6190 - val_loss: 3.0277 - val_accuracy: 0.3600\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6544 - accuracy: 0.6005 - val_loss: 2.6371 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6255 - val_loss: 2.1706 - val_accuracy: 0.3822\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6083 - val_loss: 1.7632 - val_accuracy: 0.3422\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.6000 - val_loss: 5.1391 - val_accuracy: 0.3600\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6561 - accuracy: 0.6088 - val_loss: 2.9686 - val_accuracy: 0.3844\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6420 - accuracy: 0.6144 - val_loss: 3.0251 - val_accuracy: 0.3489\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6330 - accuracy: 0.6185 - val_loss: 1.6950 - val_accuracy: 0.3311\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6194 - val_loss: 3.8749 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7654 - accuracy: 0.5829 - val_loss: 3.0659 - val_accuracy: 0.3267\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6125 - val_loss: 3.1016 - val_accuracy: 0.3378\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6253 - accuracy: 0.5958 - val_loss: 2.2518 - val_accuracy: 0.3356\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6283 - accuracy: 0.6032 - val_loss: 1.9568 - val_accuracy: 0.4022\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6242 - accuracy: 0.6162 - val_loss: 2.0002 - val_accuracy: 0.3867\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.6171 - val_loss: 1.3543 - val_accuracy: 0.3533\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6299 - accuracy: 0.6218 - val_loss: 1.5864 - val_accuracy: 0.4178\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6213 - val_loss: 4.1411 - val_accuracy: 0.3356\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6463 - accuracy: 0.6083 - val_loss: 2.8245 - val_accuracy: 0.3800\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6287 - accuracy: 0.6171 - val_loss: 3.5555 - val_accuracy: 0.3422\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6135 - accuracy: 0.6269 - val_loss: 3.5363 - val_accuracy: 0.3956\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6250 - val_loss: 4.3829 - val_accuracy: 0.3289\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6281 - accuracy: 0.6218 - val_loss: 2.4270 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6306 - val_loss: 4.7592 - val_accuracy: 0.3244\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.6181 - val_loss: 3.3614 - val_accuracy: 0.3600\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.6389 - val_loss: 5.4311 - val_accuracy: 0.3622\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6185 - val_loss: 4.4144 - val_accuracy: 0.3289\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6369 - accuracy: 0.6185 - val_loss: 3.5287 - val_accuracy: 0.3178\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6147 - accuracy: 0.6458 - val_loss: 5.0028 - val_accuracy: 0.3289\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5670 - accuracy: 0.6972 - val_loss: 3.3950 - val_accuracy: 0.3667\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5753 - accuracy: 0.7065 - val_loss: 11.0858 - val_accuracy: 0.4200\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7574 - val_loss: 5.1686 - val_accuracy: 0.3022\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7773 - val_loss: 6.5308 - val_accuracy: 0.3200\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7991 - val_loss: 8.4536 - val_accuracy: 0.3311\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4997 - accuracy: 0.7917 - val_loss: 12.2862 - val_accuracy: 0.2956\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.8019 - val_loss: 5.5362 - val_accuracy: 0.4067\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.7201 - accuracy: 0.5444 - val_loss: 1.2808 - val_accuracy: 0.4222\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7644 - val_loss: 2.8205 - val_accuracy: 0.3711\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8213 - val_loss: 6.5894 - val_accuracy: 0.3311\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8519 - val_loss: 3.9208 - val_accuracy: 0.3933\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.8907 - val_loss: 3.8904 - val_accuracy: 0.4911\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.8972 - val_loss: 6.6239 - val_accuracy: 0.3800\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2416 - accuracy: 0.9032 - val_loss: 4.7198 - val_accuracy: 0.4244\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9204 - val_loss: 9.3837 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.9273 - val_loss: 6.6874 - val_accuracy: 0.3489\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.9204 - val_loss: 4.0121 - val_accuracy: 0.4089\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9375 - val_loss: 5.6635 - val_accuracy: 0.3578\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9551 - val_loss: 5.4461 - val_accuracy: 0.3956\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9449 - val_loss: 3.4206 - val_accuracy: 0.4800\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1073 - accuracy: 0.9616 - val_loss: 6.2450 - val_accuracy: 0.3822\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.9630 - val_loss: 7.5263 - val_accuracy: 0.4133\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9583 - val_loss: 5.5026 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9676 - val_loss: 5.9849 - val_accuracy: 0.4667\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9569 - val_loss: 5.4019 - val_accuracy: 0.4133\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9616 - val_loss: 5.1676 - val_accuracy: 0.4667\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9648 - val_loss: 4.9114 - val_accuracy: 0.4911\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9731 - val_loss: 6.2073 - val_accuracy: 0.3578\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 6.3064 - val_accuracy: 0.3844\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9861 - val_loss: 5.2679 - val_accuracy: 0.4222\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.9537 - val_loss: 6.8052 - val_accuracy: 0.3933\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9468 - val_loss: 6.8259 - val_accuracy: 0.4533\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9690 - val_loss: 5.5175 - val_accuracy: 0.3756\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1443 - accuracy: 0.9606 - val_loss: 5.6873 - val_accuracy: 0.4400\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 5.6866 - val_accuracy: 0.5200\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 6.0118 - val_accuracy: 0.4689\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 7.4748 - val_accuracy: 0.5333\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9741 - val_loss: 6.3089 - val_accuracy: 0.4000\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9843 - val_loss: 6.8433 - val_accuracy: 0.4556\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9856 - val_loss: 6.3674 - val_accuracy: 0.5222\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 5.1025 - val_accuracy: 0.5111\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 6.5112 - val_accuracy: 0.4644\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 11.1827 - val_accuracy: 0.4711\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 7.0571 - val_accuracy: 0.3844\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9630 - val_loss: 5.2938 - val_accuracy: 0.5711\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9782 - val_loss: 5.1720 - val_accuracy: 0.5111\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 5.8334 - val_accuracy: 0.4800\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 6.2686 - val_accuracy: 0.4867\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9787 - val_loss: 11.9337 - val_accuracy: 0.4200\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9708 - val_loss: 5.3928 - val_accuracy: 0.4333\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9898 - val_loss: 5.9749 - val_accuracy: 0.4867\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 7.5031 - val_accuracy: 0.4822\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9912 - val_loss: 6.6061 - val_accuracy: 0.5778\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9866 - val_loss: 6.9447 - val_accuracy: 0.4622\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9880 - val_loss: 6.5864 - val_accuracy: 0.4978\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9917 - val_loss: 7.3565 - val_accuracy: 0.5267\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 16.6170 - val_accuracy: 0.3422\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.7008 - accuracy: 0.4032 - val_loss: 1.1005 - val_accuracy: 0.4511\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9260 - accuracy: 0.5421 - val_loss: 1.4891 - val_accuracy: 0.4911\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7488 - accuracy: 0.6625 - val_loss: 3.2255 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.7551 - val_loss: 4.3558 - val_accuracy: 0.3267\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7931 - val_loss: 2.3000 - val_accuracy: 0.3933\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.8037 - val_loss: 4.8041 - val_accuracy: 0.4044\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8241 - val_loss: 5.2729 - val_accuracy: 0.4244\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8653 - val_loss: 5.8561 - val_accuracy: 0.4444\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8806 - val_loss: 6.2686 - val_accuracy: 0.4489\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8727 - val_loss: 4.1769 - val_accuracy: 0.4089\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.9083 - val_loss: 7.0177 - val_accuracy: 0.4333\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9148 - val_loss: 5.6477 - val_accuracy: 0.3511\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9287 - val_loss: 6.7725 - val_accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1652 - accuracy: 0.9477 - val_loss: 7.4094 - val_accuracy: 0.4756\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9426 - val_loss: 5.4222 - val_accuracy: 0.4267\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2078 - accuracy: 0.9338 - val_loss: 6.6173 - val_accuracy: 0.4667\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9380 - val_loss: 4.8361 - val_accuracy: 0.3711\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9454 - val_loss: 4.6575 - val_accuracy: 0.4444\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9495 - val_loss: 4.0674 - val_accuracy: 0.2933\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9426 - val_loss: 5.6856 - val_accuracy: 0.3489\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9514 - val_loss: 5.3510 - val_accuracy: 0.3756\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9333 - val_loss: 6.0291 - val_accuracy: 0.4578\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9519 - val_loss: 8.7716 - val_accuracy: 0.4511\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9417 - val_loss: 3.2095 - val_accuracy: 0.5689\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9528 - val_loss: 6.0262 - val_accuracy: 0.5022\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9602 - val_loss: 7.2980 - val_accuracy: 0.3800\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9546 - val_loss: 5.0302 - val_accuracy: 0.4556\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9579 - val_loss: 5.2118 - val_accuracy: 0.4222\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9597 - val_loss: 5.1715 - val_accuracy: 0.4956\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9602 - val_loss: 7.8790 - val_accuracy: 0.5222\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9639 - val_loss: 10.0620 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9625 - val_loss: 8.3906 - val_accuracy: 0.4889\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9676 - val_loss: 7.2557 - val_accuracy: 0.4467\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9611 - val_loss: 6.4313 - val_accuracy: 0.3511\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9662 - val_loss: 10.9732 - val_accuracy: 0.5200\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9579 - val_loss: 9.3763 - val_accuracy: 0.4711\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9625 - val_loss: 7.9085 - val_accuracy: 0.3844\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9676 - val_loss: 8.4458 - val_accuracy: 0.4289\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9449 - val_loss: 16.7438 - val_accuracy: 0.4289\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9495 - val_loss: 6.9635 - val_accuracy: 0.4089\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9630 - val_loss: 10.3166 - val_accuracy: 0.3889\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9634 - val_loss: 10.5191 - val_accuracy: 0.4489\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9639 - val_loss: 8.2880 - val_accuracy: 0.4311\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9583 - val_loss: 5.3832 - val_accuracy: 0.3889\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9625 - val_loss: 8.4036 - val_accuracy: 0.4089\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9662 - val_loss: 8.1231 - val_accuracy: 0.4600\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9644 - val_loss: 8.0144 - val_accuracy: 0.4000\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9611 - val_loss: 7.4333 - val_accuracy: 0.4111\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9667 - val_loss: 7.0108 - val_accuracy: 0.4622\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9620 - val_loss: 6.7959 - val_accuracy: 0.4156\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.3137 - accuracy: 0.3569 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0808 - accuracy: 0.3528 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3361 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1003 - accuracy: 0.3116 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3389 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1003 - accuracy: 0.3292 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3292 - val_loss: 1.0996 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0997 - accuracy: 0.3310 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3352 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3306 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3282 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3222 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0995 - accuracy: 0.3162 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1000 - accuracy: 0.3199 - val_loss: 1.0998 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3417 - val_loss: 1.0996 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0999 - accuracy: 0.3301 - val_loss: 1.0998 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3065 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3245 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3333 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0996 - accuracy: 0.3375 - val_loss: 1.1001 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1004 - accuracy: 0.3306 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3222 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3375 - val_loss: 1.1009 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3222 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3319 - val_loss: 1.0999 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1002 - accuracy: 0.3231 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0999 - accuracy: 0.3352 - val_loss: 1.0994 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0999 - accuracy: 0.3111 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3278 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1004 - accuracy: 0.3181 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1000 - accuracy: 0.3333 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3269 - val_loss: 1.0997 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0999 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3236 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1001 - accuracy: 0.3222 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1000 - accuracy: 0.3171 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3245 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3380 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3227 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0999 - accuracy: 0.3130 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.3435 - val_loss: 1.1007 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.3310 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.3347 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0998 - accuracy: 0.3324 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3278 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3329 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.1000 - accuracy: 0.3282 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.3241 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.1000 - accuracy: 0.3236 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3315 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.9955 - accuracy: 0.5435 - val_loss: 1.7185 - val_accuracy: 0.3289\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7806 - val_loss: 3.0701 - val_accuracy: 0.3822\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3697 - accuracy: 0.8514 - val_loss: 3.4781 - val_accuracy: 0.4089\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.9009 - val_loss: 3.6463 - val_accuracy: 0.4956\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.9014 - val_loss: 4.5399 - val_accuracy: 0.5022\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9449 - val_loss: 4.6709 - val_accuracy: 0.5089\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9551 - val_loss: 6.2793 - val_accuracy: 0.5044\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9375 - val_loss: 4.1384 - val_accuracy: 0.4378\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9606 - val_loss: 5.0956 - val_accuracy: 0.4511\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9611 - val_loss: 4.2627 - val_accuracy: 0.5711\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9759 - val_loss: 4.6202 - val_accuracy: 0.5044\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9782 - val_loss: 5.9187 - val_accuracy: 0.4311\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9778 - val_loss: 6.8347 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9782 - val_loss: 7.1667 - val_accuracy: 0.5111\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9745 - val_loss: 4.5544 - val_accuracy: 0.4822\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9736 - val_loss: 5.1660 - val_accuracy: 0.4133\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9824 - val_loss: 6.2887 - val_accuracy: 0.4022\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9759 - val_loss: 6.3139 - val_accuracy: 0.4822\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 7.0391 - val_accuracy: 0.5044\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9556 - val_loss: 8.8013 - val_accuracy: 0.4800\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9773 - val_loss: 7.4508 - val_accuracy: 0.4756\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9852 - val_loss: 10.3368 - val_accuracy: 0.3444\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 8.5801 - val_accuracy: 0.3711\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 10.2539 - val_accuracy: 0.4289\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9778 - val_loss: 9.0981 - val_accuracy: 0.4311\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9801 - val_loss: 10.0222 - val_accuracy: 0.4489\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9815 - val_loss: 10.2869 - val_accuracy: 0.5533\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 7.7808 - val_accuracy: 0.4422\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9880 - val_loss: 7.3048 - val_accuracy: 0.4467\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 9.7892 - val_accuracy: 0.4356\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9944 - val_loss: 10.4476 - val_accuracy: 0.4333\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 9.0038 - val_accuracy: 0.5489\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 12.6446 - val_accuracy: 0.5267\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9769 - val_loss: 10.2690 - val_accuracy: 0.4356\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9773 - val_loss: 10.1140 - val_accuracy: 0.4067\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9856 - val_loss: 6.3338 - val_accuracy: 0.4756\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 7.4190 - val_accuracy: 0.5556\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 9.4358 - val_accuracy: 0.4400\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9847 - val_loss: 10.4767 - val_accuracy: 0.4067\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9787 - val_loss: 11.2948 - val_accuracy: 0.4667\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9829 - val_loss: 10.1359 - val_accuracy: 0.4667\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9907 - val_loss: 11.9378 - val_accuracy: 0.4667\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 12.9727 - val_accuracy: 0.4311\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 11.2132 - val_accuracy: 0.5311\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 12.2044 - val_accuracy: 0.4911\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 10.9167 - val_accuracy: 0.5089\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 12.4011 - val_accuracy: 0.4844\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9810 - val_loss: 14.0787 - val_accuracy: 0.4200\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9769 - val_loss: 12.8331 - val_accuracy: 0.4133\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 13.0102 - val_accuracy: 0.4711\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 2.0488 - accuracy: 0.4310 - val_loss: 1.3854 - val_accuracy: 0.3533\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.8139 - accuracy: 0.6005 - val_loss: 1.2062 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.7236 - val_loss: 1.2470 - val_accuracy: 0.4756\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7861 - val_loss: 2.7677 - val_accuracy: 0.4711\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8403 - val_loss: 1.9990 - val_accuracy: 0.5422\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8866 - val_loss: 3.5380 - val_accuracy: 0.3578\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.8995 - val_loss: 3.1292 - val_accuracy: 0.4756\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.8759 - val_loss: 6.2292 - val_accuracy: 0.3556\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.8884 - val_loss: 3.2449 - val_accuracy: 0.4444\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9079 - val_loss: 5.1218 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2159 - accuracy: 0.9116 - val_loss: 6.3848 - val_accuracy: 0.4978\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1568 - accuracy: 0.9366 - val_loss: 8.8076 - val_accuracy: 0.4467\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1616 - accuracy: 0.9440 - val_loss: 4.6186 - val_accuracy: 0.5156\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9500 - val_loss: 5.8919 - val_accuracy: 0.4978\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9579 - val_loss: 6.8204 - val_accuracy: 0.4644\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9486 - val_loss: 4.8546 - val_accuracy: 0.4689\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.9384 - val_loss: 6.6920 - val_accuracy: 0.4178\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9338 - val_loss: 11.7095 - val_accuracy: 0.4089\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.2353 - accuracy: 0.9218 - val_loss: 3.8503 - val_accuracy: 0.4956\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9500 - val_loss: 5.3638 - val_accuracy: 0.4333\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9685 - val_loss: 9.0209 - val_accuracy: 0.3822\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9778 - val_loss: 4.4395 - val_accuracy: 0.4400\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9750 - val_loss: 6.1934 - val_accuracy: 0.4489\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9773 - val_loss: 7.9352 - val_accuracy: 0.4111\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9787 - val_loss: 5.7183 - val_accuracy: 0.4911\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9694 - val_loss: 4.5319 - val_accuracy: 0.5222\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9681 - val_loss: 8.2481 - val_accuracy: 0.4733\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9597 - val_loss: 5.6712 - val_accuracy: 0.5244\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.9412 - val_loss: 5.8959 - val_accuracy: 0.4378\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9722 - val_loss: 7.4324 - val_accuracy: 0.3978\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9764 - val_loss: 9.9583 - val_accuracy: 0.4289\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9819 - val_loss: 9.4983 - val_accuracy: 0.4311\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9824 - val_loss: 10.4285 - val_accuracy: 0.4533\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 0.9773 - val_loss: 8.5529 - val_accuracy: 0.5311\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9745 - val_loss: 4.7975 - val_accuracy: 0.4800\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9764 - val_loss: 7.3471 - val_accuracy: 0.5044\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9741 - val_loss: 6.8628 - val_accuracy: 0.4956\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9745 - val_loss: 11.0961 - val_accuracy: 0.4467\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9546 - val_loss: 6.8529 - val_accuracy: 0.4800\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9778 - val_loss: 8.0171 - val_accuracy: 0.4156\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9792 - val_loss: 11.4211 - val_accuracy: 0.4533\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9736 - val_loss: 6.0788 - val_accuracy: 0.5156\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9880 - val_loss: 9.5936 - val_accuracy: 0.4556\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9824 - val_loss: 7.7185 - val_accuracy: 0.4689\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9824 - val_loss: 8.3937 - val_accuracy: 0.5178\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9787 - val_loss: 11.3427 - val_accuracy: 0.4400\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9787 - val_loss: 8.8985 - val_accuracy: 0.4933\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9852 - val_loss: 10.1161 - val_accuracy: 0.4733\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9824 - val_loss: 10.2224 - val_accuracy: 0.5044\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9898 - val_loss: 11.0826 - val_accuracy: 0.5222\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 2.0669 - accuracy: 0.4894 - val_loss: 1.3111 - val_accuracy: 0.3556\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.7329 - val_loss: 1.3702 - val_accuracy: 0.3378\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8449 - val_loss: 1.9048 - val_accuracy: 0.4378\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.8931 - val_loss: 3.4351 - val_accuracy: 0.3511\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.9185 - val_loss: 3.9842 - val_accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.9389 - val_loss: 4.4799 - val_accuracy: 0.3533\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1207 - accuracy: 0.9556 - val_loss: 5.8152 - val_accuracy: 0.3356\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.1454 - accuracy: 0.9463 - val_loss: 5.3140 - val_accuracy: 0.3267\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9662 - val_loss: 4.6961 - val_accuracy: 0.4156\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9745 - val_loss: 7.3660 - val_accuracy: 0.4156\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9685 - val_loss: 7.7055 - val_accuracy: 0.4489\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9685 - val_loss: 5.9140 - val_accuracy: 0.4422\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9657 - val_loss: 7.1608 - val_accuracy: 0.3800\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9694 - val_loss: 7.6084 - val_accuracy: 0.3889\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 6.8500 - val_accuracy: 0.4556\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9880 - val_loss: 6.2868 - val_accuracy: 0.4844\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 5.7973 - val_accuracy: 0.4556\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 6.3066 - val_accuracy: 0.4622\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 7.2173 - val_accuracy: 0.4000\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 7.2865 - val_accuracy: 0.4378\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 7.2603 - val_accuracy: 0.4311\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 9.3317 - val_accuracy: 0.4200\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9810 - val_loss: 6.8617 - val_accuracy: 0.4267\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9736 - val_loss: 9.4672 - val_accuracy: 0.3667\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9718 - val_loss: 10.8911 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9907 - val_loss: 11.5464 - val_accuracy: 0.3044\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 8.5133 - val_accuracy: 0.3800\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 8.7385 - val_accuracy: 0.3756\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 7.1229 - val_accuracy: 0.4067\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 8.4831 - val_accuracy: 0.3956\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9926 - val_loss: 9.1272 - val_accuracy: 0.4711\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 9.0053 - val_accuracy: 0.4000\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 8.5332 - val_accuracy: 0.4378\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9769 - val_loss: 11.5410 - val_accuracy: 0.3778\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9671 - val_loss: 9.8085 - val_accuracy: 0.4244\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9755 - val_loss: 13.4603 - val_accuracy: 0.3978\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9731 - val_loss: 8.8620 - val_accuracy: 0.4578\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9898 - val_loss: 9.1755 - val_accuracy: 0.4556\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9949 - val_loss: 9.5597 - val_accuracy: 0.4889\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 7.9404 - val_accuracy: 0.4311\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9944 - val_loss: 8.6334 - val_accuracy: 0.4667\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 9.5262 - val_accuracy: 0.4867\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 9.8211 - val_accuracy: 0.4311\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 9.5834 - val_accuracy: 0.4000\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 8.9213 - val_accuracy: 0.4356\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9954 - val_loss: 9.1821 - val_accuracy: 0.4489\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9866 - val_loss: 6.8430 - val_accuracy: 0.3600\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9759 - val_loss: 9.5513 - val_accuracy: 0.4556\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9843 - val_loss: 7.9378 - val_accuracy: 0.4556\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9833 - val_loss: 11.8785 - val_accuracy: 0.4889\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 2.5063 - accuracy: 0.3468 - val_loss: 1.0972 - val_accuracy: 0.3778\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0422 - accuracy: 0.4148 - val_loss: 1.1278 - val_accuracy: 0.4267\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0096 - accuracy: 0.4431 - val_loss: 1.2546 - val_accuracy: 0.4133\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.9534 - accuracy: 0.4968 - val_loss: 1.1154 - val_accuracy: 0.3956\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.8743 - accuracy: 0.5407 - val_loss: 1.7707 - val_accuracy: 0.3844\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.8183 - accuracy: 0.5690 - val_loss: 1.6043 - val_accuracy: 0.3400\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7940 - accuracy: 0.5736 - val_loss: 1.8708 - val_accuracy: 0.3933\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7708 - accuracy: 0.5931 - val_loss: 1.8008 - val_accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7404 - accuracy: 0.5972 - val_loss: 2.2256 - val_accuracy: 0.3867\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7462 - accuracy: 0.5963 - val_loss: 1.8415 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.6546 - val_loss: 2.2919 - val_accuracy: 0.3600\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6926 - val_loss: 2.8844 - val_accuracy: 0.4800\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.7380 - val_loss: 3.3726 - val_accuracy: 0.4689\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7403 - val_loss: 3.4742 - val_accuracy: 0.3467\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.8125 - val_loss: 4.0698 - val_accuracy: 0.4400\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.8019 - val_loss: 3.5125 - val_accuracy: 0.3911\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.8009 - val_loss: 3.6704 - val_accuracy: 0.4267\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7505 - val_loss: 4.1649 - val_accuracy: 0.4533\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8495 - val_loss: 3.6343 - val_accuracy: 0.4511\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8699 - val_loss: 3.8074 - val_accuracy: 0.4178\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8569 - val_loss: 5.0833 - val_accuracy: 0.4044\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8935 - val_loss: 3.9830 - val_accuracy: 0.4111\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8801 - val_loss: 3.5371 - val_accuracy: 0.4644\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8880 - val_loss: 4.8115 - val_accuracy: 0.4156\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.9088 - val_loss: 5.0140 - val_accuracy: 0.3822\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.9157 - val_loss: 6.3717 - val_accuracy: 0.4111\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.9144 - val_loss: 5.3301 - val_accuracy: 0.5422\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.9005 - val_loss: 6.0440 - val_accuracy: 0.3444\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.9319 - val_loss: 6.0513 - val_accuracy: 0.3533\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.9037 - val_loss: 6.8502 - val_accuracy: 0.3578\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.9352 - val_loss: 5.7004 - val_accuracy: 0.3533\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.9269 - val_loss: 5.9962 - val_accuracy: 0.3489\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.9356 - val_loss: 6.0639 - val_accuracy: 0.4022\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.9278 - val_loss: 7.7592 - val_accuracy: 0.3822\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9329 - val_loss: 8.3038 - val_accuracy: 0.4867\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.9366 - val_loss: 6.0946 - val_accuracy: 0.3533\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9491 - val_loss: 5.2833 - val_accuracy: 0.3778\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.9389 - val_loss: 4.9762 - val_accuracy: 0.3911\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9481 - val_loss: 5.0572 - val_accuracy: 0.4178\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9588 - val_loss: 5.6164 - val_accuracy: 0.3911\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2310 - accuracy: 0.9338 - val_loss: 9.1737 - val_accuracy: 0.4133\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.9356 - val_loss: 6.3338 - val_accuracy: 0.3889\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.9324 - val_loss: 7.1525 - val_accuracy: 0.3800\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9560 - val_loss: 7.7089 - val_accuracy: 0.3733\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2230 - accuracy: 0.9426 - val_loss: 10.3634 - val_accuracy: 0.4822\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9463 - val_loss: 7.1354 - val_accuracy: 0.4022\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1999 - accuracy: 0.9546 - val_loss: 9.2461 - val_accuracy: 0.4422\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9569 - val_loss: 9.0037 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.9356 - val_loss: 6.9358 - val_accuracy: 0.4222\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9352 - val_loss: 7.5376 - val_accuracy: 0.3822\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 2.2001 - accuracy: 0.3269 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.3306 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3204 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3361 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3319 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3259 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3134 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3134 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.3273 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0991 - accuracy: 0.3185 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3306 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3065 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3204 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3231 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3148 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3037 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3273 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3120 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3190 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1000 - accuracy: 0.3208 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3194 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3296 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3306 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3329 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3259 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3273 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3241 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0991 - accuracy: 0.3315 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3269 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.3296 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3370 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3245 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3074 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3250 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1003 - accuracy: 0.3222 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1003 - accuracy: 0.3130 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3361 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3194 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3333 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3130 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3306 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3162 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3310 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3361 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3241 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3324 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3139 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3347 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3315 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3213 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 1.5202 - accuracy: 0.3426 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0775 - accuracy: 0.3343 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0764 - accuracy: 0.3296 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0762 - accuracy: 0.3403 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0759 - accuracy: 0.3481 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0781 - accuracy: 0.3440 - val_loss: 1.1001 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0840 - accuracy: 0.3426 - val_loss: 1.1003 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3185 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3296 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3236 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3208 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3250 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 1.0996 - accuracy: 0.3236 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.3250 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 1.0994 - accuracy: 0.3333 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0999 - accuracy: 0.3162 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.3384 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3259 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3227 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0991 - accuracy: 0.3278 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3144 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3241 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3255 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3218 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3144 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3176 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3306 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.3333 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3241 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3213 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3241 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1004 - accuracy: 0.3306 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3273 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.3259 - val_loss: 1.0993 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3218 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0991 - accuracy: 0.3056 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3231 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.3028 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3338 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3139 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0993 - accuracy: 0.3306 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3352 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.3241 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3287 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.3194 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3343 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3236 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.3176 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0996 - accuracy: 0.3185 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 2.0128 - accuracy: 0.5139 - val_loss: 2.1533 - val_accuracy: 0.2911\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7593 - val_loss: 1.9959 - val_accuracy: 0.5111\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8412 - val_loss: 2.0903 - val_accuracy: 0.3867\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8569 - val_loss: 2.5092 - val_accuracy: 0.3822\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2241 - accuracy: 0.9157 - val_loss: 3.6842 - val_accuracy: 0.4178\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.9412 - val_loss: 3.6547 - val_accuracy: 0.4467\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9583 - val_loss: 4.7640 - val_accuracy: 0.5289\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9560 - val_loss: 5.2688 - val_accuracy: 0.3933\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9630 - val_loss: 4.6820 - val_accuracy: 0.5422\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9736 - val_loss: 6.3103 - val_accuracy: 0.5267\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9528 - val_loss: 8.4217 - val_accuracy: 0.4156\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9602 - val_loss: 6.4179 - val_accuracy: 0.5289\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0855 - accuracy: 0.9708 - val_loss: 6.9940 - val_accuracy: 0.5089\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9787 - val_loss: 8.6287 - val_accuracy: 0.4133\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 7.8089 - val_accuracy: 0.4622\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9856 - val_loss: 6.4967 - val_accuracy: 0.4733\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 8.3716 - val_accuracy: 0.4844\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9699 - val_loss: 6.0298 - val_accuracy: 0.4733\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9819 - val_loss: 9.0924 - val_accuracy: 0.4822\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 8.5440 - val_accuracy: 0.4844\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 8.8450 - val_accuracy: 0.4822\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 8.3626 - val_accuracy: 0.4067\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9843 - val_loss: 8.2080 - val_accuracy: 0.4667\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9782 - val_loss: 7.2361 - val_accuracy: 0.4689\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9907 - val_loss: 8.8637 - val_accuracy: 0.4911\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9787 - val_loss: 9.7955 - val_accuracy: 0.4822\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9898 - val_loss: 7.4969 - val_accuracy: 0.5044\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 9.0844 - val_accuracy: 0.4756\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9741 - val_loss: 9.1358 - val_accuracy: 0.5289\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 8.4059 - val_accuracy: 0.4867\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 8.6729 - val_accuracy: 0.5267\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 8.9464 - val_accuracy: 0.5044\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 8.8108 - val_accuracy: 0.5044\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 10.2093 - val_accuracy: 0.5133\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 9.9163 - val_accuracy: 0.4889\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9958 - val_loss: 9.0065 - val_accuracy: 0.5111\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9644 - val_loss: 9.7570 - val_accuracy: 0.4489\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9806 - val_loss: 9.8964 - val_accuracy: 0.4222\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 11.8337 - val_accuracy: 0.5022\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 10.4049 - val_accuracy: 0.4622\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9907 - val_loss: 10.6056 - val_accuracy: 0.4622\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 11.7782 - val_accuracy: 0.5044\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 10.7375 - val_accuracy: 0.4556\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 12.3643 - val_accuracy: 0.4356\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 10.2149 - val_accuracy: 0.4689\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 11.5234 - val_accuracy: 0.4933\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9829 - val_loss: 14.0632 - val_accuracy: 0.4533\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 13.6916 - val_accuracy: 0.4822\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 11.0393 - val_accuracy: 0.4289\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9866 - val_loss: 11.0831 - val_accuracy: 0.4822\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 2.3575 - accuracy: 0.3472 - val_loss: 1.0988 - val_accuracy: 0.3356\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0364 - accuracy: 0.4398 - val_loss: 1.1263 - val_accuracy: 0.3467\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.9754 - accuracy: 0.4931 - val_loss: 1.1292 - val_accuracy: 0.3467\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.9148 - accuracy: 0.5458 - val_loss: 1.4700 - val_accuracy: 0.3756\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.8468 - accuracy: 0.5926 - val_loss: 1.6232 - val_accuracy: 0.2822\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7968 - accuracy: 0.6278 - val_loss: 1.3700 - val_accuracy: 0.3489\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7545 - accuracy: 0.6685 - val_loss: 1.4880 - val_accuracy: 0.3533\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7188 - accuracy: 0.6931 - val_loss: 1.7248 - val_accuracy: 0.3667\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.7204 - val_loss: 1.7483 - val_accuracy: 0.3978\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.7306 - val_loss: 2.1776 - val_accuracy: 0.4356\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.7296 - val_loss: 2.1539 - val_accuracy: 0.3422\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.7227 - val_loss: 1.7734 - val_accuracy: 0.3578\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.7648 - val_loss: 2.2021 - val_accuracy: 0.3911\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7977 - val_loss: 1.8880 - val_accuracy: 0.3644\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7968 - val_loss: 4.1154 - val_accuracy: 0.4667\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.8134 - val_loss: 4.1219 - val_accuracy: 0.5222\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8250 - val_loss: 4.2235 - val_accuracy: 0.4089\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8153 - val_loss: 8.2056 - val_accuracy: 0.3889\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8565 - val_loss: 7.2555 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8444 - val_loss: 3.0577 - val_accuracy: 0.4689\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8685 - val_loss: 4.8853 - val_accuracy: 0.5067\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8667 - val_loss: 6.6525 - val_accuracy: 0.4800\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8861 - val_loss: 4.4357 - val_accuracy: 0.3800\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.9056 - val_loss: 7.2367 - val_accuracy: 0.4822\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8875 - val_loss: 8.5361 - val_accuracy: 0.4911\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.9005 - val_loss: 6.3273 - val_accuracy: 0.4733\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.9106 - val_loss: 4.7548 - val_accuracy: 0.4089\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.9097 - val_loss: 6.2546 - val_accuracy: 0.4489\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.9042 - val_loss: 9.7644 - val_accuracy: 0.4822\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.9241 - val_loss: 7.6869 - val_accuracy: 0.5044\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9241 - val_loss: 7.8209 - val_accuracy: 0.5222\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.9301 - val_loss: 6.6253 - val_accuracy: 0.4489\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.9361 - val_loss: 9.2296 - val_accuracy: 0.4933\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2442 - accuracy: 0.9347 - val_loss: 9.8766 - val_accuracy: 0.4822\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.2410 - accuracy: 0.9407 - val_loss: 10.5926 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.9231 - val_loss: 6.3652 - val_accuracy: 0.3822\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.9241 - val_loss: 9.1134 - val_accuracy: 0.4133\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.9352 - val_loss: 7.7755 - val_accuracy: 0.4556\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9602 - val_loss: 9.5686 - val_accuracy: 0.4667\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9509 - val_loss: 10.1382 - val_accuracy: 0.4600\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9370 - val_loss: 18.9791 - val_accuracy: 0.4244\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.9264 - val_loss: 13.6287 - val_accuracy: 0.4956\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2161 - accuracy: 0.9528 - val_loss: 9.4487 - val_accuracy: 0.4889\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9556 - val_loss: 10.5458 - val_accuracy: 0.4756\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9657 - val_loss: 13.8919 - val_accuracy: 0.4689\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.9227 - val_loss: 9.8428 - val_accuracy: 0.4733\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2159 - accuracy: 0.9431 - val_loss: 6.3812 - val_accuracy: 0.3956\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9657 - val_loss: 6.5221 - val_accuracy: 0.4267\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9630 - val_loss: 13.0166 - val_accuracy: 0.4756\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9755 - val_loss: 10.5057 - val_accuracy: 0.4356\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 13ms/step - loss: 2.7533 - accuracy: 0.3273 - val_loss: 1.1003 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0998 - accuracy: 0.3333 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.3250 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3319 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3273 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3241 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3296 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3301 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3102 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3296 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3343 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3287 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3176 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0995 - accuracy: 0.3181 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3273 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3102 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3255 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3273 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3255 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0993 - accuracy: 0.3157 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3250 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3269 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3167 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3287 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3208 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3204 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3287 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3292 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0997 - accuracy: 0.3264 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3204 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3218 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3296 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3097 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.3185 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3245 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3282 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3287 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3343 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3301 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3255 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3329 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3204 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0994 - accuracy: 0.3296 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3264 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 2.9735 - accuracy: 0.3333 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3333 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.2995 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3130 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3301 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3380 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3333 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3134 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3255 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3157 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3282 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3292 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3222 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3162 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3079 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0994 - accuracy: 0.3171 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3347 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3366 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3176 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3218 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3264 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3144 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3204 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3218 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3269 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3324 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3162 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.3213 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3208 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3065 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3301 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3259 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3245 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3218 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.3301 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3301 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3352 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0996 - accuracy: 0.3282 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3255 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.3194 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3139 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3185 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3255 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3333 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 1.9226 - accuracy: 0.3259 - val_loss: 1.1036 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3236 - val_loss: 1.1001 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3148 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3153 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3181 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3264 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3190 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3208 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3208 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3181 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3296 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3199 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3250 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3139 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3213 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3171 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3162 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3301 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0994 - accuracy: 0.3199 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3356 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3199 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0998 - accuracy: 0.3116 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3060 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3296 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3306 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3181 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3153 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3241 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3218 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0997 - accuracy: 0.3347 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.1000 - accuracy: 0.3250 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3296 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3139 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3204 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3185 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3181 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3171 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3176 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3269 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3171 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3134 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0996 - accuracy: 0.3069 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3208 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0994 - accuracy: 0.3282 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 3.9193 - accuracy: 0.3602 - val_loss: 1.1363 - val_accuracy: 0.3178\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0287 - accuracy: 0.4269 - val_loss: 1.1908 - val_accuracy: 0.4044\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.9978 - accuracy: 0.4343 - val_loss: 1.2302 - val_accuracy: 0.3533\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.9401 - accuracy: 0.4866 - val_loss: 1.3896 - val_accuracy: 0.3511\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8944 - accuracy: 0.5282 - val_loss: 1.3950 - val_accuracy: 0.3022\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8581 - accuracy: 0.5389 - val_loss: 1.2276 - val_accuracy: 0.4267\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.8536 - accuracy: 0.5440 - val_loss: 2.2241 - val_accuracy: 0.3756\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.8041 - accuracy: 0.5671 - val_loss: 2.1910 - val_accuracy: 0.3867\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7620 - accuracy: 0.5944 - val_loss: 1.5803 - val_accuracy: 0.4733\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7543 - accuracy: 0.5935 - val_loss: 3.1403 - val_accuracy: 0.3689\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7169 - accuracy: 0.6060 - val_loss: 2.1397 - val_accuracy: 0.3467\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7184 - accuracy: 0.5968 - val_loss: 2.8724 - val_accuracy: 0.3733\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.6162 - val_loss: 2.0353 - val_accuracy: 0.3733\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6450 - accuracy: 0.6282 - val_loss: 1.8022 - val_accuracy: 0.3044\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6220 - accuracy: 0.6426 - val_loss: 2.5310 - val_accuracy: 0.3556\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6282 - val_loss: 3.1675 - val_accuracy: 0.3511\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.6190 - val_loss: 2.4742 - val_accuracy: 0.3200\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.6231 - val_loss: 3.4847 - val_accuracy: 0.3644\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.6241 - val_loss: 2.6303 - val_accuracy: 0.3400\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.6190 - val_loss: 3.0884 - val_accuracy: 0.3644\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.6199 - val_loss: 3.1171 - val_accuracy: 0.3756\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.6310 - val_loss: 2.3776 - val_accuracy: 0.3044\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6360 - accuracy: 0.6213 - val_loss: 3.9836 - val_accuracy: 0.4111\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.6190 - val_loss: 3.6567 - val_accuracy: 0.4222\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.6361 - val_loss: 2.1124 - val_accuracy: 0.3378\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5704 - accuracy: 0.6338 - val_loss: 2.7871 - val_accuracy: 0.3222\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.6319 - val_loss: 3.7614 - val_accuracy: 0.3556\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.6458 - val_loss: 3.7252 - val_accuracy: 0.3889\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.6458 - val_loss: 3.0196 - val_accuracy: 0.3800\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.6431 - val_loss: 4.3170 - val_accuracy: 0.3467\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5565 - accuracy: 0.6412 - val_loss: 2.4040 - val_accuracy: 0.3444\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5577 - accuracy: 0.6463 - val_loss: 3.0383 - val_accuracy: 0.3467\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.6528 - val_loss: 2.7434 - val_accuracy: 0.3400\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5428 - accuracy: 0.6519 - val_loss: 3.6207 - val_accuracy: 0.3689\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.6556 - val_loss: 3.2551 - val_accuracy: 0.3622\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5517 - accuracy: 0.6403 - val_loss: 2.9020 - val_accuracy: 0.3600\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.6407 - val_loss: 3.7033 - val_accuracy: 0.3711\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.6523 - val_loss: 4.3497 - val_accuracy: 0.3467\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5345 - accuracy: 0.6537 - val_loss: 3.3066 - val_accuracy: 0.3711\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.6398 - val_loss: 3.9700 - val_accuracy: 0.3444\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.6606 - val_loss: 2.8916 - val_accuracy: 0.3800\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.6495 - val_loss: 2.9504 - val_accuracy: 0.3378\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.6606 - val_loss: 3.3213 - val_accuracy: 0.3667\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.6421 - val_loss: 3.5824 - val_accuracy: 0.3289\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.6588 - val_loss: 3.3681 - val_accuracy: 0.3689\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.6593 - val_loss: 3.2141 - val_accuracy: 0.3778\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.6593 - val_loss: 3.2103 - val_accuracy: 0.3667\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5604 - accuracy: 0.6421 - val_loss: 4.2608 - val_accuracy: 0.4156\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6104 - accuracy: 0.6250 - val_loss: 2.5061 - val_accuracy: 0.3356\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7157 - accuracy: 0.6088 - val_loss: 2.0066 - val_accuracy: 0.3156\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 1.9051 - accuracy: 0.3616 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0663 - accuracy: 0.3884 - val_loss: 1.1018 - val_accuracy: 0.3311\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0647 - accuracy: 0.3801 - val_loss: 1.1031 - val_accuracy: 0.3289\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0576 - accuracy: 0.3824 - val_loss: 1.1028 - val_accuracy: 0.3311\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0517 - accuracy: 0.3796 - val_loss: 1.1015 - val_accuracy: 0.3311\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0486 - accuracy: 0.3810 - val_loss: 1.1049 - val_accuracy: 0.3289\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0477 - accuracy: 0.3653 - val_loss: 1.1034 - val_accuracy: 0.3311\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0493 - accuracy: 0.3630 - val_loss: 1.1048 - val_accuracy: 0.3311\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0466 - accuracy: 0.3801 - val_loss: 1.0994 - val_accuracy: 0.3356\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0462 - accuracy: 0.3741 - val_loss: 1.1008 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0466 - accuracy: 0.3782 - val_loss: 1.1007 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0465 - accuracy: 0.3745 - val_loss: 1.1014 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0469 - accuracy: 0.3727 - val_loss: 1.1011 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0461 - accuracy: 0.3713 - val_loss: 1.1006 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0461 - accuracy: 0.3796 - val_loss: 1.1001 - val_accuracy: 0.3356\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0460 - accuracy: 0.3810 - val_loss: 1.1003 - val_accuracy: 0.3356\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0462 - accuracy: 0.3667 - val_loss: 1.1018 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0465 - accuracy: 0.3796 - val_loss: 1.1005 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0459 - accuracy: 0.3736 - val_loss: 1.1003 - val_accuracy: 0.3356\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0462 - accuracy: 0.3769 - val_loss: 1.1003 - val_accuracy: 0.3356\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0471 - accuracy: 0.3759 - val_loss: 1.0991 - val_accuracy: 0.3356\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0458 - accuracy: 0.3796 - val_loss: 1.0995 - val_accuracy: 0.3356\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0467 - accuracy: 0.3741 - val_loss: 1.0992 - val_accuracy: 0.3356\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0460 - accuracy: 0.3736 - val_loss: 1.0991 - val_accuracy: 0.3356\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0506 - accuracy: 0.3782 - val_loss: 1.1019 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0564 - accuracy: 0.3722 - val_loss: 1.2672 - val_accuracy: 0.3533\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0481 - accuracy: 0.3787 - val_loss: 1.2055 - val_accuracy: 0.3156\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0472 - accuracy: 0.3653 - val_loss: 1.2181 - val_accuracy: 0.3222\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0478 - accuracy: 0.3769 - val_loss: 1.1810 - val_accuracy: 0.3533\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0464 - accuracy: 0.3792 - val_loss: 1.1652 - val_accuracy: 0.3556\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0458 - accuracy: 0.3796 - val_loss: 1.1581 - val_accuracy: 0.3378\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0462 - accuracy: 0.3810 - val_loss: 1.1539 - val_accuracy: 0.3622\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0458 - accuracy: 0.3653 - val_loss: 1.1513 - val_accuracy: 0.3644\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0475 - accuracy: 0.3782 - val_loss: 1.1505 - val_accuracy: 0.3600\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0463 - accuracy: 0.3662 - val_loss: 1.1505 - val_accuracy: 0.3600\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0466 - accuracy: 0.3718 - val_loss: 1.1511 - val_accuracy: 0.3533\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0458 - accuracy: 0.3769 - val_loss: 1.1513 - val_accuracy: 0.3600\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0460 - accuracy: 0.3718 - val_loss: 1.1517 - val_accuracy: 0.3467\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0459 - accuracy: 0.3750 - val_loss: 1.1523 - val_accuracy: 0.3600\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0473 - accuracy: 0.3787 - val_loss: 1.1529 - val_accuracy: 0.3622\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0469 - accuracy: 0.3755 - val_loss: 1.1538 - val_accuracy: 0.3489\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0462 - accuracy: 0.3750 - val_loss: 1.1547 - val_accuracy: 0.3578\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0472 - accuracy: 0.3713 - val_loss: 1.1564 - val_accuracy: 0.3489\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0463 - accuracy: 0.3731 - val_loss: 1.1572 - val_accuracy: 0.3622\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0466 - accuracy: 0.3667 - val_loss: 1.1582 - val_accuracy: 0.3622\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0472 - accuracy: 0.3681 - val_loss: 1.1612 - val_accuracy: 0.3622\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0460 - accuracy: 0.3639 - val_loss: 1.1623 - val_accuracy: 0.3622\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0460 - accuracy: 0.3708 - val_loss: 1.1631 - val_accuracy: 0.3622\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0468 - accuracy: 0.3787 - val_loss: 1.1641 - val_accuracy: 0.3622\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0467 - accuracy: 0.3694 - val_loss: 1.1648 - val_accuracy: 0.3622\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 3.8881 - accuracy: 0.3764 - val_loss: 1.1502 - val_accuracy: 0.3200\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0998 - accuracy: 0.3333 - val_loss: 1.1031 - val_accuracy: 0.3156\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3333 - val_loss: 1.1000 - val_accuracy: 0.3022\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3194 - val_loss: 1.0964 - val_accuracy: 0.3400\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3116 - val_loss: 1.0952 - val_accuracy: 0.3244\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3264 - val_loss: 1.0956 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3329 - val_loss: 1.0949 - val_accuracy: 0.3489\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3333 - val_loss: 1.0952 - val_accuracy: 0.3489\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3139 - val_loss: 1.0961 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3208 - val_loss: 1.0973 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3120 - val_loss: 1.0980 - val_accuracy: 0.3378\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0994 - accuracy: 0.3241 - val_loss: 1.0985 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3356\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3269 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3306 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3148 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3282 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3208 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3213 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0993 - accuracy: 0.3324 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3329 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3250 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3218 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3315 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3157 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3301 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3278 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0996 - accuracy: 0.3231 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0994 - accuracy: 0.3264 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3144 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3051 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3329 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3333 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3310 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0994 - accuracy: 0.3231 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3264 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3125 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3199 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0995 - accuracy: 0.3213 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3306 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.3208 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.3139 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3292 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3032 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3250 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3227 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3255 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 3.8554 - accuracy: 0.3593 - val_loss: 1.1946 - val_accuracy: 0.3356\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3333 - val_loss: 1.1216 - val_accuracy: 0.3400\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0984 - val_accuracy: 0.3222\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.3213 - val_loss: 1.0985 - val_accuracy: 0.3222\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3287 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0987 - accuracy: 0.3287 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3236 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3264 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3282 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0992 - accuracy: 0.3264 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3264 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3190 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3194 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3287 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3310 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3292 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3236 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0993 - accuracy: 0.3287 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3273 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3292 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3176 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3301 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3315 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0991 - accuracy: 0.3181 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3194 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3245 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3310 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3296 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3181 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3144 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3278 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3310 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3185 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0990 - accuracy: 0.3255 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3282 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3264 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3264 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3199 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3231 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3333 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3222 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0992 - accuracy: 0.3032 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.3088 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0997 - accuracy: 0.3245 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3204 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0994 - accuracy: 0.3106 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0991 - accuracy: 0.3315 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.8680 - accuracy: 0.5824 - val_loss: 1.1039 - val_accuracy: 0.3400\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8426 - val_loss: 1.3681 - val_accuracy: 0.5200\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2333 - accuracy: 0.9190 - val_loss: 2.6013 - val_accuracy: 0.4044\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9366 - val_loss: 3.6158 - val_accuracy: 0.3933\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9704 - val_loss: 3.7805 - val_accuracy: 0.4511\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9796 - val_loss: 6.6109 - val_accuracy: 0.4133\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9912 - val_loss: 7.0450 - val_accuracy: 0.4578\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 8.6133 - val_accuracy: 0.4822\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 11.2339 - val_accuracy: 0.4267\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 10.2805 - val_accuracy: 0.4422\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9931 - val_loss: 10.6972 - val_accuracy: 0.5200\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 10.3931 - val_accuracy: 0.4600\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 9.4987 - val_accuracy: 0.4489\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9977 - val_loss: 13.1357 - val_accuracy: 0.4689\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9894 - val_loss: 9.6685 - val_accuracy: 0.4333\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9755 - val_loss: 8.0210 - val_accuracy: 0.4933\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 9.0614 - val_accuracy: 0.5311\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 8.8783 - val_accuracy: 0.5867\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 9.0968 - val_accuracy: 0.5644\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.9681 - val_accuracy: 0.5578\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 9.5802 - val_accuracy: 0.4422\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9796 - val_loss: 8.2422 - val_accuracy: 0.4533\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 7.4636 - val_accuracy: 0.5422\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 8.3048 - val_accuracy: 0.5689\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 9.7355 - val_accuracy: 0.5622\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.3026 - val_accuracy: 0.5511\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 8.7461 - val_accuracy: 0.5444\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 9.4425 - val_accuracy: 0.5689\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 9.8987 - val_accuracy: 0.5689\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 7.8982 - val_accuracy: 0.5356\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 10.4693 - val_accuracy: 0.5044\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 12.4482 - val_accuracy: 0.5444\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 6.5175e-04 - accuracy: 1.0000 - val_loss: 11.3846 - val_accuracy: 0.5711\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 10.2181 - val_accuracy: 0.5644\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 13.1754 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9671 - val_loss: 11.3997 - val_accuracy: 0.4644\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 8.9499 - val_accuracy: 0.4911\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 11.4126 - val_accuracy: 0.5067\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 11.5560 - val_accuracy: 0.5289\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9898 - val_loss: 13.3796 - val_accuracy: 0.4978\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 11.5533 - val_accuracy: 0.4956\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 12.2619 - val_accuracy: 0.4956\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 8.1627e-04 - accuracy: 1.0000 - val_loss: 12.1110 - val_accuracy: 0.5200\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 12.2815 - val_accuracy: 0.5400\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 12.3462 - val_accuracy: 0.5133\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 5.8942e-04 - accuracy: 1.0000 - val_loss: 12.3801 - val_accuracy: 0.5044\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 8.0436e-04 - accuracy: 1.0000 - val_loss: 12.5106 - val_accuracy: 0.5222\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 10.5966 - val_accuracy: 0.5267\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 12.1219 - val_accuracy: 0.4600\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9838 - val_loss: 10.6488 - val_accuracy: 0.4911\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.7826 - accuracy: 0.6509 - val_loss: 1.1995 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8708 - val_loss: 1.5091 - val_accuracy: 0.3822\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1935 - accuracy: 0.9287 - val_loss: 2.3119 - val_accuracy: 0.5022\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9644 - val_loss: 2.5914 - val_accuracy: 0.4867\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9782 - val_loss: 3.8142 - val_accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9694 - val_loss: 6.5074 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9861 - val_loss: 6.8277 - val_accuracy: 0.4311\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9829 - val_loss: 10.3157 - val_accuracy: 0.4578\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9949 - val_loss: 4.8733 - val_accuracy: 0.4356\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9981 - val_loss: 6.0653 - val_accuracy: 0.5044\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 5.7198 - val_accuracy: 0.4756\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 6.4557 - val_accuracy: 0.4933\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 6.0826 - val_accuracy: 0.5067\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 6.6310 - val_accuracy: 0.5244\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 6.1682 - val_accuracy: 0.4778\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 5.8367 - val_accuracy: 0.3733\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 6.4851 - val_accuracy: 0.4200\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9509 - val_loss: 8.2867 - val_accuracy: 0.4800\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9662 - val_loss: 10.3087 - val_accuracy: 0.4644\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 9.4976 - val_accuracy: 0.4489\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 8.3896 - val_accuracy: 0.4778\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 8.3983 - val_accuracy: 0.4667\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 8.1340 - val_accuracy: 0.4644\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 6.4885 - val_accuracy: 0.4333\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 8.1558 - val_accuracy: 0.4800\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.8881 - val_accuracy: 0.4556\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 9.5164e-04 - accuracy: 1.0000 - val_loss: 9.0980 - val_accuracy: 0.4578\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 6.5622e-04 - accuracy: 1.0000 - val_loss: 9.1797 - val_accuracy: 0.4622\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.7535 - val_accuracy: 0.4978\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 8.1757e-04 - accuracy: 1.0000 - val_loss: 8.4970 - val_accuracy: 0.4956\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9870 - val_loss: 8.6720 - val_accuracy: 0.4867\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9792 - val_loss: 8.8730 - val_accuracy: 0.5289\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 7.6316 - val_accuracy: 0.4333\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 8.4123 - val_accuracy: 0.5756\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 8.8998 - val_accuracy: 0.4822\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 8.6467 - val_accuracy: 0.4933\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9741 - val_loss: 10.4354 - val_accuracy: 0.4667\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 10.2698 - val_accuracy: 0.4778\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 10.9470 - val_accuracy: 0.4644\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 9.4801 - val_accuracy: 0.4911\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 9.6770 - val_accuracy: 0.4733\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 9.6879 - val_accuracy: 0.4689\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 18.9362 - val_accuracy: 0.3556\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 9.9102 - val_accuracy: 0.4978\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 9.2823 - val_accuracy: 0.5644\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 11.1808 - val_accuracy: 0.4933\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 9.6108 - val_accuracy: 0.4444\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9912 - val_loss: 9.6816 - val_accuracy: 0.5578\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 9.8109 - val_accuracy: 0.5356\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 10.5645 - val_accuracy: 0.4689\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.9669 - accuracy: 0.5116 - val_loss: 1.1134 - val_accuracy: 0.3600\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7847 - val_loss: 1.2678 - val_accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8741 - val_loss: 1.6875 - val_accuracy: 0.4844\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9144 - val_loss: 3.6897 - val_accuracy: 0.3578\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2206 - accuracy: 0.9282 - val_loss: 3.2104 - val_accuracy: 0.4489\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9593 - val_loss: 3.7127 - val_accuracy: 0.4667\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9718 - val_loss: 5.3251 - val_accuracy: 0.4844\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9773 - val_loss: 5.7134 - val_accuracy: 0.4889\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9759 - val_loss: 5.8289 - val_accuracy: 0.4822\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9866 - val_loss: 6.4939 - val_accuracy: 0.4556\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9801 - val_loss: 5.8759 - val_accuracy: 0.4444\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9815 - val_loss: 7.3682 - val_accuracy: 0.4444\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9898 - val_loss: 8.3632 - val_accuracy: 0.5244\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9958 - val_loss: 6.5495 - val_accuracy: 0.4800\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 7.6632 - val_accuracy: 0.4378\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9981 - val_loss: 8.6237 - val_accuracy: 0.4911\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9981 - val_loss: 9.5026 - val_accuracy: 0.5178\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9977 - val_loss: 8.5214 - val_accuracy: 0.5133\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9995 - val_loss: 8.8664 - val_accuracy: 0.4778\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9995 - val_loss: 9.9261 - val_accuracy: 0.5067\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9889 - val_loss: 11.6170 - val_accuracy: 0.5489\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9847 - val_loss: 9.1843 - val_accuracy: 0.4244\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9935 - val_loss: 9.6201 - val_accuracy: 0.5111\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9935 - val_loss: 8.1199 - val_accuracy: 0.4822\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9963 - val_loss: 7.5928 - val_accuracy: 0.5511\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9940 - val_loss: 10.0108 - val_accuracy: 0.5533\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9977 - val_loss: 8.8352 - val_accuracy: 0.5067\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9977 - val_loss: 10.0146 - val_accuracy: 0.5889\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 11.2383 - val_accuracy: 0.5378\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 11.8154 - val_accuracy: 0.5133\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9981 - val_loss: 11.1812 - val_accuracy: 0.5289\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 11.3961 - val_accuracy: 0.5378\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9991 - val_loss: 8.9909 - val_accuracy: 0.5267\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 10.9726 - val_accuracy: 0.5267\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 11.5824 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9764 - val_loss: 10.9068 - val_accuracy: 0.5022\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9736 - val_loss: 9.3295 - val_accuracy: 0.4844\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9958 - val_loss: 9.2587 - val_accuracy: 0.5133\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 10.5197 - val_accuracy: 0.5711\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9944 - val_loss: 11.3814 - val_accuracy: 0.5400\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 10.4554 - val_accuracy: 0.5289\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 11.1321 - val_accuracy: 0.5378\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 12.0740 - val_accuracy: 0.5222\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 11.5324 - val_accuracy: 0.5200\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 12.6395 - val_accuracy: 0.5244\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 12.1448 - val_accuracy: 0.5222\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 13.3342 - val_accuracy: 0.5200\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 12.5628 - val_accuracy: 0.5267\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 12.6337 - val_accuracy: 0.5022\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9968 - val_loss: 11.5936 - val_accuracy: 0.5311\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_62 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8556 - accuracy: 0.5755 - val_loss: 1.1515 - val_accuracy: 0.3400\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8537 - val_loss: 1.1842 - val_accuracy: 0.4911\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9269 - val_loss: 2.0355 - val_accuracy: 0.4667\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9597 - val_loss: 2.7490 - val_accuracy: 0.4933\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9727 - val_loss: 2.6886 - val_accuracy: 0.4111\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9866 - val_loss: 6.3149 - val_accuracy: 0.4422\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9949 - val_loss: 4.5493 - val_accuracy: 0.4933\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 5.0106 - val_accuracy: 0.4889\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 4.4862 - val_accuracy: 0.4600\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 5.9604 - val_accuracy: 0.4600\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1515 - accuracy: 0.9532 - val_loss: 3.7620 - val_accuracy: 0.5244\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 4.2352 - val_accuracy: 0.5578\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9986 - val_loss: 5.5937 - val_accuracy: 0.5289\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 6.5879 - val_accuracy: 0.4822\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 5.9568 - val_accuracy: 0.4667\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 6.1414 - val_accuracy: 0.4978\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.7583 - val_accuracy: 0.5200\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.6995 - val_accuracy: 0.5556\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 7.4086 - val_accuracy: 0.4889\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.9315 - val_accuracy: 0.5533\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.5364 - val_accuracy: 0.5444\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.5958 - val_accuracy: 0.5444\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.3424 - val_accuracy: 0.5067\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 7.1766 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9583 - val_loss: 3.6654 - val_accuracy: 0.3822\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9796 - val_loss: 4.2190 - val_accuracy: 0.5778\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 5.6845 - val_accuracy: 0.4822\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.5518 - val_accuracy: 0.5267\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 5.7247 - val_accuracy: 0.5533\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 5.0270 - val_accuracy: 0.5133\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.0576 - val_accuracy: 0.5200\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.3297 - val_accuracy: 0.5444\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 5.7076 - val_accuracy: 0.5511\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 5.9647 - val_accuracy: 0.4622\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 9.0408e-04 - accuracy: 1.0000 - val_loss: 5.7022 - val_accuracy: 0.5244\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 5.8220 - val_accuracy: 0.5044\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 5.7718 - val_accuracy: 0.5044\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 8.8364 - val_accuracy: 0.4689\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 5.2381 - val_accuracy: 0.5222\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 6.2244e-04 - accuracy: 1.0000 - val_loss: 5.5962 - val_accuracy: 0.5356\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 6.0494 - val_accuracy: 0.4933\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9574 - val_loss: 6.4442 - val_accuracy: 0.4822\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9852 - val_loss: 5.1076 - val_accuracy: 0.4844\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 6.4583 - val_accuracy: 0.5467\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 6.6179 - val_accuracy: 0.4844\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 6.7941 - val_accuracy: 0.4267\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 6.2764 - val_accuracy: 0.4622\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 6.2861 - val_accuracy: 0.5244\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 5.7678 - val_accuracy: 0.6022\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 5.8043 - val_accuracy: 0.5533\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.8591 - accuracy: 0.5671 - val_loss: 1.1168 - val_accuracy: 0.3644\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8106 - val_loss: 1.2236 - val_accuracy: 0.4511\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8958 - val_loss: 1.8562 - val_accuracy: 0.4689\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9361 - val_loss: 3.1938 - val_accuracy: 0.4044\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9569 - val_loss: 4.4983 - val_accuracy: 0.4800\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9736 - val_loss: 3.8593 - val_accuracy: 0.4578\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9912 - val_loss: 4.8849 - val_accuracy: 0.4511\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9944 - val_loss: 5.8160 - val_accuracy: 0.4378\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9847 - val_loss: 6.5163 - val_accuracy: 0.4067\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 5.2352 - val_accuracy: 0.4467\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9977 - val_loss: 6.1524 - val_accuracy: 0.5178\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 6.5365 - val_accuracy: 0.4089\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 6.7906 - val_accuracy: 0.4044\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9759 - val_loss: 8.9023 - val_accuracy: 0.4911\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9750 - val_loss: 6.1032 - val_accuracy: 0.4311\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9963 - val_loss: 7.6888 - val_accuracy: 0.4533\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 7.3457 - val_accuracy: 0.4711\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9977 - val_loss: 7.1368 - val_accuracy: 0.4467\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 7.6193 - val_accuracy: 0.4667\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 7.4122 - val_accuracy: 0.4756\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9787 - val_loss: 8.8893 - val_accuracy: 0.4689\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9824 - val_loss: 8.1863 - val_accuracy: 0.4756\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 7.6075 - val_accuracy: 0.4867\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 8.3362 - val_accuracy: 0.4689\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 7.4865 - val_accuracy: 0.4733\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9986 - val_loss: 7.4569 - val_accuracy: 0.4400\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 8.6431 - val_accuracy: 0.4067\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 9.0687 - val_accuracy: 0.4200\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 8.0996 - val_accuracy: 0.4533\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 8.9873 - val_accuracy: 0.4422\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 10.9848 - val_accuracy: 0.4600\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9833 - val_loss: 9.5589 - val_accuracy: 0.4244\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9708 - val_loss: 10.9245 - val_accuracy: 0.5244\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 9.8312 - val_accuracy: 0.4689\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 10.2679 - val_accuracy: 0.4422\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 10.6434 - val_accuracy: 0.4600\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 9.9904 - val_accuracy: 0.4422\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 8.7875 - val_accuracy: 0.4711\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 9.2953 - val_accuracy: 0.4578\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 9.6704 - val_accuracy: 0.4844\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 9.2014 - val_accuracy: 0.4822\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 8.8079 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 8.1933 - val_accuracy: 0.4867\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 8.6869 - val_accuracy: 0.4778\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.2124 - val_accuracy: 0.4867\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 10.5564 - val_accuracy: 0.4844\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 11.2901 - val_accuracy: 0.5422\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9736 - val_loss: 12.0656 - val_accuracy: 0.5378\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 8.8470 - val_accuracy: 0.5044\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 9.7970 - val_accuracy: 0.4978\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_66 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7160 - accuracy: 0.7088 - val_loss: 1.1176 - val_accuracy: 0.3400\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.9005 - val_loss: 1.1044 - val_accuracy: 0.4356\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9384 - val_loss: 1.5043 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9593 - val_loss: 2.4049 - val_accuracy: 0.5756\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9741 - val_loss: 4.2727 - val_accuracy: 0.5644\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9782 - val_loss: 3.5173 - val_accuracy: 0.5511\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9875 - val_loss: 4.8592 - val_accuracy: 0.5333\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 5.1322 - val_accuracy: 0.6089\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 7.1182 - val_accuracy: 0.5467\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 5.7225 - val_accuracy: 0.6111\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9866 - val_loss: 6.0277 - val_accuracy: 0.5511\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9912 - val_loss: 7.6128 - val_accuracy: 0.4800\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 7.3816 - val_accuracy: 0.6378\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 6.4404 - val_accuracy: 0.6222\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 7.2634 - val_accuracy: 0.6444\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.3755 - val_accuracy: 0.6311\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9949 - val_loss: 4.8470 - val_accuracy: 0.5378\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9694 - val_loss: 12.4079 - val_accuracy: 0.4044\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9472 - val_loss: 5.9384 - val_accuracy: 0.5800\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 5.3097 - val_accuracy: 0.6178\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 6.2574 - val_accuracy: 0.6156\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 8.2204 - val_accuracy: 0.5267\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 6.9681 - val_accuracy: 0.6244\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.7854 - val_accuracy: 0.6200\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 11.0732 - val_accuracy: 0.4778\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 7.1536 - val_accuracy: 0.6156\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 6.9395 - val_accuracy: 0.6222\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.1848 - val_accuracy: 0.6156\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 9.8924e-04 - accuracy: 1.0000 - val_loss: 8.1174 - val_accuracy: 0.6089\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 7.7470 - val_accuracy: 0.5556\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 8.4779 - val_accuracy: 0.6044\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 7.2681e-04 - accuracy: 1.0000 - val_loss: 8.5511 - val_accuracy: 0.6133\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 5.3457e-04 - accuracy: 1.0000 - val_loss: 8.6156 - val_accuracy: 0.6156\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 6.4787 - val_accuracy: 0.5978\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 5.6839 - val_accuracy: 0.6111\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 7.5570 - val_accuracy: 0.6044\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 6.4342e-04 - accuracy: 1.0000 - val_loss: 7.4937 - val_accuracy: 0.6200\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 3.8835e-04 - accuracy: 1.0000 - val_loss: 7.4516 - val_accuracy: 0.6333\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 8.7513 - val_accuracy: 0.6044\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 7.3258 - val_accuracy: 0.6244\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 6.4380e-04 - accuracy: 1.0000 - val_loss: 8.3710 - val_accuracy: 0.6311\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 9.7144e-04 - accuracy: 1.0000 - val_loss: 9.0341 - val_accuracy: 0.6289\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9366 - val_loss: 6.8730 - val_accuracy: 0.6333\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9801 - val_loss: 5.5152 - val_accuracy: 0.6578\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 9.0352 - val_accuracy: 0.5978\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 9.1848 - val_accuracy: 0.6089\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 8.6746 - val_accuracy: 0.5911\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 8.6718 - val_accuracy: 0.6644\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.0082 - val_accuracy: 0.6578\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 6.5396 - val_accuracy: 0.6244\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_68 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.9893 - accuracy: 0.5213 - val_loss: 1.0957 - val_accuracy: 0.2867\n",
      "Epoch 2/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.7495 - val_loss: 1.0989 - val_accuracy: 0.3533\n",
      "Epoch 3/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8481 - val_loss: 1.3332 - val_accuracy: 0.4778\n",
      "Epoch 4/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9162 - val_loss: 2.9058 - val_accuracy: 0.4489\n",
      "Epoch 5/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9505 - val_loss: 3.5460 - val_accuracy: 0.4956\n",
      "Epoch 6/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9546 - val_loss: 3.8995 - val_accuracy: 0.5356\n",
      "Epoch 7/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9741 - val_loss: 5.2176 - val_accuracy: 0.4222\n",
      "Epoch 8/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 6.2228 - val_accuracy: 0.5444\n",
      "Epoch 9/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9852 - val_loss: 6.0442 - val_accuracy: 0.5111\n",
      "Epoch 10/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9847 - val_loss: 6.1719 - val_accuracy: 0.5378\n",
      "Epoch 11/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9852 - val_loss: 4.7565 - val_accuracy: 0.5400\n",
      "Epoch 12/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 5.8249 - val_accuracy: 0.5800\n",
      "Epoch 13/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 6.8100 - val_accuracy: 0.5422\n",
      "Epoch 14/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9907 - val_loss: 5.8560 - val_accuracy: 0.5511\n",
      "Epoch 15/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9917 - val_loss: 5.7634 - val_accuracy: 0.5156\n",
      "Epoch 16/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9921 - val_loss: 7.2089 - val_accuracy: 0.5222\n",
      "Epoch 17/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9773 - val_loss: 10.2135 - val_accuracy: 0.4400\n",
      "Epoch 18/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9514 - val_loss: 6.3038 - val_accuracy: 0.4578\n",
      "Epoch 19/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9861 - val_loss: 6.2898 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9921 - val_loss: 6.5397 - val_accuracy: 0.5467\n",
      "Epoch 21/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9921 - val_loss: 6.8451 - val_accuracy: 0.5644\n",
      "Epoch 22/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9926 - val_loss: 6.8728 - val_accuracy: 0.5444\n",
      "Epoch 23/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9921 - val_loss: 7.0136 - val_accuracy: 0.4867\n",
      "Epoch 24/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9926 - val_loss: 6.8642 - val_accuracy: 0.5556\n",
      "Epoch 25/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9921 - val_loss: 7.3522 - val_accuracy: 0.5533\n",
      "Epoch 26/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9787 - val_loss: 10.7624 - val_accuracy: 0.3867\n",
      "Epoch 27/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9870 - val_loss: 7.3344 - val_accuracy: 0.5022\n",
      "Epoch 28/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9903 - val_loss: 7.9165 - val_accuracy: 0.5133\n",
      "Epoch 29/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9843 - val_loss: 7.1630 - val_accuracy: 0.4867\n",
      "Epoch 30/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9801 - val_loss: 5.8294 - val_accuracy: 0.5400\n",
      "Epoch 31/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 8.1867 - val_accuracy: 0.4489\n",
      "Epoch 32/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 8.7347 - val_accuracy: 0.4578\n",
      "Epoch 33/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9894 - val_loss: 6.6514 - val_accuracy: 0.5644\n",
      "Epoch 34/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9926 - val_loss: 7.5155 - val_accuracy: 0.5667\n",
      "Epoch 35/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9972 - val_loss: 6.5981 - val_accuracy: 0.5511\n",
      "Epoch 36/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 6.9639 - val_accuracy: 0.5756\n",
      "Epoch 37/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 7.2623 - val_accuracy: 0.5644\n",
      "Epoch 38/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 6.3606 - val_accuracy: 0.5889\n",
      "Epoch 39/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 7.3476 - val_accuracy: 0.5578\n",
      "Epoch 40/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 6.5869 - val_accuracy: 0.4889\n",
      "Epoch 41/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9944 - val_loss: 10.4194 - val_accuracy: 0.5333\n",
      "Epoch 42/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9977 - val_loss: 10.6059 - val_accuracy: 0.5111\n",
      "Epoch 43/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 9.3876 - val_accuracy: 0.5533\n",
      "Epoch 44/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 8.2151 - val_accuracy: 0.5022\n",
      "Epoch 45/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 7.2630 - val_accuracy: 0.5467\n",
      "Epoch 46/50\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 8.0414 - val_accuracy: 0.5444\n",
      "Epoch 47/50\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 10.1108 - val_accuracy: 0.3978\n",
      "Epoch 48/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 6.5935 - val_accuracy: 0.6289\n",
      "Epoch 49/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 14.0105 - val_accuracy: 0.3733\n",
      "Epoch 50/50\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 5.8279 - val_accuracy: 0.5267\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_70 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 0.9398 - accuracy: 0.5616 - val_loss: 1.1590 - val_accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7986 - val_loss: 1.3799 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8995 - val_loss: 1.5781 - val_accuracy: 0.3733\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.9421 - val_loss: 1.6213 - val_accuracy: 0.4244\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1369 - accuracy: 0.9602 - val_loss: 1.8900 - val_accuracy: 0.4489\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9745 - val_loss: 2.7526 - val_accuracy: 0.3756\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9755 - val_loss: 2.5545 - val_accuracy: 0.4800\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9898 - val_loss: 3.1675 - val_accuracy: 0.4889\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9889 - val_loss: 4.1202 - val_accuracy: 0.4689\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9944 - val_loss: 4.6465 - val_accuracy: 0.4556\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9944 - val_loss: 4.9090 - val_accuracy: 0.5022\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9954 - val_loss: 5.6236 - val_accuracy: 0.4733\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9917 - val_loss: 5.2836 - val_accuracy: 0.4911\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9931 - val_loss: 6.7366 - val_accuracy: 0.4867\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9972 - val_loss: 4.1170 - val_accuracy: 0.5067\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 5.2947 - val_accuracy: 0.5089\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 5.6360 - val_accuracy: 0.4667\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 5.4718 - val_accuracy: 0.5489\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 5.4882 - val_accuracy: 0.5067\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 5.6034 - val_accuracy: 0.5311\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 5.5918 - val_accuracy: 0.4578\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 6.2283 - val_accuracy: 0.4867\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 8.1185 - val_accuracy: 0.5044\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 6.4991 - val_accuracy: 0.4289\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 7.0891 - val_accuracy: 0.4978\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 6.8788 - val_accuracy: 0.5711\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 6.1260 - val_accuracy: 0.5622\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 7.1282 - val_accuracy: 0.5489\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9981 - val_loss: 5.6016 - val_accuracy: 0.5622\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9981 - val_loss: 6.2934 - val_accuracy: 0.5733\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 6.4025 - val_accuracy: 0.5156\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 6.7318 - val_accuracy: 0.4489\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 5.6453 - val_accuracy: 0.5556\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 6.1699 - val_accuracy: 0.5956\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 8.3675 - val_accuracy: 0.4756\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9981 - val_loss: 6.5811 - val_accuracy: 0.5311\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9912 - val_loss: 7.7074 - val_accuracy: 0.4711\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9727 - val_loss: 12.6328 - val_accuracy: 0.4156\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9829 - val_loss: 7.8614 - val_accuracy: 0.5244\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 7.0541 - val_accuracy: 0.5578\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 6.9354 - val_accuracy: 0.5333\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 7.1446 - val_accuracy: 0.5111\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 7.2382 - val_accuracy: 0.5689\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 7.2525 - val_accuracy: 0.5311\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 8.3651 - val_accuracy: 0.5511\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 7.4214 - val_accuracy: 0.6022\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 6.6263 - val_accuracy: 0.5778\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 6.7661 - val_accuracy: 0.5578\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 7.0918 - val_accuracy: 0.5889\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 5.7362e-04 - accuracy: 1.0000 - val_loss: 7.2528 - val_accuracy: 0.5956\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_72 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 0.8382 - accuracy: 0.6190 - val_loss: 1.1038 - val_accuracy: 0.4178\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8755 - val_loss: 1.2140 - val_accuracy: 0.3511\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9417 - val_loss: 1.7568 - val_accuracy: 0.3822\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9704 - val_loss: 2.1323 - val_accuracy: 0.4933\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9810 - val_loss: 2.3252 - val_accuracy: 0.4889\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 2.8837 - val_accuracy: 0.4667\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9935 - val_loss: 3.1190 - val_accuracy: 0.4644\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 5.1523 - val_accuracy: 0.4889\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 5.7273 - val_accuracy: 0.5489\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 5.1726 - val_accuracy: 0.4911\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 5.4577 - val_accuracy: 0.5044\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 5.1584 - val_accuracy: 0.4711\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 6.1191 - val_accuracy: 0.5133\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 6.0374 - val_accuracy: 0.5178\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 5.8475 - val_accuracy: 0.4711\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 10.6877 - val_accuracy: 0.4244\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9894 - val_loss: 7.5647 - val_accuracy: 0.5467\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9194 - val_loss: 4.0797 - val_accuracy: 0.5889\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9907 - val_loss: 5.1206 - val_accuracy: 0.5578\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9995 - val_loss: 5.6040 - val_accuracy: 0.5644\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 6.1445 - val_accuracy: 0.5222\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 6.1725 - val_accuracy: 0.5333\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 6.7517 - val_accuracy: 0.5533\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 6.3202 - val_accuracy: 0.5400\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 6.6778 - val_accuracy: 0.5533\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 6.0807 - val_accuracy: 0.5156\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 6.4268 - val_accuracy: 0.5511\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.9352 - val_accuracy: 0.5578\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 6.3185 - val_accuracy: 0.5422\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.6800 - val_accuracy: 0.5400\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 7.8159 - val_accuracy: 0.5200\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 6.2923 - val_accuracy: 0.4733\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.6169 - val_accuracy: 0.5111\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7073 - val_accuracy: 0.5200\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.8944 - val_accuracy: 0.5578\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.7184 - val_accuracy: 0.5178\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 7.2608 - val_accuracy: 0.5178\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.9264 - val_accuracy: 0.5400\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 7.0728 - val_accuracy: 0.5378\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 7.5551 - val_accuracy: 0.5533\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 5.9399 - val_accuracy: 0.5578\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.0927 - val_accuracy: 0.5311\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 9.8894 - val_accuracy: 0.5311\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9838 - val_loss: 15.7999 - val_accuracy: 0.3956\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9870 - val_loss: 11.3303 - val_accuracy: 0.4711\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9912 - val_loss: 8.6413 - val_accuracy: 0.5800\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 9.3345 - val_accuracy: 0.5311\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 10.6592 - val_accuracy: 0.5244\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 10.2164 - val_accuracy: 0.5333\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 5.1998e-04 - accuracy: 1.0000 - val_loss: 9.8521 - val_accuracy: 0.5356\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_74 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 0.8679 - accuracy: 0.6282 - val_loss: 1.1250 - val_accuracy: 0.3400\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8523 - val_loss: 1.1155 - val_accuracy: 0.3200\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2309 - accuracy: 0.9208 - val_loss: 1.3833 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9639 - val_loss: 1.6813 - val_accuracy: 0.3467\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9713 - val_loss: 2.0571 - val_accuracy: 0.5200\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9856 - val_loss: 2.7482 - val_accuracy: 0.4889\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9870 - val_loss: 3.4366 - val_accuracy: 0.6133\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9819 - val_loss: 5.0238 - val_accuracy: 0.6044\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 4.9519 - val_accuracy: 0.4889\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 6.1507 - val_accuracy: 0.5667\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 6.0819 - val_accuracy: 0.5667\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 6.8028 - val_accuracy: 0.5800\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 6.8192 - val_accuracy: 0.5844\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 7.6174 - val_accuracy: 0.5867\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 7.7022 - val_accuracy: 0.5600\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 7.0585 - val_accuracy: 0.5489\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 7.3773 - val_accuracy: 0.5844\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 7.0574 - val_accuracy: 0.5778\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9565 - val_loss: 12.2257 - val_accuracy: 0.5089\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9653 - val_loss: 8.5249 - val_accuracy: 0.5244\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9935 - val_loss: 7.0340 - val_accuracy: 0.5822\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 8.8167 - val_accuracy: 0.5533\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 7.7616 - val_accuracy: 0.5867\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 6.8209 - val_accuracy: 0.5933\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 8.2258 - val_accuracy: 0.5578\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 8.9933 - val_accuracy: 0.5800\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.6096 - val_accuracy: 0.5867\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 9.3554 - val_accuracy: 0.5933\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.4181 - val_accuracy: 0.6156\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.2340 - val_accuracy: 0.6111\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 9.0679 - val_accuracy: 0.5689\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 6.5391 - val_accuracy: 0.5156\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 11.4313 - val_accuracy: 0.4333\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 10.3063 - val_accuracy: 0.5022\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 9.1629 - val_accuracy: 0.5756\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.2356 - val_accuracy: 0.6022\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 11.1766 - val_accuracy: 0.5622\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 9.0725 - val_accuracy: 0.5733\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 9.5526 - val_accuracy: 0.6156\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 9.6748 - val_accuracy: 0.5733\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 8.8982 - val_accuracy: 0.6044\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 7.2504e-04 - accuracy: 1.0000 - val_loss: 9.5625 - val_accuracy: 0.5867\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 7.3114e-04 - accuracy: 1.0000 - val_loss: 10.6909 - val_accuracy: 0.5244\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 4.4763e-04 - accuracy: 1.0000 - val_loss: 10.8050 - val_accuracy: 0.5467\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 4.6249e-04 - accuracy: 1.0000 - val_loss: 10.6560 - val_accuracy: 0.5622\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9694 - val_loss: 5.6678 - val_accuracy: 0.4400\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9801 - val_loss: 11.8653 - val_accuracy: 0.4644\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 9.1921 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9954 - val_loss: 10.2401 - val_accuracy: 0.5467\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9894 - val_loss: 10.1726 - val_accuracy: 0.5467\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_76 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 0.7762 - accuracy: 0.6718 - val_loss: 1.1304 - val_accuracy: 0.3978\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8903 - val_loss: 1.1789 - val_accuracy: 0.3311\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1916 - accuracy: 0.9347 - val_loss: 1.2850 - val_accuracy: 0.3378\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9676 - val_loss: 1.4649 - val_accuracy: 0.3756\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9759 - val_loss: 1.4732 - val_accuracy: 0.3844\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9847 - val_loss: 2.0477 - val_accuracy: 0.5067\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9903 - val_loss: 2.8783 - val_accuracy: 0.4778\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9931 - val_loss: 3.5797 - val_accuracy: 0.5089\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9958 - val_loss: 3.1849 - val_accuracy: 0.4667\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 3.6808 - val_accuracy: 0.5356\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9995 - val_loss: 4.4289 - val_accuracy: 0.4978\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 4.2399 - val_accuracy: 0.4911\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 3.8614 - val_accuracy: 0.4822\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.4076 - val_accuracy: 0.5022\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 4.1954 - val_accuracy: 0.5244\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9704 - val_loss: 8.5068 - val_accuracy: 0.4400\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9894 - val_loss: 5.2769 - val_accuracy: 0.5422\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 4.2984 - val_accuracy: 0.5133\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6065 - val_accuracy: 0.5400\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.7509 - val_accuracy: 0.5444\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.9558 - val_accuracy: 0.5356\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.0522 - val_accuracy: 0.5333\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.1010 - val_accuracy: 0.5400\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 4.7411 - val_accuracy: 0.5333\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.5237 - val_accuracy: 0.4956\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.3143 - val_accuracy: 0.5222\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9.8524e-04 - accuracy: 1.0000 - val_loss: 5.6758 - val_accuracy: 0.5267\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 4.8123 - val_accuracy: 0.5200\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.2798 - val_accuracy: 0.5156\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 7.2782e-04 - accuracy: 1.0000 - val_loss: 5.1187 - val_accuracy: 0.5400\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 6.4036 - val_accuracy: 0.5711\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.0826 - val_accuracy: 0.5511\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 6.5758 - val_accuracy: 0.5356\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 6.3329e-04 - accuracy: 1.0000 - val_loss: 6.0892 - val_accuracy: 0.5533\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 4.6874e-04 - accuracy: 1.0000 - val_loss: 6.0103 - val_accuracy: 0.5533\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 5.0065e-04 - accuracy: 1.0000 - val_loss: 6.1785 - val_accuracy: 0.5511\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 5.0678e-04 - accuracy: 1.0000 - val_loss: 6.0339 - val_accuracy: 0.5511\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 3.8477e-04 - accuracy: 1.0000 - val_loss: 6.0114 - val_accuracy: 0.5578\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 4.5506 - val_accuracy: 0.4533\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9843 - val_loss: 4.9583 - val_accuracy: 0.4444\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2090 - accuracy: 0.9366 - val_loss: 10.1364 - val_accuracy: 0.4356\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 10.6363 - val_accuracy: 0.4378\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 6.3131 - val_accuracy: 0.5489\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 6.4105 - val_accuracy: 0.5289\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 6.9744 - val_accuracy: 0.4822\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 6.8814 - val_accuracy: 0.5044\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 7.4105e-04 - accuracy: 1.0000 - val_loss: 7.0455 - val_accuracy: 0.5156\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 5.2310 - val_accuracy: 0.4822\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 5.7306 - val_accuracy: 0.5244\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9.1968e-04 - accuracy: 1.0000 - val_loss: 6.0292 - val_accuracy: 0.5444\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 1.3171 - accuracy: 0.3620 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0789 - accuracy: 0.3759 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0593 - accuracy: 0.3782 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.0343 - accuracy: 0.3819 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.9860 - accuracy: 0.4389 - val_loss: 1.1001 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.9194 - accuracy: 0.5042 - val_loss: 0.9951 - val_accuracy: 0.4244\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7607 - accuracy: 0.6792 - val_loss: 1.0450 - val_accuracy: 0.4044\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.7736 - val_loss: 1.0191 - val_accuracy: 0.4156\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.8130 - val_loss: 1.3790 - val_accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.8440 - val_loss: 1.0451 - val_accuracy: 0.4222\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8546 - val_loss: 0.9888 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8750 - val_loss: 1.4117 - val_accuracy: 0.4244\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8838 - val_loss: 1.4658 - val_accuracy: 0.4022\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8898 - val_loss: 1.6320 - val_accuracy: 0.4467\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.9009 - val_loss: 1.3188 - val_accuracy: 0.4933\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.9069 - val_loss: 1.3890 - val_accuracy: 0.4267\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.9162 - val_loss: 2.0547 - val_accuracy: 0.4200\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.9310 - val_loss: 1.1159 - val_accuracy: 0.5022\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.9444 - val_loss: 1.4582 - val_accuracy: 0.4289\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9505 - val_loss: 1.5806 - val_accuracy: 0.4978\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2193 - accuracy: 0.9532 - val_loss: 2.4126 - val_accuracy: 0.4689\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2013 - accuracy: 0.9597 - val_loss: 2.7002 - val_accuracy: 0.5222\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9611 - val_loss: 1.8194 - val_accuracy: 0.5044\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.9620 - val_loss: 1.4559 - val_accuracy: 0.4556\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1747 - accuracy: 0.9634 - val_loss: 1.6537 - val_accuracy: 0.4044\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9644 - val_loss: 1.7381 - val_accuracy: 0.4533\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9653 - val_loss: 1.7364 - val_accuracy: 0.4467\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.9667 - val_loss: 2.6281 - val_accuracy: 0.4978\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9630 - val_loss: 2.5442 - val_accuracy: 0.4333\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9523 - val_loss: 1.7899 - val_accuracy: 0.4333\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9639 - val_loss: 2.3371 - val_accuracy: 0.4333\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9657 - val_loss: 1.7190 - val_accuracy: 0.5333\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9685 - val_loss: 1.8978 - val_accuracy: 0.5244\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9690 - val_loss: 1.9716 - val_accuracy: 0.5311\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9708 - val_loss: 2.1348 - val_accuracy: 0.5156\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9690 - val_loss: 2.1287 - val_accuracy: 0.5467\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9727 - val_loss: 2.2692 - val_accuracy: 0.5489\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9722 - val_loss: 2.2108 - val_accuracy: 0.5267\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9722 - val_loss: 2.1692 - val_accuracy: 0.5200\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.9727 - val_loss: 2.3998 - val_accuracy: 0.5333\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9722 - val_loss: 2.5634 - val_accuracy: 0.5400\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9704 - val_loss: 2.6211 - val_accuracy: 0.5489\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.9718 - val_loss: 2.4529 - val_accuracy: 0.5244\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9727 - val_loss: 2.2662 - val_accuracy: 0.5222\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9727 - val_loss: 2.2076 - val_accuracy: 0.4978\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9713 - val_loss: 2.5334 - val_accuracy: 0.5244\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9718 - val_loss: 2.3821 - val_accuracy: 0.5156\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9708 - val_loss: 2.6307 - val_accuracy: 0.5400\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9727 - val_loss: 2.7114 - val_accuracy: 0.5311\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9718 - val_loss: 2.5745 - val_accuracy: 0.5200\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_80 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 6ms/step - loss: 0.9894 - accuracy: 0.5093 - val_loss: 1.0984 - val_accuracy: 0.3667\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6912 - val_loss: 1.1060 - val_accuracy: 0.3489\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7963 - val_loss: 1.2020 - val_accuracy: 0.4600\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.9019 - val_loss: 1.4239 - val_accuracy: 0.4911\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9449 - val_loss: 2.2945 - val_accuracy: 0.5156\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9463 - val_loss: 2.2320 - val_accuracy: 0.3378\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9722 - val_loss: 2.9786 - val_accuracy: 0.5667\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9787 - val_loss: 3.6847 - val_accuracy: 0.4889\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9889 - val_loss: 4.0863 - val_accuracy: 0.3933\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9912 - val_loss: 4.8101 - val_accuracy: 0.3978\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9940 - val_loss: 4.8000 - val_accuracy: 0.4089\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9917 - val_loss: 4.9214 - val_accuracy: 0.3956\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 5.4005 - val_accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9926 - val_loss: 4.3117 - val_accuracy: 0.4067\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9972 - val_loss: 5.2638 - val_accuracy: 0.3533\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 5.0425 - val_accuracy: 0.3644\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9968 - val_loss: 6.0854 - val_accuracy: 0.4133\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 6.1211 - val_accuracy: 0.3756\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9944 - val_loss: 6.6025 - val_accuracy: 0.4511\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 6.4647 - val_accuracy: 0.4067\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 5.3439 - val_accuracy: 0.3689\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 4.4189 - val_accuracy: 0.4444\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 5.6188 - val_accuracy: 0.3956\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 5.5986 - val_accuracy: 0.4000\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 5.4151 - val_accuracy: 0.3689\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 5.8484 - val_accuracy: 0.3289\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 5.9953 - val_accuracy: 0.3956\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 7.1537 - val_accuracy: 0.3689\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 7.8939 - val_accuracy: 0.3778\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 6.3332 - val_accuracy: 0.4067\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 5.6236 - val_accuracy: 0.4333\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 6.5901 - val_accuracy: 0.3844\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 5.2167 - val_accuracy: 0.4333\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 5.6338 - val_accuracy: 0.4222\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 5.9137 - val_accuracy: 0.4089\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 3.9805 - val_accuracy: 0.4489\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2088 - accuracy: 0.9366 - val_loss: 10.4350 - val_accuracy: 0.3200\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9773 - val_loss: 6.8836 - val_accuracy: 0.3667\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 6.4582 - val_accuracy: 0.3378\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 5.7612 - val_accuracy: 0.4200\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.1171 - val_accuracy: 0.4133\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 5.7789 - val_accuracy: 0.4444\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 6.2948 - val_accuracy: 0.4067\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 6.6974 - val_accuracy: 0.4022\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 5.7265 - val_accuracy: 0.3933\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 6.7486 - val_accuracy: 0.4156\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 5.9920 - val_accuracy: 0.4333\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 5.0460 - val_accuracy: 0.4733\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 6.0125 - val_accuracy: 0.4311\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 5.9080 - val_accuracy: 0.3756\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_82 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 0.9124 - accuracy: 0.5662 - val_loss: 1.1773 - val_accuracy: 0.3511\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8310 - val_loss: 1.3248 - val_accuracy: 0.3489\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9190 - val_loss: 1.5320 - val_accuracy: 0.3422\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9505 - val_loss: 1.4973 - val_accuracy: 0.3422\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9736 - val_loss: 1.9897 - val_accuracy: 0.3711\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9861 - val_loss: 2.7076 - val_accuracy: 0.4244\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9856 - val_loss: 2.5347 - val_accuracy: 0.5156\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9870 - val_loss: 3.3936 - val_accuracy: 0.5111\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 3.0789 - val_accuracy: 0.5267\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9981 - val_loss: 3.3070 - val_accuracy: 0.5200\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9991 - val_loss: 3.5533 - val_accuracy: 0.5711\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 3.7370 - val_accuracy: 0.5244\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9986 - val_loss: 3.9202 - val_accuracy: 0.5556\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 4.9092 - val_accuracy: 0.4667\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 4.2073 - val_accuracy: 0.5200\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.9382 - val_accuracy: 0.4889\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.1631 - val_accuracy: 0.5578\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 5.1691 - val_accuracy: 0.4933\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9903 - val_loss: 5.8814 - val_accuracy: 0.4444\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9644 - val_loss: 6.0275 - val_accuracy: 0.4889\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9806 - val_loss: 5.5683 - val_accuracy: 0.4867\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 5.3413 - val_accuracy: 0.4400\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 4.1018 - val_accuracy: 0.5200\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.8695 - val_accuracy: 0.5200\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 4.4217 - val_accuracy: 0.4800\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.2801 - val_accuracy: 0.4911\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.9835 - val_accuracy: 0.5133\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.1335 - val_accuracy: 0.5222\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.1839 - val_accuracy: 0.5200\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9.6621e-04 - accuracy: 1.0000 - val_loss: 4.2448 - val_accuracy: 0.5200\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 5.0874 - val_accuracy: 0.4444\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 4.5254 - val_accuracy: 0.5422\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 5.2141 - val_accuracy: 0.5022\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.4709 - val_accuracy: 0.5533\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 4.6786 - val_accuracy: 0.4778\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.7348 - val_accuracy: 0.5178\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 4.8240 - val_accuracy: 0.5111\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 5.1399 - val_accuracy: 0.4756\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8.0343e-04 - accuracy: 1.0000 - val_loss: 4.8685 - val_accuracy: 0.5244\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 4.9880 - val_accuracy: 0.4267\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9792 - val_loss: 4.3058 - val_accuracy: 0.4756\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9829 - val_loss: 5.0860 - val_accuracy: 0.4311\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 4.9242 - val_accuracy: 0.5244\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 3.7004 - val_accuracy: 0.5844\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 5.1960 - val_accuracy: 0.5778\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 4.9995 - val_accuracy: 0.5711\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 4.3681 - val_accuracy: 0.5933\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 6.5109e-04 - accuracy: 1.0000 - val_loss: 4.2645 - val_accuracy: 0.5933\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 5.8864e-04 - accuracy: 1.0000 - val_loss: 4.5223 - val_accuracy: 0.5956\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 4.4193 - val_accuracy: 0.5822\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_84 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 11ms/step - loss: 0.9858 - accuracy: 0.5694 - val_loss: 1.1110 - val_accuracy: 0.3244\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8356 - val_loss: 1.1090 - val_accuracy: 0.3622\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2902 - accuracy: 0.9102 - val_loss: 1.1436 - val_accuracy: 0.3200\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2037 - accuracy: 0.9417 - val_loss: 1.2213 - val_accuracy: 0.3578\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1399 - accuracy: 0.9648 - val_loss: 1.3073 - val_accuracy: 0.4089\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9819 - val_loss: 1.4554 - val_accuracy: 0.4511\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9889 - val_loss: 1.6902 - val_accuracy: 0.4333\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9921 - val_loss: 1.8495 - val_accuracy: 0.4622\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9926 - val_loss: 2.1547 - val_accuracy: 0.3978\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9958 - val_loss: 2.1779 - val_accuracy: 0.4844\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9972 - val_loss: 2.2555 - val_accuracy: 0.5378\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9977 - val_loss: 2.7307 - val_accuracy: 0.5400\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9986 - val_loss: 3.0237 - val_accuracy: 0.4956\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9995 - val_loss: 3.3379 - val_accuracy: 0.5533\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 3.8439 - val_accuracy: 0.4978\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 3.8117 - val_accuracy: 0.4333\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 4.8196 - val_accuracy: 0.5422\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 4.7661 - val_accuracy: 0.4356\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9986 - val_loss: 4.2820 - val_accuracy: 0.4333\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 5.2679 - val_accuracy: 0.5044\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 5.2072 - val_accuracy: 0.4933\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.5726 - val_accuracy: 0.4933\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.7710 - val_accuracy: 0.5022\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 6.0088 - val_accuracy: 0.4778\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 6.4336 - val_accuracy: 0.4822\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 5.5096 - val_accuracy: 0.4600\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.5270 - val_accuracy: 0.4711\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 6.5937 - val_accuracy: 0.4222\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9801 - val_loss: 7.0072 - val_accuracy: 0.4178\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9806 - val_loss: 6.8529 - val_accuracy: 0.5200\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 7.3410 - val_accuracy: 0.4533\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 6.4931 - val_accuracy: 0.5089\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 6.5401 - val_accuracy: 0.5133\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.3867 - val_accuracy: 0.5444\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.2809 - val_accuracy: 0.5467\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 8.2585 - val_accuracy: 0.4844\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 6.3330 - val_accuracy: 0.4756\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 6.8553 - val_accuracy: 0.5044\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5237 - val_accuracy: 0.5067\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.7950e-04 - accuracy: 1.0000 - val_loss: 6.6499 - val_accuracy: 0.5067\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.7589 - val_accuracy: 0.5156\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 6.4264 - val_accuracy: 0.5178\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.4718 - val_accuracy: 0.5044\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 8.6209e-04 - accuracy: 1.0000 - val_loss: 6.7177 - val_accuracy: 0.5156\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 6.0857 - val_accuracy: 0.4978\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.5694 - val_accuracy: 0.4933\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 8.4974e-04 - accuracy: 1.0000 - val_loss: 7.0536 - val_accuracy: 0.4956\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.8473e-04 - accuracy: 1.0000 - val_loss: 7.6941 - val_accuracy: 0.5267\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 7.2829 - val_accuracy: 0.4978\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.8267 - val_accuracy: 0.5422\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_86 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 9ms/step - loss: 0.8240 - accuracy: 0.6310 - val_loss: 1.1092 - val_accuracy: 0.3422\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8681 - val_loss: 1.0892 - val_accuracy: 0.4022\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2174 - accuracy: 0.9306 - val_loss: 1.1340 - val_accuracy: 0.3400\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9616 - val_loss: 1.1096 - val_accuracy: 0.3889\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9731 - val_loss: 1.2460 - val_accuracy: 0.3978\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9884 - val_loss: 1.5573 - val_accuracy: 0.4222\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9958 - val_loss: 1.4245 - val_accuracy: 0.4311\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9898 - val_loss: 2.3199 - val_accuracy: 0.3178\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9940 - val_loss: 2.2587 - val_accuracy: 0.3956\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9972 - val_loss: 2.1229 - val_accuracy: 0.3667\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 2.6467 - val_accuracy: 0.4222\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 3.3028 - val_accuracy: 0.3822\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.5150 - val_accuracy: 0.4178\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.7638 - val_accuracy: 0.4489\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.9682 - val_accuracy: 0.4178\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.7658 - val_accuracy: 0.4378\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.1322 - val_accuracy: 0.4356\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.9758 - val_accuracy: 0.4689\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.8497 - val_accuracy: 0.4556\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 5.6695 - val_accuracy: 0.4511\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 6.3337 - val_accuracy: 0.4356\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.1397 - val_accuracy: 0.4467\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.7040 - val_accuracy: 0.4400\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.7668 - val_accuracy: 0.4644\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.4275 - val_accuracy: 0.4400\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 8.2373 - val_accuracy: 0.5200\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.9894 - val_accuracy: 0.4533\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.8046 - val_accuracy: 0.4822\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 7.4150 - val_accuracy: 0.4244\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.4200 - val_accuracy: 0.4533\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.4484 - val_accuracy: 0.4311\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.2546 - val_accuracy: 0.4400\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.3174e-04 - accuracy: 1.0000 - val_loss: 7.2978 - val_accuracy: 0.4689\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.8614e-04 - accuracy: 1.0000 - val_loss: 8.4507 - val_accuracy: 0.4200\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 8.3420 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 9.2480 - val_accuracy: 0.4333\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9782 - val_loss: 7.0986 - val_accuracy: 0.3867\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9560 - val_loss: 8.0453 - val_accuracy: 0.5022\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9745 - val_loss: 6.2977 - val_accuracy: 0.4600\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 5.5735 - val_accuracy: 0.5044\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 6.4907 - val_accuracy: 0.4800\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.2982 - val_accuracy: 0.4956\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.3681 - val_accuracy: 0.5044\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 8.9766e-04 - accuracy: 1.0000 - val_loss: 7.9336 - val_accuracy: 0.4667\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7.8956e-04 - accuracy: 1.0000 - val_loss: 7.6477 - val_accuracy: 0.4822\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7.4903e-04 - accuracy: 1.0000 - val_loss: 7.3737 - val_accuracy: 0.4956\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5.9155e-04 - accuracy: 1.0000 - val_loss: 7.5812 - val_accuracy: 0.4889\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 7.4360 - val_accuracy: 0.4889\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 7.8685 - val_accuracy: 0.4311\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.7738 - val_accuracy: 0.4956\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_88 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 1.0482 - accuracy: 0.4764 - val_loss: 1.0951 - val_accuracy: 0.4111\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 0.6954 - val_loss: 1.1011 - val_accuracy: 0.3644\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8333 - val_loss: 1.0869 - val_accuracy: 0.4222\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 0.9051 - val_loss: 1.1080 - val_accuracy: 0.4933\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9394 - val_loss: 1.2428 - val_accuracy: 0.4778\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.9639 - val_loss: 1.3351 - val_accuracy: 0.5044\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9796 - val_loss: 1.6055 - val_accuracy: 0.4778\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 1.9511 - val_accuracy: 0.4711\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9870 - val_loss: 2.0389 - val_accuracy: 0.5289\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9963 - val_loss: 2.5916 - val_accuracy: 0.4778\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9944 - val_loss: 2.8179 - val_accuracy: 0.5022\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9977 - val_loss: 3.2573 - val_accuracy: 0.4844\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9981 - val_loss: 3.9740 - val_accuracy: 0.4800\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9991 - val_loss: 4.1442 - val_accuracy: 0.5089\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9977 - val_loss: 4.9277 - val_accuracy: 0.5133\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 4.9178 - val_accuracy: 0.5311\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 5.2006 - val_accuracy: 0.5600\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9991 - val_loss: 5.6406 - val_accuracy: 0.5244\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 6.1474 - val_accuracy: 0.5667\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 6.5125 - val_accuracy: 0.5289\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 6.7409 - val_accuracy: 0.5667\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 6.4834 - val_accuracy: 0.5844\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 7.2058 - val_accuracy: 0.5578\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 8.6661 - val_accuracy: 0.5311\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9981 - val_loss: 9.3240 - val_accuracy: 0.4467\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 7.6180 - val_accuracy: 0.5756\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 8.2447 - val_accuracy: 0.5378\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 7.7160 - val_accuracy: 0.5600\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 8.1291 - val_accuracy: 0.5578\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 9.1210 - val_accuracy: 0.5756\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 8.1866 - val_accuracy: 0.5222\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 8.5956 - val_accuracy: 0.4733\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 7.7854 - val_accuracy: 0.5111\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 7.9948 - val_accuracy: 0.4978\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 8.3515 - val_accuracy: 0.5022\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 8.2567 - val_accuracy: 0.5289\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 8.3735 - val_accuracy: 0.5311\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 8.5904 - val_accuracy: 0.5111\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 8.1194 - val_accuracy: 0.5356\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 8.2264 - val_accuracy: 0.5400\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 8.0952 - val_accuracy: 0.5267\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 9.4634 - val_accuracy: 0.4733\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.5325 - val_accuracy: 0.5378\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 9.1327 - val_accuracy: 0.5667\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 8.7265 - val_accuracy: 0.5578\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 8.8250 - val_accuracy: 0.5333\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 9.6162 - val_accuracy: 0.4467\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 10.1929 - val_accuracy: 0.5467\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 9.6636 - val_accuracy: 0.5178\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 9.0994 - val_accuracy: 0.5489\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 1.2362 - accuracy: 0.3583 - val_loss: 1.1023 - val_accuracy: 0.3822\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.8957 - accuracy: 0.5319 - val_loss: 1.0979 - val_accuracy: 0.3844\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7742 - accuracy: 0.5792 - val_loss: 1.1113 - val_accuracy: 0.3378\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6747 - accuracy: 0.6162 - val_loss: 1.1029 - val_accuracy: 0.3444\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.6319 - val_loss: 1.1760 - val_accuracy: 0.3822\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.6579 - val_loss: 1.1617 - val_accuracy: 0.3711\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.6838 - val_loss: 1.1823 - val_accuracy: 0.3844\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.6963 - val_loss: 1.2331 - val_accuracy: 0.4200\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7588 - val_loss: 1.3071 - val_accuracy: 0.3733\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7963 - val_loss: 1.3478 - val_accuracy: 0.3756\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8301 - val_loss: 2.0226 - val_accuracy: 0.3889\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8630 - val_loss: 2.0852 - val_accuracy: 0.3889\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.8981 - val_loss: 1.8265 - val_accuracy: 0.3933\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.9259 - val_loss: 2.1573 - val_accuracy: 0.3778\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2099 - accuracy: 0.9361 - val_loss: 2.7872 - val_accuracy: 0.3933\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1743 - accuracy: 0.9500 - val_loss: 2.7062 - val_accuracy: 0.4067\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1538 - accuracy: 0.9579 - val_loss: 2.9193 - val_accuracy: 0.4111\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1349 - accuracy: 0.9648 - val_loss: 3.3681 - val_accuracy: 0.3756\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9718 - val_loss: 3.5591 - val_accuracy: 0.4244\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9796 - val_loss: 3.3386 - val_accuracy: 0.4689\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9806 - val_loss: 3.6276 - val_accuracy: 0.4711\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0932 - accuracy: 0.9764 - val_loss: 4.0070 - val_accuracy: 0.4311\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9847 - val_loss: 4.9989 - val_accuracy: 0.4289\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9889 - val_loss: 4.6367 - val_accuracy: 0.4378\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9931 - val_loss: 5.0464 - val_accuracy: 0.4022\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9921 - val_loss: 5.3188 - val_accuracy: 0.4022\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.9935 - val_loss: 5.2214 - val_accuracy: 0.4222\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9926 - val_loss: 6.9152 - val_accuracy: 0.3622\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9958 - val_loss: 5.6391 - val_accuracy: 0.4067\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9963 - val_loss: 5.9533 - val_accuracy: 0.4133\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9968 - val_loss: 6.2460 - val_accuracy: 0.4289\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9972 - val_loss: 6.8159 - val_accuracy: 0.4156\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9977 - val_loss: 6.2051 - val_accuracy: 0.4356\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9991 - val_loss: 7.0459 - val_accuracy: 0.4267\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9972 - val_loss: 7.0835 - val_accuracy: 0.4044\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 0.9986 - val_loss: 6.4862 - val_accuracy: 0.4222\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9963 - val_loss: 9.1293 - val_accuracy: 0.3644\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9986 - val_loss: 6.9837 - val_accuracy: 0.4467\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9986 - val_loss: 7.2802 - val_accuracy: 0.4244\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9986 - val_loss: 7.7768 - val_accuracy: 0.4089\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 7.1904 - val_accuracy: 0.4489\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9995 - val_loss: 7.4680 - val_accuracy: 0.4222\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9968 - val_loss: 9.7761 - val_accuracy: 0.3578\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9940 - val_loss: 7.7131 - val_accuracy: 0.4311\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9995 - val_loss: 7.2209 - val_accuracy: 0.4222\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9991 - val_loss: 8.6581 - val_accuracy: 0.4133\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9991 - val_loss: 8.3678 - val_accuracy: 0.3822\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9986 - val_loss: 7.4540 - val_accuracy: 0.4467\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9995 - val_loss: 7.7487 - val_accuracy: 0.4289\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9981 - val_loss: 8.0085 - val_accuracy: 0.4156\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_92 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 0.9875 - accuracy: 0.5454 - val_loss: 1.0992 - val_accuracy: 0.3444\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.8144 - val_loss: 1.1193 - val_accuracy: 0.3422\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2863 - accuracy: 0.9106 - val_loss: 1.1175 - val_accuracy: 0.3200\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1914 - accuracy: 0.9394 - val_loss: 1.1578 - val_accuracy: 0.3289\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9671 - val_loss: 1.1498 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9824 - val_loss: 1.2170 - val_accuracy: 0.3511\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9852 - val_loss: 1.3408 - val_accuracy: 0.3667\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9921 - val_loss: 1.5096 - val_accuracy: 0.4178\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9931 - val_loss: 1.7176 - val_accuracy: 0.4311\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9968 - val_loss: 2.1595 - val_accuracy: 0.4422\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9968 - val_loss: 2.4658 - val_accuracy: 0.4289\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 0.9977 - val_loss: 2.8170 - val_accuracy: 0.4578\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 3.1499 - val_accuracy: 0.4533\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9995 - val_loss: 3.4223 - val_accuracy: 0.4467\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 3.7945 - val_accuracy: 0.4644\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 4.2087 - val_accuracy: 0.4622\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.5963 - val_accuracy: 0.4800\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 5.1170 - val_accuracy: 0.4400\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 4.6639 - val_accuracy: 0.3778\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 7.5843 - val_accuracy: 0.4800\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 6.3879 - val_accuracy: 0.5222\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 5.1629 - val_accuracy: 0.5333\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 6.7834 - val_accuracy: 0.4356\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 7.1206 - val_accuracy: 0.5622\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 6.9614 - val_accuracy: 0.5289\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 7.2560 - val_accuracy: 0.4867\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.2717 - val_accuracy: 0.5111\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.7352 - val_accuracy: 0.5156\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.6434 - val_accuracy: 0.5089\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.7404 - val_accuracy: 0.5200\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 7.5064 - val_accuracy: 0.4711\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 8.1949 - val_accuracy: 0.4467\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 7.8514 - val_accuracy: 0.5622\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.9325 - val_accuracy: 0.5689\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 8.7173e-04 - accuracy: 1.0000 - val_loss: 7.9763 - val_accuracy: 0.5400\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9.4679e-04 - accuracy: 1.0000 - val_loss: 8.3765 - val_accuracy: 0.5911\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7.3989e-04 - accuracy: 1.0000 - val_loss: 8.6882 - val_accuracy: 0.5556\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 8.5908e-04 - accuracy: 1.0000 - val_loss: 8.7152 - val_accuracy: 0.5089\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.3490 - val_accuracy: 0.5111\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7.9049e-04 - accuracy: 1.0000 - val_loss: 8.0161 - val_accuracy: 0.4978\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.4632 - val_accuracy: 0.5244\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 5.2447e-04 - accuracy: 1.0000 - val_loss: 8.4414 - val_accuracy: 0.5311\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 4.9755e-04 - accuracy: 1.0000 - val_loss: 8.4623 - val_accuracy: 0.5378\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 8.5015 - val_accuracy: 0.5022\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7.2376e-04 - accuracy: 1.0000 - val_loss: 8.6772 - val_accuracy: 0.5067\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 4.6676e-04 - accuracy: 1.0000 - val_loss: 8.5384 - val_accuracy: 0.5200\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3.9332e-04 - accuracy: 1.0000 - val_loss: 8.7174 - val_accuracy: 0.5422\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 7.9425 - val_accuracy: 0.5400\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 7.3627 - val_accuracy: 0.3889\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 7.2650 - val_accuracy: 0.5489\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_94 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 1.0196 - accuracy: 0.5505 - val_loss: 1.0888 - val_accuracy: 0.3644\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.7602 - val_loss: 1.1038 - val_accuracy: 0.3400\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8588 - val_loss: 1.1053 - val_accuracy: 0.3400\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2832 - accuracy: 0.9042 - val_loss: 1.1262 - val_accuracy: 0.3600\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1847 - accuracy: 0.9472 - val_loss: 1.1585 - val_accuracy: 0.4644\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9523 - val_loss: 1.1622 - val_accuracy: 0.4956\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9620 - val_loss: 1.3768 - val_accuracy: 0.4067\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9778 - val_loss: 1.4190 - val_accuracy: 0.5244\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9856 - val_loss: 1.6552 - val_accuracy: 0.5356\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9921 - val_loss: 1.8534 - val_accuracy: 0.5467\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9958 - val_loss: 2.1561 - val_accuracy: 0.5356\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9921 - val_loss: 2.3148 - val_accuracy: 0.4911\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9968 - val_loss: 2.8056 - val_accuracy: 0.5889\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9972 - val_loss: 3.0969 - val_accuracy: 0.5822\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9986 - val_loss: 3.2544 - val_accuracy: 0.5489\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 3.6852 - val_accuracy: 0.6044\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 4.2494 - val_accuracy: 0.5867\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9991 - val_loss: 4.0093 - val_accuracy: 0.5556\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 4.6242 - val_accuracy: 0.5378\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 5.2012 - val_accuracy: 0.5178\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 5.1737 - val_accuracy: 0.5844\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 5.6499 - val_accuracy: 0.5511\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9977 - val_loss: 5.6270 - val_accuracy: 0.5667\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 6.0786 - val_accuracy: 0.5533\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 5.7916 - val_accuracy: 0.5844\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 6.0561 - val_accuracy: 0.5400\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 6.1727 - val_accuracy: 0.5911\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 6.0936 - val_accuracy: 0.5778\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.2537 - val_accuracy: 0.5422\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.2562 - val_accuracy: 0.5311\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 6.1167 - val_accuracy: 0.5044\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 7.1599 - val_accuracy: 0.5222\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 6.1223 - val_accuracy: 0.5889\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 6.3867 - val_accuracy: 0.4889\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 6.3861 - val_accuracy: 0.5289\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 7.2405 - val_accuracy: 0.5778\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 6.7156 - val_accuracy: 0.4778\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 7.0101 - val_accuracy: 0.5067\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 7.3584 - val_accuracy: 0.5000\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 9.1958 - val_accuracy: 0.4422\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 7.5531 - val_accuracy: 0.4489\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9801 - val_loss: 13.1083 - val_accuracy: 0.3911\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 8.3575 - val_accuracy: 0.5200\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 8.9549 - val_accuracy: 0.3778\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 8.6083 - val_accuracy: 0.5756\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 8.2355 - val_accuracy: 0.5689\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 8.6376 - val_accuracy: 0.5778\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 8.2089 - val_accuracy: 0.5556\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 7.8185 - val_accuracy: 0.5533\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.6199 - val_accuracy: 0.5244\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_96 (Conv2D)           (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 54, 54, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 54, 54, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,947\n",
      "Trainable params: 150,863\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 10ms/step - loss: 1.0594 - accuracy: 0.4556 - val_loss: 1.0978 - val_accuracy: 0.3133\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6970 - accuracy: 0.6509 - val_loss: 1.1028 - val_accuracy: 0.3378\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.8273 - val_loss: 1.1333 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8977 - val_loss: 1.2624 - val_accuracy: 0.4533\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2145 - accuracy: 0.9417 - val_loss: 1.5297 - val_accuracy: 0.4200\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9625 - val_loss: 1.8361 - val_accuracy: 0.4022\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1396 - accuracy: 0.9616 - val_loss: 2.2105 - val_accuracy: 0.3733\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9722 - val_loss: 3.0460 - val_accuracy: 0.2867\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9898 - val_loss: 3.4427 - val_accuracy: 0.3000\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9889 - val_loss: 4.2538 - val_accuracy: 0.2911\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9954 - val_loss: 4.6823 - val_accuracy: 0.3111\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9954 - val_loss: 5.4024 - val_accuracy: 0.3200\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9972 - val_loss: 5.4630 - val_accuracy: 0.4622\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9968 - val_loss: 7.2160 - val_accuracy: 0.2933\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9991 - val_loss: 5.6147 - val_accuracy: 0.4689\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9968 - val_loss: 6.0921 - val_accuracy: 0.4978\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9991 - val_loss: 6.8642 - val_accuracy: 0.4533\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 6.6934 - val_accuracy: 0.4933\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 6.8060 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 6.6087 - val_accuracy: 0.5511\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 7.9264 - val_accuracy: 0.5133\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 8.3997 - val_accuracy: 0.5600\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 8.5514 - val_accuracy: 0.5800\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.9585 - val_accuracy: 0.5578\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 9.0089 - val_accuracy: 0.5422\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 8.8412 - val_accuracy: 0.5422\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 8.4712 - val_accuracy: 0.4533\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9949 - val_loss: 8.2952 - val_accuracy: 0.5556\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 12.5679 - val_accuracy: 0.4822\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 13.2721 - val_accuracy: 0.5289\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 11.2439 - val_accuracy: 0.4556\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 10.7719 - val_accuracy: 0.5133\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 10.7666 - val_accuracy: 0.3889\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 10.3090 - val_accuracy: 0.5333\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 10.2767 - val_accuracy: 0.5333\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 10.8445 - val_accuracy: 0.5333\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 9.7354 - val_accuracy: 0.5067\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 10.3718 - val_accuracy: 0.5133\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.9319 - val_accuracy: 0.5111\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 8.6465 - val_accuracy: 0.5222\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 9.3237 - val_accuracy: 0.5111\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 11.6465 - val_accuracy: 0.5400\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7.5507e-04 - accuracy: 1.0000 - val_loss: 11.0743 - val_accuracy: 0.5711\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 10.6803 - val_accuracy: 0.5222\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 10.3187 - val_accuracy: 0.5578\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 10.5335 - val_accuracy: 0.5444\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 10.9583 - val_accuracy: 0.5533\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 10.6445 - val_accuracy: 0.5356\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 7.8757e-04 - accuracy: 1.0000 - val_loss: 11.0280 - val_accuracy: 0.5289\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 11.2805 - val_accuracy: 0.5467\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=10\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=50\n",
    "dropout_rate=[i*0.1 for i in range(3,10)]\n",
    "lrs=[0.01,0.001]\n",
    "batch_size=[2**i for i in range(4,7)]\n",
    "\n",
    "acc={}\n",
    "for i in lrs:\n",
    "    for j in batch_size:\n",
    "        for k in dropout_rate:\n",
    "            history=model1(n_channel_1, n_channel_2, n_dense, i,n_train_epoch,j,i)\n",
    "            acc[f\"{i}-{j}-{k}\"]=history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91aa7e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>BS</th>\n",
       "      <th>dropout</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.664444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.628889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr  BS dropout       acc\n",
       "26  0.001  16     0.8  0.664444\n",
       "27  0.001  16     0.9  0.628889"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_acc(acc, key,hp):\n",
    "    hp1,hp2,hp3=key.split(\"-\")\n",
    "    dd=pd.DataFrame(acc[key].history)\n",
    "    return {hp[0]:hp1,hp[1]:hp2,hp[2]:hp3,\"acc\":dd.max()[3]}\n",
    "\n",
    "dict_list=[]\n",
    "for i in acc.keys():\n",
    "    dict_list.append(find_acc(acc,i,(\"lr\",\"BS\",\"dropout\")))\n",
    "    \n",
    "acc_df=pd.DataFrame(dict_list) # 가장 높은 accuracy는 0.574667\n",
    "acc_df.loc[acc_df[\"acc\"]>0.626667].sort_values(\"acc\", ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd7f51",
   "metadata": {},
   "source": [
    "베이스 모델에서 최고 성능보다 높은 성능을 보인 하이퍼 파라미터 조합은 2개가 나왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ee71d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first=pd.DataFrame(acc[\"0.001-16-0.8\"].history)\n",
    "second=pd.DataFrame(acc[\"0.001-16-0.9\"].history)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(first[\"val_accuracy\"])\n",
    "plt.plot(first[\"accuracy\"])\n",
    "plt.title(\"lr:0.001,BS:16,dropout:0.8\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(second[\"val_accuracy\"])\n",
    "plt.plot(second[\"accuracy\"])\n",
    "plt.title(\"lr:0.001,BS:16,dropout:0.9\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(first[\"val_loss\"])\n",
    "plt.plot(first[\"loss\"])\n",
    "plt.title(\"lr:0.001,BS:16,dropout:0.8\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(second[\"val_loss\"])\n",
    "plt.plot(second[\"loss\"])\n",
    "plt.title(\"lr:0.001,BS:16,dropout:0.9\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4b872",
   "metadata": {},
   "source": [
    "최고 accuracy가 가장 좋게나왔던 learning rate, batch size, dropout rate의 조합의 train과 test의 accuracy가 epoch가 증가함에 따라서 어떻게 변하는지 그래프를 그려보았다. \n",
    "- 학습 데이터셋이 안정적으로 학습이 되는 것을 볼수 있고 학습 데이터가 안정적으로 학습이 되어가면서 시험데이터셋(test dataset)의 성능이 매우 떨어지는 것을 볼 수 있었다. \n",
    "- 신기하게도 둘다 학습률(learning rate)를 0.001, 배치 사이즈(batch size)를 16이고 드롭아웃 시키는 비율이 0.9와 0.8이었다.\n",
    "- 오버피팅을 방지하기 위해서 batch normalization과 mini batch gredient descent, drop out을 시도하였고 학습률에도 변화를 주어보았다. 그럼에도 불구하고 오버피팅의 문제가 해결이 되지는 않았지만, 최소한 베이스 모델보다는 accuracy가 0.04 0.002 올라간 것을 확인 할 수 있었다. \n",
    "\n",
    "다음 단계에서는 모델의 정확도를 올라갔던 하이퍼파라미터의 조합으로 2개의 2차원 컨볼루션 레이어의 필터의 개수와 마지막 max pooling을 거친 다음 히든레이어로 fully connetion되는 레이어의 출력노드를 튜닝해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1ed427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_102 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 25, 25, 8)         1304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 38,907\n",
      "Trainable params: 38,855\n",
      "Non-trainable params: 52\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1722 - accuracy: 0.3449 - val_loss: 1.1008 - val_accuracy: 0.3222\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0553 - accuracy: 0.3662 - val_loss: 1.1194 - val_accuracy: 0.3667\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0251 - accuracy: 0.4042 - val_loss: 1.1318 - val_accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0137 - accuracy: 0.4218 - val_loss: 1.1668 - val_accuracy: 0.4733\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9764 - accuracy: 0.4477 - val_loss: 1.4057 - val_accuracy: 0.3978\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9536 - accuracy: 0.4514 - val_loss: 1.4299 - val_accuracy: 0.4578\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9354 - accuracy: 0.4708 - val_loss: 1.5145 - val_accuracy: 0.4311\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9193 - accuracy: 0.4727 - val_loss: 1.6336 - val_accuracy: 0.5022\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9029 - accuracy: 0.4912 - val_loss: 1.4256 - val_accuracy: 0.4489\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8878 - accuracy: 0.5042 - val_loss: 1.6085 - val_accuracy: 0.4644\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8650 - accuracy: 0.5241 - val_loss: 1.3970 - val_accuracy: 0.4844\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8687 - accuracy: 0.5042 - val_loss: 1.5632 - val_accuracy: 0.4556\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8527 - accuracy: 0.5218 - val_loss: 1.3054 - val_accuracy: 0.4844\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8213 - accuracy: 0.5426 - val_loss: 1.9349 - val_accuracy: 0.3733\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8313 - accuracy: 0.5282 - val_loss: 1.4952 - val_accuracy: 0.5178\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8250 - accuracy: 0.5481 - val_loss: 2.3026 - val_accuracy: 0.5244\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7774 - accuracy: 0.5667 - val_loss: 2.1099 - val_accuracy: 0.4822\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7811 - accuracy: 0.5676 - val_loss: 2.5644 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7480 - accuracy: 0.5935 - val_loss: 1.8202 - val_accuracy: 0.5533\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.6060 - val_loss: 4.0765 - val_accuracy: 0.4444\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7453 - accuracy: 0.6028 - val_loss: 1.6506 - val_accuracy: 0.5622\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.6204 - val_loss: 2.3376 - val_accuracy: 0.5222\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.6366 - val_loss: 3.3555 - val_accuracy: 0.5400\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.6343 - val_loss: 3.8092 - val_accuracy: 0.5156\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6569 - val_loss: 2.9955 - val_accuracy: 0.4200\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6585 - accuracy: 0.6407 - val_loss: 1.7359 - val_accuracy: 0.5378\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6773 - val_loss: 3.3562 - val_accuracy: 0.5311\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6481 - val_loss: 2.0509 - val_accuracy: 0.5089\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6325 - accuracy: 0.6514 - val_loss: 2.7482 - val_accuracy: 0.5044\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6256 - accuracy: 0.6602 - val_loss: 5.3152 - val_accuracy: 0.4489\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5858 - accuracy: 0.6833 - val_loss: 4.8530 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6690 - val_loss: 4.5606 - val_accuracy: 0.5444\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5940 - accuracy: 0.6940 - val_loss: 3.7588 - val_accuracy: 0.5022\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.6843 - val_loss: 3.9262 - val_accuracy: 0.5200\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5705 - accuracy: 0.6907 - val_loss: 3.8560 - val_accuracy: 0.4444\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.6968 - val_loss: 5.3496 - val_accuracy: 0.4489\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.6875 - val_loss: 4.6566 - val_accuracy: 0.5556\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7093 - val_loss: 4.5358 - val_accuracy: 0.5289\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7065 - val_loss: 4.6158 - val_accuracy: 0.4822\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7083 - val_loss: 5.4658 - val_accuracy: 0.4711\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7199 - val_loss: 6.9798 - val_accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5445 - accuracy: 0.7046 - val_loss: 4.9000 - val_accuracy: 0.4978\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7222 - val_loss: 4.9020 - val_accuracy: 0.4911\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.6949 - val_loss: 5.0285 - val_accuracy: 0.4800\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7227 - val_loss: 6.4632 - val_accuracy: 0.5178\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5628 - accuracy: 0.7093 - val_loss: 6.1664 - val_accuracy: 0.5467\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5494 - accuracy: 0.7208 - val_loss: 8.7131 - val_accuracy: 0.4333\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7301 - val_loss: 6.4546 - val_accuracy: 0.5244\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7306 - val_loss: 5.1430 - val_accuracy: 0.4667\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7431 - val_loss: 9.6099 - val_accuracy: 0.4178\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7245 - val_loss: 4.9225 - val_accuracy: 0.4956\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7208 - val_loss: 6.8650 - val_accuracy: 0.4956\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5055 - accuracy: 0.7361 - val_loss: 7.6818 - val_accuracy: 0.4489\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7509 - val_loss: 9.5592 - val_accuracy: 0.4267\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5026 - accuracy: 0.7403 - val_loss: 6.1370 - val_accuracy: 0.4600\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7477 - val_loss: 5.1625 - val_accuracy: 0.4422\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7259 - val_loss: 8.2510 - val_accuracy: 0.4444\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7282 - val_loss: 6.3709 - val_accuracy: 0.5689\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7282 - val_loss: 4.5213 - val_accuracy: 0.5578\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7370 - val_loss: 6.4407 - val_accuracy: 0.5400\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7269 - val_loss: 14.6293 - val_accuracy: 0.3778\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7213 - val_loss: 7.1964 - val_accuracy: 0.4800\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7310 - val_loss: 7.8250 - val_accuracy: 0.4756\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7343 - val_loss: 8.7466 - val_accuracy: 0.4444\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7458 - val_loss: 7.3691 - val_accuracy: 0.4644\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4724 - accuracy: 0.7519 - val_loss: 10.5485 - val_accuracy: 0.4067\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7579 - val_loss: 5.3169 - val_accuracy: 0.5044\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7565 - val_loss: 7.1447 - val_accuracy: 0.4600\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7574 - val_loss: 12.5677 - val_accuracy: 0.3622\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7588 - val_loss: 3.6998 - val_accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7667 - val_loss: 9.5513 - val_accuracy: 0.4733\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7880 - val_loss: 9.6700 - val_accuracy: 0.4533\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7653 - val_loss: 8.4582 - val_accuracy: 0.5756\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4319 - accuracy: 0.7718 - val_loss: 8.1176 - val_accuracy: 0.5067\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7773 - val_loss: 7.2565 - val_accuracy: 0.4711\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7620 - val_loss: 7.8753 - val_accuracy: 0.5067\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7611 - val_loss: 9.3315 - val_accuracy: 0.4822\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7736 - val_loss: 7.8059 - val_accuracy: 0.4689\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7694 - val_loss: 13.9822 - val_accuracy: 0.4000\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7861 - val_loss: 10.8414 - val_accuracy: 0.4533\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4275 - accuracy: 0.7708 - val_loss: 11.8161 - val_accuracy: 0.4556\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4638 - accuracy: 0.7657 - val_loss: 7.8384 - val_accuracy: 0.5289\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7713 - val_loss: 11.8397 - val_accuracy: 0.4244\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7769 - val_loss: 9.2419 - val_accuracy: 0.4667\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7792 - val_loss: 11.4198 - val_accuracy: 0.4689\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7731 - val_loss: 10.7543 - val_accuracy: 0.5556\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4206 - accuracy: 0.7833 - val_loss: 10.2157 - val_accuracy: 0.4889\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7815 - val_loss: 7.6158 - val_accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.7870 - val_loss: 10.8279 - val_accuracy: 0.4222\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.7949 - val_loss: 11.6811 - val_accuracy: 0.4622\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8005 - val_loss: 8.0914 - val_accuracy: 0.5644\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3889 - accuracy: 0.8074 - val_loss: 7.8444 - val_accuracy: 0.4867\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3962 - accuracy: 0.8023 - val_loss: 10.7402 - val_accuracy: 0.4644\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4100 - accuracy: 0.7889 - val_loss: 7.3535 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3977 - accuracy: 0.8009 - val_loss: 11.8648 - val_accuracy: 0.4244\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8139 - val_loss: 11.7362 - val_accuracy: 0.4511\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8005 - val_loss: 8.5149 - val_accuracy: 0.4956\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8181 - val_loss: 11.3636 - val_accuracy: 0.4422\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.7889 - val_loss: 10.5905 - val_accuracy: 0.4711\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.7907 - val_loss: 8.7722 - val_accuracy: 0.4756\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_104 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 25, 25, 8)         1304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_105 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 75,899\n",
      "Trainable params: 75,847\n",
      "Non-trainable params: 52\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2249 - accuracy: 0.3648 - val_loss: 1.0966 - val_accuracy: 0.3400\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0439 - accuracy: 0.4097 - val_loss: 1.1113 - val_accuracy: 0.3356\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.4532 - val_loss: 1.0302 - val_accuracy: 0.3933\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9414 - accuracy: 0.4796 - val_loss: 1.0065 - val_accuracy: 0.5622\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9152 - accuracy: 0.5069 - val_loss: 1.1341 - val_accuracy: 0.4711\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8709 - accuracy: 0.5319 - val_loss: 1.1514 - val_accuracy: 0.5156\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.5704 - val_loss: 1.2005 - val_accuracy: 0.4667\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7822 - accuracy: 0.5852 - val_loss: 1.1590 - val_accuracy: 0.5667\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7691 - accuracy: 0.5912 - val_loss: 1.5685 - val_accuracy: 0.4556\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7245 - accuracy: 0.6162 - val_loss: 1.6341 - val_accuracy: 0.4489\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.6023 - val_loss: 1.0809 - val_accuracy: 0.5867\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.6157 - val_loss: 1.1746 - val_accuracy: 0.4822\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7215 - accuracy: 0.6088 - val_loss: 1.2533 - val_accuracy: 0.5467\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.6218 - val_loss: 1.2909 - val_accuracy: 0.5489\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.6380 - val_loss: 1.1678 - val_accuracy: 0.6200\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6417 - val_loss: 1.5266 - val_accuracy: 0.5622\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.6412 - val_loss: 0.9464 - val_accuracy: 0.6178\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6630 - val_loss: 1.5075 - val_accuracy: 0.5378\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6313 - accuracy: 0.6597 - val_loss: 1.1585 - val_accuracy: 0.4956\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6463 - val_loss: 1.0905 - val_accuracy: 0.5867\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6796 - val_loss: 1.7610 - val_accuracy: 0.5178\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.6935 - val_loss: 1.4480 - val_accuracy: 0.5533\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6745 - val_loss: 1.3561 - val_accuracy: 0.6089\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.6981 - val_loss: 1.1166 - val_accuracy: 0.6067\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7208 - val_loss: 1.4441 - val_accuracy: 0.6178\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.7222 - val_loss: 1.2620 - val_accuracy: 0.6111\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7181 - val_loss: 3.4090 - val_accuracy: 0.4556\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7255 - val_loss: 3.8611 - val_accuracy: 0.4267\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7370 - val_loss: 1.5298 - val_accuracy: 0.5778\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7389 - val_loss: 1.3534 - val_accuracy: 0.6089\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 1.2060 - val_accuracy: 0.5933\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7519 - val_loss: 1.3299 - val_accuracy: 0.5978\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7505 - val_loss: 1.4591 - val_accuracy: 0.6378\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7458 - val_loss: 1.5060 - val_accuracy: 0.6267\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7477 - val_loss: 1.9311 - val_accuracy: 0.5800\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7519 - val_loss: 2.0849 - val_accuracy: 0.5844\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7903 - val_loss: 1.9234 - val_accuracy: 0.5622\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7898 - val_loss: 1.9160 - val_accuracy: 0.6178\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8097 - val_loss: 2.4885 - val_accuracy: 0.5622\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7866 - val_loss: 3.0182 - val_accuracy: 0.5667\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7940 - val_loss: 2.4940 - val_accuracy: 0.5622\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7949 - val_loss: 1.8669 - val_accuracy: 0.6178\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7977 - val_loss: 1.9910 - val_accuracy: 0.6156\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8088 - val_loss: 4.2633 - val_accuracy: 0.4511\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8028 - val_loss: 3.4025 - val_accuracy: 0.5267\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8162 - val_loss: 2.6224 - val_accuracy: 0.5578\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8046 - val_loss: 2.3795 - val_accuracy: 0.5533\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7912 - val_loss: 2.1907 - val_accuracy: 0.6089\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8199 - val_loss: 2.7420 - val_accuracy: 0.5889\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8005 - val_loss: 2.3509 - val_accuracy: 0.5756\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8259 - val_loss: 3.5272 - val_accuracy: 0.5578\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8319 - val_loss: 3.6297 - val_accuracy: 0.5822\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8324 - val_loss: 3.4648 - val_accuracy: 0.5378\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8282 - val_loss: 2.0389 - val_accuracy: 0.6044\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3929 - accuracy: 0.8157 - val_loss: 3.6456 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8213 - val_loss: 2.1597 - val_accuracy: 0.5911\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8241 - val_loss: 4.3998 - val_accuracy: 0.4867\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8255 - val_loss: 3.5826 - val_accuracy: 0.5578\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8407 - val_loss: 2.9704 - val_accuracy: 0.6133\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8356 - val_loss: 3.7457 - val_accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8463 - val_loss: 4.8011 - val_accuracy: 0.5222\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.8375 - val_loss: 5.3698 - val_accuracy: 0.4644\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8412 - val_loss: 4.5195 - val_accuracy: 0.5711\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8338 - val_loss: 3.6694 - val_accuracy: 0.5622\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8514 - val_loss: 2.7414 - val_accuracy: 0.5911\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8528 - val_loss: 3.4641 - val_accuracy: 0.5356\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8625 - val_loss: 5.8664 - val_accuracy: 0.4267\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8454 - val_loss: 3.1041 - val_accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8532 - val_loss: 3.1381 - val_accuracy: 0.5667\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8681 - val_loss: 4.2882 - val_accuracy: 0.5778\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.8639 - val_loss: 5.3496 - val_accuracy: 0.5778\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8755 - val_loss: 7.3118 - val_accuracy: 0.5467\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8546 - val_loss: 4.1585 - val_accuracy: 0.6311\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8662 - val_loss: 3.6612 - val_accuracy: 0.5422\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8597 - val_loss: 2.6885 - val_accuracy: 0.5778\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8519 - val_loss: 6.2949 - val_accuracy: 0.5022\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8602 - val_loss: 5.9025 - val_accuracy: 0.5178\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8671 - val_loss: 3.0591 - val_accuracy: 0.6067\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8722 - val_loss: 6.4786 - val_accuracy: 0.5800\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8644 - val_loss: 4.5457 - val_accuracy: 0.5711\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8722 - val_loss: 3.3461 - val_accuracy: 0.5889\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8755 - val_loss: 3.8835 - val_accuracy: 0.5689\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.8792 - val_loss: 6.6807 - val_accuracy: 0.5156\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8824 - val_loss: 5.4858 - val_accuracy: 0.5533\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8769 - val_loss: 4.2768 - val_accuracy: 0.5822\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8741 - val_loss: 8.5428 - val_accuracy: 0.5200\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.8856 - val_loss: 8.8030 - val_accuracy: 0.4578\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8796 - val_loss: 7.9009 - val_accuracy: 0.4956\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.8815 - val_loss: 9.9493 - val_accuracy: 0.4733\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2579 - accuracy: 0.8838 - val_loss: 5.3983 - val_accuracy: 0.5489\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8769 - val_loss: 5.0617 - val_accuracy: 0.5289\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.8907 - val_loss: 4.1184 - val_accuracy: 0.5956\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8718 - val_loss: 4.1785 - val_accuracy: 0.5644\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.8829 - val_loss: 5.3354 - val_accuracy: 0.5644\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8741 - val_loss: 7.4925 - val_accuracy: 0.4733\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2301 - accuracy: 0.8986 - val_loss: 5.2991 - val_accuracy: 0.5733\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.8819 - val_loss: 5.3086 - val_accuracy: 0.5422\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.8787 - val_loss: 5.2788 - val_accuracy: 0.5556\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.8903 - val_loss: 7.7330 - val_accuracy: 0.5200\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2381 - accuracy: 0.8949 - val_loss: 5.4314 - val_accuracy: 0.5444\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_106 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_106 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 25, 25, 8)         1304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 149,883\n",
      "Trainable params: 149,831\n",
      "Non-trainable params: 52\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2441 - accuracy: 0.4296 - val_loss: 1.1025 - val_accuracy: 0.3178\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9395 - accuracy: 0.5250 - val_loss: 1.0640 - val_accuracy: 0.3911\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8295 - accuracy: 0.5926 - val_loss: 1.0465 - val_accuracy: 0.4733\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7471 - accuracy: 0.6657 - val_loss: 1.5915 - val_accuracy: 0.3844\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.7046 - val_loss: 1.0426 - val_accuracy: 0.4911\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5991 - accuracy: 0.7204 - val_loss: 1.0584 - val_accuracy: 0.5400\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5576 - accuracy: 0.7477 - val_loss: 1.8637 - val_accuracy: 0.4178\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5174 - accuracy: 0.7597 - val_loss: 1.1189 - val_accuracy: 0.5489\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4735 - accuracy: 0.7824 - val_loss: 1.5625 - val_accuracy: 0.5600\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7921 - val_loss: 1.5048 - val_accuracy: 0.5644\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8005 - val_loss: 2.0136 - val_accuracy: 0.4489\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 1.7092 - val_accuracy: 0.4444\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3824 - accuracy: 0.8259 - val_loss: 1.4460 - val_accuracy: 0.5533\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3766 - accuracy: 0.8329 - val_loss: 2.1127 - val_accuracy: 0.4333\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3632 - accuracy: 0.8306 - val_loss: 3.1072 - val_accuracy: 0.4067\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8384 - val_loss: 3.7770 - val_accuracy: 0.3978\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3371 - accuracy: 0.8407 - val_loss: 1.9606 - val_accuracy: 0.4933\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8468 - val_loss: 2.3483 - val_accuracy: 0.4400\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3163 - accuracy: 0.8620 - val_loss: 7.4450 - val_accuracy: 0.4444\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8648 - val_loss: 2.6818 - val_accuracy: 0.4867\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8560 - val_loss: 2.5115 - val_accuracy: 0.5356\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.8741 - val_loss: 2.7484 - val_accuracy: 0.4556\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2661 - accuracy: 0.8764 - val_loss: 2.6756 - val_accuracy: 0.4622\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.8833 - val_loss: 4.9623 - val_accuracy: 0.4400\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.8843 - val_loss: 3.3825 - val_accuracy: 0.3889\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 3.9868 - val_accuracy: 0.3889\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.9000 - val_loss: 3.5548 - val_accuracy: 0.4911\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2308 - accuracy: 0.8949 - val_loss: 3.0344 - val_accuracy: 0.5044\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2190 - accuracy: 0.8991 - val_loss: 5.1387 - val_accuracy: 0.4244\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2225 - accuracy: 0.8986 - val_loss: 3.1742 - val_accuracy: 0.5267\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2095 - accuracy: 0.9083 - val_loss: 6.2676 - val_accuracy: 0.3600\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9190 - val_loss: 6.1601 - val_accuracy: 0.3511\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9065 - val_loss: 2.2939 - val_accuracy: 0.5156\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9093 - val_loss: 5.1223 - val_accuracy: 0.4267\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9199 - val_loss: 4.1446 - val_accuracy: 0.4644\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9162 - val_loss: 2.6120 - val_accuracy: 0.5267\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9079 - val_loss: 5.0486 - val_accuracy: 0.4511\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.9144 - val_loss: 4.3269 - val_accuracy: 0.4600\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9130 - val_loss: 3.6157 - val_accuracy: 0.5800\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.9218 - val_loss: 6.9299 - val_accuracy: 0.3956\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9278 - val_loss: 2.7458 - val_accuracy: 0.5044\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1621 - accuracy: 0.9273 - val_loss: 4.5395 - val_accuracy: 0.5244\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1659 - accuracy: 0.9306 - val_loss: 5.8210 - val_accuracy: 0.4778\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9361 - val_loss: 5.0949 - val_accuracy: 0.4733\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9306 - val_loss: 4.1849 - val_accuracy: 0.5644\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9296 - val_loss: 4.2208 - val_accuracy: 0.5156\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9236 - val_loss: 4.4077 - val_accuracy: 0.5733\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9306 - val_loss: 8.1900 - val_accuracy: 0.4689\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1703 - accuracy: 0.9259 - val_loss: 8.5938 - val_accuracy: 0.3911\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9407 - val_loss: 3.8520 - val_accuracy: 0.4689\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1583 - accuracy: 0.9287 - val_loss: 4.8145 - val_accuracy: 0.5600\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9375 - val_loss: 4.1323 - val_accuracy: 0.5511\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9356 - val_loss: 7.7254 - val_accuracy: 0.4600\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9440 - val_loss: 8.1940 - val_accuracy: 0.4489\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1315 - accuracy: 0.9454 - val_loss: 6.7372 - val_accuracy: 0.4978\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1457 - accuracy: 0.9421 - val_loss: 7.7531 - val_accuracy: 0.3844\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9384 - val_loss: 4.4355 - val_accuracy: 0.5289\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9472 - val_loss: 7.5180 - val_accuracy: 0.4578\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9375 - val_loss: 6.5379 - val_accuracy: 0.5244\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9375 - val_loss: 6.1623 - val_accuracy: 0.4356\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1315 - accuracy: 0.9458 - val_loss: 6.4922 - val_accuracy: 0.4844\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9532 - val_loss: 6.0643 - val_accuracy: 0.5422\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9505 - val_loss: 6.5945 - val_accuracy: 0.4978\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9602 - val_loss: 5.1761 - val_accuracy: 0.5644\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9551 - val_loss: 4.8915 - val_accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1132 - accuracy: 0.9509 - val_loss: 7.3415 - val_accuracy: 0.4689\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9514 - val_loss: 6.2417 - val_accuracy: 0.5044\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.9588 - val_loss: 5.6783 - val_accuracy: 0.5244\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9523 - val_loss: 9.1197 - val_accuracy: 0.4200\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1094 - accuracy: 0.9532 - val_loss: 7.2023 - val_accuracy: 0.5089\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9491 - val_loss: 6.3232 - val_accuracy: 0.4711\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9486 - val_loss: 9.0535 - val_accuracy: 0.4111\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1277 - accuracy: 0.9495 - val_loss: 5.4654 - val_accuracy: 0.5711\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1120 - accuracy: 0.9588 - val_loss: 7.6366 - val_accuracy: 0.4867\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9611 - val_loss: 7.2152 - val_accuracy: 0.4667\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9532 - val_loss: 9.1705 - val_accuracy: 0.4844\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9630 - val_loss: 8.7239 - val_accuracy: 0.4889\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9630 - val_loss: 8.8421 - val_accuracy: 0.5622\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9648 - val_loss: 8.9746 - val_accuracy: 0.5911\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.9569 - val_loss: 7.8168 - val_accuracy: 0.5067\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9685 - val_loss: 6.7884 - val_accuracy: 0.5489\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9602 - val_loss: 6.7141 - val_accuracy: 0.5756\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9620 - val_loss: 13.1623 - val_accuracy: 0.4111\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9644 - val_loss: 7.4579 - val_accuracy: 0.5044\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0851 - accuracy: 0.9662 - val_loss: 11.0126 - val_accuracy: 0.4756\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9556 - val_loss: 6.2851 - val_accuracy: 0.5667\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9704 - val_loss: 9.1311 - val_accuracy: 0.4778\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9713 - val_loss: 6.9053 - val_accuracy: 0.5533\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9630 - val_loss: 9.1094 - val_accuracy: 0.5578\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9644 - val_loss: 7.8844 - val_accuracy: 0.5156\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9681 - val_loss: 9.4124 - val_accuracy: 0.5067\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0836 - accuracy: 0.9694 - val_loss: 9.0000 - val_accuracy: 0.5267\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9681 - val_loss: 7.9776 - val_accuracy: 0.5400\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0749 - accuracy: 0.9704 - val_loss: 13.9666 - val_accuracy: 0.4156\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9676 - val_loss: 15.2028 - val_accuracy: 0.4578\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9713 - val_loss: 10.5146 - val_accuracy: 0.4489\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9764 - val_loss: 15.5979 - val_accuracy: 0.4044\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9644 - val_loss: 7.9375 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9634 - val_loss: 11.0362 - val_accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9620 - val_loss: 6.9476 - val_accuracy: 0.6022\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_108 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 25, 25, 8)         1304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 297,851\n",
      "Trainable params: 297,799\n",
      "Non-trainable params: 52\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 2s 9ms/step - loss: 1.2802 - accuracy: 0.4731 - val_loss: 1.0970 - val_accuracy: 0.3378\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7983 - accuracy: 0.6222 - val_loss: 1.0770 - val_accuracy: 0.5444\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6556 - accuracy: 0.7176 - val_loss: 1.0221 - val_accuracy: 0.5156\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7486 - val_loss: 0.9342 - val_accuracy: 0.5156\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5204 - accuracy: 0.7755 - val_loss: 1.1609 - val_accuracy: 0.5067\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4269 - accuracy: 0.8167 - val_loss: 1.2656 - val_accuracy: 0.4489\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8255 - val_loss: 1.6976 - val_accuracy: 0.4622\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3391 - accuracy: 0.8477 - val_loss: 2.4206 - val_accuracy: 0.4578\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8579 - val_loss: 2.2998 - val_accuracy: 0.4333\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.8602 - val_loss: 1.5871 - val_accuracy: 0.5044\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8713 - val_loss: 1.4173 - val_accuracy: 0.4822\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.8819 - val_loss: 2.8551 - val_accuracy: 0.5200\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2615 - accuracy: 0.8931 - val_loss: 1.8252 - val_accuracy: 0.4667\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2278 - accuracy: 0.9046 - val_loss: 2.5657 - val_accuracy: 0.5022\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2213 - accuracy: 0.9028 - val_loss: 1.9468 - val_accuracy: 0.5400\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9014 - val_loss: 3.1553 - val_accuracy: 0.5467\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9074 - val_loss: 3.0506 - val_accuracy: 0.4844\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2121 - accuracy: 0.9171 - val_loss: 1.9192 - val_accuracy: 0.4778\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9259 - val_loss: 2.3108 - val_accuracy: 0.5756\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1811 - accuracy: 0.9310 - val_loss: 3.4324 - val_accuracy: 0.5156\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9181 - val_loss: 6.9343 - val_accuracy: 0.3711\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9264 - val_loss: 4.4148 - val_accuracy: 0.4267\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9218 - val_loss: 2.8914 - val_accuracy: 0.5111\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9435 - val_loss: 3.5635 - val_accuracy: 0.5178\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9347 - val_loss: 4.6558 - val_accuracy: 0.4844\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9394 - val_loss: 3.2079 - val_accuracy: 0.4667\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9417 - val_loss: 4.9573 - val_accuracy: 0.4867\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9491 - val_loss: 3.4694 - val_accuracy: 0.5067\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9509 - val_loss: 5.1614 - val_accuracy: 0.4956\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1343 - accuracy: 0.9454 - val_loss: 4.2056 - val_accuracy: 0.4400\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9574 - val_loss: 4.9558 - val_accuracy: 0.5156\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9500 - val_loss: 3.9066 - val_accuracy: 0.5778\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1092 - accuracy: 0.9560 - val_loss: 5.3871 - val_accuracy: 0.4733\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9556 - val_loss: 4.7469 - val_accuracy: 0.4467\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9593 - val_loss: 3.4323 - val_accuracy: 0.5244\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9588 - val_loss: 3.4251 - val_accuracy: 0.5978\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9685 - val_loss: 4.1118 - val_accuracy: 0.5178\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9681 - val_loss: 7.7926 - val_accuracy: 0.4889\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9546 - val_loss: 6.2778 - val_accuracy: 0.4644\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9681 - val_loss: 7.4825 - val_accuracy: 0.4600\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9667 - val_loss: 4.3856 - val_accuracy: 0.5044\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0854 - accuracy: 0.9676 - val_loss: 5.1149 - val_accuracy: 0.4933\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9690 - val_loss: 4.1281 - val_accuracy: 0.5044\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 4.5666 - val_accuracy: 0.5200\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0725 - accuracy: 0.9745 - val_loss: 4.0437 - val_accuracy: 0.5200\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9727 - val_loss: 3.8443 - val_accuracy: 0.5511\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9708 - val_loss: 5.4939 - val_accuracy: 0.6067\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9708 - val_loss: 5.5191 - val_accuracy: 0.5133\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9667 - val_loss: 6.8767 - val_accuracy: 0.4289\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0633 - accuracy: 0.9741 - val_loss: 5.1589 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0802 - accuracy: 0.9685 - val_loss: 12.7545 - val_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1022 - accuracy: 0.9611 - val_loss: 5.0630 - val_accuracy: 0.4844\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9801 - val_loss: 5.7670 - val_accuracy: 0.5178\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9815 - val_loss: 7.4957 - val_accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9787 - val_loss: 6.1345 - val_accuracy: 0.5289\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9764 - val_loss: 6.6562 - val_accuracy: 0.4956\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9796 - val_loss: 4.6330 - val_accuracy: 0.5178\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9731 - val_loss: 5.7650 - val_accuracy: 0.5511\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 6.0944 - val_accuracy: 0.5267\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9755 - val_loss: 4.7811 - val_accuracy: 0.6111\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 6.8160 - val_accuracy: 0.5267\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0648 - accuracy: 0.9782 - val_loss: 5.0770 - val_accuracy: 0.4689\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9815 - val_loss: 5.3157 - val_accuracy: 0.4733\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9838 - val_loss: 5.8333 - val_accuracy: 0.5289\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9778 - val_loss: 6.2951 - val_accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 7.2727 - val_accuracy: 0.5111\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9778 - val_loss: 5.1734 - val_accuracy: 0.5578\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9861 - val_loss: 5.0098 - val_accuracy: 0.5622\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 7.5173 - val_accuracy: 0.4933\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9847 - val_loss: 8.7197 - val_accuracy: 0.5267\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0393 - accuracy: 0.9838 - val_loss: 7.3925 - val_accuracy: 0.4867\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9843 - val_loss: 5.6023 - val_accuracy: 0.5022\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9861 - val_loss: 9.3036 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 5.9954 - val_accuracy: 0.5467\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 5.8727 - val_accuracy: 0.4533\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9856 - val_loss: 7.6909 - val_accuracy: 0.5044\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9801 - val_loss: 5.6522 - val_accuracy: 0.5200\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9787 - val_loss: 5.5858 - val_accuracy: 0.5111\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 5.9144 - val_accuracy: 0.5489\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 6.4375 - val_accuracy: 0.4911\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 6.7277 - val_accuracy: 0.4978\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9894 - val_loss: 7.0033 - val_accuracy: 0.5378\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9782 - val_loss: 7.0974 - val_accuracy: 0.4689\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9843 - val_loss: 5.6817 - val_accuracy: 0.5089\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9852 - val_loss: 7.2103 - val_accuracy: 0.4733\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 9.2017 - val_accuracy: 0.5311\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 7.9619 - val_accuracy: 0.5089\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9884 - val_loss: 9.0361 - val_accuracy: 0.5267\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9847 - val_loss: 7.3706 - val_accuracy: 0.4800\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 8.8871 - val_accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9884 - val_loss: 8.0338 - val_accuracy: 0.5178\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9833 - val_loss: 9.1149 - val_accuracy: 0.5022\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9884 - val_loss: 9.6212 - val_accuracy: 0.5267\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9870 - val_loss: 8.2547 - val_accuracy: 0.4444\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9833 - val_loss: 6.9910 - val_accuracy: 0.5178\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9866 - val_loss: 8.0517 - val_accuracy: 0.5200\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 8.8497 - val_accuracy: 0.4822\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9880 - val_loss: 10.5258 - val_accuracy: 0.5156\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9829 - val_loss: 7.9862 - val_accuracy: 0.5267\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 7.9350 - val_accuracy: 0.5378\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_110 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 25, 25, 10)        1630      \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 48,457\n",
      "Trainable params: 48,401\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1507 - accuracy: 0.3417 - val_loss: 1.0966 - val_accuracy: 0.3756\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0788 - accuracy: 0.3542 - val_loss: 1.0969 - val_accuracy: 0.3400\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0691 - accuracy: 0.3681 - val_loss: 1.1010 - val_accuracy: 0.3689\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0406 - accuracy: 0.3907 - val_loss: 1.0703 - val_accuracy: 0.4333\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0478 - accuracy: 0.3940 - val_loss: 1.0634 - val_accuracy: 0.4156\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0334 - accuracy: 0.4102 - val_loss: 1.1015 - val_accuracy: 0.2933\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0201 - accuracy: 0.4171 - val_loss: 1.2355 - val_accuracy: 0.3889\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0216 - accuracy: 0.4171 - val_loss: 1.1857 - val_accuracy: 0.3178\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9939 - accuracy: 0.4449 - val_loss: 1.1639 - val_accuracy: 0.3222\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9881 - accuracy: 0.4514 - val_loss: 1.1495 - val_accuracy: 0.4200\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9575 - accuracy: 0.4676 - val_loss: 1.0959 - val_accuracy: 0.3400\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9557 - accuracy: 0.4741 - val_loss: 1.4735 - val_accuracy: 0.3911\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9241 - accuracy: 0.4833 - val_loss: 1.1516 - val_accuracy: 0.4333\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9127 - accuracy: 0.4880 - val_loss: 1.0816 - val_accuracy: 0.4644\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9024 - accuracy: 0.5065 - val_loss: 1.1282 - val_accuracy: 0.4311\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9002 - accuracy: 0.4995 - val_loss: 1.1169 - val_accuracy: 0.4222\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8841 - accuracy: 0.4972 - val_loss: 1.1630 - val_accuracy: 0.3822\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8975 - accuracy: 0.4986 - val_loss: 1.1086 - val_accuracy: 0.3533\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8910 - accuracy: 0.4954 - val_loss: 1.9283 - val_accuracy: 0.3867\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.5190 - val_loss: 1.2347 - val_accuracy: 0.3844\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8742 - accuracy: 0.5065 - val_loss: 1.2356 - val_accuracy: 0.4067\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8605 - accuracy: 0.5264 - val_loss: 1.1729 - val_accuracy: 0.3756\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8523 - accuracy: 0.5236 - val_loss: 1.3363 - val_accuracy: 0.4089\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8376 - accuracy: 0.5417 - val_loss: 1.2900 - val_accuracy: 0.4467\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8500 - accuracy: 0.5259 - val_loss: 1.3880 - val_accuracy: 0.4422\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.5282 - val_loss: 1.1554 - val_accuracy: 0.3822\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8549 - accuracy: 0.5185 - val_loss: 1.8145 - val_accuracy: 0.3956\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8434 - accuracy: 0.5292 - val_loss: 1.2442 - val_accuracy: 0.3778\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8429 - accuracy: 0.5301 - val_loss: 1.1608 - val_accuracy: 0.4267\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8309 - accuracy: 0.5356 - val_loss: 1.2024 - val_accuracy: 0.3911\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8605 - accuracy: 0.5199 - val_loss: 2.4862 - val_accuracy: 0.3956\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8584 - accuracy: 0.5213 - val_loss: 1.1879 - val_accuracy: 0.4022\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8321 - accuracy: 0.5403 - val_loss: 1.3384 - val_accuracy: 0.3956\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8399 - accuracy: 0.5315 - val_loss: 1.6217 - val_accuracy: 0.3822\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8120 - accuracy: 0.5486 - val_loss: 1.4542 - val_accuracy: 0.4556\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8282 - accuracy: 0.5421 - val_loss: 1.8438 - val_accuracy: 0.4289\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8055 - accuracy: 0.5588 - val_loss: 1.5823 - val_accuracy: 0.4400\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7797 - accuracy: 0.5662 - val_loss: 1.3905 - val_accuracy: 0.4333\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7872 - accuracy: 0.5634 - val_loss: 1.5536 - val_accuracy: 0.4289\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7884 - accuracy: 0.5602 - val_loss: 1.3913 - val_accuracy: 0.4289\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7839 - accuracy: 0.5579 - val_loss: 1.1898 - val_accuracy: 0.4111\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7647 - accuracy: 0.5773 - val_loss: 1.3289 - val_accuracy: 0.3933\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7449 - accuracy: 0.5843 - val_loss: 1.3080 - val_accuracy: 0.4533\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7586 - accuracy: 0.5759 - val_loss: 1.3545 - val_accuracy: 0.3778\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7632 - accuracy: 0.5759 - val_loss: 1.5808 - val_accuracy: 0.3911\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7595 - accuracy: 0.5884 - val_loss: 1.8085 - val_accuracy: 0.4444\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.5718 - val_loss: 1.3376 - val_accuracy: 0.4711\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7783 - accuracy: 0.5685 - val_loss: 1.5555 - val_accuracy: 0.4378\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7510 - accuracy: 0.5847 - val_loss: 1.7760 - val_accuracy: 0.4489\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7381 - accuracy: 0.5986 - val_loss: 1.6963 - val_accuracy: 0.4422\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7547 - accuracy: 0.5787 - val_loss: 1.6967 - val_accuracy: 0.4267\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7690 - accuracy: 0.5681 - val_loss: 1.7549 - val_accuracy: 0.3778\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7768 - accuracy: 0.5718 - val_loss: 1.6400 - val_accuracy: 0.3978\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7639 - accuracy: 0.5847 - val_loss: 2.0371 - val_accuracy: 0.4267\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7694 - accuracy: 0.5773 - val_loss: 2.9142 - val_accuracy: 0.4422\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7421 - accuracy: 0.6005 - val_loss: 2.1265 - val_accuracy: 0.4156\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7004 - accuracy: 0.6194 - val_loss: 2.3761 - val_accuracy: 0.4933\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.6139 - val_loss: 2.3984 - val_accuracy: 0.4111\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7140 - accuracy: 0.6065 - val_loss: 2.1417 - val_accuracy: 0.5089\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.6218 - val_loss: 3.5208 - val_accuracy: 0.4400\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6222 - val_loss: 2.5254 - val_accuracy: 0.5067\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7050 - accuracy: 0.6181 - val_loss: 2.5024 - val_accuracy: 0.4178\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6352 - val_loss: 2.6268 - val_accuracy: 0.4222\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6953 - accuracy: 0.6241 - val_loss: 2.1889 - val_accuracy: 0.4978\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6417 - val_loss: 4.3591 - val_accuracy: 0.4178\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.6264 - val_loss: 2.0478 - val_accuracy: 0.4578\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6426 - val_loss: 2.5694 - val_accuracy: 0.4733\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.6352 - val_loss: 2.8309 - val_accuracy: 0.5133\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6431 - val_loss: 2.8623 - val_accuracy: 0.4489\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.6264 - val_loss: 2.5741 - val_accuracy: 0.4556\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6259 - val_loss: 4.0621 - val_accuracy: 0.4711\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.6324 - val_loss: 2.6665 - val_accuracy: 0.4644\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6394 - val_loss: 2.3837 - val_accuracy: 0.4844\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6472 - val_loss: 2.8890 - val_accuracy: 0.4311\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6343 - val_loss: 2.2902 - val_accuracy: 0.3867\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6394 - val_loss: 2.1201 - val_accuracy: 0.4689\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6598 - accuracy: 0.6435 - val_loss: 2.3342 - val_accuracy: 0.4222\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.6361 - val_loss: 2.4264 - val_accuracy: 0.4467\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6375 - val_loss: 2.1653 - val_accuracy: 0.5089\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6444 - val_loss: 2.8528 - val_accuracy: 0.4489\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6394 - val_loss: 2.3618 - val_accuracy: 0.4689\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6435 - val_loss: 2.3979 - val_accuracy: 0.4733\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6403 - val_loss: 2.3154 - val_accuracy: 0.4756\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6389 - val_loss: 2.4517 - val_accuracy: 0.4711\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6519 - val_loss: 3.1939 - val_accuracy: 0.4400\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.6417 - val_loss: 2.9276 - val_accuracy: 0.4978\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6303 - accuracy: 0.6537 - val_loss: 2.5116 - val_accuracy: 0.4111\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6472 - val_loss: 2.2667 - val_accuracy: 0.4200\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6444 - val_loss: 2.4467 - val_accuracy: 0.4333\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6583 - val_loss: 2.5293 - val_accuracy: 0.3867\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6611 - val_loss: 2.8003 - val_accuracy: 0.4600\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6449 - val_loss: 2.9974 - val_accuracy: 0.4356\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6500 - val_loss: 2.9133 - val_accuracy: 0.4200\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6477 - val_loss: 2.6752 - val_accuracy: 0.4733\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6109 - accuracy: 0.6625 - val_loss: 2.6477 - val_accuracy: 0.4644\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6569 - val_loss: 3.8703 - val_accuracy: 0.4556\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.6644 - val_loss: 3.0996 - val_accuracy: 0.5200\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6551 - val_loss: 3.6319 - val_accuracy: 0.5222\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.6676 - val_loss: 3.4635 - val_accuracy: 0.5378\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.6694 - val_loss: 3.7162 - val_accuracy: 0.5044\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_112 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 25, 25, 10)        1630      \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_113 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 94,665\n",
      "Trainable params: 94,609\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1750 - accuracy: 0.4009 - val_loss: 1.1009 - val_accuracy: 0.3244\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0410 - accuracy: 0.4282 - val_loss: 1.1204 - val_accuracy: 0.3578\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0057 - accuracy: 0.4634 - val_loss: 1.1332 - val_accuracy: 0.4733\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9893 - accuracy: 0.4792 - val_loss: 1.1188 - val_accuracy: 0.3756\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9229 - accuracy: 0.5167 - val_loss: 1.0691 - val_accuracy: 0.4822\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9068 - accuracy: 0.5296 - val_loss: 1.2438 - val_accuracy: 0.4556\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8663 - accuracy: 0.5625 - val_loss: 2.1443 - val_accuracy: 0.3311\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.5606 - val_loss: 1.2411 - val_accuracy: 0.4956\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7978 - accuracy: 0.6042 - val_loss: 2.5764 - val_accuracy: 0.4089\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.6218 - val_loss: 1.6520 - val_accuracy: 0.3667\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7486 - accuracy: 0.6407 - val_loss: 1.5527 - val_accuracy: 0.4133\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7386 - accuracy: 0.6431 - val_loss: 1.8180 - val_accuracy: 0.4711\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.6671 - val_loss: 3.5804 - val_accuracy: 0.4911\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.6537 - val_loss: 1.8081 - val_accuracy: 0.5467\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.6759 - val_loss: 1.7512 - val_accuracy: 0.5022\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6861 - val_loss: 8.2405 - val_accuracy: 0.3511\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6944 - val_loss: 2.7971 - val_accuracy: 0.4400\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6764 - val_loss: 2.4805 - val_accuracy: 0.4089\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6995 - val_loss: 4.1928 - val_accuracy: 0.4022\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.7250 - val_loss: 1.9626 - val_accuracy: 0.4956\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7255 - val_loss: 3.1373 - val_accuracy: 0.5067\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7319 - val_loss: 2.8812 - val_accuracy: 0.4822\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7315 - val_loss: 4.2151 - val_accuracy: 0.4178\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7528 - val_loss: 3.1355 - val_accuracy: 0.4689\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7477 - val_loss: 3.7142 - val_accuracy: 0.4333\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7398 - val_loss: 3.7177 - val_accuracy: 0.4267\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7394 - val_loss: 9.0421 - val_accuracy: 0.3800\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7750 - val_loss: 3.7594 - val_accuracy: 0.4822\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7667 - val_loss: 5.2483 - val_accuracy: 0.4867\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7699 - val_loss: 2.5931 - val_accuracy: 0.5244\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7736 - val_loss: 4.9713 - val_accuracy: 0.4400\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7981 - val_loss: 4.3242 - val_accuracy: 0.4378\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7792 - val_loss: 6.1709 - val_accuracy: 0.3822\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7838 - val_loss: 3.9264 - val_accuracy: 0.4622\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7968 - val_loss: 3.7262 - val_accuracy: 0.4711\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8097 - val_loss: 3.4618 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8116 - val_loss: 3.0194 - val_accuracy: 0.4956\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8056 - val_loss: 3.2395 - val_accuracy: 0.5289\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8181 - val_loss: 3.3241 - val_accuracy: 0.4289\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8079 - val_loss: 6.4176 - val_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8324 - val_loss: 5.3160 - val_accuracy: 0.4756\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8144 - val_loss: 3.7368 - val_accuracy: 0.4978\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8218 - val_loss: 5.2116 - val_accuracy: 0.4422\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8264 - val_loss: 7.9877 - val_accuracy: 0.4489\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8162 - val_loss: 6.2414 - val_accuracy: 0.4889\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8329 - val_loss: 11.6913 - val_accuracy: 0.3822\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8343 - val_loss: 4.0648 - val_accuracy: 0.4889\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8250 - val_loss: 15.0070 - val_accuracy: 0.3689\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8347 - val_loss: 5.7883 - val_accuracy: 0.4467\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8440 - val_loss: 6.5761 - val_accuracy: 0.3889\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8375 - val_loss: 5.7421 - val_accuracy: 0.4311\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8407 - val_loss: 6.9044 - val_accuracy: 0.4422\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8282 - val_loss: 4.7938 - val_accuracy: 0.5111\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8546 - val_loss: 10.2831 - val_accuracy: 0.3822\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8500 - val_loss: 9.4561 - val_accuracy: 0.4956\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8509 - val_loss: 9.2086 - val_accuracy: 0.4933\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8477 - val_loss: 5.0159 - val_accuracy: 0.4400\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8523 - val_loss: 6.5565 - val_accuracy: 0.4022\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8583 - val_loss: 9.2839 - val_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8694 - val_loss: 11.9029 - val_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8620 - val_loss: 7.2248 - val_accuracy: 0.4711\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8542 - val_loss: 6.7852 - val_accuracy: 0.4178\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8597 - val_loss: 6.0865 - val_accuracy: 0.4511\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8500 - val_loss: 6.8235 - val_accuracy: 0.5133\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8588 - val_loss: 7.7136 - val_accuracy: 0.4378\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8699 - val_loss: 14.2316 - val_accuracy: 0.3978\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8676 - val_loss: 10.1630 - val_accuracy: 0.4133\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.8667 - val_loss: 7.6680 - val_accuracy: 0.4333\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8750 - val_loss: 7.0747 - val_accuracy: 0.4556\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8713 - val_loss: 9.3329 - val_accuracy: 0.4089\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8708 - val_loss: 8.6284 - val_accuracy: 0.4933\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8787 - val_loss: 15.7128 - val_accuracy: 0.3644\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.8769 - val_loss: 12.0868 - val_accuracy: 0.4289\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.8880 - val_loss: 7.7825 - val_accuracy: 0.4533\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.8917 - val_loss: 11.6032 - val_accuracy: 0.4467\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.8838 - val_loss: 10.6290 - val_accuracy: 0.4956\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.8852 - val_loss: 9.9816 - val_accuracy: 0.4756\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.8935 - val_loss: 11.0076 - val_accuracy: 0.4556\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.8810 - val_loss: 11.1830 - val_accuracy: 0.4689\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.8921 - val_loss: 9.4177 - val_accuracy: 0.4467\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.8847 - val_loss: 6.5164 - val_accuracy: 0.4911\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.8968 - val_loss: 8.7754 - val_accuracy: 0.4667\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.8861 - val_loss: 7.3611 - val_accuracy: 0.5644\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.8935 - val_loss: 7.2947 - val_accuracy: 0.4956\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.8907 - val_loss: 9.2379 - val_accuracy: 0.4844\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.8949 - val_loss: 4.7910 - val_accuracy: 0.5578\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2393 - accuracy: 0.9032 - val_loss: 13.0331 - val_accuracy: 0.4422\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9060 - val_loss: 11.3926 - val_accuracy: 0.4689\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.8995 - val_loss: 13.0159 - val_accuracy: 0.4489\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.8903 - val_loss: 9.2087 - val_accuracy: 0.5222\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9032 - val_loss: 13.6609 - val_accuracy: 0.4889\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.8898 - val_loss: 10.8282 - val_accuracy: 0.4533\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9042 - val_loss: 11.5923 - val_accuracy: 0.4622\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9019 - val_loss: 10.0307 - val_accuracy: 0.4844\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9111 - val_loss: 9.3756 - val_accuracy: 0.4444\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9069 - val_loss: 15.3891 - val_accuracy: 0.4467\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9083 - val_loss: 8.1689 - val_accuracy: 0.5467\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9097 - val_loss: 14.4694 - val_accuracy: 0.4733\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9088 - val_loss: 10.0335 - val_accuracy: 0.4600\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9046 - val_loss: 12.1943 - val_accuracy: 0.4556\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_114 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_114 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 25, 25, 10)        1630      \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_115 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 128)               184448    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 187,081\n",
      "Trainable params: 187,025\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1420 - accuracy: 0.4556 - val_loss: 1.0913 - val_accuracy: 0.4422\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9023 - accuracy: 0.5421 - val_loss: 1.0914 - val_accuracy: 0.3200\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8121 - accuracy: 0.6023 - val_loss: 1.0989 - val_accuracy: 0.4911\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7270 - accuracy: 0.6403 - val_loss: 1.3233 - val_accuracy: 0.5711\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6815 - val_loss: 1.9693 - val_accuracy: 0.4844\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7134 - val_loss: 2.3541 - val_accuracy: 0.4444\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7319 - val_loss: 2.0130 - val_accuracy: 0.3511\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7306 - val_loss: 2.0245 - val_accuracy: 0.4644\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7472 - val_loss: 3.8742 - val_accuracy: 0.3867\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7704 - val_loss: 2.7100 - val_accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7898 - val_loss: 3.2269 - val_accuracy: 0.4578\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.7926 - val_loss: 6.5535 - val_accuracy: 0.4222\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.7986 - val_loss: 2.0284 - val_accuracy: 0.4422\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8167 - val_loss: 2.2629 - val_accuracy: 0.4356\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8319 - val_loss: 5.4467 - val_accuracy: 0.3422\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8287 - val_loss: 2.2497 - val_accuracy: 0.4889\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8421 - val_loss: 2.3455 - val_accuracy: 0.5467\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8546 - val_loss: 3.0187 - val_accuracy: 0.4689\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8528 - val_loss: 4.8283 - val_accuracy: 0.4556\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8588 - val_loss: 5.5794 - val_accuracy: 0.4311\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8597 - val_loss: 5.6559 - val_accuracy: 0.4156\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8583 - val_loss: 2.7910 - val_accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8755 - val_loss: 4.5058 - val_accuracy: 0.4467\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.8773 - val_loss: 3.0980 - val_accuracy: 0.4844\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8755 - val_loss: 4.9550 - val_accuracy: 0.4400\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.8866 - val_loss: 5.5860 - val_accuracy: 0.4711\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.8778 - val_loss: 3.5891 - val_accuracy: 0.4489\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8824 - val_loss: 3.3145 - val_accuracy: 0.5067\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2391 - accuracy: 0.8894 - val_loss: 3.8693 - val_accuracy: 0.4533\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.8931 - val_loss: 5.9587 - val_accuracy: 0.4111\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.8986 - val_loss: 4.5749 - val_accuracy: 0.5089\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2359 - accuracy: 0.9032 - val_loss: 3.8421 - val_accuracy: 0.5133\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2082 - accuracy: 0.9065 - val_loss: 3.3949 - val_accuracy: 0.5822\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9111 - val_loss: 3.2112 - val_accuracy: 0.4933\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1944 - accuracy: 0.9083 - val_loss: 3.9171 - val_accuracy: 0.4933\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9056 - val_loss: 3.9935 - val_accuracy: 0.5044\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9134 - val_loss: 4.1515 - val_accuracy: 0.4756\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9056 - val_loss: 2.8545 - val_accuracy: 0.5244\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9264 - val_loss: 3.3493 - val_accuracy: 0.5156\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.9194 - val_loss: 3.4977 - val_accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9255 - val_loss: 3.8779 - val_accuracy: 0.5444\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9282 - val_loss: 3.2016 - val_accuracy: 0.5111\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9250 - val_loss: 4.7399 - val_accuracy: 0.5222\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.9296 - val_loss: 4.4422 - val_accuracy: 0.4844\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9245 - val_loss: 3.5352 - val_accuracy: 0.4956\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9444 - val_loss: 4.4360 - val_accuracy: 0.5089\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9269 - val_loss: 3.6471 - val_accuracy: 0.4467\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9329 - val_loss: 4.2958 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9296 - val_loss: 9.3118 - val_accuracy: 0.4422\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9361 - val_loss: 5.0002 - val_accuracy: 0.5533\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9338 - val_loss: 5.1202 - val_accuracy: 0.5156\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9324 - val_loss: 5.9474 - val_accuracy: 0.5133\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9282 - val_loss: 4.2078 - val_accuracy: 0.4911\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9468 - val_loss: 4.2567 - val_accuracy: 0.5578\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9468 - val_loss: 4.4126 - val_accuracy: 0.5267\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9421 - val_loss: 4.4209 - val_accuracy: 0.5467\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9505 - val_loss: 4.8344 - val_accuracy: 0.5533\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9491 - val_loss: 7.7809 - val_accuracy: 0.5422\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9403 - val_loss: 10.2653 - val_accuracy: 0.4244\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9454 - val_loss: 5.1634 - val_accuracy: 0.5356\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9458 - val_loss: 6.7206 - val_accuracy: 0.5289\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9634 - val_loss: 5.4977 - val_accuracy: 0.5644\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9458 - val_loss: 6.8993 - val_accuracy: 0.4844\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9407 - val_loss: 4.7433 - val_accuracy: 0.5489\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9486 - val_loss: 6.9439 - val_accuracy: 0.5378\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9500 - val_loss: 5.0968 - val_accuracy: 0.4711\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9463 - val_loss: 14.4989 - val_accuracy: 0.3467\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9551 - val_loss: 6.4440 - val_accuracy: 0.5356\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9500 - val_loss: 6.2475 - val_accuracy: 0.5489\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9574 - val_loss: 6.5597 - val_accuracy: 0.4978\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9546 - val_loss: 6.6976 - val_accuracy: 0.5289\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9556 - val_loss: 6.2735 - val_accuracy: 0.5311\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9606 - val_loss: 6.6914 - val_accuracy: 0.5444\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9560 - val_loss: 7.7558 - val_accuracy: 0.5644\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9565 - val_loss: 5.8571 - val_accuracy: 0.5378\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9556 - val_loss: 6.8170 - val_accuracy: 0.5356\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9583 - val_loss: 5.8950 - val_accuracy: 0.5467\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9630 - val_loss: 12.0246 - val_accuracy: 0.3956\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9644 - val_loss: 7.4547 - val_accuracy: 0.5089\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9597 - val_loss: 8.1935 - val_accuracy: 0.4689\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9542 - val_loss: 7.4249 - val_accuracy: 0.5222\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9569 - val_loss: 7.8585 - val_accuracy: 0.4533\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9556 - val_loss: 5.9764 - val_accuracy: 0.5667\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9616 - val_loss: 5.8430 - val_accuracy: 0.5622\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9634 - val_loss: 6.8531 - val_accuracy: 0.5733\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9639 - val_loss: 6.5868 - val_accuracy: 0.5089\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9681 - val_loss: 8.0801 - val_accuracy: 0.4689\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9667 - val_loss: 6.8181 - val_accuracy: 0.5156\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9671 - val_loss: 7.8348 - val_accuracy: 0.4911\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9671 - val_loss: 8.1430 - val_accuracy: 0.5600\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9537 - val_loss: 5.9758 - val_accuracy: 0.5156\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9625 - val_loss: 6.0614 - val_accuracy: 0.6156\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9648 - val_loss: 7.4842 - val_accuracy: 0.5667\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9630 - val_loss: 7.6321 - val_accuracy: 0.4667\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9681 - val_loss: 6.8617 - val_accuracy: 0.5644\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9653 - val_loss: 8.0193 - val_accuracy: 0.5044\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9699 - val_loss: 7.2268 - val_accuracy: 0.6089\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9694 - val_loss: 8.5766 - val_accuracy: 0.4667\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9542 - val_loss: 7.5565 - val_accuracy: 0.5267\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9731 - val_loss: 7.5803 - val_accuracy: 0.5467\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_116 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_116 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 25, 25, 10)        1630      \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_117 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 256)               368896    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 371,913\n",
      "Trainable params: 371,857\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.3557 - accuracy: 0.4343 - val_loss: 1.1028 - val_accuracy: 0.3978\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8860 - accuracy: 0.5639 - val_loss: 1.0717 - val_accuracy: 0.4644\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7722 - accuracy: 0.6403 - val_loss: 1.0413 - val_accuracy: 0.4022\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6912 - val_loss: 1.1233 - val_accuracy: 0.4667\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7481 - val_loss: 1.3863 - val_accuracy: 0.5356\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7616 - val_loss: 1.8648 - val_accuracy: 0.4444\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7884 - val_loss: 1.7814 - val_accuracy: 0.4867\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8106 - val_loss: 3.2998 - val_accuracy: 0.4600\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8366 - val_loss: 3.0177 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8398 - val_loss: 2.1519 - val_accuracy: 0.4844\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8491 - val_loss: 2.1063 - val_accuracy: 0.5044\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8431 - val_loss: 2.6521 - val_accuracy: 0.5133\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8500 - val_loss: 2.9074 - val_accuracy: 0.4511\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8713 - val_loss: 3.0449 - val_accuracy: 0.4400\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8694 - val_loss: 3.5542 - val_accuracy: 0.5089\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2984 - accuracy: 0.8653 - val_loss: 3.2580 - val_accuracy: 0.4156\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2465 - accuracy: 0.9009 - val_loss: 3.3409 - val_accuracy: 0.4578\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.9097 - val_loss: 6.0074 - val_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.8898 - val_loss: 4.0529 - val_accuracy: 0.4222\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.8977 - val_loss: 5.3708 - val_accuracy: 0.4067\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9134 - val_loss: 6.0492 - val_accuracy: 0.4933\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9125 - val_loss: 4.6715 - val_accuracy: 0.4600\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9102 - val_loss: 3.7498 - val_accuracy: 0.4711\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9319 - val_loss: 8.2870 - val_accuracy: 0.4533\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9264 - val_loss: 3.3198 - val_accuracy: 0.5133\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9190 - val_loss: 3.0421 - val_accuracy: 0.5756\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9245 - val_loss: 4.4329 - val_accuracy: 0.4889\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9296 - val_loss: 5.4815 - val_accuracy: 0.4667\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9343 - val_loss: 5.5148 - val_accuracy: 0.4933\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9403 - val_loss: 6.3034 - val_accuracy: 0.4444\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1568 - accuracy: 0.9398 - val_loss: 5.6600 - val_accuracy: 0.4778\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1476 - accuracy: 0.9426 - val_loss: 5.3400 - val_accuracy: 0.4844\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9523 - val_loss: 4.5635 - val_accuracy: 0.5311\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.9468 - val_loss: 5.2824 - val_accuracy: 0.4933\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9468 - val_loss: 6.2333 - val_accuracy: 0.4244\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9519 - val_loss: 7.6427 - val_accuracy: 0.4733\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1041 - accuracy: 0.9569 - val_loss: 5.6367 - val_accuracy: 0.5356\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9639 - val_loss: 11.3453 - val_accuracy: 0.4356\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9569 - val_loss: 4.1831 - val_accuracy: 0.5200\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9505 - val_loss: 7.4956 - val_accuracy: 0.4956\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9625 - val_loss: 6.5234 - val_accuracy: 0.5556\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9639 - val_loss: 5.0748 - val_accuracy: 0.5022\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9546 - val_loss: 6.4095 - val_accuracy: 0.4867\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9579 - val_loss: 7.9858 - val_accuracy: 0.4889\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9574 - val_loss: 6.3696 - val_accuracy: 0.4667\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9690 - val_loss: 11.1703 - val_accuracy: 0.4667\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9634 - val_loss: 8.9862 - val_accuracy: 0.4689\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9667 - val_loss: 6.5253 - val_accuracy: 0.4489\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9708 - val_loss: 11.4293 - val_accuracy: 0.4178\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9736 - val_loss: 9.6674 - val_accuracy: 0.5178\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9639 - val_loss: 6.3517 - val_accuracy: 0.5200\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9745 - val_loss: 6.5577 - val_accuracy: 0.5556\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9648 - val_loss: 6.4901 - val_accuracy: 0.5289\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9662 - val_loss: 5.7904 - val_accuracy: 0.5556\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0901 - accuracy: 0.9657 - val_loss: 6.5089 - val_accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9685 - val_loss: 6.1213 - val_accuracy: 0.5267\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9764 - val_loss: 6.9223 - val_accuracy: 0.4667\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9676 - val_loss: 6.0756 - val_accuracy: 0.5267\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9792 - val_loss: 6.0577 - val_accuracy: 0.5533\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0727 - accuracy: 0.9718 - val_loss: 11.3840 - val_accuracy: 0.4378\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9708 - val_loss: 6.4686 - val_accuracy: 0.5622\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9745 - val_loss: 5.9120 - val_accuracy: 0.5178\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9801 - val_loss: 7.1343 - val_accuracy: 0.5356\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9769 - val_loss: 5.9644 - val_accuracy: 0.5689\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9764 - val_loss: 5.9073 - val_accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9750 - val_loss: 8.2411 - val_accuracy: 0.4978\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9824 - val_loss: 6.7278 - val_accuracy: 0.5733\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9769 - val_loss: 7.6352 - val_accuracy: 0.4844\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9819 - val_loss: 6.6075 - val_accuracy: 0.5822\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9718 - val_loss: 13.6756 - val_accuracy: 0.4889\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9801 - val_loss: 9.3894 - val_accuracy: 0.4156\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9708 - val_loss: 16.2584 - val_accuracy: 0.4356\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9801 - val_loss: 8.6050 - val_accuracy: 0.5111\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 9.5092 - val_accuracy: 0.5111\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 7.8296 - val_accuracy: 0.4844\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 8.9416 - val_accuracy: 0.4644\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9856 - val_loss: 7.2625 - val_accuracy: 0.5400\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9843 - val_loss: 7.6838 - val_accuracy: 0.5267\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9792 - val_loss: 7.5243 - val_accuracy: 0.5556\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9880 - val_loss: 8.1440 - val_accuracy: 0.5556\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9792 - val_loss: 7.5681 - val_accuracy: 0.5422\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9843 - val_loss: 6.4013 - val_accuracy: 0.5533\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 9.2528 - val_accuracy: 0.4822\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9847 - val_loss: 35.3346 - val_accuracy: 0.3333\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9829 - val_loss: 9.1905 - val_accuracy: 0.5400\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9824 - val_loss: 8.7122 - val_accuracy: 0.5089\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 8.7776 - val_accuracy: 0.5200\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9833 - val_loss: 9.6157 - val_accuracy: 0.5178\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 7.3865 - val_accuracy: 0.5689\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 14.0801 - val_accuracy: 0.4422\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 9.6074 - val_accuracy: 0.4378\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9880 - val_loss: 9.1128 - val_accuracy: 0.4600\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9866 - val_loss: 7.9714 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9866 - val_loss: 9.0263 - val_accuracy: 0.5489\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9875 - val_loss: 13.3495 - val_accuracy: 0.4911\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 11.1398 - val_accuracy: 0.4756\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9866 - val_loss: 10.9490 - val_accuracy: 0.4867\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 8.9524 - val_accuracy: 0.5089\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9861 - val_loss: 9.3658 - val_accuracy: 0.4889\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9852 - val_loss: 9.8376 - val_accuracy: 0.4978\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_118 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_118 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 25, 25, 12)        1956      \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_119 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32)                55328     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 58,007\n",
      "Trainable params: 57,947\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1669 - accuracy: 0.3597 - val_loss: 1.0990 - val_accuracy: 0.3244\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0676 - accuracy: 0.3810 - val_loss: 1.0998 - val_accuracy: 0.3044\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0497 - accuracy: 0.3981 - val_loss: 1.0900 - val_accuracy: 0.4044\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0247 - accuracy: 0.4051 - val_loss: 1.3000 - val_accuracy: 0.3533\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0213 - accuracy: 0.4204 - val_loss: 1.1287 - val_accuracy: 0.4267\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0027 - accuracy: 0.4250 - val_loss: 1.0835 - val_accuracy: 0.3733\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9946 - accuracy: 0.4333 - val_loss: 1.0276 - val_accuracy: 0.4978\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9639 - accuracy: 0.4593 - val_loss: 1.7452 - val_accuracy: 0.3822\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9441 - accuracy: 0.4616 - val_loss: 1.0713 - val_accuracy: 0.4489\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9218 - accuracy: 0.4778 - val_loss: 1.2514 - val_accuracy: 0.3911\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9300 - accuracy: 0.4782 - val_loss: 1.0024 - val_accuracy: 0.3956\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9264 - accuracy: 0.4741 - val_loss: 1.7392 - val_accuracy: 0.4022\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9091 - accuracy: 0.4847 - val_loss: 0.9973 - val_accuracy: 0.4644\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9095 - accuracy: 0.4852 - val_loss: 3.2953 - val_accuracy: 0.3156\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8973 - accuracy: 0.5042 - val_loss: 1.2514 - val_accuracy: 0.4778\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8807 - accuracy: 0.5037 - val_loss: 1.2961 - val_accuracy: 0.4333\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8786 - accuracy: 0.5208 - val_loss: 1.5846 - val_accuracy: 0.4156\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8449 - accuracy: 0.5398 - val_loss: 1.3997 - val_accuracy: 0.4489\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.5333 - val_loss: 3.0975 - val_accuracy: 0.3822\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8358 - accuracy: 0.5491 - val_loss: 1.3189 - val_accuracy: 0.4244\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8425 - accuracy: 0.5366 - val_loss: 1.4894 - val_accuracy: 0.4133\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8288 - accuracy: 0.5505 - val_loss: 1.7598 - val_accuracy: 0.4067\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8104 - accuracy: 0.5537 - val_loss: 1.1778 - val_accuracy: 0.4800\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.5995 - val_loss: 3.9410 - val_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7847 - accuracy: 0.5866 - val_loss: 2.1506 - val_accuracy: 0.4244\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7705 - accuracy: 0.5782 - val_loss: 1.7577 - val_accuracy: 0.4733\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.5949 - val_loss: 2.8522 - val_accuracy: 0.4200\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.5940 - val_loss: 1.8268 - val_accuracy: 0.4044\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.5995 - val_loss: 3.1558 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.6162 - val_loss: 2.1245 - val_accuracy: 0.4311\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.5921 - val_loss: 3.3857 - val_accuracy: 0.3711\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.6139 - val_loss: 1.8412 - val_accuracy: 0.4356\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7475 - accuracy: 0.6019 - val_loss: 2.5058 - val_accuracy: 0.4489\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.6130 - val_loss: 1.7642 - val_accuracy: 0.4244\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.6153 - val_loss: 2.1991 - val_accuracy: 0.4356\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.6060 - val_loss: 4.0095 - val_accuracy: 0.4200\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.6111 - val_loss: 1.5973 - val_accuracy: 0.4933\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.6301 - val_loss: 3.1860 - val_accuracy: 0.4133\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.6301 - val_loss: 1.6666 - val_accuracy: 0.4778\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.6343 - val_loss: 1.8726 - val_accuracy: 0.4467\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.6329 - val_loss: 4.8532 - val_accuracy: 0.3956\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.6588 - val_loss: 3.1401 - val_accuracy: 0.4178\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.6523 - val_loss: 4.5137 - val_accuracy: 0.4133\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6481 - val_loss: 1.4758 - val_accuracy: 0.5778\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6574 - val_loss: 1.9193 - val_accuracy: 0.4533\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.6468 - val_loss: 3.6366 - val_accuracy: 0.3800\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6926 - val_loss: 3.2803 - val_accuracy: 0.4467\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6602 - val_loss: 1.2169 - val_accuracy: 0.5444\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6713 - val_loss: 1.9055 - val_accuracy: 0.5156\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6560 - val_loss: 1.8583 - val_accuracy: 0.5089\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6657 - val_loss: 3.6789 - val_accuracy: 0.4356\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6579 - val_loss: 2.7362 - val_accuracy: 0.5156\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6648 - val_loss: 2.4597 - val_accuracy: 0.4933\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.6755 - val_loss: 1.7739 - val_accuracy: 0.5400\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6671 - val_loss: 2.5784 - val_accuracy: 0.5444\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.6847 - val_loss: 3.5830 - val_accuracy: 0.4422\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6815 - val_loss: 4.0577 - val_accuracy: 0.4356\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6847 - val_loss: 15.6700 - val_accuracy: 0.3422\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6764 - val_loss: 2.8648 - val_accuracy: 0.5178\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6829 - val_loss: 3.8778 - val_accuracy: 0.4244\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7032 - val_loss: 4.3844 - val_accuracy: 0.4867\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.6977 - val_loss: 5.7320 - val_accuracy: 0.3978\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.6870 - val_loss: 3.4007 - val_accuracy: 0.4778\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.6870 - val_loss: 4.3932 - val_accuracy: 0.4911\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6894 - val_loss: 1.8883 - val_accuracy: 0.4711\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6861 - val_loss: 4.2802 - val_accuracy: 0.4111\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.6986 - val_loss: 3.7962 - val_accuracy: 0.4800\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7194 - val_loss: 3.0299 - val_accuracy: 0.5089\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7222 - val_loss: 6.0399 - val_accuracy: 0.4467\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.6931 - val_loss: 4.7262 - val_accuracy: 0.4822\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7329 - val_loss: 5.0998 - val_accuracy: 0.4756\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7361 - val_loss: 5.1836 - val_accuracy: 0.4400\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7019 - val_loss: 4.1315 - val_accuracy: 0.5156\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7296 - val_loss: 4.0489 - val_accuracy: 0.4889\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7250 - val_loss: 4.7233 - val_accuracy: 0.4511\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7204 - val_loss: 2.0601 - val_accuracy: 0.5667\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7241 - val_loss: 2.8172 - val_accuracy: 0.4978\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7324 - val_loss: 3.8514 - val_accuracy: 0.4978\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7449 - val_loss: 6.5064 - val_accuracy: 0.4756\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7296 - val_loss: 3.5707 - val_accuracy: 0.4533\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7245 - val_loss: 6.0200 - val_accuracy: 0.4311\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7245 - val_loss: 7.4277 - val_accuracy: 0.3467\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7440 - val_loss: 4.6850 - val_accuracy: 0.4156\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7486 - val_loss: 5.0530 - val_accuracy: 0.4667\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7491 - val_loss: 4.4855 - val_accuracy: 0.5067\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7375 - val_loss: 4.4748 - val_accuracy: 0.4511\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7546 - val_loss: 5.3861 - val_accuracy: 0.4400\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7444 - val_loss: 5.8552 - val_accuracy: 0.4511\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7634 - val_loss: 7.2072 - val_accuracy: 0.4356\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7523 - val_loss: 4.1759 - val_accuracy: 0.5156\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7569 - val_loss: 4.9179 - val_accuracy: 0.4467\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7458 - val_loss: 6.1744 - val_accuracy: 0.3956\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7708 - val_loss: 5.0857 - val_accuracy: 0.4911\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7565 - val_loss: 7.4588 - val_accuracy: 0.3978\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7718 - val_loss: 2.3378 - val_accuracy: 0.5356\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7755 - val_loss: 5.0224 - val_accuracy: 0.4822\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7727 - val_loss: 5.6755 - val_accuracy: 0.4378\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7667 - val_loss: 4.7877 - val_accuracy: 0.4178\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7745 - val_loss: 11.5919 - val_accuracy: 0.3867\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7759 - val_loss: 3.9677 - val_accuracy: 0.5511\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_120 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_120 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 25, 25, 12)        1956      \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_121 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 113,431\n",
      "Trainable params: 113,371\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1741 - accuracy: 0.3699 - val_loss: 1.0987 - val_accuracy: 0.4022\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0382 - accuracy: 0.4102 - val_loss: 1.1047 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9951 - accuracy: 0.4181 - val_loss: 1.0964 - val_accuracy: 0.4733\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9507 - accuracy: 0.4778 - val_loss: 1.0651 - val_accuracy: 0.4489\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8904 - accuracy: 0.5051 - val_loss: 1.1341 - val_accuracy: 0.4333\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8443 - accuracy: 0.5352 - val_loss: 1.2456 - val_accuracy: 0.3267\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8315 - accuracy: 0.5468 - val_loss: 0.9495 - val_accuracy: 0.5867\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8048 - accuracy: 0.5569 - val_loss: 1.3276 - val_accuracy: 0.4289\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7806 - accuracy: 0.5630 - val_loss: 1.1344 - val_accuracy: 0.4800\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7679 - accuracy: 0.5653 - val_loss: 1.0352 - val_accuracy: 0.5911\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7585 - accuracy: 0.5806 - val_loss: 1.8885 - val_accuracy: 0.3889\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.5884 - val_loss: 1.2614 - val_accuracy: 0.5089\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.5722 - val_loss: 1.0155 - val_accuracy: 0.5667\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7167 - accuracy: 0.5907 - val_loss: 1.1616 - val_accuracy: 0.4667\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.5926 - val_loss: 2.0890 - val_accuracy: 0.4267\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.6116 - val_loss: 1.0174 - val_accuracy: 0.5911\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6097 - val_loss: 1.2176 - val_accuracy: 0.5156\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6255 - val_loss: 1.1325 - val_accuracy: 0.5422\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6097 - val_loss: 1.6940 - val_accuracy: 0.4578\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.5903 - val_loss: 1.3157 - val_accuracy: 0.5178\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6167 - val_loss: 1.1530 - val_accuracy: 0.6089\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6301 - val_loss: 2.1081 - val_accuracy: 0.4489\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6134 - val_loss: 1.2736 - val_accuracy: 0.5089\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6264 - val_loss: 1.3522 - val_accuracy: 0.5422\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6394 - val_loss: 1.3939 - val_accuracy: 0.5422\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6329 - val_loss: 1.5990 - val_accuracy: 0.5422\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6588 - val_loss: 2.9639 - val_accuracy: 0.4422\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.6579 - val_loss: 2.2100 - val_accuracy: 0.4511\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.6648 - val_loss: 1.8608 - val_accuracy: 0.4378\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6745 - val_loss: 2.3750 - val_accuracy: 0.4822\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6741 - val_loss: 1.6216 - val_accuracy: 0.5244\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.6759 - val_loss: 2.0751 - val_accuracy: 0.4822\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.6681 - val_loss: 2.2230 - val_accuracy: 0.4689\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.6931 - val_loss: 2.5912 - val_accuracy: 0.4622\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6685 - val_loss: 3.2174 - val_accuracy: 0.4400\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7005 - val_loss: 2.4595 - val_accuracy: 0.4511\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.6944 - val_loss: 2.4459 - val_accuracy: 0.4733\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7046 - val_loss: 2.2748 - val_accuracy: 0.5933\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7005 - val_loss: 2.8906 - val_accuracy: 0.5022\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7130 - val_loss: 4.4301 - val_accuracy: 0.4289\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7148 - val_loss: 3.5463 - val_accuracy: 0.4911\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7231 - val_loss: 2.4206 - val_accuracy: 0.5889\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7417 - val_loss: 2.5633 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7315 - val_loss: 2.8011 - val_accuracy: 0.4422\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7250 - val_loss: 3.7820 - val_accuracy: 0.4867\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7361 - val_loss: 3.3119 - val_accuracy: 0.5133\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7481 - val_loss: 3.3827 - val_accuracy: 0.4644\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7468 - val_loss: 3.4452 - val_accuracy: 0.4756\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7495 - val_loss: 2.7152 - val_accuracy: 0.5600\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7407 - val_loss: 2.9050 - val_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7509 - val_loss: 2.8189 - val_accuracy: 0.4933\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7333 - val_loss: 2.3327 - val_accuracy: 0.5778\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7551 - val_loss: 4.5808 - val_accuracy: 0.4800\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7301 - val_loss: 4.8317 - val_accuracy: 0.4578\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7509 - val_loss: 2.7366 - val_accuracy: 0.4756\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7463 - val_loss: 3.5150 - val_accuracy: 0.5533\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7551 - val_loss: 2.8433 - val_accuracy: 0.5311\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7542 - val_loss: 4.4416 - val_accuracy: 0.5156\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7634 - val_loss: 4.1793 - val_accuracy: 0.4489\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7556 - val_loss: 2.8539 - val_accuracy: 0.6111\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7801 - val_loss: 3.5189 - val_accuracy: 0.6400\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7722 - val_loss: 3.7769 - val_accuracy: 0.4800\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7755 - val_loss: 3.9158 - val_accuracy: 0.4533\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.7833 - val_loss: 3.5776 - val_accuracy: 0.5578\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7958 - val_loss: 3.1356 - val_accuracy: 0.5222\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.7926 - val_loss: 2.9523 - val_accuracy: 0.5533\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7806 - val_loss: 3.0719 - val_accuracy: 0.5600\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.7926 - val_loss: 3.6728 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8065 - val_loss: 3.7523 - val_accuracy: 0.6244\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8028 - val_loss: 3.7653 - val_accuracy: 0.5044\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8056 - val_loss: 3.2608 - val_accuracy: 0.6111\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8079 - val_loss: 3.4658 - val_accuracy: 0.5800\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8167 - val_loss: 3.8895 - val_accuracy: 0.5933\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8204 - val_loss: 3.6435 - val_accuracy: 0.5267\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8088 - val_loss: 3.5922 - val_accuracy: 0.5756\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8236 - val_loss: 3.6327 - val_accuracy: 0.5378\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8255 - val_loss: 4.7005 - val_accuracy: 0.5133\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8250 - val_loss: 3.7120 - val_accuracy: 0.5489\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8185 - val_loss: 3.7855 - val_accuracy: 0.5444\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8231 - val_loss: 4.5572 - val_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8273 - val_loss: 4.5712 - val_accuracy: 0.5200\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8259 - val_loss: 4.9168 - val_accuracy: 0.5244\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8245 - val_loss: 4.8964 - val_accuracy: 0.5844\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8356 - val_loss: 5.9732 - val_accuracy: 0.5022\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8250 - val_loss: 5.0890 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8463 - val_loss: 6.5619 - val_accuracy: 0.5022\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8185 - val_loss: 4.0639 - val_accuracy: 0.4844\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8338 - val_loss: 4.3025 - val_accuracy: 0.5178\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8421 - val_loss: 6.3844 - val_accuracy: 0.5444\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8352 - val_loss: 4.9048 - val_accuracy: 0.4689\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8347 - val_loss: 5.3986 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8338 - val_loss: 5.8310 - val_accuracy: 0.4556\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8556 - val_loss: 5.2246 - val_accuracy: 0.4911\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8486 - val_loss: 6.0801 - val_accuracy: 0.4778\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8296 - val_loss: 5.3656 - val_accuracy: 0.5400\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8481 - val_loss: 4.5468 - val_accuracy: 0.5222\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8551 - val_loss: 4.7740 - val_accuracy: 0.5711\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8657 - val_loss: 5.9077 - val_accuracy: 0.5444\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8551 - val_loss: 4.2551 - val_accuracy: 0.5156\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8454 - val_loss: 4.4092 - val_accuracy: 0.5311\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_122 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_122 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 25, 25, 12)        1956      \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_123 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 224,279\n",
      "Trainable params: 224,219\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2808 - accuracy: 0.4106 - val_loss: 1.0994 - val_accuracy: 0.3533\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9602 - accuracy: 0.4921 - val_loss: 1.1590 - val_accuracy: 0.3400\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8829 - accuracy: 0.5481 - val_loss: 1.2743 - val_accuracy: 0.3356\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8286 - accuracy: 0.5690 - val_loss: 1.3522 - val_accuracy: 0.3978\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7824 - accuracy: 0.6074 - val_loss: 1.8756 - val_accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.6222 - val_loss: 1.1873 - val_accuracy: 0.4556\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7105 - accuracy: 0.6315 - val_loss: 1.2777 - val_accuracy: 0.4089\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6662 - val_loss: 1.2227 - val_accuracy: 0.5267\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6977 - val_loss: 1.6294 - val_accuracy: 0.5356\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.6995 - val_loss: 1.3227 - val_accuracy: 0.5978\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7069 - val_loss: 2.6509 - val_accuracy: 0.4289\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7370 - val_loss: 1.8358 - val_accuracy: 0.4044\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7241 - val_loss: 2.2315 - val_accuracy: 0.4333\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7292 - val_loss: 1.8015 - val_accuracy: 0.4600\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7588 - val_loss: 1.4642 - val_accuracy: 0.4333\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7639 - val_loss: 1.8458 - val_accuracy: 0.5822\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7880 - val_loss: 1.9055 - val_accuracy: 0.4956\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7949 - val_loss: 1.8667 - val_accuracy: 0.5289\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8051 - val_loss: 2.1480 - val_accuracy: 0.5244\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8088 - val_loss: 3.3291 - val_accuracy: 0.3933\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8019 - val_loss: 2.1778 - val_accuracy: 0.5600\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8199 - val_loss: 2.0511 - val_accuracy: 0.5689\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8343 - val_loss: 2.4784 - val_accuracy: 0.4444\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8273 - val_loss: 2.1819 - val_accuracy: 0.5444\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8440 - val_loss: 2.9323 - val_accuracy: 0.4422\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8370 - val_loss: 3.3845 - val_accuracy: 0.4356\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8449 - val_loss: 2.9098 - val_accuracy: 0.4733\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8644 - val_loss: 5.2934 - val_accuracy: 0.3889\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.8537 - val_loss: 4.0342 - val_accuracy: 0.4600\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8569 - val_loss: 2.8238 - val_accuracy: 0.5133\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.8639 - val_loss: 3.3009 - val_accuracy: 0.4156\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8681 - val_loss: 4.0888 - val_accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2839 - accuracy: 0.8745 - val_loss: 4.7403 - val_accuracy: 0.4578\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.8741 - val_loss: 3.8617 - val_accuracy: 0.5400\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2372 - accuracy: 0.8856 - val_loss: 4.1267 - val_accuracy: 0.4667\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.8810 - val_loss: 3.4013 - val_accuracy: 0.4644\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8787 - val_loss: 3.2073 - val_accuracy: 0.5622\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.8935 - val_loss: 4.7822 - val_accuracy: 0.4178\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.8958 - val_loss: 7.0105 - val_accuracy: 0.4156\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.8861 - val_loss: 3.2063 - val_accuracy: 0.4867\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2235 - accuracy: 0.8949 - val_loss: 6.2233 - val_accuracy: 0.4689\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9042 - val_loss: 5.5476 - val_accuracy: 0.4422\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9005 - val_loss: 3.3045 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9102 - val_loss: 4.8121 - val_accuracy: 0.3978\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.8958 - val_loss: 5.7945 - val_accuracy: 0.5533\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9139 - val_loss: 6.3976 - val_accuracy: 0.3933\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9056 - val_loss: 6.0522 - val_accuracy: 0.5044\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9065 - val_loss: 5.4246 - val_accuracy: 0.4489\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9185 - val_loss: 7.7608 - val_accuracy: 0.4489\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9000 - val_loss: 6.5435 - val_accuracy: 0.4111\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9130 - val_loss: 6.3031 - val_accuracy: 0.4711\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9227 - val_loss: 6.0679 - val_accuracy: 0.3933\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9218 - val_loss: 4.7329 - val_accuracy: 0.5067\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9292 - val_loss: 6.3518 - val_accuracy: 0.4156\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9204 - val_loss: 5.6189 - val_accuracy: 0.5067\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9176 - val_loss: 6.8532 - val_accuracy: 0.4889\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1779 - accuracy: 0.9167 - val_loss: 5.6805 - val_accuracy: 0.4467\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9231 - val_loss: 5.5943 - val_accuracy: 0.4622\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9264 - val_loss: 4.8344 - val_accuracy: 0.5489\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9255 - val_loss: 11.9004 - val_accuracy: 0.4022\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9366 - val_loss: 6.7542 - val_accuracy: 0.4267\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9148 - val_loss: 4.5688 - val_accuracy: 0.5156\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9185 - val_loss: 3.9599 - val_accuracy: 0.5778\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1546 - accuracy: 0.9352 - val_loss: 10.4818 - val_accuracy: 0.4133\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9222 - val_loss: 5.2021 - val_accuracy: 0.4978\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9421 - val_loss: 6.8184 - val_accuracy: 0.4756\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9384 - val_loss: 8.8049 - val_accuracy: 0.4311\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9338 - val_loss: 7.5757 - val_accuracy: 0.4933\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1645 - accuracy: 0.9394 - val_loss: 4.2301 - val_accuracy: 0.4778\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9449 - val_loss: 8.8082 - val_accuracy: 0.4067\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9435 - val_loss: 6.7882 - val_accuracy: 0.4933\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1171 - accuracy: 0.9477 - val_loss: 7.4987 - val_accuracy: 0.4289\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9477 - val_loss: 6.8026 - val_accuracy: 0.4733\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9403 - val_loss: 8.4924 - val_accuracy: 0.3778\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9463 - val_loss: 5.5209 - val_accuracy: 0.4689\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9389 - val_loss: 5.2140 - val_accuracy: 0.4756\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9463 - val_loss: 7.6845 - val_accuracy: 0.4178\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9463 - val_loss: 5.8212 - val_accuracy: 0.4533\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9477 - val_loss: 5.5356 - val_accuracy: 0.4733\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9514 - val_loss: 5.6220 - val_accuracy: 0.5622\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9477 - val_loss: 27.1762 - val_accuracy: 0.3378\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9426 - val_loss: 5.0715 - val_accuracy: 0.5089\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9370 - val_loss: 4.6303 - val_accuracy: 0.5467\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9398 - val_loss: 4.4823 - val_accuracy: 0.5844\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1128 - accuracy: 0.9481 - val_loss: 4.6138 - val_accuracy: 0.5489\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9583 - val_loss: 6.4887 - val_accuracy: 0.5022\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9509 - val_loss: 7.0170 - val_accuracy: 0.4156\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9583 - val_loss: 6.5751 - val_accuracy: 0.4844\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9546 - val_loss: 6.8140 - val_accuracy: 0.5644\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9565 - val_loss: 10.2672 - val_accuracy: 0.4800\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9625 - val_loss: 7.8717 - val_accuracy: 0.5200\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9606 - val_loss: 7.3004 - val_accuracy: 0.5400\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9491 - val_loss: 7.0079 - val_accuracy: 0.5044\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9569 - val_loss: 8.3275 - val_accuracy: 0.4756\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9560 - val_loss: 7.4143 - val_accuracy: 0.4867\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9546 - val_loss: 10.2306 - val_accuracy: 0.4378\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9588 - val_loss: 8.5650 - val_accuracy: 0.4600\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9574 - val_loss: 8.0801 - val_accuracy: 0.5644\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9611 - val_loss: 7.1089 - val_accuracy: 0.5267\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9583 - val_loss: 9.9175 - val_accuracy: 0.4778\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_124 (Conv2D)          (None, 54, 54, 18)        504       \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 54, 54, 18)        72        \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 54, 54, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_124 (MaxPoolin (None, 27, 27, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 25, 25, 12)        1956      \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_125 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 256)               442624    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 445,975\n",
      "Trainable params: 445,915\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2482 - accuracy: 0.4690 - val_loss: 1.1244 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8362 - accuracy: 0.5861 - val_loss: 1.0529 - val_accuracy: 0.4400\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.6523 - val_loss: 1.0663 - val_accuracy: 0.4200\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6991 - val_loss: 1.1600 - val_accuracy: 0.5089\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5877 - accuracy: 0.7370 - val_loss: 1.2572 - val_accuracy: 0.6311\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7741 - val_loss: 1.6630 - val_accuracy: 0.5022\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7972 - val_loss: 3.3586 - val_accuracy: 0.3511\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8051 - val_loss: 2.2376 - val_accuracy: 0.4467\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8009 - val_loss: 1.5810 - val_accuracy: 0.4867\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8384 - val_loss: 2.0382 - val_accuracy: 0.4244\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8616 - val_loss: 2.4547 - val_accuracy: 0.4800\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8574 - val_loss: 1.8273 - val_accuracy: 0.5356\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8634 - val_loss: 1.8312 - val_accuracy: 0.4156\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.8602 - val_loss: 5.2677 - val_accuracy: 0.4200\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8731 - val_loss: 2.2722 - val_accuracy: 0.5622\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.8843 - val_loss: 4.3327 - val_accuracy: 0.4044\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2568 - accuracy: 0.8903 - val_loss: 4.0632 - val_accuracy: 0.5378\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2400 - accuracy: 0.9046 - val_loss: 4.9835 - val_accuracy: 0.4467\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9130 - val_loss: 3.2553 - val_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2049 - accuracy: 0.9097 - val_loss: 3.0843 - val_accuracy: 0.4867\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9176 - val_loss: 4.2746 - val_accuracy: 0.4178\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9227 - val_loss: 2.6636 - val_accuracy: 0.6000\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9259 - val_loss: 3.1733 - val_accuracy: 0.5356\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9306 - val_loss: 2.7236 - val_accuracy: 0.5600\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9296 - val_loss: 3.7412 - val_accuracy: 0.6089\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9361 - val_loss: 2.6279 - val_accuracy: 0.5400\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9352 - val_loss: 4.9397 - val_accuracy: 0.4756\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1409 - accuracy: 0.9384 - val_loss: 3.9772 - val_accuracy: 0.5022\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9407 - val_loss: 4.4357 - val_accuracy: 0.5533\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9398 - val_loss: 5.7211 - val_accuracy: 0.5133\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9426 - val_loss: 4.6526 - val_accuracy: 0.5533\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9426 - val_loss: 7.1727 - val_accuracy: 0.4667\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9366 - val_loss: 5.1723 - val_accuracy: 0.4667\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9546 - val_loss: 3.8476 - val_accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9472 - val_loss: 4.4775 - val_accuracy: 0.5533\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9579 - val_loss: 4.3920 - val_accuracy: 0.5844\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9556 - val_loss: 6.3265 - val_accuracy: 0.5022\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9477 - val_loss: 3.8713 - val_accuracy: 0.4711\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9630 - val_loss: 4.1210 - val_accuracy: 0.5533\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9546 - val_loss: 7.0786 - val_accuracy: 0.4733\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9523 - val_loss: 4.0438 - val_accuracy: 0.5578\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9657 - val_loss: 7.3148 - val_accuracy: 0.4911\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9579 - val_loss: 4.7924 - val_accuracy: 0.5467\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9606 - val_loss: 6.0133 - val_accuracy: 0.5578\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9713 - val_loss: 3.7753 - val_accuracy: 0.5867\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9560 - val_loss: 9.0164 - val_accuracy: 0.4600\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9606 - val_loss: 3.7818 - val_accuracy: 0.5756\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9704 - val_loss: 9.5934 - val_accuracy: 0.5089\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9681 - val_loss: 5.7666 - val_accuracy: 0.5244\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9671 - val_loss: 4.6470 - val_accuracy: 0.5644\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9699 - val_loss: 5.7833 - val_accuracy: 0.5111\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9736 - val_loss: 6.7855 - val_accuracy: 0.4800\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9727 - val_loss: 7.6873 - val_accuracy: 0.4311\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9787 - val_loss: 6.7962 - val_accuracy: 0.5289\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9662 - val_loss: 8.8831 - val_accuracy: 0.4689\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9708 - val_loss: 5.4863 - val_accuracy: 0.5156\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9681 - val_loss: 6.7195 - val_accuracy: 0.4756\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9745 - val_loss: 10.6711 - val_accuracy: 0.4422\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9750 - val_loss: 7.1228 - val_accuracy: 0.5400\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9755 - val_loss: 6.5494 - val_accuracy: 0.5422\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9713 - val_loss: 11.0946 - val_accuracy: 0.4133\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9736 - val_loss: 7.8652 - val_accuracy: 0.4933\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9685 - val_loss: 5.8429 - val_accuracy: 0.5111\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9787 - val_loss: 5.2826 - val_accuracy: 0.5444\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9745 - val_loss: 8.9124 - val_accuracy: 0.4400\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9764 - val_loss: 6.0419 - val_accuracy: 0.6111\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9778 - val_loss: 7.6904 - val_accuracy: 0.4822\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9792 - val_loss: 4.9199 - val_accuracy: 0.6044\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9810 - val_loss: 6.6213 - val_accuracy: 0.5356\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9759 - val_loss: 6.3132 - val_accuracy: 0.5222\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9773 - val_loss: 7.4894 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 9.0300 - val_accuracy: 0.4489\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9796 - val_loss: 10.0436 - val_accuracy: 0.4533\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9778 - val_loss: 7.5335 - val_accuracy: 0.5089\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9806 - val_loss: 8.1266 - val_accuracy: 0.4533\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9708 - val_loss: 10.0718 - val_accuracy: 0.4356\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9782 - val_loss: 7.4274 - val_accuracy: 0.5044\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9750 - val_loss: 4.7961 - val_accuracy: 0.6089\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9727 - val_loss: 6.4756 - val_accuracy: 0.5400\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9801 - val_loss: 5.1339 - val_accuracy: 0.5978\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9856 - val_loss: 6.9711 - val_accuracy: 0.5133\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9847 - val_loss: 7.2267 - val_accuracy: 0.5178\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9843 - val_loss: 7.0707 - val_accuracy: 0.5600\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9856 - val_loss: 9.8321 - val_accuracy: 0.4733\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9769 - val_loss: 5.7541 - val_accuracy: 0.6333\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9843 - val_loss: 27.4573 - val_accuracy: 0.3489\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9824 - val_loss: 6.7308 - val_accuracy: 0.6067\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9843 - val_loss: 10.4039 - val_accuracy: 0.4956\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9819 - val_loss: 10.9230 - val_accuracy: 0.4422\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 7.1550 - val_accuracy: 0.5289\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9769 - val_loss: 6.1512 - val_accuracy: 0.5667\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9898 - val_loss: 6.8525 - val_accuracy: 0.5800\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9866 - val_loss: 22.8001 - val_accuracy: 0.3467\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9824 - val_loss: 5.6174 - val_accuracy: 0.5578\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9847 - val_loss: 8.3397 - val_accuracy: 0.5556\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9838 - val_loss: 7.9109 - val_accuracy: 0.4844\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9875 - val_loss: 9.0599 - val_accuracy: 0.4511\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9833 - val_loss: 13.4749 - val_accuracy: 0.4000\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9824 - val_loss: 6.2553 - val_accuracy: 0.5044\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 8.9787 - val_accuracy: 0.4822\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_126 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_126 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 25, 25, 8)         1520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_127 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 39,219\n",
      "Trainable params: 39,161\n",
      "Non-trainable params: 58\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1595 - accuracy: 0.3310 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0695 - accuracy: 0.3458 - val_loss: 1.1029 - val_accuracy: 0.2889\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0652 - accuracy: 0.3542 - val_loss: 1.0839 - val_accuracy: 0.3800\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0534 - accuracy: 0.3782 - val_loss: 1.0869 - val_accuracy: 0.3733\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0487 - accuracy: 0.3616 - val_loss: 1.0936 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0449 - accuracy: 0.3690 - val_loss: 1.2860 - val_accuracy: 0.3067\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0385 - accuracy: 0.3699 - val_loss: 1.2224 - val_accuracy: 0.3156\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0471 - accuracy: 0.3722 - val_loss: 2.0765 - val_accuracy: 0.4400\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.3796 - val_loss: 1.1051 - val_accuracy: 0.3600\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0274 - accuracy: 0.3926 - val_loss: 1.0996 - val_accuracy: 0.3000\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0402 - accuracy: 0.3861 - val_loss: 1.3009 - val_accuracy: 0.4689\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0071 - accuracy: 0.4046 - val_loss: 1.6878 - val_accuracy: 0.3556\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.4042 - val_loss: 1.7799 - val_accuracy: 0.3533\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0215 - accuracy: 0.3949 - val_loss: 1.0526 - val_accuracy: 0.3622\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0029 - accuracy: 0.3958 - val_loss: 1.6054 - val_accuracy: 0.3422\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9757 - accuracy: 0.4125 - val_loss: 1.1606 - val_accuracy: 0.4422\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9747 - accuracy: 0.4019 - val_loss: 1.2615 - val_accuracy: 0.3378\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9676 - accuracy: 0.4236 - val_loss: 1.4890 - val_accuracy: 0.4044\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9581 - accuracy: 0.4213 - val_loss: 1.3725 - val_accuracy: 0.4622\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9543 - accuracy: 0.4269 - val_loss: 1.3233 - val_accuracy: 0.4800\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9333 - accuracy: 0.4495 - val_loss: 1.1045 - val_accuracy: 0.4178\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9439 - accuracy: 0.4458 - val_loss: 1.2018 - val_accuracy: 0.4933\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9243 - accuracy: 0.4519 - val_loss: 1.8948 - val_accuracy: 0.3622\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9142 - accuracy: 0.4556 - val_loss: 1.4762 - val_accuracy: 0.5044\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9201 - accuracy: 0.4542 - val_loss: 1.8110 - val_accuracy: 0.4044\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9132 - accuracy: 0.4778 - val_loss: 2.0062 - val_accuracy: 0.4422\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.4824 - val_loss: 1.7768 - val_accuracy: 0.4800\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8739 - accuracy: 0.4806 - val_loss: 1.2127 - val_accuracy: 0.4378\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8808 - accuracy: 0.4921 - val_loss: 1.9069 - val_accuracy: 0.3667\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8790 - accuracy: 0.4824 - val_loss: 1.8101 - val_accuracy: 0.3778\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8937 - accuracy: 0.4884 - val_loss: 1.4740 - val_accuracy: 0.3622\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.4968 - val_loss: 1.8490 - val_accuracy: 0.4911\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8641 - accuracy: 0.5000 - val_loss: 1.6144 - val_accuracy: 0.3667\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8579 - accuracy: 0.5046 - val_loss: 1.2909 - val_accuracy: 0.4978\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8602 - accuracy: 0.5005 - val_loss: 1.7991 - val_accuracy: 0.3444\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8173 - accuracy: 0.5208 - val_loss: 2.3271 - val_accuracy: 0.4400\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8056 - accuracy: 0.5287 - val_loss: 1.7808 - val_accuracy: 0.3778\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8012 - accuracy: 0.5310 - val_loss: 3.9535 - val_accuracy: 0.3911\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8146 - accuracy: 0.5361 - val_loss: 1.6707 - val_accuracy: 0.4911\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7790 - accuracy: 0.5440 - val_loss: 1.7084 - val_accuracy: 0.4200\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7878 - accuracy: 0.5468 - val_loss: 1.7839 - val_accuracy: 0.3800\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7676 - accuracy: 0.5694 - val_loss: 1.6553 - val_accuracy: 0.4911\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7794 - accuracy: 0.5481 - val_loss: 1.9114 - val_accuracy: 0.3844\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7742 - accuracy: 0.5537 - val_loss: 2.0430 - val_accuracy: 0.4689\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.5616 - val_loss: 1.8340 - val_accuracy: 0.3956\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.5657 - val_loss: 1.5639 - val_accuracy: 0.4933\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.5745 - val_loss: 1.8880 - val_accuracy: 0.4133\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7652 - accuracy: 0.5690 - val_loss: 1.7109 - val_accuracy: 0.4222\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.5736 - val_loss: 1.9785 - val_accuracy: 0.4800\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7593 - accuracy: 0.5616 - val_loss: 2.4321 - val_accuracy: 0.3689\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.5801 - val_loss: 2.2653 - val_accuracy: 0.4644\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.5750 - val_loss: 2.0286 - val_accuracy: 0.3911\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.5870 - val_loss: 3.9492 - val_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7333 - accuracy: 0.5870 - val_loss: 2.9759 - val_accuracy: 0.4489\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.6065 - val_loss: 2.2699 - val_accuracy: 0.4133\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.5833 - val_loss: 2.1471 - val_accuracy: 0.4667\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.6079 - val_loss: 2.1423 - val_accuracy: 0.4800\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.6120 - val_loss: 1.9495 - val_accuracy: 0.5067\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.6148 - val_loss: 2.4305 - val_accuracy: 0.4489\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6148 - val_loss: 3.7257 - val_accuracy: 0.3911\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.6083 - val_loss: 2.1416 - val_accuracy: 0.5400\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.6278 - val_loss: 3.7246 - val_accuracy: 0.3689\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.6269 - val_loss: 1.6454 - val_accuracy: 0.5156\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.6102 - val_loss: 3.4603 - val_accuracy: 0.4267\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6370 - val_loss: 3.1726 - val_accuracy: 0.4333\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.6319 - val_loss: 2.5984 - val_accuracy: 0.4578\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6569 - val_loss: 2.1410 - val_accuracy: 0.4800\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.6417 - val_loss: 2.4530 - val_accuracy: 0.4289\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6472 - val_loss: 3.1478 - val_accuracy: 0.5178\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6597 - val_loss: 5.5232 - val_accuracy: 0.3844\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6630 - val_loss: 2.7528 - val_accuracy: 0.4756\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6583 - val_loss: 3.1567 - val_accuracy: 0.4489\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6796 - val_loss: 3.0671 - val_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6704 - val_loss: 3.3438 - val_accuracy: 0.4178\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.6792 - val_loss: 2.7842 - val_accuracy: 0.4267\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.6764 - val_loss: 3.7085 - val_accuracy: 0.3956\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.6806 - val_loss: 3.1051 - val_accuracy: 0.4422\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.6843 - val_loss: 3.0384 - val_accuracy: 0.4178\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6880 - val_loss: 3.0436 - val_accuracy: 0.4733\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7074 - val_loss: 3.0934 - val_accuracy: 0.4311\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6810 - val_loss: 3.7456 - val_accuracy: 0.4244\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7167 - val_loss: 3.6659 - val_accuracy: 0.4711\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7088 - val_loss: 3.5820 - val_accuracy: 0.4178\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7134 - val_loss: 2.4156 - val_accuracy: 0.5267\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.6880 - val_loss: 6.2326 - val_accuracy: 0.3844\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7065 - val_loss: 3.8577 - val_accuracy: 0.4222\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7023 - val_loss: 6.1974 - val_accuracy: 0.4044\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7032 - val_loss: 3.4943 - val_accuracy: 0.5489\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.6954 - val_loss: 4.1199 - val_accuracy: 0.4133\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7301 - val_loss: 4.0168 - val_accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7148 - val_loss: 4.3251 - val_accuracy: 0.4333\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7162 - val_loss: 3.6453 - val_accuracy: 0.5089\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7199 - val_loss: 7.7153 - val_accuracy: 0.3911\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7315 - val_loss: 3.8901 - val_accuracy: 0.4756\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7245 - val_loss: 3.2586 - val_accuracy: 0.5089\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7139 - val_loss: 2.9724 - val_accuracy: 0.5089\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7347 - val_loss: 3.5056 - val_accuracy: 0.5556\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7343 - val_loss: 4.0521 - val_accuracy: 0.4733\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7514 - val_loss: 3.2425 - val_accuracy: 0.5244\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7389 - val_loss: 7.9431 - val_accuracy: 0.3689\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_128 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 25, 25, 8)         1520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_129 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 76,211\n",
      "Trainable params: 76,153\n",
      "Non-trainable params: 58\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2027 - accuracy: 0.3741 - val_loss: 1.0992 - val_accuracy: 0.3178\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0242 - accuracy: 0.4222 - val_loss: 1.0826 - val_accuracy: 0.3978\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9754 - accuracy: 0.4426 - val_loss: 1.1236 - val_accuracy: 0.4889\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9624 - accuracy: 0.4681 - val_loss: 1.1425 - val_accuracy: 0.3600\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9160 - accuracy: 0.4829 - val_loss: 1.2444 - val_accuracy: 0.4733\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8886 - accuracy: 0.5144 - val_loss: 1.4386 - val_accuracy: 0.4222\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.5292 - val_loss: 1.3261 - val_accuracy: 0.5711\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8331 - accuracy: 0.5329 - val_loss: 2.5693 - val_accuracy: 0.3689\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8291 - accuracy: 0.5375 - val_loss: 1.5674 - val_accuracy: 0.4622\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8162 - accuracy: 0.5569 - val_loss: 1.4578 - val_accuracy: 0.5267\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7867 - accuracy: 0.5838 - val_loss: 1.2875 - val_accuracy: 0.4400\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7538 - accuracy: 0.5940 - val_loss: 1.8827 - val_accuracy: 0.4933\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.6176 - val_loss: 1.3540 - val_accuracy: 0.4400\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.6250 - val_loss: 1.8657 - val_accuracy: 0.5089\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.6292 - val_loss: 2.0533 - val_accuracy: 0.5489\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.6546 - val_loss: 1.7131 - val_accuracy: 0.4511\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.6472 - val_loss: 1.9059 - val_accuracy: 0.5689\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6519 - val_loss: 2.8006 - val_accuracy: 0.4911\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6685 - val_loss: 1.5906 - val_accuracy: 0.4578\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6681 - val_loss: 3.1974 - val_accuracy: 0.4422\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6829 - val_loss: 1.6144 - val_accuracy: 0.4844\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6917 - val_loss: 2.5686 - val_accuracy: 0.4733\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6954 - val_loss: 2.3308 - val_accuracy: 0.4911\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.7023 - val_loss: 2.8734 - val_accuracy: 0.5378\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7019 - val_loss: 2.4131 - val_accuracy: 0.4400\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7000 - val_loss: 3.0318 - val_accuracy: 0.4800\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7069 - val_loss: 3.0739 - val_accuracy: 0.4511\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7088 - val_loss: 3.7996 - val_accuracy: 0.4511\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7093 - val_loss: 3.4330 - val_accuracy: 0.4511\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7329 - val_loss: 3.2654 - val_accuracy: 0.4444\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7343 - val_loss: 3.5287 - val_accuracy: 0.4111\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7292 - val_loss: 3.8955 - val_accuracy: 0.4556\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7551 - val_loss: 4.5728 - val_accuracy: 0.4244\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7403 - val_loss: 4.6392 - val_accuracy: 0.4822\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7454 - val_loss: 3.7063 - val_accuracy: 0.4200\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7569 - val_loss: 3.9815 - val_accuracy: 0.5067\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7620 - val_loss: 4.9391 - val_accuracy: 0.4622\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7560 - val_loss: 3.5289 - val_accuracy: 0.4533\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7759 - val_loss: 4.0123 - val_accuracy: 0.5200\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7671 - val_loss: 5.6096 - val_accuracy: 0.4511\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7639 - val_loss: 5.8915 - val_accuracy: 0.4533\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7750 - val_loss: 3.5552 - val_accuracy: 0.4844\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.7829 - val_loss: 4.9547 - val_accuracy: 0.4378\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.7764 - val_loss: 3.7765 - val_accuracy: 0.5178\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7764 - val_loss: 5.2860 - val_accuracy: 0.4667\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.7778 - val_loss: 4.7249 - val_accuracy: 0.4667\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.7903 - val_loss: 6.9016 - val_accuracy: 0.4378\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7907 - val_loss: 4.1854 - val_accuracy: 0.4333\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8014 - val_loss: 4.2274 - val_accuracy: 0.3911\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8088 - val_loss: 4.0256 - val_accuracy: 0.4222\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8009 - val_loss: 4.1890 - val_accuracy: 0.4533\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8157 - val_loss: 5.2465 - val_accuracy: 0.4356\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3822 - accuracy: 0.8028 - val_loss: 4.6881 - val_accuracy: 0.4422\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8255 - val_loss: 6.5352 - val_accuracy: 0.4533\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8301 - val_loss: 5.6753 - val_accuracy: 0.4889\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8185 - val_loss: 5.1676 - val_accuracy: 0.4267\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8278 - val_loss: 5.4754 - val_accuracy: 0.4689\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8384 - val_loss: 5.1163 - val_accuracy: 0.4222\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8241 - val_loss: 4.2057 - val_accuracy: 0.4244\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8273 - val_loss: 5.0037 - val_accuracy: 0.4022\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8296 - val_loss: 5.2472 - val_accuracy: 0.4578\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8269 - val_loss: 6.6756 - val_accuracy: 0.4400\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8454 - val_loss: 5.5419 - val_accuracy: 0.4156\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8338 - val_loss: 6.0816 - val_accuracy: 0.4022\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8468 - val_loss: 4.6961 - val_accuracy: 0.4644\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8477 - val_loss: 5.6216 - val_accuracy: 0.4467\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8556 - val_loss: 5.1352 - val_accuracy: 0.4533\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8537 - val_loss: 5.9601 - val_accuracy: 0.4511\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8606 - val_loss: 6.4567 - val_accuracy: 0.4267\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8551 - val_loss: 7.8729 - val_accuracy: 0.4822\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8551 - val_loss: 5.0867 - val_accuracy: 0.4600\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8639 - val_loss: 6.0671 - val_accuracy: 0.4044\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.8727 - val_loss: 7.1655 - val_accuracy: 0.4267\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8745 - val_loss: 5.8458 - val_accuracy: 0.4422\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8694 - val_loss: 7.3172 - val_accuracy: 0.4200\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.8810 - val_loss: 7.3686 - val_accuracy: 0.3978\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8653 - val_loss: 11.9215 - val_accuracy: 0.3822\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8653 - val_loss: 11.2080 - val_accuracy: 0.4089\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8755 - val_loss: 7.0455 - val_accuracy: 0.3822\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.8792 - val_loss: 5.8701 - val_accuracy: 0.4444\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.8727 - val_loss: 6.7954 - val_accuracy: 0.4400\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.8889 - val_loss: 6.5392 - val_accuracy: 0.4333\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.8875 - val_loss: 6.6691 - val_accuracy: 0.4733\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.8931 - val_loss: 7.5450 - val_accuracy: 0.4178\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9032 - val_loss: 8.3490 - val_accuracy: 0.4333\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.8866 - val_loss: 7.3267 - val_accuracy: 0.4711\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8755 - val_loss: 7.4422 - val_accuracy: 0.4267\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.8912 - val_loss: 8.7148 - val_accuracy: 0.4578\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.8921 - val_loss: 8.7848 - val_accuracy: 0.4333\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.8838 - val_loss: 8.3393 - val_accuracy: 0.4444\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.8963 - val_loss: 8.8423 - val_accuracy: 0.4667\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8861 - val_loss: 7.8304 - val_accuracy: 0.4889\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9046 - val_loss: 8.6213 - val_accuracy: 0.4689\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9014 - val_loss: 11.3397 - val_accuracy: 0.3911\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9106 - val_loss: 10.1446 - val_accuracy: 0.4511\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9060 - val_loss: 8.8726 - val_accuracy: 0.4267\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9037 - val_loss: 9.8140 - val_accuracy: 0.4289\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.2204 - accuracy: 0.8995 - val_loss: 8.4976 - val_accuracy: 0.4378\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9157 - val_loss: 8.5503 - val_accuracy: 0.4622\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2139 - accuracy: 0.9032 - val_loss: 9.1532 - val_accuracy: 0.4378\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_130 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_130 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 25, 25, 8)         1520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_131 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 150,195\n",
      "Trainable params: 150,137\n",
      "Non-trainable params: 58\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2142 - accuracy: 0.4218 - val_loss: 1.0975 - val_accuracy: 0.4044\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9451 - accuracy: 0.5032 - val_loss: 1.0978 - val_accuracy: 0.3444\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8802 - accuracy: 0.5421 - val_loss: 1.0936 - val_accuracy: 0.4444\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.5958 - val_loss: 1.1404 - val_accuracy: 0.4533\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.6292 - val_loss: 1.1933 - val_accuracy: 0.5111\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6755 - val_loss: 1.6939 - val_accuracy: 0.4533\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6759 - val_loss: 1.4215 - val_accuracy: 0.5422\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7088 - val_loss: 2.4736 - val_accuracy: 0.4311\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.7019 - val_loss: 2.1899 - val_accuracy: 0.4356\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7185 - val_loss: 1.6365 - val_accuracy: 0.4844\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7347 - val_loss: 1.7865 - val_accuracy: 0.4867\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7537 - val_loss: 2.0770 - val_accuracy: 0.4356\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7606 - val_loss: 7.1392 - val_accuracy: 0.4156\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7662 - val_loss: 2.4968 - val_accuracy: 0.4756\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7880 - val_loss: 3.1993 - val_accuracy: 0.4400\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8079 - val_loss: 2.7420 - val_accuracy: 0.4200\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8069 - val_loss: 2.7465 - val_accuracy: 0.4267\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8074 - val_loss: 2.3733 - val_accuracy: 0.5200\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8208 - val_loss: 2.4726 - val_accuracy: 0.4844\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 0.3575 - accuracy: 0.8222 - val_loss: 2.9546 - val_accuracy: 0.4689\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3593 - accuracy: 0.8208 - val_loss: 3.4169 - val_accuracy: 0.4356\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3320 - accuracy: 0.8343 - val_loss: 2.5264 - val_accuracy: 0.5244\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8269 - val_loss: 3.5555 - val_accuracy: 0.4133\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8537 - val_loss: 4.3062 - val_accuracy: 0.4489\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2920 - accuracy: 0.8648 - val_loss: 9.3963 - val_accuracy: 0.3911\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8597 - val_loss: 5.3663 - val_accuracy: 0.4333\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8699 - val_loss: 6.5549 - val_accuracy: 0.4222\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8648 - val_loss: 3.1842 - val_accuracy: 0.5489\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8856 - val_loss: 3.9527 - val_accuracy: 0.4400\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8741 - val_loss: 5.5841 - val_accuracy: 0.4600\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9032 - val_loss: 4.8309 - val_accuracy: 0.4622\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.8819 - val_loss: 3.8652 - val_accuracy: 0.5600\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2297 - accuracy: 0.8903 - val_loss: 4.2389 - val_accuracy: 0.5311\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2203 - accuracy: 0.8935 - val_loss: 6.0378 - val_accuracy: 0.4044\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2410 - accuracy: 0.8944 - val_loss: 7.8334 - val_accuracy: 0.4844\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.8926 - val_loss: 5.5792 - val_accuracy: 0.5022\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9019 - val_loss: 8.4077 - val_accuracy: 0.4133\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9042 - val_loss: 5.7843 - val_accuracy: 0.3733\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.9083 - val_loss: 7.7410 - val_accuracy: 0.4067\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9032 - val_loss: 5.2750 - val_accuracy: 0.5156\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9139 - val_loss: 8.5209 - val_accuracy: 0.4111\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9065 - val_loss: 14.8622 - val_accuracy: 0.3222\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9130 - val_loss: 6.0048 - val_accuracy: 0.5044\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9167 - val_loss: 10.8860 - val_accuracy: 0.3933\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1783 - accuracy: 0.9222 - val_loss: 6.3300 - val_accuracy: 0.5289\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1747 - accuracy: 0.9190 - val_loss: 6.5466 - val_accuracy: 0.5089\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9093 - val_loss: 8.1571 - val_accuracy: 0.4178\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9190 - val_loss: 6.6763 - val_accuracy: 0.4933\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9208 - val_loss: 14.0663 - val_accuracy: 0.3956\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.9255 - val_loss: 7.4258 - val_accuracy: 0.4978\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1439 - accuracy: 0.9292 - val_loss: 18.3345 - val_accuracy: 0.3667\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9292 - val_loss: 7.8389 - val_accuracy: 0.5111\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9269 - val_loss: 7.3988 - val_accuracy: 0.5311\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9306 - val_loss: 12.6644 - val_accuracy: 0.3289\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1542 - accuracy: 0.9278 - val_loss: 11.9736 - val_accuracy: 0.4067\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1565 - accuracy: 0.9218 - val_loss: 7.3705 - val_accuracy: 0.4889\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9310 - val_loss: 19.4147 - val_accuracy: 0.3556\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1311 - accuracy: 0.9384 - val_loss: 9.5340 - val_accuracy: 0.4333\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9444 - val_loss: 13.3799 - val_accuracy: 0.3956\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9463 - val_loss: 9.1417 - val_accuracy: 0.4689\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9403 - val_loss: 8.5726 - val_accuracy: 0.5600\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1202 - accuracy: 0.9472 - val_loss: 9.3408 - val_accuracy: 0.5267\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9421 - val_loss: 9.1221 - val_accuracy: 0.5289\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.9389 - val_loss: 7.9094 - val_accuracy: 0.5156\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1332 - accuracy: 0.9403 - val_loss: 9.3470 - val_accuracy: 0.4622\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1331 - accuracy: 0.9435 - val_loss: 10.8577 - val_accuracy: 0.4533\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1118 - accuracy: 0.9528 - val_loss: 12.6793 - val_accuracy: 0.4600\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9431 - val_loss: 12.7837 - val_accuracy: 0.5089\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9449 - val_loss: 10.6317 - val_accuracy: 0.4556\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9551 - val_loss: 10.2226 - val_accuracy: 0.4311\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9491 - val_loss: 12.9320 - val_accuracy: 0.4267\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9495 - val_loss: 10.6279 - val_accuracy: 0.4667\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9505 - val_loss: 11.8483 - val_accuracy: 0.4511\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9505 - val_loss: 17.4782 - val_accuracy: 0.3911\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9440 - val_loss: 12.2315 - val_accuracy: 0.4267\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9583 - val_loss: 9.1774 - val_accuracy: 0.4489\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9569 - val_loss: 13.2020 - val_accuracy: 0.4667\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9532 - val_loss: 20.3067 - val_accuracy: 0.3267\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9602 - val_loss: 10.8735 - val_accuracy: 0.4489\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9565 - val_loss: 13.7570 - val_accuracy: 0.4111\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9565 - val_loss: 9.1691 - val_accuracy: 0.5067\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9537 - val_loss: 15.4461 - val_accuracy: 0.3956\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9634 - val_loss: 13.6366 - val_accuracy: 0.4267\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9565 - val_loss: 10.7867 - val_accuracy: 0.4622\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9639 - val_loss: 28.5836 - val_accuracy: 0.3644\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9495 - val_loss: 8.6696 - val_accuracy: 0.5400\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9579 - val_loss: 15.6219 - val_accuracy: 0.3956\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 0.9644 - val_loss: 11.4346 - val_accuracy: 0.4444\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9495 - val_loss: 47.1237 - val_accuracy: 0.3378\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9602 - val_loss: 10.4336 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9764 - val_loss: 14.1343 - val_accuracy: 0.4222\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9662 - val_loss: 13.7265 - val_accuracy: 0.4533\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9713 - val_loss: 9.9597 - val_accuracy: 0.4978\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9569 - val_loss: 13.4020 - val_accuracy: 0.4333\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9704 - val_loss: 10.2767 - val_accuracy: 0.5111\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9690 - val_loss: 11.5431 - val_accuracy: 0.4600\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9759 - val_loss: 14.1862 - val_accuracy: 0.4467\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9690 - val_loss: 10.3018 - val_accuracy: 0.4933\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9699 - val_loss: 11.4737 - val_accuracy: 0.5133\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9639 - val_loss: 19.1960 - val_accuracy: 0.4844\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_132 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_132 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 25, 25, 8)         1520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_133 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 298,163\n",
      "Trainable params: 298,105\n",
      "Non-trainable params: 58\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2587 - accuracy: 0.4472 - val_loss: 1.0985 - val_accuracy: 0.2978\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8813 - accuracy: 0.5611 - val_loss: 1.1056 - val_accuracy: 0.3689\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7549 - accuracy: 0.6347 - val_loss: 1.1264 - val_accuracy: 0.3956\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6824 - val_loss: 1.0656 - val_accuracy: 0.5422\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.7361 - val_loss: 1.7479 - val_accuracy: 0.4711\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7606 - val_loss: 1.7328 - val_accuracy: 0.5022\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7792 - val_loss: 1.7293 - val_accuracy: 0.4822\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8153 - val_loss: 2.2360 - val_accuracy: 0.4644\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8231 - val_loss: 3.7537 - val_accuracy: 0.4622\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8264 - val_loss: 2.1663 - val_accuracy: 0.4844\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8546 - val_loss: 2.8474 - val_accuracy: 0.4733\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8477 - val_loss: 3.8540 - val_accuracy: 0.4378\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3088 - accuracy: 0.8759 - val_loss: 3.1776 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8796 - val_loss: 4.7640 - val_accuracy: 0.4044\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.8819 - val_loss: 2.7254 - val_accuracy: 0.5489\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.8949 - val_loss: 4.5168 - val_accuracy: 0.4489\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2403 - accuracy: 0.8889 - val_loss: 3.5493 - val_accuracy: 0.4778\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2400 - accuracy: 0.9046 - val_loss: 4.5712 - val_accuracy: 0.4822\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9181 - val_loss: 3.1909 - val_accuracy: 0.4244\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.9213 - val_loss: 5.1287 - val_accuracy: 0.4422\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9162 - val_loss: 3.4485 - val_accuracy: 0.4978\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9144 - val_loss: 2.3458 - val_accuracy: 0.5489\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9245 - val_loss: 5.1563 - val_accuracy: 0.4933\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9306 - val_loss: 5.5917 - val_accuracy: 0.5400\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9338 - val_loss: 3.5210 - val_accuracy: 0.5444\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9347 - val_loss: 4.6633 - val_accuracy: 0.4867\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.9356 - val_loss: 6.5482 - val_accuracy: 0.5489\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9417 - val_loss: 5.6958 - val_accuracy: 0.4622\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9407 - val_loss: 7.0134 - val_accuracy: 0.4644\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9542 - val_loss: 3.2140 - val_accuracy: 0.5756\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9486 - val_loss: 5.8167 - val_accuracy: 0.4667\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9421 - val_loss: 4.6232 - val_accuracy: 0.5267\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1368 - accuracy: 0.9458 - val_loss: 4.8725 - val_accuracy: 0.5533\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9565 - val_loss: 10.1151 - val_accuracy: 0.3800\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9495 - val_loss: 5.4393 - val_accuracy: 0.5133\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9597 - val_loss: 3.8733 - val_accuracy: 0.5600\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9597 - val_loss: 5.7960 - val_accuracy: 0.5111\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9634 - val_loss: 3.7228 - val_accuracy: 0.6867\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9551 - val_loss: 5.9572 - val_accuracy: 0.4400\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9644 - val_loss: 4.4596 - val_accuracy: 0.5489\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9630 - val_loss: 10.0509 - val_accuracy: 0.4511\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9588 - val_loss: 6.3757 - val_accuracy: 0.5378\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9644 - val_loss: 4.8692 - val_accuracy: 0.5378\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9597 - val_loss: 3.4434 - val_accuracy: 0.6289\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9657 - val_loss: 6.6250 - val_accuracy: 0.4978\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9676 - val_loss: 7.1765 - val_accuracy: 0.4178\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9685 - val_loss: 4.9510 - val_accuracy: 0.5644\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9699 - val_loss: 5.0349 - val_accuracy: 0.5867\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9657 - val_loss: 5.6087 - val_accuracy: 0.5178\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9718 - val_loss: 5.4327 - val_accuracy: 0.5533\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9722 - val_loss: 4.7918 - val_accuracy: 0.5889\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9727 - val_loss: 3.3430 - val_accuracy: 0.6089\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9704 - val_loss: 6.6635 - val_accuracy: 0.5178\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9778 - val_loss: 6.8801 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9741 - val_loss: 6.5449 - val_accuracy: 0.4911\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9759 - val_loss: 10.1790 - val_accuracy: 0.4533\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9796 - val_loss: 7.2942 - val_accuracy: 0.5044\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9713 - val_loss: 3.7109 - val_accuracy: 0.6333\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9806 - val_loss: 6.9107 - val_accuracy: 0.4556\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9694 - val_loss: 4.0445 - val_accuracy: 0.6378\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9769 - val_loss: 5.6886 - val_accuracy: 0.6022\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9796 - val_loss: 7.1137 - val_accuracy: 0.5111\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9778 - val_loss: 6.8995 - val_accuracy: 0.5133\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9778 - val_loss: 7.7503 - val_accuracy: 0.4689\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9833 - val_loss: 5.6284 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9727 - val_loss: 8.5412 - val_accuracy: 0.4667\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9787 - val_loss: 6.0493 - val_accuracy: 0.6089\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9792 - val_loss: 6.2400 - val_accuracy: 0.5867\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9792 - val_loss: 8.6925 - val_accuracy: 0.5889\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9838 - val_loss: 6.7660 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 9.9346 - val_accuracy: 0.5133\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9806 - val_loss: 6.1705 - val_accuracy: 0.5556\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9815 - val_loss: 5.2585 - val_accuracy: 0.6156\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9838 - val_loss: 5.1966 - val_accuracy: 0.5689\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9815 - val_loss: 6.9614 - val_accuracy: 0.5622\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9875 - val_loss: 30.1899 - val_accuracy: 0.3400\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 5.8909 - val_accuracy: 0.5711\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9861 - val_loss: 15.4397 - val_accuracy: 0.3356\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9829 - val_loss: 8.4309 - val_accuracy: 0.4733\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9866 - val_loss: 6.9613 - val_accuracy: 0.5444\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 11.4022 - val_accuracy: 0.5133\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9856 - val_loss: 11.6783 - val_accuracy: 0.5244\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9750 - val_loss: 10.4623 - val_accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9782 - val_loss: 5.9920 - val_accuracy: 0.5644\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9894 - val_loss: 7.7916 - val_accuracy: 0.5200\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 8.3062 - val_accuracy: 0.6067\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 7.5103 - val_accuracy: 0.5156\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 8.2438 - val_accuracy: 0.5244\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 9.6246 - val_accuracy: 0.4356\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 10.6643 - val_accuracy: 0.4422\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 9.6192 - val_accuracy: 0.4822\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9884 - val_loss: 10.9442 - val_accuracy: 0.4378\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 6.9824 - val_accuracy: 0.6111\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 5.1769 - val_accuracy: 0.6444\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 12.1844 - val_accuracy: 0.4533\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9866 - val_loss: 5.9772 - val_accuracy: 0.6244\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9894 - val_loss: 12.5037 - val_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9870 - val_loss: 8.8471 - val_accuracy: 0.5489\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 9.6748 - val_accuracy: 0.4956\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 9.0125 - val_accuracy: 0.5267\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_134 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_134 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 25, 25, 10)        1900      \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_135 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_67 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 48,823\n",
      "Trainable params: 48,761\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1745 - accuracy: 0.3310 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0862 - accuracy: 0.3264 - val_loss: 1.0985 - val_accuracy: 0.3378\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0816 - accuracy: 0.3514 - val_loss: 1.0896 - val_accuracy: 0.3356\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0798 - accuracy: 0.3620 - val_loss: 1.0560 - val_accuracy: 0.3467\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0757 - accuracy: 0.3611 - val_loss: 1.0808 - val_accuracy: 0.3556\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.3884 - val_loss: 1.0893 - val_accuracy: 0.3622\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0051 - accuracy: 0.4069 - val_loss: 1.1150 - val_accuracy: 0.3511\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0044 - accuracy: 0.4162 - val_loss: 1.0879 - val_accuracy: 0.3467\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9901 - accuracy: 0.4176 - val_loss: 2.0590 - val_accuracy: 0.3800\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.4384 - val_loss: 1.1351 - val_accuracy: 0.3622\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9608 - accuracy: 0.4514 - val_loss: 1.3236 - val_accuracy: 0.4067\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9438 - accuracy: 0.4546 - val_loss: 1.0652 - val_accuracy: 0.4133\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9348 - accuracy: 0.4620 - val_loss: 1.0832 - val_accuracy: 0.3933\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9335 - accuracy: 0.4856 - val_loss: 1.2482 - val_accuracy: 0.4289\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8946 - accuracy: 0.5190 - val_loss: 1.0962 - val_accuracy: 0.3867\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8704 - accuracy: 0.5162 - val_loss: 1.2592 - val_accuracy: 0.3867\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8698 - accuracy: 0.5292 - val_loss: 1.2666 - val_accuracy: 0.4378\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8595 - accuracy: 0.5449 - val_loss: 1.1323 - val_accuracy: 0.5089\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8463 - accuracy: 0.5389 - val_loss: 1.1016 - val_accuracy: 0.5089\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8305 - accuracy: 0.5519 - val_loss: 1.0421 - val_accuracy: 0.4533\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8157 - accuracy: 0.5551 - val_loss: 1.8926 - val_accuracy: 0.3267\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7774 - accuracy: 0.5926 - val_loss: 1.5026 - val_accuracy: 0.4133\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7827 - accuracy: 0.5796 - val_loss: 1.6691 - val_accuracy: 0.3978\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7818 - accuracy: 0.5843 - val_loss: 1.2132 - val_accuracy: 0.4222\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7757 - accuracy: 0.5824 - val_loss: 1.0312 - val_accuracy: 0.4889\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.6079 - val_loss: 1.1707 - val_accuracy: 0.4444\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.6046 - val_loss: 1.5534 - val_accuracy: 0.4489\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.6083 - val_loss: 1.5336 - val_accuracy: 0.4444\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7201 - accuracy: 0.6356 - val_loss: 1.2066 - val_accuracy: 0.5711\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.6278 - val_loss: 1.3133 - val_accuracy: 0.4778\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.6255 - val_loss: 1.3685 - val_accuracy: 0.4756\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.6231 - val_loss: 1.7296 - val_accuracy: 0.4867\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.6236 - val_loss: 1.5185 - val_accuracy: 0.4644\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.6310 - val_loss: 1.5941 - val_accuracy: 0.4778\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.6477 - val_loss: 1.6655 - val_accuracy: 0.4378\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.6333 - val_loss: 1.4400 - val_accuracy: 0.4711\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.6431 - val_loss: 2.1013 - val_accuracy: 0.3667\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6449 - val_loss: 1.6714 - val_accuracy: 0.4356\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6597 - val_loss: 1.9415 - val_accuracy: 0.4111\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6574 - val_loss: 1.6849 - val_accuracy: 0.4889\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6537 - val_loss: 2.6590 - val_accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6551 - val_loss: 1.7269 - val_accuracy: 0.4933\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.6384 - val_loss: 1.5871 - val_accuracy: 0.4489\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6694 - val_loss: 1.8120 - val_accuracy: 0.5289\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6519 - val_loss: 1.8729 - val_accuracy: 0.4556\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6657 - val_loss: 2.4147 - val_accuracy: 0.5289\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6597 - val_loss: 9.4820 - val_accuracy: 0.3133\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6657 - val_loss: 2.4241 - val_accuracy: 0.4756\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6764 - val_loss: 2.5777 - val_accuracy: 0.4733\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6736 - val_loss: 2.1434 - val_accuracy: 0.4133\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6722 - val_loss: 3.0001 - val_accuracy: 0.4578\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.6833 - val_loss: 3.4406 - val_accuracy: 0.4244\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.6880 - val_loss: 2.4694 - val_accuracy: 0.4778\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.6745 - val_loss: 2.8645 - val_accuracy: 0.4889\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7019 - val_loss: 3.9137 - val_accuracy: 0.3844\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6806 - val_loss: 2.9763 - val_accuracy: 0.4400\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.6981 - val_loss: 2.4642 - val_accuracy: 0.4800\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6829 - val_loss: 2.4003 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.6972 - val_loss: 3.2202 - val_accuracy: 0.4356\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7032 - val_loss: 2.5270 - val_accuracy: 0.5022\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7171 - val_loss: 2.2083 - val_accuracy: 0.4711\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7028 - val_loss: 2.6155 - val_accuracy: 0.4733\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7088 - val_loss: 2.2557 - val_accuracy: 0.5022\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7148 - val_loss: 2.7798 - val_accuracy: 0.4556\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7292 - val_loss: 3.1890 - val_accuracy: 0.4822\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7287 - val_loss: 5.2830 - val_accuracy: 0.3400\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7324 - val_loss: 4.4404 - val_accuracy: 0.3867\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7426 - val_loss: 7.2461 - val_accuracy: 0.3667\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7495 - val_loss: 3.0033 - val_accuracy: 0.5178\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7509 - val_loss: 4.9008 - val_accuracy: 0.4333\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7537 - val_loss: 2.0348 - val_accuracy: 0.3889\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7486 - val_loss: 4.8557 - val_accuracy: 0.3178\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7454 - val_loss: 6.8866 - val_accuracy: 0.3178\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7588 - val_loss: 2.5785 - val_accuracy: 0.5044\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7620 - val_loss: 2.1322 - val_accuracy: 0.4533\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7685 - val_loss: 2.3944 - val_accuracy: 0.4822\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7569 - val_loss: 2.4965 - val_accuracy: 0.4244\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7815 - val_loss: 4.6821 - val_accuracy: 0.3778\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7657 - val_loss: 3.5853 - val_accuracy: 0.3911\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7606 - val_loss: 5.3187 - val_accuracy: 0.3756\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7648 - val_loss: 2.5775 - val_accuracy: 0.4467\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7681 - val_loss: 3.7925 - val_accuracy: 0.4467\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7630 - val_loss: 3.5936 - val_accuracy: 0.4956\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7694 - val_loss: 4.2999 - val_accuracy: 0.4244\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7792 - val_loss: 3.3329 - val_accuracy: 0.4889\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7727 - val_loss: 2.4145 - val_accuracy: 0.5200\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7597 - val_loss: 3.5744 - val_accuracy: 0.4622\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7880 - val_loss: 3.9578 - val_accuracy: 0.4644\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7750 - val_loss: 3.0678 - val_accuracy: 0.5044\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7787 - val_loss: 4.4357 - val_accuracy: 0.3956\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7796 - val_loss: 5.6203 - val_accuracy: 0.3778\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7755 - val_loss: 3.0659 - val_accuracy: 0.4622\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7731 - val_loss: 4.3306 - val_accuracy: 0.4289\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.7977 - val_loss: 3.8500 - val_accuracy: 0.4667\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7792 - val_loss: 3.6411 - val_accuracy: 0.4867\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7843 - val_loss: 4.1554 - val_accuracy: 0.4578\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.7986 - val_loss: 6.5160 - val_accuracy: 0.4089\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.7963 - val_loss: 6.3216 - val_accuracy: 0.4289\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7907 - val_loss: 5.7189 - val_accuracy: 0.4889\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 3.6407 - val_accuracy: 0.4200\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_136 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_136 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 25, 25, 10)        1900      \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_137 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_68 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 95,031\n",
      "Trainable params: 94,969\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2224 - accuracy: 0.3324 - val_loss: 1.0993 - val_accuracy: 0.3356\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0855 - accuracy: 0.3389 - val_loss: 1.0982 - val_accuracy: 0.4133\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0663 - accuracy: 0.3810 - val_loss: 1.1031 - val_accuracy: 0.3200\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0609 - accuracy: 0.3880 - val_loss: 1.0996 - val_accuracy: 0.2956\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0490 - accuracy: 0.3889 - val_loss: 1.1048 - val_accuracy: 0.3933\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0159 - accuracy: 0.4120 - val_loss: 1.1532 - val_accuracy: 0.3778\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4204 - val_loss: 1.0843 - val_accuracy: 0.4356\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9966 - accuracy: 0.4199 - val_loss: 1.0876 - val_accuracy: 0.3667\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9899 - accuracy: 0.4157 - val_loss: 1.2187 - val_accuracy: 0.4044\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9719 - accuracy: 0.4361 - val_loss: 1.1442 - val_accuracy: 0.3378\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9440 - accuracy: 0.4366 - val_loss: 1.1010 - val_accuracy: 0.4444\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9244 - accuracy: 0.4644 - val_loss: 1.0794 - val_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9179 - accuracy: 0.4782 - val_loss: 1.0462 - val_accuracy: 0.4533\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9059 - accuracy: 0.4944 - val_loss: 1.1637 - val_accuracy: 0.3933\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9003 - accuracy: 0.4972 - val_loss: 1.0192 - val_accuracy: 0.5533\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8911 - accuracy: 0.4926 - val_loss: 1.3773 - val_accuracy: 0.3933\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8778 - accuracy: 0.5208 - val_loss: 1.0595 - val_accuracy: 0.5289\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8523 - accuracy: 0.5278 - val_loss: 1.1430 - val_accuracy: 0.5400\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8245 - accuracy: 0.5593 - val_loss: 1.5335 - val_accuracy: 0.5133\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8114 - accuracy: 0.5648 - val_loss: 1.4537 - val_accuracy: 0.3800\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7730 - accuracy: 0.5894 - val_loss: 1.4243 - val_accuracy: 0.4267\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.5704 - val_loss: 1.1081 - val_accuracy: 0.5467\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7619 - accuracy: 0.5977 - val_loss: 1.8510 - val_accuracy: 0.4267\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.6181 - val_loss: 1.5669 - val_accuracy: 0.4933\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.5963 - val_loss: 1.3571 - val_accuracy: 0.5111\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7054 - accuracy: 0.6306 - val_loss: 1.7890 - val_accuracy: 0.3867\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7112 - accuracy: 0.6255 - val_loss: 1.2952 - val_accuracy: 0.4600\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6329 - val_loss: 2.6016 - val_accuracy: 0.4089\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6505 - val_loss: 1.8840 - val_accuracy: 0.5289\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6421 - val_loss: 2.3860 - val_accuracy: 0.4400\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6648 - val_loss: 2.7359 - val_accuracy: 0.4422\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.6546 - val_loss: 1.5719 - val_accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6741 - val_loss: 1.8503 - val_accuracy: 0.4733\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6750 - val_loss: 3.4201 - val_accuracy: 0.4511\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6648 - val_loss: 2.1170 - val_accuracy: 0.4267\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6731 - val_loss: 1.6745 - val_accuracy: 0.5022\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6792 - val_loss: 2.6629 - val_accuracy: 0.4889\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6889 - val_loss: 1.6882 - val_accuracy: 0.5600\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6958 - val_loss: 1.8015 - val_accuracy: 0.4933\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6981 - val_loss: 1.9963 - val_accuracy: 0.5378\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7093 - val_loss: 2.4314 - val_accuracy: 0.4978\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7176 - val_loss: 5.0537 - val_accuracy: 0.3956\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7403 - val_loss: 1.6267 - val_accuracy: 0.5644\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7097 - val_loss: 2.4055 - val_accuracy: 0.4978\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7134 - val_loss: 2.1342 - val_accuracy: 0.4822\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7361 - val_loss: 3.0072 - val_accuracy: 0.5156\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7370 - val_loss: 6.7183 - val_accuracy: 0.3778\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7315 - val_loss: 6.0435 - val_accuracy: 0.3822\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7495 - val_loss: 2.3065 - val_accuracy: 0.5200\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7356 - val_loss: 2.7644 - val_accuracy: 0.5933\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7486 - val_loss: 2.5344 - val_accuracy: 0.4778\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7481 - val_loss: 3.6963 - val_accuracy: 0.4267\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7528 - val_loss: 3.2214 - val_accuracy: 0.4889\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7519 - val_loss: 2.2938 - val_accuracy: 0.4933\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7514 - val_loss: 3.2224 - val_accuracy: 0.5667\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7667 - val_loss: 2.8343 - val_accuracy: 0.4689\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7653 - val_loss: 3.8610 - val_accuracy: 0.4778\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7556 - val_loss: 2.6295 - val_accuracy: 0.5244\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7718 - val_loss: 2.6681 - val_accuracy: 0.5022\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7829 - val_loss: 2.8947 - val_accuracy: 0.4733\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7833 - val_loss: 2.6348 - val_accuracy: 0.5178\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7769 - val_loss: 4.0990 - val_accuracy: 0.4467\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7875 - val_loss: 2.7139 - val_accuracy: 0.4867\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8134 - val_loss: 5.1532 - val_accuracy: 0.4756\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8028 - val_loss: 3.3459 - val_accuracy: 0.5156\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8051 - val_loss: 3.5397 - val_accuracy: 0.5067\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7981 - val_loss: 3.6918 - val_accuracy: 0.4689\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8093 - val_loss: 3.2616 - val_accuracy: 0.5444\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8088 - val_loss: 3.1546 - val_accuracy: 0.5222\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8162 - val_loss: 3.5272 - val_accuracy: 0.5289\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8097 - val_loss: 4.4134 - val_accuracy: 0.4911\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8241 - val_loss: 4.8983 - val_accuracy: 0.4422\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.8079 - val_loss: 4.0097 - val_accuracy: 0.4422\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8269 - val_loss: 3.7080 - val_accuracy: 0.5044\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8199 - val_loss: 3.3968 - val_accuracy: 0.5044\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8111 - val_loss: 6.9183 - val_accuracy: 0.4644\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8241 - val_loss: 3.8093 - val_accuracy: 0.4711\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8250 - val_loss: 4.5856 - val_accuracy: 0.5844\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8148 - val_loss: 4.5958 - val_accuracy: 0.4689\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8287 - val_loss: 6.1730 - val_accuracy: 0.5267\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8231 - val_loss: 3.4815 - val_accuracy: 0.5267\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8278 - val_loss: 6.7492 - val_accuracy: 0.4511\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8380 - val_loss: 4.4922 - val_accuracy: 0.5400\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8412 - val_loss: 8.7250 - val_accuracy: 0.4400\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8426 - val_loss: 6.3082 - val_accuracy: 0.4867\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8556 - val_loss: 6.6474 - val_accuracy: 0.4600\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8440 - val_loss: 6.7030 - val_accuracy: 0.4356\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8380 - val_loss: 6.0720 - val_accuracy: 0.5133\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8532 - val_loss: 3.6456 - val_accuracy: 0.5044\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8532 - val_loss: 4.4616 - val_accuracy: 0.5378\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8532 - val_loss: 5.8834 - val_accuracy: 0.4800\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8514 - val_loss: 10.7501 - val_accuracy: 0.3867\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8616 - val_loss: 5.0478 - val_accuracy: 0.5044\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8458 - val_loss: 5.6053 - val_accuracy: 0.5422\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8671 - val_loss: 5.4128 - val_accuracy: 0.5178\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8606 - val_loss: 4.7493 - val_accuracy: 0.4867\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8579 - val_loss: 4.2261 - val_accuracy: 0.5422\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8602 - val_loss: 5.5579 - val_accuracy: 0.5067\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8569 - val_loss: 12.1229 - val_accuracy: 0.4089\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8583 - val_loss: 6.2228 - val_accuracy: 0.4778\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_138 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_134 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_138 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 25, 25, 10)        1900      \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_139 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 128)               184448    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 187,447\n",
      "Trainable params: 187,385\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2543 - accuracy: 0.4088 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9531 - accuracy: 0.4704 - val_loss: 1.1113 - val_accuracy: 0.3356\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9053 - accuracy: 0.5194 - val_loss: 1.0564 - val_accuracy: 0.4711\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8343 - accuracy: 0.5773 - val_loss: 1.1051 - val_accuracy: 0.3800\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.6153 - val_loss: 0.9713 - val_accuracy: 0.4844\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7292 - accuracy: 0.6306 - val_loss: 1.3883 - val_accuracy: 0.5022\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.6514 - val_loss: 1.3875 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6764 - val_loss: 1.4537 - val_accuracy: 0.4044\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6963 - val_loss: 1.7689 - val_accuracy: 0.4222\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7014 - val_loss: 2.0309 - val_accuracy: 0.3933\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7310 - val_loss: 1.3785 - val_accuracy: 0.4289\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7375 - val_loss: 1.8939 - val_accuracy: 0.4489\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7375 - val_loss: 1.3928 - val_accuracy: 0.5111\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7681 - val_loss: 1.2447 - val_accuracy: 0.5267\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7523 - val_loss: 1.6298 - val_accuracy: 0.4933\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 1.8491 - val_accuracy: 0.4533\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7606 - val_loss: 1.4226 - val_accuracy: 0.5244\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4365 - accuracy: 0.7787 - val_loss: 1.9903 - val_accuracy: 0.5378\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7694 - val_loss: 2.1653 - val_accuracy: 0.5600\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.7838 - val_loss: 2.9677 - val_accuracy: 0.4178\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.7991 - val_loss: 6.5891 - val_accuracy: 0.4044\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8148 - val_loss: 5.9933 - val_accuracy: 0.3844\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8157 - val_loss: 2.0143 - val_accuracy: 0.5222\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8389 - val_loss: 2.4836 - val_accuracy: 0.5578\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8213 - val_loss: 4.2118 - val_accuracy: 0.4644\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8278 - val_loss: 2.1794 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8380 - val_loss: 2.3974 - val_accuracy: 0.4956\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8472 - val_loss: 2.9882 - val_accuracy: 0.4644\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8472 - val_loss: 7.5173 - val_accuracy: 0.3733\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8259 - val_loss: 3.3768 - val_accuracy: 0.4867\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8407 - val_loss: 8.5705 - val_accuracy: 0.3689\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8546 - val_loss: 6.6752 - val_accuracy: 0.4044\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8648 - val_loss: 2.4402 - val_accuracy: 0.5289\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8653 - val_loss: 2.4647 - val_accuracy: 0.4556\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8699 - val_loss: 3.5926 - val_accuracy: 0.5933\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8685 - val_loss: 5.0320 - val_accuracy: 0.4711\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8620 - val_loss: 3.9335 - val_accuracy: 0.5844\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.8690 - val_loss: 3.9852 - val_accuracy: 0.5756\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.8782 - val_loss: 7.1523 - val_accuracy: 0.4044\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.8667 - val_loss: 2.2225 - val_accuracy: 0.5689\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.8750 - val_loss: 15.9260 - val_accuracy: 0.3467\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.8833 - val_loss: 7.3048 - val_accuracy: 0.3956\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.8856 - val_loss: 3.1286 - val_accuracy: 0.5689\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.8963 - val_loss: 2.5398 - val_accuracy: 0.5556\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.8935 - val_loss: 5.7733 - val_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2329 - accuracy: 0.8931 - val_loss: 3.6453 - val_accuracy: 0.5778\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.9079 - val_loss: 3.3517 - val_accuracy: 0.5267\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.8949 - val_loss: 3.2925 - val_accuracy: 0.5667\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9134 - val_loss: 5.3483 - val_accuracy: 0.4778\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9074 - val_loss: 6.0930 - val_accuracy: 0.5400\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9046 - val_loss: 4.1256 - val_accuracy: 0.4533\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9111 - val_loss: 3.2192 - val_accuracy: 0.5444\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.8963 - val_loss: 7.3463 - val_accuracy: 0.3733\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.9208 - val_loss: 4.3915 - val_accuracy: 0.5244\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9111 - val_loss: 4.7705 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9181 - val_loss: 6.9343 - val_accuracy: 0.4022\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9227 - val_loss: 5.5675 - val_accuracy: 0.5200\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9093 - val_loss: 16.9183 - val_accuracy: 0.3622\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9222 - val_loss: 15.1604 - val_accuracy: 0.4133\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.9269 - val_loss: 8.9848 - val_accuracy: 0.4778\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9343 - val_loss: 6.2978 - val_accuracy: 0.4711\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9227 - val_loss: 4.9605 - val_accuracy: 0.4289\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9227 - val_loss: 3.7711 - val_accuracy: 0.5378\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9324 - val_loss: 7.6440 - val_accuracy: 0.4556\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1503 - accuracy: 0.9352 - val_loss: 5.8344 - val_accuracy: 0.5489\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9380 - val_loss: 7.0521 - val_accuracy: 0.4644\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9440 - val_loss: 8.5899 - val_accuracy: 0.5067\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1634 - accuracy: 0.9269 - val_loss: 5.3332 - val_accuracy: 0.5378\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9301 - val_loss: 5.2738 - val_accuracy: 0.4800\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9384 - val_loss: 5.6941 - val_accuracy: 0.6089\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9398 - val_loss: 9.3124 - val_accuracy: 0.4667\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9481 - val_loss: 6.1826 - val_accuracy: 0.4511\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9426 - val_loss: 15.3734 - val_accuracy: 0.4244\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9472 - val_loss: 5.9580 - val_accuracy: 0.5156\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9426 - val_loss: 9.3048 - val_accuracy: 0.5422\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9444 - val_loss: 4.9275 - val_accuracy: 0.5622\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9444 - val_loss: 6.3401 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1611 - accuracy: 0.9310 - val_loss: 11.3122 - val_accuracy: 0.4578\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1366 - accuracy: 0.9463 - val_loss: 4.9374 - val_accuracy: 0.5244\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9514 - val_loss: 7.0721 - val_accuracy: 0.4933\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9509 - val_loss: 6.0771 - val_accuracy: 0.5067\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1203 - accuracy: 0.9514 - val_loss: 10.2150 - val_accuracy: 0.4244\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9537 - val_loss: 5.5971 - val_accuracy: 0.5222\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1182 - accuracy: 0.9514 - val_loss: 7.9443 - val_accuracy: 0.5867\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9472 - val_loss: 7.8972 - val_accuracy: 0.4800\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9565 - val_loss: 6.9541 - val_accuracy: 0.6178\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9509 - val_loss: 5.2551 - val_accuracy: 0.5889\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9477 - val_loss: 5.2712 - val_accuracy: 0.5556\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9611 - val_loss: 7.4987 - val_accuracy: 0.5311\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9514 - val_loss: 7.2049 - val_accuracy: 0.5822\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9500 - val_loss: 5.2372 - val_accuracy: 0.6000\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9602 - val_loss: 14.1804 - val_accuracy: 0.4267\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9611 - val_loss: 6.1652 - val_accuracy: 0.6000\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9644 - val_loss: 7.0735 - val_accuracy: 0.5533\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9644 - val_loss: 14.2921 - val_accuracy: 0.4156\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9565 - val_loss: 5.7033 - val_accuracy: 0.4978\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9574 - val_loss: 7.0100 - val_accuracy: 0.4844\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9616 - val_loss: 7.4130 - val_accuracy: 0.4911\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9722 - val_loss: 7.7312 - val_accuracy: 0.5267\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9519 - val_loss: 9.9148 - val_accuracy: 0.4800\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_140 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_140 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 25, 25, 10)        1900      \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_141 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_70 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 256)               368896    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 372,279\n",
      "Trainable params: 372,217\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2521 - accuracy: 0.4708 - val_loss: 1.1026 - val_accuracy: 0.3867\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8524 - accuracy: 0.5991 - val_loss: 1.1006 - val_accuracy: 0.3911\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.6648 - val_loss: 1.2300 - val_accuracy: 0.4756\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7130 - val_loss: 1.0517 - val_accuracy: 0.5022\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7454 - val_loss: 1.3011 - val_accuracy: 0.5778\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7866 - val_loss: 1.2580 - val_accuracy: 0.5200\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7995 - val_loss: 2.7919 - val_accuracy: 0.4889\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8106 - val_loss: 4.3104 - val_accuracy: 0.4467\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8250 - val_loss: 2.8899 - val_accuracy: 0.4422\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8458 - val_loss: 2.9933 - val_accuracy: 0.5111\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8630 - val_loss: 2.7714 - val_accuracy: 0.4067\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8551 - val_loss: 1.7810 - val_accuracy: 0.4711\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8690 - val_loss: 3.0838 - val_accuracy: 0.4956\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.8986 - val_loss: 2.2160 - val_accuracy: 0.5467\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8935 - val_loss: 4.5855 - val_accuracy: 0.4133\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.8912 - val_loss: 4.3919 - val_accuracy: 0.4489\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.9005 - val_loss: 2.6424 - val_accuracy: 0.5178\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.8907 - val_loss: 3.7380 - val_accuracy: 0.4822\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9060 - val_loss: 2.5570 - val_accuracy: 0.5622\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2043 - accuracy: 0.9120 - val_loss: 2.4660 - val_accuracy: 0.5422\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1921 - accuracy: 0.9130 - val_loss: 5.1021 - val_accuracy: 0.4533\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.9130 - val_loss: 2.6528 - val_accuracy: 0.5556\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9204 - val_loss: 3.0759 - val_accuracy: 0.4933\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9269 - val_loss: 6.3340 - val_accuracy: 0.4844\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9241 - val_loss: 7.9983 - val_accuracy: 0.4556\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9310 - val_loss: 3.1349 - val_accuracy: 0.5378\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9333 - val_loss: 3.0069 - val_accuracy: 0.5222\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9384 - val_loss: 2.4524 - val_accuracy: 0.5800\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9412 - val_loss: 3.3896 - val_accuracy: 0.5489\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9398 - val_loss: 4.4032 - val_accuracy: 0.5244\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9486 - val_loss: 2.9606 - val_accuracy: 0.5933\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9421 - val_loss: 6.8080 - val_accuracy: 0.4556\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9426 - val_loss: 5.3260 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9505 - val_loss: 5.6805 - val_accuracy: 0.5800\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9560 - val_loss: 5.6690 - val_accuracy: 0.4622\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9593 - val_loss: 8.7176 - val_accuracy: 0.4289\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9458 - val_loss: 4.5265 - val_accuracy: 0.5444\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9477 - val_loss: 3.1003 - val_accuracy: 0.5689\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9560 - val_loss: 2.7514 - val_accuracy: 0.5600\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9620 - val_loss: 3.5165 - val_accuracy: 0.5600\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9634 - val_loss: 5.7559 - val_accuracy: 0.4933\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9630 - val_loss: 3.8087 - val_accuracy: 0.5844\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0866 - accuracy: 0.9648 - val_loss: 5.7531 - val_accuracy: 0.4844\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9667 - val_loss: 3.4300 - val_accuracy: 0.5111\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1054 - accuracy: 0.9560 - val_loss: 3.5016 - val_accuracy: 0.5711\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9690 - val_loss: 11.2595 - val_accuracy: 0.4622\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9639 - val_loss: 3.2083 - val_accuracy: 0.5467\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9681 - val_loss: 3.3510 - val_accuracy: 0.6200\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9718 - val_loss: 5.8341 - val_accuracy: 0.4800\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9722 - val_loss: 7.2225 - val_accuracy: 0.5622\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9764 - val_loss: 3.9810 - val_accuracy: 0.5711\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9764 - val_loss: 5.9407 - val_accuracy: 0.4244\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9616 - val_loss: 4.1691 - val_accuracy: 0.5022\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9718 - val_loss: 6.4554 - val_accuracy: 0.4667\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 6.2923 - val_accuracy: 0.4844\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9736 - val_loss: 10.8643 - val_accuracy: 0.4311\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9662 - val_loss: 5.3110 - val_accuracy: 0.5067\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9713 - val_loss: 12.0086 - val_accuracy: 0.4400\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9690 - val_loss: 6.7297 - val_accuracy: 0.4778\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9787 - val_loss: 4.7379 - val_accuracy: 0.4756\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9792 - val_loss: 5.6474 - val_accuracy: 0.5044\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9782 - val_loss: 7.0456 - val_accuracy: 0.4889\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9847 - val_loss: 11.8382 - val_accuracy: 0.4444\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9778 - val_loss: 9.8277 - val_accuracy: 0.4756\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9694 - val_loss: 6.4421 - val_accuracy: 0.5578\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9773 - val_loss: 4.4188 - val_accuracy: 0.5644\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9769 - val_loss: 9.4377 - val_accuracy: 0.4622\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9801 - val_loss: 8.3404 - val_accuracy: 0.5156\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9801 - val_loss: 6.8834 - val_accuracy: 0.5022\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9861 - val_loss: 8.8625 - val_accuracy: 0.4622\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9810 - val_loss: 7.3076 - val_accuracy: 0.4267\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9736 - val_loss: 9.3006 - val_accuracy: 0.4622\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9792 - val_loss: 4.1187 - val_accuracy: 0.5511\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9843 - val_loss: 5.5597 - val_accuracy: 0.4933\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9870 - val_loss: 9.2388 - val_accuracy: 0.4711\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9889 - val_loss: 11.1257 - val_accuracy: 0.4778\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9778 - val_loss: 5.9186 - val_accuracy: 0.4867\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9824 - val_loss: 4.7148 - val_accuracy: 0.4911\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9824 - val_loss: 6.5165 - val_accuracy: 0.5400\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9875 - val_loss: 8.6139 - val_accuracy: 0.4978\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9819 - val_loss: 5.0162 - val_accuracy: 0.5267\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9856 - val_loss: 7.9234 - val_accuracy: 0.4889\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9856 - val_loss: 11.1692 - val_accuracy: 0.4400\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9824 - val_loss: 7.1347 - val_accuracy: 0.5200\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 10.2531 - val_accuracy: 0.4622\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 8.5480 - val_accuracy: 0.4400\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9894 - val_loss: 10.9853 - val_accuracy: 0.3911\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 7.7349 - val_accuracy: 0.5067\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9787 - val_loss: 9.0777 - val_accuracy: 0.4911\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9778 - val_loss: 6.8569 - val_accuracy: 0.6111\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 7.1278 - val_accuracy: 0.5911\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9898 - val_loss: 15.0550 - val_accuracy: 0.4956\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9741 - val_loss: 5.9816 - val_accuracy: 0.4978\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9829 - val_loss: 8.6292 - val_accuracy: 0.5133\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9801 - val_loss: 6.9933 - val_accuracy: 0.5289\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9866 - val_loss: 6.7990 - val_accuracy: 0.5400\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9870 - val_loss: 6.5769 - val_accuracy: 0.4622\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9912 - val_loss: 8.8745 - val_accuracy: 0.4933\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9847 - val_loss: 4.8916 - val_accuracy: 0.5533\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9875 - val_loss: 9.9698 - val_accuracy: 0.4689\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_142 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_138 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_142 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 25, 25, 12)        2280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_143 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_71 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 32)                55328     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 58,427\n",
      "Trainable params: 58,361\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1536 - accuracy: 0.3486 - val_loss: 1.0965 - val_accuracy: 0.3822\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0744 - accuracy: 0.3815 - val_loss: 1.0999 - val_accuracy: 0.3267\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0638 - accuracy: 0.3949 - val_loss: 1.1091 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0589 - accuracy: 0.4000 - val_loss: 1.1067 - val_accuracy: 0.3933\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0456 - accuracy: 0.4111 - val_loss: 1.1760 - val_accuracy: 0.3956\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0198 - accuracy: 0.4273 - val_loss: 1.0905 - val_accuracy: 0.5067\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0334 - accuracy: 0.4255 - val_loss: 1.1614 - val_accuracy: 0.5533\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0133 - accuracy: 0.4477 - val_loss: 1.0464 - val_accuracy: 0.5400\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.4431 - val_loss: 1.3886 - val_accuracy: 0.3978\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9993 - accuracy: 0.4417 - val_loss: 1.4460 - val_accuracy: 0.4600\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.4491 - val_loss: 1.6066 - val_accuracy: 0.4356\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9693 - accuracy: 0.4634 - val_loss: 1.4534 - val_accuracy: 0.5156\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9506 - accuracy: 0.4681 - val_loss: 1.5106 - val_accuracy: 0.3356\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9538 - accuracy: 0.4708 - val_loss: 1.1544 - val_accuracy: 0.4044\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9322 - accuracy: 0.4759 - val_loss: 1.9697 - val_accuracy: 0.4578\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9100 - accuracy: 0.4861 - val_loss: 2.4377 - val_accuracy: 0.5089\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9168 - accuracy: 0.4833 - val_loss: 1.2447 - val_accuracy: 0.4400\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9184 - accuracy: 0.4745 - val_loss: 1.5192 - val_accuracy: 0.5222\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9020 - accuracy: 0.4782 - val_loss: 2.5697 - val_accuracy: 0.5556\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8780 - accuracy: 0.4903 - val_loss: 1.3687 - val_accuracy: 0.5622\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8823 - accuracy: 0.4949 - val_loss: 2.3653 - val_accuracy: 0.3911\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8721 - accuracy: 0.5009 - val_loss: 2.1057 - val_accuracy: 0.5156\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8900 - accuracy: 0.4954 - val_loss: 1.0208 - val_accuracy: 0.4822\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8757 - accuracy: 0.5046 - val_loss: 2.8522 - val_accuracy: 0.4222\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8551 - accuracy: 0.5190 - val_loss: 1.2866 - val_accuracy: 0.4400\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8325 - accuracy: 0.5329 - val_loss: 2.0980 - val_accuracy: 0.4267\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8292 - accuracy: 0.5440 - val_loss: 1.4331 - val_accuracy: 0.4422\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8312 - accuracy: 0.5269 - val_loss: 1.7802 - val_accuracy: 0.5667\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8291 - accuracy: 0.5278 - val_loss: 2.2657 - val_accuracy: 0.4311\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8150 - accuracy: 0.5333 - val_loss: 1.7458 - val_accuracy: 0.4867\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8152 - accuracy: 0.5356 - val_loss: 1.9828 - val_accuracy: 0.4511\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8191 - accuracy: 0.5306 - val_loss: 2.3132 - val_accuracy: 0.4067\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7900 - accuracy: 0.5551 - val_loss: 1.4537 - val_accuracy: 0.4267\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8092 - accuracy: 0.5403 - val_loss: 1.3944 - val_accuracy: 0.3822\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.5486 - val_loss: 2.3909 - val_accuracy: 0.4289\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7960 - accuracy: 0.5421 - val_loss: 1.3319 - val_accuracy: 0.4178\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.5597 - val_loss: 1.5253 - val_accuracy: 0.3756\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.5644 - val_loss: 1.8400 - val_accuracy: 0.4267\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.5486 - val_loss: 2.5465 - val_accuracy: 0.5022\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7730 - accuracy: 0.5667 - val_loss: 2.0947 - val_accuracy: 0.4978\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7574 - accuracy: 0.5606 - val_loss: 1.6352 - val_accuracy: 0.3911\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7672 - accuracy: 0.5708 - val_loss: 2.3364 - val_accuracy: 0.4111\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7655 - accuracy: 0.5745 - val_loss: 1.9875 - val_accuracy: 0.3667\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.5667 - val_loss: 1.5931 - val_accuracy: 0.3533\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.5773 - val_loss: 3.0115 - val_accuracy: 0.4933\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.5708 - val_loss: 1.2105 - val_accuracy: 0.4333\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.5681 - val_loss: 2.8208 - val_accuracy: 0.4244\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.5778 - val_loss: 2.4084 - val_accuracy: 0.4267\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.5829 - val_loss: 2.0928 - val_accuracy: 0.3911\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.5736 - val_loss: 3.6106 - val_accuracy: 0.5089\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.5866 - val_loss: 2.4802 - val_accuracy: 0.4711\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7352 - accuracy: 0.5940 - val_loss: 3.1290 - val_accuracy: 0.4844\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.5977 - val_loss: 2.1785 - val_accuracy: 0.4733\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.6060 - val_loss: 2.3318 - val_accuracy: 0.4067\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.6069 - val_loss: 2.8468 - val_accuracy: 0.4511\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.6153 - val_loss: 2.6690 - val_accuracy: 0.4756\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7216 - accuracy: 0.5944 - val_loss: 2.7851 - val_accuracy: 0.4956\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 0.6116 - val_loss: 2.7966 - val_accuracy: 0.5222\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7086 - accuracy: 0.6134 - val_loss: 2.4219 - val_accuracy: 0.4200\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.6222 - val_loss: 2.0381 - val_accuracy: 0.4533\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7103 - accuracy: 0.6130 - val_loss: 4.5423 - val_accuracy: 0.4711\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.6190 - val_loss: 6.1151 - val_accuracy: 0.4222\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6227 - val_loss: 4.8936 - val_accuracy: 0.5244\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7106 - accuracy: 0.6264 - val_loss: 3.5881 - val_accuracy: 0.5244\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.6199 - val_loss: 2.8376 - val_accuracy: 0.5267\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.6366 - val_loss: 5.6834 - val_accuracy: 0.4422\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6472 - val_loss: 4.0882 - val_accuracy: 0.5378\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.6380 - val_loss: 3.0023 - val_accuracy: 0.4556\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.6218 - val_loss: 4.2300 - val_accuracy: 0.4578\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6301 - val_loss: 4.9427 - val_accuracy: 0.4644\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6546 - val_loss: 3.5634 - val_accuracy: 0.5111\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6481 - val_loss: 2.9221 - val_accuracy: 0.4022\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6468 - val_loss: 3.0280 - val_accuracy: 0.5044\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6463 - val_loss: 4.8398 - val_accuracy: 0.5467\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6500 - val_loss: 8.1934 - val_accuracy: 0.4267\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6449 - val_loss: 3.6046 - val_accuracy: 0.4778\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.6287 - val_loss: 3.1257 - val_accuracy: 0.4911\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6481 - val_loss: 3.2164 - val_accuracy: 0.4044\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6620 - val_loss: 4.0598 - val_accuracy: 0.5267\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6565 - val_loss: 3.4139 - val_accuracy: 0.5311\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6745 - val_loss: 3.8117 - val_accuracy: 0.4578\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6625 - val_loss: 4.4108 - val_accuracy: 0.4111\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6625 - val_loss: 2.9484 - val_accuracy: 0.4156\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6713 - val_loss: 4.6563 - val_accuracy: 0.4511\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6662 - val_loss: 3.7401 - val_accuracy: 0.4289\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6657 - val_loss: 2.2978 - val_accuracy: 0.4467\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6685 - val_loss: 2.4295 - val_accuracy: 0.4956\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6537 - val_loss: 3.6065 - val_accuracy: 0.4733\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6764 - val_loss: 2.0709 - val_accuracy: 0.4333\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.6616 - val_loss: 5.1387 - val_accuracy: 0.4844\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6630 - val_loss: 3.4473 - val_accuracy: 0.5200\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6769 - val_loss: 5.7582 - val_accuracy: 0.4444\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6907 - val_loss: 3.1527 - val_accuracy: 0.5156\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6778 - val_loss: 4.0859 - val_accuracy: 0.4311\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6616 - val_loss: 5.0972 - val_accuracy: 0.5200\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6801 - val_loss: 6.6397 - val_accuracy: 0.4444\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6579 - val_loss: 2.1883 - val_accuracy: 0.4022\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6091 - accuracy: 0.6880 - val_loss: 3.0278 - val_accuracy: 0.4733\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6713 - val_loss: 4.7285 - val_accuracy: 0.4933\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6704 - val_loss: 4.2794 - val_accuracy: 0.5022\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_144 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_144 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 25, 25, 12)        2280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_145 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_72 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 113,851\n",
      "Trainable params: 113,785\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1895 - accuracy: 0.3773 - val_loss: 1.1008 - val_accuracy: 0.3067\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0486 - accuracy: 0.4065 - val_loss: 1.1078 - val_accuracy: 0.3267\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0219 - accuracy: 0.4227 - val_loss: 1.0704 - val_accuracy: 0.4178\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9901 - accuracy: 0.4259 - val_loss: 1.0127 - val_accuracy: 0.4600\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9447 - accuracy: 0.4444 - val_loss: 1.0629 - val_accuracy: 0.4578\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9626 - accuracy: 0.4769 - val_loss: 1.0296 - val_accuracy: 0.4378\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8890 - accuracy: 0.5083 - val_loss: 1.7487 - val_accuracy: 0.4222\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8963 - accuracy: 0.5056 - val_loss: 1.1348 - val_accuracy: 0.4733\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.5190 - val_loss: 1.2992 - val_accuracy: 0.4978\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8465 - accuracy: 0.5356 - val_loss: 1.0571 - val_accuracy: 0.5222\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8085 - accuracy: 0.5523 - val_loss: 1.6320 - val_accuracy: 0.4378\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8065 - accuracy: 0.5616 - val_loss: 1.0266 - val_accuracy: 0.5200\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7633 - accuracy: 0.5829 - val_loss: 1.0341 - val_accuracy: 0.5511\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.6051 - val_loss: 1.4279 - val_accuracy: 0.4600\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.6130 - val_loss: 1.1832 - val_accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7111 - accuracy: 0.6204 - val_loss: 1.0712 - val_accuracy: 0.4800\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.6324 - val_loss: 1.3673 - val_accuracy: 0.4733\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.6273 - val_loss: 1.5733 - val_accuracy: 0.4533\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.6352 - val_loss: 1.1266 - val_accuracy: 0.5911\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6356 - val_loss: 1.4616 - val_accuracy: 0.4867\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.6569 - val_loss: 1.3992 - val_accuracy: 0.5667\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6505 - accuracy: 0.6491 - val_loss: 1.3240 - val_accuracy: 0.4889\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6491 - val_loss: 1.7671 - val_accuracy: 0.4467\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.6843 - val_loss: 1.4559 - val_accuracy: 0.5711\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6708 - val_loss: 1.3085 - val_accuracy: 0.4711\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.6819 - val_loss: 1.6014 - val_accuracy: 0.4911\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.6898 - val_loss: 1.7926 - val_accuracy: 0.4978\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.6981 - val_loss: 2.7694 - val_accuracy: 0.4556\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7009 - val_loss: 1.8108 - val_accuracy: 0.4733\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7051 - val_loss: 2.2174 - val_accuracy: 0.5422\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7125 - val_loss: 3.4541 - val_accuracy: 0.4778\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7019 - val_loss: 2.7998 - val_accuracy: 0.4733\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7065 - val_loss: 3.4742 - val_accuracy: 0.4578\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7181 - val_loss: 2.6557 - val_accuracy: 0.4889\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7065 - val_loss: 3.5137 - val_accuracy: 0.4578\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7139 - val_loss: 2.9083 - val_accuracy: 0.4711\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7190 - val_loss: 2.7615 - val_accuracy: 0.4556\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7250 - val_loss: 3.6468 - val_accuracy: 0.5022\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7366 - val_loss: 3.0645 - val_accuracy: 0.4800\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7273 - val_loss: 3.1692 - val_accuracy: 0.4422\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7384 - val_loss: 2.6933 - val_accuracy: 0.5044\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7218 - val_loss: 2.0030 - val_accuracy: 0.4667\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7222 - val_loss: 2.3045 - val_accuracy: 0.4222\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7227 - val_loss: 1.9716 - val_accuracy: 0.4622\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7491 - val_loss: 3.2659 - val_accuracy: 0.4489\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7319 - val_loss: 3.1955 - val_accuracy: 0.3889\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7440 - val_loss: 2.3496 - val_accuracy: 0.4911\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7505 - val_loss: 3.2882 - val_accuracy: 0.4600\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7426 - val_loss: 2.2061 - val_accuracy: 0.4644\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7417 - val_loss: 3.6588 - val_accuracy: 0.4444\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7421 - val_loss: 2.8994 - val_accuracy: 0.4200\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7481 - val_loss: 6.2316 - val_accuracy: 0.3689\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7315 - val_loss: 5.8398 - val_accuracy: 0.4133\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4673 - accuracy: 0.7458 - val_loss: 4.8960 - val_accuracy: 0.4022\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4703 - accuracy: 0.7486 - val_loss: 3.4317 - val_accuracy: 0.5067\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4783 - accuracy: 0.7389 - val_loss: 4.0461 - val_accuracy: 0.4578\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7667 - val_loss: 5.3456 - val_accuracy: 0.4933\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7519 - val_loss: 3.2612 - val_accuracy: 0.4400\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7653 - val_loss: 3.4763 - val_accuracy: 0.5133\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7736 - val_loss: 3.9194 - val_accuracy: 0.4800\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7704 - val_loss: 3.8459 - val_accuracy: 0.4844\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7648 - val_loss: 3.0742 - val_accuracy: 0.4556\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7745 - val_loss: 3.0691 - val_accuracy: 0.5222\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7634 - val_loss: 3.9406 - val_accuracy: 0.5156\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7819 - val_loss: 3.5502 - val_accuracy: 0.4556\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.7847 - val_loss: 4.6469 - val_accuracy: 0.4133\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.7806 - val_loss: 4.2185 - val_accuracy: 0.4644\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7792 - val_loss: 4.3960 - val_accuracy: 0.5089\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.7843 - val_loss: 3.2413 - val_accuracy: 0.5111\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.7921 - val_loss: 4.7088 - val_accuracy: 0.4178\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.7810 - val_loss: 4.9971 - val_accuracy: 0.4444\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7963 - val_loss: 5.3012 - val_accuracy: 0.4378\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7806 - val_loss: 3.4352 - val_accuracy: 0.5600\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.7949 - val_loss: 4.4379 - val_accuracy: 0.4733\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.7810 - val_loss: 4.1939 - val_accuracy: 0.4867\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.7940 - val_loss: 4.8751 - val_accuracy: 0.5222\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.7968 - val_loss: 4.5148 - val_accuracy: 0.5178\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8093 - val_loss: 3.9186 - val_accuracy: 0.5444\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8009 - val_loss: 4.3771 - val_accuracy: 0.5089\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8097 - val_loss: 4.9166 - val_accuracy: 0.5356\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8014 - val_loss: 4.8971 - val_accuracy: 0.4933\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.7907 - val_loss: 4.1176 - val_accuracy: 0.4911\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8023 - val_loss: 3.9853 - val_accuracy: 0.4622\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8093 - val_loss: 5.0816 - val_accuracy: 0.4733\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8056 - val_loss: 6.6908 - val_accuracy: 0.4333\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8106 - val_loss: 6.7500 - val_accuracy: 0.4578\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8032 - val_loss: 4.4411 - val_accuracy: 0.4689\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.7898 - val_loss: 5.0947 - val_accuracy: 0.4822\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8171 - val_loss: 7.0395 - val_accuracy: 0.4711\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8125 - val_loss: 3.9804 - val_accuracy: 0.4578\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8097 - val_loss: 4.3170 - val_accuracy: 0.4511\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8116 - val_loss: 5.3831 - val_accuracy: 0.4911\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8148 - val_loss: 6.1275 - val_accuracy: 0.4533\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8227 - val_loss: 5.0408 - val_accuracy: 0.4711\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8199 - val_loss: 13.8182 - val_accuracy: 0.3778\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8264 - val_loss: 6.3069 - val_accuracy: 0.4978\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8194 - val_loss: 4.6963 - val_accuracy: 0.4978\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8347 - val_loss: 5.5688 - val_accuracy: 0.4689\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8176 - val_loss: 5.0186 - val_accuracy: 0.5422\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8199 - val_loss: 6.3895 - val_accuracy: 0.5267\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_146 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_146 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 25, 25, 12)        2280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_147 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_73 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 224,699\n",
      "Trainable params: 224,633\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2453 - accuracy: 0.4315 - val_loss: 1.0954 - val_accuracy: 0.4978\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9446 - accuracy: 0.5046 - val_loss: 1.0655 - val_accuracy: 0.4289\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8560 - accuracy: 0.5625 - val_loss: 1.0145 - val_accuracy: 0.5133\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7766 - accuracy: 0.5852 - val_loss: 0.9324 - val_accuracy: 0.5756\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.6384 - val_loss: 1.3630 - val_accuracy: 0.4578\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.6301 - val_loss: 1.4640 - val_accuracy: 0.4511\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6431 - val_loss: 3.2926 - val_accuracy: 0.3356\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6574 - val_loss: 1.2751 - val_accuracy: 0.5244\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.6880 - val_loss: 2.6920 - val_accuracy: 0.4422\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.6954 - val_loss: 2.0973 - val_accuracy: 0.4533\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7181 - val_loss: 1.4187 - val_accuracy: 0.5444\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7227 - val_loss: 1.7719 - val_accuracy: 0.5311\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7560 - val_loss: 1.5550 - val_accuracy: 0.5756\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7463 - val_loss: 2.9606 - val_accuracy: 0.4200\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7653 - val_loss: 4.0971 - val_accuracy: 0.4200\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7685 - val_loss: 2.0446 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.7995 - val_loss: 2.6184 - val_accuracy: 0.4400\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.7796 - val_loss: 1.8705 - val_accuracy: 0.5533\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4210 - accuracy: 0.7755 - val_loss: 2.1035 - val_accuracy: 0.5533\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.7866 - val_loss: 4.6327 - val_accuracy: 0.3400\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.7977 - val_loss: 1.6760 - val_accuracy: 0.6022\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.7912 - val_loss: 4.0086 - val_accuracy: 0.3333\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8000 - val_loss: 4.2200 - val_accuracy: 0.4844\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8208 - val_loss: 3.7770 - val_accuracy: 0.4067\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8301 - val_loss: 3.2684 - val_accuracy: 0.4356\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8241 - val_loss: 2.6426 - val_accuracy: 0.4844\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8380 - val_loss: 2.3868 - val_accuracy: 0.4956\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8241 - val_loss: 4.1336 - val_accuracy: 0.5667\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8426 - val_loss: 4.8215 - val_accuracy: 0.4711\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8505 - val_loss: 3.3603 - val_accuracy: 0.4733\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8509 - val_loss: 6.1042 - val_accuracy: 0.3844\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8509 - val_loss: 3.4741 - val_accuracy: 0.5867\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8546 - val_loss: 3.4467 - val_accuracy: 0.4600\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8685 - val_loss: 4.3036 - val_accuracy: 0.4600\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8653 - val_loss: 4.0022 - val_accuracy: 0.5044\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.8653 - val_loss: 3.2180 - val_accuracy: 0.4444\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8583 - val_loss: 5.4134 - val_accuracy: 0.4311\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.8801 - val_loss: 3.6023 - val_accuracy: 0.4333\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.8819 - val_loss: 2.8395 - val_accuracy: 0.5533\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2290 - accuracy: 0.8819 - val_loss: 4.7682 - val_accuracy: 0.4822\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.8898 - val_loss: 3.8372 - val_accuracy: 0.5689\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.8806 - val_loss: 4.8572 - val_accuracy: 0.4778\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.8838 - val_loss: 3.6345 - val_accuracy: 0.5044\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.8954 - val_loss: 4.0425 - val_accuracy: 0.5400\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.8940 - val_loss: 4.7702 - val_accuracy: 0.4511\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9065 - val_loss: 3.6636 - val_accuracy: 0.5311\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.8981 - val_loss: 3.8570 - val_accuracy: 0.5556\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2215 - accuracy: 0.8926 - val_loss: 7.7233 - val_accuracy: 0.4311\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9051 - val_loss: 5.8779 - val_accuracy: 0.5689\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.9051 - val_loss: 4.0492 - val_accuracy: 0.5844\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9005 - val_loss: 14.8163 - val_accuracy: 0.3622\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9060 - val_loss: 3.8599 - val_accuracy: 0.5178\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9181 - val_loss: 3.8868 - val_accuracy: 0.5311\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9116 - val_loss: 4.7091 - val_accuracy: 0.5022\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9194 - val_loss: 3.8912 - val_accuracy: 0.5511\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1597 - accuracy: 0.9148 - val_loss: 6.6492 - val_accuracy: 0.4756\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9120 - val_loss: 6.9302 - val_accuracy: 0.4511\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9120 - val_loss: 5.0249 - val_accuracy: 0.4133\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9194 - val_loss: 17.6695 - val_accuracy: 0.3311\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9139 - val_loss: 6.5132 - val_accuracy: 0.5044\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9241 - val_loss: 6.9115 - val_accuracy: 0.4711\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9269 - val_loss: 5.1797 - val_accuracy: 0.5644\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9310 - val_loss: 5.3150 - val_accuracy: 0.5978\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9329 - val_loss: 5.3217 - val_accuracy: 0.5356\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.9370 - val_loss: 9.0073 - val_accuracy: 0.4511\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9370 - val_loss: 9.1132 - val_accuracy: 0.3911\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9352 - val_loss: 6.6808 - val_accuracy: 0.5067\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1496 - accuracy: 0.9310 - val_loss: 6.0683 - val_accuracy: 0.4911\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9287 - val_loss: 5.3737 - val_accuracy: 0.5467\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9426 - val_loss: 6.0409 - val_accuracy: 0.5556\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9343 - val_loss: 7.5468 - val_accuracy: 0.5022\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9440 - val_loss: 8.3155 - val_accuracy: 0.5089\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9403 - val_loss: 5.0784 - val_accuracy: 0.6444\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.9417 - val_loss: 5.9815 - val_accuracy: 0.5178\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9389 - val_loss: 5.4716 - val_accuracy: 0.5311\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1133 - accuracy: 0.9500 - val_loss: 4.9970 - val_accuracy: 0.5822\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9417 - val_loss: 6.3477 - val_accuracy: 0.5133\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9537 - val_loss: 6.6364 - val_accuracy: 0.5711\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9481 - val_loss: 7.4739 - val_accuracy: 0.5067\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9486 - val_loss: 5.3670 - val_accuracy: 0.5822\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9431 - val_loss: 5.6559 - val_accuracy: 0.4956\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9468 - val_loss: 6.4774 - val_accuracy: 0.5222\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9583 - val_loss: 9.4341 - val_accuracy: 0.4578\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9431 - val_loss: 10.3573 - val_accuracy: 0.4711\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9551 - val_loss: 12.1591 - val_accuracy: 0.4267\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1092 - accuracy: 0.9588 - val_loss: 28.0469 - val_accuracy: 0.3267\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9505 - val_loss: 9.4781 - val_accuracy: 0.4378\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9546 - val_loss: 5.7951 - val_accuracy: 0.5689\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9620 - val_loss: 8.7204 - val_accuracy: 0.4933\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9537 - val_loss: 10.3607 - val_accuracy: 0.4533\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9574 - val_loss: 10.1574 - val_accuracy: 0.4378\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9597 - val_loss: 13.4068 - val_accuracy: 0.4667\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9597 - val_loss: 8.6873 - val_accuracy: 0.5622\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9657 - val_loss: 8.7039 - val_accuracy: 0.4533\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9620 - val_loss: 10.6975 - val_accuracy: 0.4622\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9602 - val_loss: 7.3661 - val_accuracy: 0.4667\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9639 - val_loss: 9.5895 - val_accuracy: 0.4778\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9556 - val_loss: 6.7168 - val_accuracy: 0.5422\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9616 - val_loss: 6.5173 - val_accuracy: 0.6378\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9699 - val_loss: 7.6566 - val_accuracy: 0.4756\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_148 (Conv2D)          (None, 54, 54, 21)        588       \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 54, 54, 21)        84        \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 54, 54, 21)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_148 (MaxPoolin (None, 27, 27, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 25, 25, 12)        2280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_149 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_74 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 256)               442624    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 446,395\n",
      "Trainable params: 446,329\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.3555 - accuracy: 0.4565 - val_loss: 1.1034 - val_accuracy: 0.3733\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8884 - accuracy: 0.5375 - val_loss: 1.0630 - val_accuracy: 0.4867\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7791 - accuracy: 0.6245 - val_loss: 1.0714 - val_accuracy: 0.4867\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.6750 - val_loss: 1.0541 - val_accuracy: 0.5200\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7301 - val_loss: 2.9302 - val_accuracy: 0.4733\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7523 - val_loss: 4.9143 - val_accuracy: 0.3778\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7926 - val_loss: 3.8361 - val_accuracy: 0.4822\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7931 - val_loss: 2.8573 - val_accuracy: 0.4289\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8231 - val_loss: 4.3759 - val_accuracy: 0.4800\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8278 - val_loss: 3.0613 - val_accuracy: 0.5289\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8444 - val_loss: 2.6763 - val_accuracy: 0.5578\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8546 - val_loss: 2.4884 - val_accuracy: 0.4600\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8625 - val_loss: 1.9934 - val_accuracy: 0.5156\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8593 - val_loss: 3.6454 - val_accuracy: 0.5778\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8694 - val_loss: 3.9517 - val_accuracy: 0.5556\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.8787 - val_loss: 4.2725 - val_accuracy: 0.4889\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.8991 - val_loss: 2.2844 - val_accuracy: 0.5044\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.8944 - val_loss: 5.5567 - val_accuracy: 0.5111\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.8940 - val_loss: 7.4421 - val_accuracy: 0.4444\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9088 - val_loss: 3.9271 - val_accuracy: 0.5067\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9088 - val_loss: 4.9785 - val_accuracy: 0.5022\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9111 - val_loss: 9.8896 - val_accuracy: 0.3933\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2231 - accuracy: 0.8954 - val_loss: 8.1072 - val_accuracy: 0.4467\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9130 - val_loss: 19.5478 - val_accuracy: 0.3333\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1862 - accuracy: 0.9259 - val_loss: 4.9979 - val_accuracy: 0.5067\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1874 - accuracy: 0.9167 - val_loss: 4.5141 - val_accuracy: 0.5867\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1764 - accuracy: 0.9245 - val_loss: 4.8310 - val_accuracy: 0.5600\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9287 - val_loss: 13.5871 - val_accuracy: 0.4156\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9194 - val_loss: 4.7636 - val_accuracy: 0.4267\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9352 - val_loss: 9.8968 - val_accuracy: 0.4356\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9282 - val_loss: 6.9675 - val_accuracy: 0.5178\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9449 - val_loss: 13.9213 - val_accuracy: 0.4356\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9486 - val_loss: 12.2241 - val_accuracy: 0.4333\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9324 - val_loss: 4.1406 - val_accuracy: 0.5844\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9477 - val_loss: 9.1550 - val_accuracy: 0.5200\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9431 - val_loss: 10.6886 - val_accuracy: 0.4200\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9486 - val_loss: 4.3334 - val_accuracy: 0.5822\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9514 - val_loss: 4.7213 - val_accuracy: 0.6089\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9477 - val_loss: 7.6997 - val_accuracy: 0.5378\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9556 - val_loss: 5.6249 - val_accuracy: 0.5956\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9625 - val_loss: 4.9314 - val_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9574 - val_loss: 5.7815 - val_accuracy: 0.5956\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9593 - val_loss: 4.6638 - val_accuracy: 0.5711\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9602 - val_loss: 4.6999 - val_accuracy: 0.5711\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9625 - val_loss: 11.3992 - val_accuracy: 0.4333\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9579 - val_loss: 7.2471 - val_accuracy: 0.5578\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9611 - val_loss: 6.7671 - val_accuracy: 0.5222\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9639 - val_loss: 6.6983 - val_accuracy: 0.5644\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9690 - val_loss: 6.9708 - val_accuracy: 0.5511\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9634 - val_loss: 10.8762 - val_accuracy: 0.4489\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9731 - val_loss: 7.7340 - val_accuracy: 0.5044\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9713 - val_loss: 14.7124 - val_accuracy: 0.4067\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9671 - val_loss: 7.7652 - val_accuracy: 0.5156\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9676 - val_loss: 7.0711 - val_accuracy: 0.5533\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9676 - val_loss: 10.3275 - val_accuracy: 0.4511\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9681 - val_loss: 9.9386 - val_accuracy: 0.4933\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9699 - val_loss: 11.2280 - val_accuracy: 0.4489\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9671 - val_loss: 9.4990 - val_accuracy: 0.5311\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9731 - val_loss: 5.6132 - val_accuracy: 0.5556\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9755 - val_loss: 9.8634 - val_accuracy: 0.4733\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9690 - val_loss: 8.0357 - val_accuracy: 0.4222\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9755 - val_loss: 12.4675 - val_accuracy: 0.4422\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9699 - val_loss: 19.8569 - val_accuracy: 0.3711\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9750 - val_loss: 7.8733 - val_accuracy: 0.4844\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9731 - val_loss: 11.3681 - val_accuracy: 0.4267\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9741 - val_loss: 12.9648 - val_accuracy: 0.4311\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9736 - val_loss: 8.4800 - val_accuracy: 0.4689\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9741 - val_loss: 9.0441 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0668 - accuracy: 0.9704 - val_loss: 26.8737 - val_accuracy: 0.3511\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9833 - val_loss: 8.8146 - val_accuracy: 0.4867\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9792 - val_loss: 9.2313 - val_accuracy: 0.5422\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9801 - val_loss: 14.5364 - val_accuracy: 0.3933\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9769 - val_loss: 9.0220 - val_accuracy: 0.4711\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9843 - val_loss: 8.4925 - val_accuracy: 0.5400\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9792 - val_loss: 6.3012 - val_accuracy: 0.5200\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9731 - val_loss: 14.2217 - val_accuracy: 0.5067\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9769 - val_loss: 7.7262 - val_accuracy: 0.5133\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9782 - val_loss: 6.7641 - val_accuracy: 0.5067\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9861 - val_loss: 11.5132 - val_accuracy: 0.4644\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9833 - val_loss: 14.6553 - val_accuracy: 0.4756\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9806 - val_loss: 11.1153 - val_accuracy: 0.5422\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 8.2920 - val_accuracy: 0.5067\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9843 - val_loss: 7.5251 - val_accuracy: 0.5044\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9861 - val_loss: 20.0169 - val_accuracy: 0.3978\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9838 - val_loss: 17.4641 - val_accuracy: 0.3911\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9861 - val_loss: 8.1436 - val_accuracy: 0.5911\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9870 - val_loss: 8.4929 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9847 - val_loss: 18.5801 - val_accuracy: 0.4311\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9852 - val_loss: 10.4068 - val_accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 16.2890 - val_accuracy: 0.4267\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0393 - accuracy: 0.9843 - val_loss: 6.3962 - val_accuracy: 0.5689\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 15.6122 - val_accuracy: 0.4378\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 16.9460 - val_accuracy: 0.4156\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 8.3260 - val_accuracy: 0.5556\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 11.9980 - val_accuracy: 0.4244\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9843 - val_loss: 9.2642 - val_accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 10.2921 - val_accuracy: 0.5111\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9838 - val_loss: 17.5886 - val_accuracy: 0.4111\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9833 - val_loss: 7.3532 - val_accuracy: 0.5733\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9847 - val_loss: 12.9192 - val_accuracy: 0.4600\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_150 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_150 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 25, 25, 8)         1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_151 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_75 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 39,531\n",
      "Trainable params: 39,467\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1724 - accuracy: 0.3616 - val_loss: 1.0969 - val_accuracy: 0.3133\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0668 - accuracy: 0.3759 - val_loss: 1.0869 - val_accuracy: 0.3933\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0412 - accuracy: 0.3931 - val_loss: 1.0956 - val_accuracy: 0.3356\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0319 - accuracy: 0.4116 - val_loss: 1.1027 - val_accuracy: 0.3533\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0138 - accuracy: 0.4213 - val_loss: 1.1270 - val_accuracy: 0.4400\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9969 - accuracy: 0.4255 - val_loss: 1.4369 - val_accuracy: 0.3600\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.4329 - val_loss: 1.0770 - val_accuracy: 0.4467\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9706 - accuracy: 0.4477 - val_loss: 1.2384 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9576 - accuracy: 0.4514 - val_loss: 2.4511 - val_accuracy: 0.3200\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9374 - accuracy: 0.4671 - val_loss: 2.0684 - val_accuracy: 0.4333\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9101 - accuracy: 0.4852 - val_loss: 1.3642 - val_accuracy: 0.3911\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9168 - accuracy: 0.4912 - val_loss: 1.4958 - val_accuracy: 0.3844\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9072 - accuracy: 0.4894 - val_loss: 1.5375 - val_accuracy: 0.4222\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8884 - accuracy: 0.4991 - val_loss: 2.0140 - val_accuracy: 0.5556\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8962 - accuracy: 0.4833 - val_loss: 1.3298 - val_accuracy: 0.4267\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8440 - accuracy: 0.5380 - val_loss: 4.2593 - val_accuracy: 0.3200\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8551 - accuracy: 0.5287 - val_loss: 4.7708 - val_accuracy: 0.3378\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8595 - accuracy: 0.5338 - val_loss: 1.2779 - val_accuracy: 0.4378\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8159 - accuracy: 0.5569 - val_loss: 1.6220 - val_accuracy: 0.5067\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8396 - accuracy: 0.5421 - val_loss: 1.3418 - val_accuracy: 0.4511\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8086 - accuracy: 0.5569 - val_loss: 1.3422 - val_accuracy: 0.4978\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8460 - accuracy: 0.5440 - val_loss: 1.3702 - val_accuracy: 0.5111\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8039 - accuracy: 0.5667 - val_loss: 1.8782 - val_accuracy: 0.4378\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8207 - accuracy: 0.5579 - val_loss: 1.1644 - val_accuracy: 0.4822\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8054 - accuracy: 0.5671 - val_loss: 1.3009 - val_accuracy: 0.5178\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8299 - accuracy: 0.5606 - val_loss: 3.0923 - val_accuracy: 0.3467\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7856 - accuracy: 0.5713 - val_loss: 1.6561 - val_accuracy: 0.6044\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.5861 - val_loss: 1.7151 - val_accuracy: 0.5511\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7699 - accuracy: 0.5944 - val_loss: 2.9282 - val_accuracy: 0.4400\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7715 - accuracy: 0.5912 - val_loss: 2.4309 - val_accuracy: 0.5822\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7711 - accuracy: 0.5875 - val_loss: 2.4139 - val_accuracy: 0.4911\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7621 - accuracy: 0.5884 - val_loss: 3.5983 - val_accuracy: 0.4511\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.6005 - val_loss: 2.7156 - val_accuracy: 0.5667\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.5963 - val_loss: 1.8941 - val_accuracy: 0.4400\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7409 - accuracy: 0.5972 - val_loss: 1.5702 - val_accuracy: 0.5400\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.6134 - val_loss: 2.1622 - val_accuracy: 0.4267\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.6153 - val_loss: 1.1907 - val_accuracy: 0.5356\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.6083 - val_loss: 2.6643 - val_accuracy: 0.4556\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.6176 - val_loss: 3.2562 - val_accuracy: 0.5178\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.6102 - val_loss: 1.7394 - val_accuracy: 0.5378\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7368 - accuracy: 0.6083 - val_loss: 1.6883 - val_accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7221 - accuracy: 0.6097 - val_loss: 2.3711 - val_accuracy: 0.4956\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.6176 - val_loss: 1.5094 - val_accuracy: 0.5400\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.6222 - val_loss: 1.2438 - val_accuracy: 0.5400\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.6181 - val_loss: 2.1851 - val_accuracy: 0.5289\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.6236 - val_loss: 2.7644 - val_accuracy: 0.4756\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.6417 - val_loss: 2.1716 - val_accuracy: 0.5622\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.6435 - val_loss: 2.0182 - val_accuracy: 0.4800\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6468 - val_loss: 1.6898 - val_accuracy: 0.5844\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6528 - val_loss: 1.8522 - val_accuracy: 0.5400\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6556 - val_loss: 2.5080 - val_accuracy: 0.5400\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6491 - val_loss: 1.7029 - val_accuracy: 0.5222\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6588 - val_loss: 5.1290 - val_accuracy: 0.4356\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.6671 - val_loss: 4.5585 - val_accuracy: 0.3667\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6449 - val_loss: 2.1896 - val_accuracy: 0.5422\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6546 - val_loss: 3.3319 - val_accuracy: 0.5289\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6667 - val_loss: 6.6527 - val_accuracy: 0.3689\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6708 - val_loss: 9.3088 - val_accuracy: 0.3356\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6718 - val_loss: 2.5872 - val_accuracy: 0.5844\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6833 - val_loss: 1.9089 - val_accuracy: 0.5956\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6699 - val_loss: 2.2178 - val_accuracy: 0.6067\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6722 - val_loss: 2.1491 - val_accuracy: 0.5600\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6657 - val_loss: 3.9420 - val_accuracy: 0.4578\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6829 - val_loss: 3.0341 - val_accuracy: 0.5822\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6681 - val_loss: 3.1729 - val_accuracy: 0.5044\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6810 - val_loss: 2.6464 - val_accuracy: 0.4956\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6653 - val_loss: 3.9080 - val_accuracy: 0.4978\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6824 - val_loss: 2.3877 - val_accuracy: 0.5400\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.6815 - val_loss: 2.0826 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6819 - val_loss: 2.9316 - val_accuracy: 0.5311\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6713 - val_loss: 2.8004 - val_accuracy: 0.5644\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6917 - val_loss: 4.7120 - val_accuracy: 0.3800\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.6926 - val_loss: 2.8607 - val_accuracy: 0.5644\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6856 - val_loss: 4.0585 - val_accuracy: 0.5311\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6870 - val_loss: 3.4365 - val_accuracy: 0.4822\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6843 - val_loss: 3.9925 - val_accuracy: 0.4644\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7014 - val_loss: 3.6716 - val_accuracy: 0.5133\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.6991 - val_loss: 3.8556 - val_accuracy: 0.4956\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7019 - val_loss: 3.4477 - val_accuracy: 0.5178\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6713 - val_loss: 4.0862 - val_accuracy: 0.5267\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7000 - val_loss: 5.4471 - val_accuracy: 0.4378\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.6958 - val_loss: 6.5813 - val_accuracy: 0.4156\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7065 - val_loss: 4.4159 - val_accuracy: 0.4867\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6889 - val_loss: 5.1045 - val_accuracy: 0.5067\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6935 - val_loss: 3.1653 - val_accuracy: 0.4933\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7042 - val_loss: 4.1830 - val_accuracy: 0.4711\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.6880 - val_loss: 4.6760 - val_accuracy: 0.5067\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.6981 - val_loss: 4.3753 - val_accuracy: 0.4356\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.6838 - val_loss: 2.9678 - val_accuracy: 0.5644\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7065 - val_loss: 4.1177 - val_accuracy: 0.5289\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.6995 - val_loss: 4.8166 - val_accuracy: 0.5400\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7102 - val_loss: 4.0589 - val_accuracy: 0.5667\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.6782 - val_loss: 3.6832 - val_accuracy: 0.5911\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7051 - val_loss: 5.0030 - val_accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5298 - accuracy: 0.7130 - val_loss: 4.3788 - val_accuracy: 0.5267\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7088 - val_loss: 4.9092 - val_accuracy: 0.5422\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7231 - val_loss: 3.1690 - val_accuracy: 0.5444\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7056 - val_loss: 3.6902 - val_accuracy: 0.5644\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7125 - val_loss: 4.0278 - val_accuracy: 0.5533\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7213 - val_loss: 4.4424 - val_accuracy: 0.5489\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_152 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_148 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_152 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 25, 25, 8)         1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_149 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_153 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_76 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 76,523\n",
      "Trainable params: 76,459\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1510 - accuracy: 0.3644 - val_loss: 1.0914 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0436 - accuracy: 0.3843 - val_loss: 1.0881 - val_accuracy: 0.3156\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0137 - accuracy: 0.4125 - val_loss: 1.0735 - val_accuracy: 0.3933\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9727 - accuracy: 0.4662 - val_loss: 1.0388 - val_accuracy: 0.5267\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9233 - accuracy: 0.4954 - val_loss: 1.3389 - val_accuracy: 0.6267\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9363 - accuracy: 0.5097 - val_loss: 1.0482 - val_accuracy: 0.4778\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8825 - accuracy: 0.5301 - val_loss: 1.4610 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8122 - accuracy: 0.5796 - val_loss: 1.4034 - val_accuracy: 0.4844\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7827 - accuracy: 0.6051 - val_loss: 1.2425 - val_accuracy: 0.4533\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7481 - accuracy: 0.6222 - val_loss: 1.8477 - val_accuracy: 0.3756\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.6120 - val_loss: 3.1750 - val_accuracy: 0.4311\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.6366 - val_loss: 2.1598 - val_accuracy: 0.5289\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6593 - val_loss: 1.6342 - val_accuracy: 0.4089\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6620 - val_loss: 6.9498 - val_accuracy: 0.4911\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6699 - val_loss: 2.0021 - val_accuracy: 0.4067\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6889 - val_loss: 2.1725 - val_accuracy: 0.4089\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7032 - val_loss: 2.4021 - val_accuracy: 0.4333\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.7042 - val_loss: 1.8366 - val_accuracy: 0.4400\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7194 - val_loss: 2.4488 - val_accuracy: 0.4133\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7106 - val_loss: 1.7418 - val_accuracy: 0.3978\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7319 - val_loss: 4.3656 - val_accuracy: 0.4511\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7380 - val_loss: 4.8350 - val_accuracy: 0.4756\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7306 - val_loss: 2.5404 - val_accuracy: 0.4222\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7579 - val_loss: 1.1927 - val_accuracy: 0.5222\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7514 - val_loss: 2.9399 - val_accuracy: 0.4511\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7593 - val_loss: 3.2488 - val_accuracy: 0.4689\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 2.9375 - val_accuracy: 0.4467\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7731 - val_loss: 1.8407 - val_accuracy: 0.6022\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7750 - val_loss: 5.9563 - val_accuracy: 0.4511\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7713 - val_loss: 3.0321 - val_accuracy: 0.4889\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7704 - val_loss: 3.7754 - val_accuracy: 0.4644\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7806 - val_loss: 6.9646 - val_accuracy: 0.3867\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7690 - val_loss: 4.4607 - val_accuracy: 0.4889\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7792 - val_loss: 2.9439 - val_accuracy: 0.5467\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7935 - val_loss: 3.8987 - val_accuracy: 0.4378\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7907 - val_loss: 3.0633 - val_accuracy: 0.5600\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7880 - val_loss: 3.3979 - val_accuracy: 0.4889\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7954 - val_loss: 4.4692 - val_accuracy: 0.5311\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8000 - val_loss: 6.2441 - val_accuracy: 0.4422\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 3.1977 - val_accuracy: 0.4978\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8148 - val_loss: 5.1432 - val_accuracy: 0.5489\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8116 - val_loss: 4.4374 - val_accuracy: 0.5467\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8097 - val_loss: 2.6137 - val_accuracy: 0.5244\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8153 - val_loss: 3.6146 - val_accuracy: 0.5133\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8338 - val_loss: 3.6334 - val_accuracy: 0.5200\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3681 - accuracy: 0.8190 - val_loss: 3.9437 - val_accuracy: 0.5511\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8259 - val_loss: 5.8698 - val_accuracy: 0.5267\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8259 - val_loss: 8.3007 - val_accuracy: 0.4444\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 2.7418 - val_accuracy: 0.5822\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8375 - val_loss: 2.9807 - val_accuracy: 0.6400\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8315 - val_loss: 4.7325 - val_accuracy: 0.5800\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8454 - val_loss: 5.5480 - val_accuracy: 0.4356\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8449 - val_loss: 5.8101 - val_accuracy: 0.5044\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8440 - val_loss: 5.6384 - val_accuracy: 0.4756\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8481 - val_loss: 7.7436 - val_accuracy: 0.4356\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8560 - val_loss: 4.5766 - val_accuracy: 0.5089\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8667 - val_loss: 6.2209 - val_accuracy: 0.5578\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8653 - val_loss: 7.0777 - val_accuracy: 0.4778\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8625 - val_loss: 9.6367 - val_accuracy: 0.4156\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8602 - val_loss: 10.5555 - val_accuracy: 0.4022\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8722 - val_loss: 16.7909 - val_accuracy: 0.3778\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 0.8681 - val_loss: 7.0883 - val_accuracy: 0.5067\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8708 - val_loss: 7.9615 - val_accuracy: 0.4356\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8727 - val_loss: 6.5863 - val_accuracy: 0.4067\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.8815 - val_loss: 6.3782 - val_accuracy: 0.4200\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8759 - val_loss: 7.1977 - val_accuracy: 0.4267\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.8694 - val_loss: 8.3443 - val_accuracy: 0.4733\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8671 - val_loss: 4.1370 - val_accuracy: 0.5933\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.8773 - val_loss: 8.2475 - val_accuracy: 0.4200\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8759 - val_loss: 7.9411 - val_accuracy: 0.4356\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8782 - val_loss: 4.5855 - val_accuracy: 0.4956\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.8755 - val_loss: 7.8733 - val_accuracy: 0.5022\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.8838 - val_loss: 6.0593 - val_accuracy: 0.5511\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.8838 - val_loss: 8.0676 - val_accuracy: 0.4333\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8875 - val_loss: 9.3202 - val_accuracy: 0.4467\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.8907 - val_loss: 9.5550 - val_accuracy: 0.3978\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.8926 - val_loss: 8.5233 - val_accuracy: 0.4778\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.8935 - val_loss: 7.6184 - val_accuracy: 0.4311\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.8843 - val_loss: 5.3391 - val_accuracy: 0.5289\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.8935 - val_loss: 9.4684 - val_accuracy: 0.4489\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.8898 - val_loss: 7.1170 - val_accuracy: 0.4711\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8940 - val_loss: 8.8543 - val_accuracy: 0.5022\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.8884 - val_loss: 12.9695 - val_accuracy: 0.4333\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.8921 - val_loss: 10.0519 - val_accuracy: 0.4556\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2289 - accuracy: 0.8977 - val_loss: 9.2722 - val_accuracy: 0.4622\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2214 - accuracy: 0.9037 - val_loss: 8.2484 - val_accuracy: 0.4400\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9060 - val_loss: 10.6022 - val_accuracy: 0.4756\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.8981 - val_loss: 6.8974 - val_accuracy: 0.4711\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.8944 - val_loss: 8.3142 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.8972 - val_loss: 4.1109 - val_accuracy: 0.5311\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9051 - val_loss: 10.3067 - val_accuracy: 0.4422\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.8958 - val_loss: 9.1870 - val_accuracy: 0.4756\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9120 - val_loss: 6.9464 - val_accuracy: 0.4933\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2023 - accuracy: 0.9051 - val_loss: 10.9645 - val_accuracy: 0.4156\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9000 - val_loss: 8.0588 - val_accuracy: 0.5133\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9148 - val_loss: 5.2284 - val_accuracy: 0.4844\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9162 - val_loss: 6.8294 - val_accuracy: 0.4333\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9000 - val_loss: 8.1119 - val_accuracy: 0.4978\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9037 - val_loss: 8.6363 - val_accuracy: 0.4133\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9042 - val_loss: 8.8694 - val_accuracy: 0.4911\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_154 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_150 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_154 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 25, 25, 8)         1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_151 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_155 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_77 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 150,507\n",
      "Trainable params: 150,443\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1997 - accuracy: 0.4083 - val_loss: 1.1058 - val_accuracy: 0.3111\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9893 - accuracy: 0.4736 - val_loss: 1.1033 - val_accuracy: 0.3289\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8814 - accuracy: 0.5505 - val_loss: 1.0477 - val_accuracy: 0.4889\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8028 - accuracy: 0.6046 - val_loss: 1.0471 - val_accuracy: 0.4933\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.6264 - val_loss: 1.1921 - val_accuracy: 0.4956\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.6602 - val_loss: 1.4743 - val_accuracy: 0.5467\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6833 - val_loss: 2.0827 - val_accuracy: 0.4867\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6935 - val_loss: 1.6650 - val_accuracy: 0.5733\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.7208 - val_loss: 2.6082 - val_accuracy: 0.4644\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7324 - val_loss: 2.2307 - val_accuracy: 0.4289\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7329 - val_loss: 1.4127 - val_accuracy: 0.6156\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4865 - accuracy: 0.7616 - val_loss: 1.6418 - val_accuracy: 0.5400\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7676 - val_loss: 2.9725 - val_accuracy: 0.5111\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7852 - val_loss: 1.5686 - val_accuracy: 0.5511\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7926 - val_loss: 2.5602 - val_accuracy: 0.4533\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.7926 - val_loss: 1.7856 - val_accuracy: 0.6422\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8162 - val_loss: 2.2460 - val_accuracy: 0.6356\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8102 - val_loss: 3.9026 - val_accuracy: 0.4844\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8167 - val_loss: 3.7830 - val_accuracy: 0.4956\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8319 - val_loss: 6.5136 - val_accuracy: 0.4333\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8259 - val_loss: 5.9073 - val_accuracy: 0.3711\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8347 - val_loss: 3.2060 - val_accuracy: 0.4422\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8509 - val_loss: 2.1995 - val_accuracy: 0.6356\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8444 - val_loss: 2.2297 - val_accuracy: 0.6578\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8398 - val_loss: 3.8295 - val_accuracy: 0.5178\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.8644 - val_loss: 3.5112 - val_accuracy: 0.5111\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8616 - val_loss: 4.3515 - val_accuracy: 0.5578\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.8667 - val_loss: 4.5196 - val_accuracy: 0.4778\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.8778 - val_loss: 7.4720 - val_accuracy: 0.4111\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.8718 - val_loss: 4.5149 - val_accuracy: 0.5422\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8759 - val_loss: 5.4088 - val_accuracy: 0.5644\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.8792 - val_loss: 4.4402 - val_accuracy: 0.5733\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.8889 - val_loss: 5.0510 - val_accuracy: 0.5156\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.8968 - val_loss: 3.5683 - val_accuracy: 0.5756\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.8806 - val_loss: 4.5398 - val_accuracy: 0.5911\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 5.9933 - val_accuracy: 0.5600\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.8954 - val_loss: 5.6358 - val_accuracy: 0.5156\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2391 - accuracy: 0.8894 - val_loss: 3.0807 - val_accuracy: 0.6711\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9088 - val_loss: 5.4526 - val_accuracy: 0.4800\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9023 - val_loss: 4.3071 - val_accuracy: 0.6356\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9120 - val_loss: 5.6241 - val_accuracy: 0.5133\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.8944 - val_loss: 8.4057 - val_accuracy: 0.4556\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9176 - val_loss: 4.9848 - val_accuracy: 0.5378\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9056 - val_loss: 4.1859 - val_accuracy: 0.6200\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9116 - val_loss: 6.1058 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9194 - val_loss: 5.6167 - val_accuracy: 0.4778\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9231 - val_loss: 4.6529 - val_accuracy: 0.6111\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1946 - accuracy: 0.9134 - val_loss: 4.1904 - val_accuracy: 0.5600\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.9130 - val_loss: 7.7249 - val_accuracy: 0.4867\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9222 - val_loss: 5.0660 - val_accuracy: 0.6533\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9231 - val_loss: 7.4994 - val_accuracy: 0.4844\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9301 - val_loss: 5.4282 - val_accuracy: 0.6333\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9245 - val_loss: 6.0071 - val_accuracy: 0.5311\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9218 - val_loss: 8.1226 - val_accuracy: 0.4867\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9347 - val_loss: 5.8839 - val_accuracy: 0.6178\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9444 - val_loss: 4.8255 - val_accuracy: 0.6600\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1380 - accuracy: 0.9375 - val_loss: 6.7056 - val_accuracy: 0.5156\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9324 - val_loss: 7.4262 - val_accuracy: 0.5844\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9370 - val_loss: 7.2036 - val_accuracy: 0.5889\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9444 - val_loss: 5.8199 - val_accuracy: 0.6400\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9380 - val_loss: 12.6892 - val_accuracy: 0.4311\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9310 - val_loss: 5.1378 - val_accuracy: 0.6289\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9366 - val_loss: 6.6992 - val_accuracy: 0.6622\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1409 - accuracy: 0.9292 - val_loss: 7.7198 - val_accuracy: 0.4911\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.9417 - val_loss: 4.8351 - val_accuracy: 0.6622\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9361 - val_loss: 7.7175 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9310 - val_loss: 6.8661 - val_accuracy: 0.4978\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9403 - val_loss: 5.7316 - val_accuracy: 0.6067\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9463 - val_loss: 6.8338 - val_accuracy: 0.5578\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9375 - val_loss: 5.0804 - val_accuracy: 0.6600\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9481 - val_loss: 11.0617 - val_accuracy: 0.4800\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1121 - accuracy: 0.9454 - val_loss: 5.1263 - val_accuracy: 0.5844\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9398 - val_loss: 8.2520 - val_accuracy: 0.5733\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9523 - val_loss: 12.0907 - val_accuracy: 0.4844\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9523 - val_loss: 7.5132 - val_accuracy: 0.6489\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9472 - val_loss: 9.1842 - val_accuracy: 0.4911\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9519 - val_loss: 7.3778 - val_accuracy: 0.5756\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9481 - val_loss: 6.9518 - val_accuracy: 0.5600\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9491 - val_loss: 9.6951 - val_accuracy: 0.4800\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9579 - val_loss: 7.1465 - val_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9606 - val_loss: 8.3725 - val_accuracy: 0.6711\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9556 - val_loss: 8.2794 - val_accuracy: 0.6444\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0937 - accuracy: 0.9556 - val_loss: 8.9637 - val_accuracy: 0.5533\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9537 - val_loss: 7.8322 - val_accuracy: 0.6711\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9528 - val_loss: 7.6257 - val_accuracy: 0.6622\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9583 - val_loss: 8.8535 - val_accuracy: 0.6422\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9611 - val_loss: 6.6491 - val_accuracy: 0.5689\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9606 - val_loss: 11.2953 - val_accuracy: 0.4733\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9481 - val_loss: 6.1690 - val_accuracy: 0.5733\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9579 - val_loss: 10.3780 - val_accuracy: 0.4733\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9662 - val_loss: 8.7607 - val_accuracy: 0.5533\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9644 - val_loss: 11.4158 - val_accuracy: 0.4933\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9708 - val_loss: 9.2323 - val_accuracy: 0.5378\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9583 - val_loss: 7.8387 - val_accuracy: 0.5556\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9574 - val_loss: 8.0573 - val_accuracy: 0.5444\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0729 - accuracy: 0.9644 - val_loss: 10.5640 - val_accuracy: 0.5489\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9611 - val_loss: 9.1665 - val_accuracy: 0.5244\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9551 - val_loss: 7.1661 - val_accuracy: 0.5533\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9657 - val_loss: 6.9807 - val_accuracy: 0.5689\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9644 - val_loss: 6.7652 - val_accuracy: 0.6222\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_156 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_152 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_156 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 25, 25, 8)         1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_153 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_157 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_78 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 298,475\n",
      "Trainable params: 298,411\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.3024 - accuracy: 0.4412 - val_loss: 1.1172 - val_accuracy: 0.3044\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8905 - accuracy: 0.5634 - val_loss: 1.1554 - val_accuracy: 0.3667\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7654 - accuracy: 0.6532 - val_loss: 1.2257 - val_accuracy: 0.4622\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6829 - val_loss: 1.8027 - val_accuracy: 0.4778\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7556 - val_loss: 1.6771 - val_accuracy: 0.4356\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7671 - val_loss: 1.3816 - val_accuracy: 0.4422\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4665 - accuracy: 0.8019 - val_loss: 4.0729 - val_accuracy: 0.3178\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.8074 - val_loss: 2.1919 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8282 - val_loss: 2.5945 - val_accuracy: 0.4089\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8468 - val_loss: 6.4257 - val_accuracy: 0.3800\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8644 - val_loss: 3.1934 - val_accuracy: 0.3978\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.8699 - val_loss: 3.5767 - val_accuracy: 0.4711\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.8713 - val_loss: 2.4192 - val_accuracy: 0.4444\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8852 - val_loss: 2.5281 - val_accuracy: 0.4356\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9139 - val_loss: 3.6141 - val_accuracy: 0.4089\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.9056 - val_loss: 3.7861 - val_accuracy: 0.4289\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.9042 - val_loss: 2.5829 - val_accuracy: 0.4800\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.9204 - val_loss: 4.0532 - val_accuracy: 0.4267\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9153 - val_loss: 4.1711 - val_accuracy: 0.4422\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9204 - val_loss: 2.2979 - val_accuracy: 0.5200\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9222 - val_loss: 4.2730 - val_accuracy: 0.4067\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9324 - val_loss: 3.4870 - val_accuracy: 0.4422\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1843 - accuracy: 0.9227 - val_loss: 3.0704 - val_accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9394 - val_loss: 4.6950 - val_accuracy: 0.4378\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9366 - val_loss: 3.1917 - val_accuracy: 0.5600\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9333 - val_loss: 8.4755 - val_accuracy: 0.3844\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9398 - val_loss: 5.2503 - val_accuracy: 0.3889\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9431 - val_loss: 5.5504 - val_accuracy: 0.4311\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9468 - val_loss: 4.6244 - val_accuracy: 0.4911\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1225 - accuracy: 0.9574 - val_loss: 4.4887 - val_accuracy: 0.4711\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9426 - val_loss: 7.2151 - val_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9514 - val_loss: 3.6044 - val_accuracy: 0.4867\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9421 - val_loss: 4.3650 - val_accuracy: 0.4800\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9532 - val_loss: 4.2227 - val_accuracy: 0.5267\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9537 - val_loss: 4.3474 - val_accuracy: 0.4289\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9616 - val_loss: 4.8793 - val_accuracy: 0.4644\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9546 - val_loss: 7.4591 - val_accuracy: 0.3978\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9565 - val_loss: 6.1072 - val_accuracy: 0.4200\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9630 - val_loss: 5.8213 - val_accuracy: 0.4511\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9634 - val_loss: 5.9028 - val_accuracy: 0.5022\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9625 - val_loss: 4.3287 - val_accuracy: 0.5178\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9630 - val_loss: 4.1160 - val_accuracy: 0.4978\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9694 - val_loss: 10.0533 - val_accuracy: 0.3689\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9639 - val_loss: 4.8226 - val_accuracy: 0.5133\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9685 - val_loss: 4.8347 - val_accuracy: 0.6200\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9708 - val_loss: 4.9442 - val_accuracy: 0.5667\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9653 - val_loss: 10.6733 - val_accuracy: 0.3644\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9736 - val_loss: 4.9345 - val_accuracy: 0.5556\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9690 - val_loss: 4.7014 - val_accuracy: 0.4933\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9634 - val_loss: 4.6291 - val_accuracy: 0.5400\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9611 - val_loss: 5.2702 - val_accuracy: 0.5667\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9583 - val_loss: 5.8096 - val_accuracy: 0.4933\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9731 - val_loss: 5.1562 - val_accuracy: 0.4289\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9694 - val_loss: 4.8910 - val_accuracy: 0.5556\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9704 - val_loss: 4.9983 - val_accuracy: 0.5022\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9718 - val_loss: 5.0315 - val_accuracy: 0.5378\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9745 - val_loss: 4.3163 - val_accuracy: 0.5422\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9704 - val_loss: 4.1504 - val_accuracy: 0.5444\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9750 - val_loss: 5.3981 - val_accuracy: 0.5311\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9704 - val_loss: 4.4071 - val_accuracy: 0.5267\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9704 - val_loss: 9.8357 - val_accuracy: 0.4644\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9773 - val_loss: 5.9616 - val_accuracy: 0.5556\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9745 - val_loss: 26.7320 - val_accuracy: 0.3333\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9782 - val_loss: 8.1107 - val_accuracy: 0.5289\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9787 - val_loss: 7.1920 - val_accuracy: 0.4889\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9759 - val_loss: 13.9359 - val_accuracy: 0.4156\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9778 - val_loss: 6.3939 - val_accuracy: 0.4600\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9833 - val_loss: 7.1320 - val_accuracy: 0.4133\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9787 - val_loss: 6.3161 - val_accuracy: 0.4956\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9787 - val_loss: 6.6506 - val_accuracy: 0.5378\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 8.5358 - val_accuracy: 0.4178\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9792 - val_loss: 7.0866 - val_accuracy: 0.4733\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9824 - val_loss: 6.9773 - val_accuracy: 0.4889\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9806 - val_loss: 24.6651 - val_accuracy: 0.3578\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9824 - val_loss: 9.9164 - val_accuracy: 0.4578\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9718 - val_loss: 5.0705 - val_accuracy: 0.4667\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9759 - val_loss: 18.1773 - val_accuracy: 0.3778\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 5.8636 - val_accuracy: 0.5022\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 5.6458 - val_accuracy: 0.4956\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 9.1650 - val_accuracy: 0.5067\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9745 - val_loss: 6.8483 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 8.4298 - val_accuracy: 0.4689\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9778 - val_loss: 5.0722 - val_accuracy: 0.5556\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9847 - val_loss: 6.7504 - val_accuracy: 0.5311\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9861 - val_loss: 5.7340 - val_accuracy: 0.5089\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9755 - val_loss: 12.8599 - val_accuracy: 0.3978\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9861 - val_loss: 11.3182 - val_accuracy: 0.4311\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 9.0419 - val_accuracy: 0.5200\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9843 - val_loss: 5.9586 - val_accuracy: 0.5311\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9833 - val_loss: 16.3749 - val_accuracy: 0.3711\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9792 - val_loss: 6.1963 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 5.1972 - val_accuracy: 0.5644\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9838 - val_loss: 6.4478 - val_accuracy: 0.4822\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9838 - val_loss: 9.4345 - val_accuracy: 0.5111\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9875 - val_loss: 9.0679 - val_accuracy: 0.4778\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9801 - val_loss: 17.6170 - val_accuracy: 0.4222\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9856 - val_loss: 5.3752 - val_accuracy: 0.5844\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9819 - val_loss: 24.9015 - val_accuracy: 0.3867\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9829 - val_loss: 5.3360 - val_accuracy: 0.5689\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 6.4722 - val_accuracy: 0.5444\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_158 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_154 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_158 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 25, 25, 10)        2170      \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_159 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_79 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 49,189\n",
      "Trainable params: 49,121\n",
      "Non-trainable params: 68\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1566 - accuracy: 0.3366 - val_loss: 1.0986 - val_accuracy: 0.3311\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0852 - accuracy: 0.3440 - val_loss: 1.0986 - val_accuracy: 0.3200\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0827 - accuracy: 0.3463 - val_loss: 1.0956 - val_accuracy: 0.3533\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0801 - accuracy: 0.3602 - val_loss: 1.1010 - val_accuracy: 0.3489\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0768 - accuracy: 0.3546 - val_loss: 1.0923 - val_accuracy: 0.3533\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0771 - accuracy: 0.3602 - val_loss: 1.0983 - val_accuracy: 0.3400\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0795 - accuracy: 0.3644 - val_loss: 1.0897 - val_accuracy: 0.3644\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0621 - accuracy: 0.3657 - val_loss: 1.0893 - val_accuracy: 0.3133\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0647 - accuracy: 0.3755 - val_loss: 1.0988 - val_accuracy: 0.3311\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0458 - accuracy: 0.3843 - val_loss: 1.0743 - val_accuracy: 0.4067\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0223 - accuracy: 0.3986 - val_loss: 1.0961 - val_accuracy: 0.4356\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0252 - accuracy: 0.4037 - val_loss: 1.0806 - val_accuracy: 0.3600\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0230 - accuracy: 0.3921 - val_loss: 1.0718 - val_accuracy: 0.3733\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0129 - accuracy: 0.3995 - val_loss: 1.0933 - val_accuracy: 0.3578\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0044 - accuracy: 0.3972 - val_loss: 1.0853 - val_accuracy: 0.3778\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0076 - accuracy: 0.4218 - val_loss: 1.0984 - val_accuracy: 0.3378\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9822 - accuracy: 0.4338 - val_loss: 1.8705 - val_accuracy: 0.3289\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9905 - accuracy: 0.4208 - val_loss: 1.0802 - val_accuracy: 0.4578\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9694 - accuracy: 0.4255 - val_loss: 1.0565 - val_accuracy: 0.4244\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9659 - accuracy: 0.4329 - val_loss: 1.3357 - val_accuracy: 0.4533\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9627 - accuracy: 0.4412 - val_loss: 0.9661 - val_accuracy: 0.5978\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9562 - accuracy: 0.4338 - val_loss: 1.0859 - val_accuracy: 0.3756\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9603 - accuracy: 0.4301 - val_loss: 0.9632 - val_accuracy: 0.5156\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9615 - accuracy: 0.4431 - val_loss: 1.0908 - val_accuracy: 0.4467\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9610 - accuracy: 0.4486 - val_loss: 1.0934 - val_accuracy: 0.4889\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9498 - accuracy: 0.4551 - val_loss: 1.0378 - val_accuracy: 0.5311\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9217 - accuracy: 0.4579 - val_loss: 1.0274 - val_accuracy: 0.5622\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9408 - accuracy: 0.4662 - val_loss: 1.0587 - val_accuracy: 0.4267\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9157 - accuracy: 0.4750 - val_loss: 0.9941 - val_accuracy: 0.4267\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9151 - accuracy: 0.4782 - val_loss: 1.0547 - val_accuracy: 0.4822\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8977 - accuracy: 0.4944 - val_loss: 1.0655 - val_accuracy: 0.4044\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8879 - accuracy: 0.4972 - val_loss: 1.1970 - val_accuracy: 0.4556\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9030 - accuracy: 0.4986 - val_loss: 1.0288 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8893 - accuracy: 0.4931 - val_loss: 1.2610 - val_accuracy: 0.4022\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8866 - accuracy: 0.5046 - val_loss: 1.6734 - val_accuracy: 0.4244\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8831 - accuracy: 0.5088 - val_loss: 1.0217 - val_accuracy: 0.4622\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8737 - accuracy: 0.5051 - val_loss: 1.0704 - val_accuracy: 0.5111\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8565 - accuracy: 0.5236 - val_loss: 1.0812 - val_accuracy: 0.4933\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8596 - accuracy: 0.5227 - val_loss: 1.1555 - val_accuracy: 0.3511\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8519 - accuracy: 0.5282 - val_loss: 1.1319 - val_accuracy: 0.5311\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8415 - accuracy: 0.5380 - val_loss: 1.4813 - val_accuracy: 0.5111\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8603 - accuracy: 0.5227 - val_loss: 1.1218 - val_accuracy: 0.4778\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.5278 - val_loss: 1.1812 - val_accuracy: 0.4600\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8180 - accuracy: 0.5495 - val_loss: 1.1702 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8025 - accuracy: 0.5671 - val_loss: 1.1580 - val_accuracy: 0.4778\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7988 - accuracy: 0.5704 - val_loss: 1.0977 - val_accuracy: 0.4578\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8159 - accuracy: 0.5611 - val_loss: 1.1451 - val_accuracy: 0.5133\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.5606 - val_loss: 1.2412 - val_accuracy: 0.5422\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7966 - accuracy: 0.5593 - val_loss: 1.3370 - val_accuracy: 0.5156\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8166 - accuracy: 0.5593 - val_loss: 1.1823 - val_accuracy: 0.3800\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7980 - accuracy: 0.5625 - val_loss: 1.3877 - val_accuracy: 0.4511\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8102 - accuracy: 0.5551 - val_loss: 1.0204 - val_accuracy: 0.4667\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7861 - accuracy: 0.5708 - val_loss: 1.4039 - val_accuracy: 0.4822\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7792 - accuracy: 0.5741 - val_loss: 1.1758 - val_accuracy: 0.4756\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7697 - accuracy: 0.5787 - val_loss: 2.0346 - val_accuracy: 0.4600\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7610 - accuracy: 0.5926 - val_loss: 1.6990 - val_accuracy: 0.4911\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.5912 - val_loss: 1.9040 - val_accuracy: 0.4733\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7492 - accuracy: 0.5903 - val_loss: 2.8458 - val_accuracy: 0.3644\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.6028 - val_loss: 1.6490 - val_accuracy: 0.5178\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.6056 - val_loss: 1.4826 - val_accuracy: 0.5111\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.6023 - val_loss: 1.9816 - val_accuracy: 0.4267\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.6060 - val_loss: 1.6601 - val_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7316 - accuracy: 0.6023 - val_loss: 1.6597 - val_accuracy: 0.5089\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7127 - accuracy: 0.6199 - val_loss: 1.4981 - val_accuracy: 0.4956\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.6218 - val_loss: 1.4645 - val_accuracy: 0.4089\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.6227 - val_loss: 2.2483 - val_accuracy: 0.4844\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7001 - accuracy: 0.6296 - val_loss: 2.0716 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.6292 - val_loss: 6.9817 - val_accuracy: 0.3511\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.6296 - val_loss: 4.5634 - val_accuracy: 0.4311\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.6236 - val_loss: 2.7402 - val_accuracy: 0.4444\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.6255 - val_loss: 2.3848 - val_accuracy: 0.4533\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.6343 - val_loss: 2.5481 - val_accuracy: 0.5089\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7130 - accuracy: 0.6176 - val_loss: 6.6373 - val_accuracy: 0.3444\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.6255 - val_loss: 2.2099 - val_accuracy: 0.4378\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.6407 - val_loss: 2.2479 - val_accuracy: 0.4689\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6398 - val_loss: 3.7708 - val_accuracy: 0.4289\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.6176 - val_loss: 1.7785 - val_accuracy: 0.4133\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6821 - accuracy: 0.6324 - val_loss: 3.0121 - val_accuracy: 0.4800\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6370 - accuracy: 0.6606 - val_loss: 4.7812 - val_accuracy: 0.4467\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.6301 - val_loss: 3.0259 - val_accuracy: 0.4578\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6407 - val_loss: 2.4720 - val_accuracy: 0.3933\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.6486 - val_loss: 2.8617 - val_accuracy: 0.4067\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6454 - val_loss: 3.3290 - val_accuracy: 0.4844\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6762 - accuracy: 0.6306 - val_loss: 2.5575 - val_accuracy: 0.4444\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6465 - accuracy: 0.6463 - val_loss: 3.4416 - val_accuracy: 0.4133\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6560 - val_loss: 4.2007 - val_accuracy: 0.4489\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6685 - val_loss: 7.6482 - val_accuracy: 0.4267\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6657 - val_loss: 2.3741 - val_accuracy: 0.4867\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6574 - val_loss: 2.9528 - val_accuracy: 0.4778\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6662 - val_loss: 2.4363 - val_accuracy: 0.4422\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6495 - val_loss: 4.4630 - val_accuracy: 0.4378\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6440 - val_loss: 9.6238 - val_accuracy: 0.3844\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6602 - val_loss: 3.8607 - val_accuracy: 0.4244\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6792 - val_loss: 4.6554 - val_accuracy: 0.3911\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6142 - accuracy: 0.6769 - val_loss: 7.9416 - val_accuracy: 0.4089\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6699 - val_loss: 3.9699 - val_accuracy: 0.4489\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6750 - val_loss: 3.0709 - val_accuracy: 0.4200\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6690 - val_loss: 3.1542 - val_accuracy: 0.4156\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6935 - val_loss: 10.0024 - val_accuracy: 0.4111\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6045 - accuracy: 0.6806 - val_loss: 3.6612 - val_accuracy: 0.4644\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_160 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_156 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_160 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 25, 25, 10)        2170      \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_161 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_80 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 95,397\n",
      "Trainable params: 95,329\n",
      "Non-trainable params: 68\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1733 - accuracy: 0.3759 - val_loss: 1.0988 - val_accuracy: 0.3289\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0369 - accuracy: 0.3963 - val_loss: 1.0937 - val_accuracy: 0.3356\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9890 - accuracy: 0.4421 - val_loss: 1.0970 - val_accuracy: 0.4089\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9425 - accuracy: 0.4731 - val_loss: 1.2025 - val_accuracy: 0.3911\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9345 - accuracy: 0.4759 - val_loss: 1.1217 - val_accuracy: 0.4311\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8709 - accuracy: 0.5250 - val_loss: 2.7267 - val_accuracy: 0.3511\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8486 - accuracy: 0.5338 - val_loss: 1.1924 - val_accuracy: 0.4200\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8137 - accuracy: 0.5718 - val_loss: 1.3949 - val_accuracy: 0.4222\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.5843 - val_loss: 1.6768 - val_accuracy: 0.4156\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7641 - accuracy: 0.5963 - val_loss: 1.2492 - val_accuracy: 0.4778\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.6139 - val_loss: 1.7596 - val_accuracy: 0.4356\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7163 - accuracy: 0.6324 - val_loss: 2.0279 - val_accuracy: 0.4422\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.6593 - val_loss: 3.1371 - val_accuracy: 0.4400\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.6500 - val_loss: 2.1965 - val_accuracy: 0.4067\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6634 - val_loss: 1.6730 - val_accuracy: 0.4867\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6824 - val_loss: 2.6733 - val_accuracy: 0.4178\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6188 - accuracy: 0.6894 - val_loss: 1.8302 - val_accuracy: 0.4156\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6898 - val_loss: 2.1689 - val_accuracy: 0.4889\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5727 - accuracy: 0.7213 - val_loss: 3.6885 - val_accuracy: 0.4333\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7199 - val_loss: 3.5017 - val_accuracy: 0.4067\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5602 - accuracy: 0.7236 - val_loss: 2.9365 - val_accuracy: 0.4067\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7236 - val_loss: 2.1438 - val_accuracy: 0.5156\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7426 - val_loss: 2.2726 - val_accuracy: 0.4933\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7444 - val_loss: 3.4360 - val_accuracy: 0.4822\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7449 - val_loss: 1.9592 - val_accuracy: 0.5244\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7458 - val_loss: 3.0411 - val_accuracy: 0.4889\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7611 - val_loss: 11.7018 - val_accuracy: 0.3422\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7593 - val_loss: 2.5772 - val_accuracy: 0.5511\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7556 - val_loss: 2.3320 - val_accuracy: 0.4800\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7597 - val_loss: 5.0327 - val_accuracy: 0.4356\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7685 - val_loss: 2.3621 - val_accuracy: 0.5400\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7625 - val_loss: 4.7125 - val_accuracy: 0.4267\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7718 - val_loss: 8.0852 - val_accuracy: 0.3578\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7759 - val_loss: 4.1152 - val_accuracy: 0.5089\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7907 - val_loss: 3.6532 - val_accuracy: 0.5556\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7907 - val_loss: 3.8192 - val_accuracy: 0.5711\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4331 - accuracy: 0.7889 - val_loss: 5.5192 - val_accuracy: 0.5222\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8111 - val_loss: 5.7449 - val_accuracy: 0.4489\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7954 - val_loss: 5.3592 - val_accuracy: 0.4644\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4259 - accuracy: 0.7963 - val_loss: 5.0010 - val_accuracy: 0.4644\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8065 - val_loss: 5.1807 - val_accuracy: 0.5089\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8199 - val_loss: 5.8989 - val_accuracy: 0.4178\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8241 - val_loss: 4.5095 - val_accuracy: 0.4933\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8259 - val_loss: 4.3011 - val_accuracy: 0.4800\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8403 - val_loss: 3.7010 - val_accuracy: 0.5556\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8347 - val_loss: 4.2929 - val_accuracy: 0.5622\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8361 - val_loss: 4.7550 - val_accuracy: 0.5156\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3546 - accuracy: 0.8380 - val_loss: 3.4792 - val_accuracy: 0.5489\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8449 - val_loss: 5.3215 - val_accuracy: 0.5444\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3545 - accuracy: 0.8375 - val_loss: 5.2638 - val_accuracy: 0.5667\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8370 - val_loss: 11.2738 - val_accuracy: 0.3533\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3544 - accuracy: 0.8384 - val_loss: 3.8376 - val_accuracy: 0.5311\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8366 - val_loss: 7.0459 - val_accuracy: 0.4467\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8426 - val_loss: 4.5957 - val_accuracy: 0.5378\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8671 - val_loss: 4.5591 - val_accuracy: 0.5689\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8519 - val_loss: 5.2547 - val_accuracy: 0.5578\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8528 - val_loss: 17.1385 - val_accuracy: 0.3400\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8537 - val_loss: 7.9671 - val_accuracy: 0.5711\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8593 - val_loss: 4.9121 - val_accuracy: 0.5133\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8523 - val_loss: 8.6016 - val_accuracy: 0.5444\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8644 - val_loss: 7.8611 - val_accuracy: 0.5911\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8796 - val_loss: 4.9591 - val_accuracy: 0.6311\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.8657 - val_loss: 4.7011 - val_accuracy: 0.5556\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.8509 - val_loss: 5.5321 - val_accuracy: 0.6089\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8676 - val_loss: 5.6623 - val_accuracy: 0.5111\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.8856 - val_loss: 6.4350 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8745 - val_loss: 5.8260 - val_accuracy: 0.5356\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.8722 - val_loss: 5.9606 - val_accuracy: 0.6022\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2859 - accuracy: 0.8644 - val_loss: 6.9622 - val_accuracy: 0.5444\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.8806 - val_loss: 6.4081 - val_accuracy: 0.5556\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8806 - val_loss: 6.7729 - val_accuracy: 0.5200\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.8852 - val_loss: 13.4023 - val_accuracy: 0.3889\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.8741 - val_loss: 6.1882 - val_accuracy: 0.5289\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2415 - accuracy: 0.8926 - val_loss: 7.9760 - val_accuracy: 0.5467\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.8796 - val_loss: 6.3849 - val_accuracy: 0.5711\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.8801 - val_loss: 5.7285 - val_accuracy: 0.5756\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.8866 - val_loss: 7.5309 - val_accuracy: 0.5400\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.8856 - val_loss: 6.3148 - val_accuracy: 0.5733\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.8931 - val_loss: 7.3592 - val_accuracy: 0.5556\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9028 - val_loss: 10.2375 - val_accuracy: 0.4867\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9000 - val_loss: 5.9723 - val_accuracy: 0.5644\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2764 - accuracy: 0.8861 - val_loss: 5.1001 - val_accuracy: 0.4622\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9065 - val_loss: 6.1639 - val_accuracy: 0.5733\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9130 - val_loss: 7.8878 - val_accuracy: 0.5733\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.8986 - val_loss: 5.1100 - val_accuracy: 0.5867\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9032 - val_loss: 9.9077 - val_accuracy: 0.5089\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9028 - val_loss: 13.0299 - val_accuracy: 0.4156\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.8968 - val_loss: 6.9691 - val_accuracy: 0.4956\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.8949 - val_loss: 9.1746 - val_accuracy: 0.4578\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9046 - val_loss: 6.2311 - val_accuracy: 0.6089\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.9051 - val_loss: 5.3100 - val_accuracy: 0.6444\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.9065 - val_loss: 6.1280 - val_accuracy: 0.5889\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9093 - val_loss: 5.9321 - val_accuracy: 0.5556\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9190 - val_loss: 8.4275 - val_accuracy: 0.4978\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9111 - val_loss: 5.9900 - val_accuracy: 0.5889\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9125 - val_loss: 12.3736 - val_accuracy: 0.4133\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9116 - val_loss: 6.4097 - val_accuracy: 0.6111\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9167 - val_loss: 6.7760 - val_accuracy: 0.6022\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9088 - val_loss: 5.8479 - val_accuracy: 0.6178\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2002 - accuracy: 0.9125 - val_loss: 7.7762 - val_accuracy: 0.6022\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_162 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_162 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 25, 25, 10)        2170      \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_163 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 128)               184448    \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 187,813\n",
      "Trainable params: 187,745\n",
      "Non-trainable params: 68\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1901 - accuracy: 0.3991 - val_loss: 1.0976 - val_accuracy: 0.3489\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0184 - accuracy: 0.4093 - val_loss: 1.0945 - val_accuracy: 0.4578\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9423 - accuracy: 0.4782 - val_loss: 1.0825 - val_accuracy: 0.4578\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8887 - accuracy: 0.5144 - val_loss: 1.1361 - val_accuracy: 0.3933\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8265 - accuracy: 0.5597 - val_loss: 1.1138 - val_accuracy: 0.4422\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7693 - accuracy: 0.5731 - val_loss: 1.0481 - val_accuracy: 0.4356\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.6296 - val_loss: 1.1792 - val_accuracy: 0.4600\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.6370 - val_loss: 1.4183 - val_accuracy: 0.4333\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6769 - val_loss: 1.9105 - val_accuracy: 0.4111\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7005 - val_loss: 1.5440 - val_accuracy: 0.4489\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7231 - val_loss: 1.2817 - val_accuracy: 0.4400\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7264 - val_loss: 1.6359 - val_accuracy: 0.4133\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7407 - val_loss: 1.3665 - val_accuracy: 0.4578\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7583 - val_loss: 2.8539 - val_accuracy: 0.4378\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7685 - val_loss: 4.5975 - val_accuracy: 0.3911\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7736 - val_loss: 2.0605 - val_accuracy: 0.4422\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7699 - val_loss: 1.2700 - val_accuracy: 0.5511\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4298 - accuracy: 0.7977 - val_loss: 3.2473 - val_accuracy: 0.3822\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4044 - accuracy: 0.8028 - val_loss: 3.8366 - val_accuracy: 0.3711\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.7981 - val_loss: 5.1642 - val_accuracy: 0.3489\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8028 - val_loss: 2.6569 - val_accuracy: 0.4422\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.7986 - val_loss: 2.7366 - val_accuracy: 0.3711\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3930 - accuracy: 0.8046 - val_loss: 3.1623 - val_accuracy: 0.3711\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8194 - val_loss: 5.4960 - val_accuracy: 0.3444\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8292 - val_loss: 3.0379 - val_accuracy: 0.4489\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8231 - val_loss: 3.3371 - val_accuracy: 0.4111\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3249 - accuracy: 0.8338 - val_loss: 2.9227 - val_accuracy: 0.4933\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8319 - val_loss: 2.3813 - val_accuracy: 0.4844\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8509 - val_loss: 7.2406 - val_accuracy: 0.4022\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8440 - val_loss: 5.3532 - val_accuracy: 0.3867\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8454 - val_loss: 4.1376 - val_accuracy: 0.3867\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8611 - val_loss: 3.0485 - val_accuracy: 0.4733\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8523 - val_loss: 2.7596 - val_accuracy: 0.4644\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8579 - val_loss: 2.3804 - val_accuracy: 0.4822\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.8644 - val_loss: 4.3615 - val_accuracy: 0.4889\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.8713 - val_loss: 7.3877 - val_accuracy: 0.4511\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.8769 - val_loss: 3.5109 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8657 - val_loss: 5.7224 - val_accuracy: 0.4133\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.8699 - val_loss: 4.3575 - val_accuracy: 0.4422\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2749 - accuracy: 0.8699 - val_loss: 4.9084 - val_accuracy: 0.4756\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2304 - accuracy: 0.8963 - val_loss: 11.5195 - val_accuracy: 0.3600\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.8986 - val_loss: 5.8118 - val_accuracy: 0.4356\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2137 - accuracy: 0.8968 - val_loss: 3.8074 - val_accuracy: 0.5156\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.8898 - val_loss: 3.9414 - val_accuracy: 0.5067\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.8903 - val_loss: 5.0256 - val_accuracy: 0.4778\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2122 - accuracy: 0.8968 - val_loss: 3.8163 - val_accuracy: 0.4978\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9046 - val_loss: 4.9565 - val_accuracy: 0.4156\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1909 - accuracy: 0.9065 - val_loss: 5.4642 - val_accuracy: 0.4267\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2059 - accuracy: 0.9097 - val_loss: 4.7481 - val_accuracy: 0.4733\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9019 - val_loss: 3.8885 - val_accuracy: 0.5222\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9153 - val_loss: 9.6075 - val_accuracy: 0.4111\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9185 - val_loss: 3.6146 - val_accuracy: 0.5067\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9204 - val_loss: 6.7706 - val_accuracy: 0.4756\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9241 - val_loss: 7.4080 - val_accuracy: 0.4400\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1709 - accuracy: 0.9264 - val_loss: 14.0557 - val_accuracy: 0.3400\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9273 - val_loss: 6.6136 - val_accuracy: 0.4689\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9222 - val_loss: 9.0598 - val_accuracy: 0.4400\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9398 - val_loss: 6.1721 - val_accuracy: 0.4467\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9324 - val_loss: 3.5384 - val_accuracy: 0.5889\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1577 - accuracy: 0.9269 - val_loss: 7.3504 - val_accuracy: 0.4711\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9306 - val_loss: 5.0599 - val_accuracy: 0.5156\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9398 - val_loss: 7.1245 - val_accuracy: 0.4422\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9361 - val_loss: 8.4460 - val_accuracy: 0.4444\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9394 - val_loss: 6.7244 - val_accuracy: 0.5378\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9259 - val_loss: 6.3981 - val_accuracy: 0.5622\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9361 - val_loss: 7.0173 - val_accuracy: 0.4489\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9444 - val_loss: 9.2204 - val_accuracy: 0.4600\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9389 - val_loss: 8.9442 - val_accuracy: 0.5089\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1496 - accuracy: 0.9319 - val_loss: 5.2456 - val_accuracy: 0.5489\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9375 - val_loss: 8.1534 - val_accuracy: 0.4956\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9486 - val_loss: 8.3873 - val_accuracy: 0.4933\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9491 - val_loss: 6.6989 - val_accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9537 - val_loss: 8.0407 - val_accuracy: 0.4911\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9551 - val_loss: 10.0673 - val_accuracy: 0.4533\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9500 - val_loss: 8.9886 - val_accuracy: 0.4956\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9602 - val_loss: 7.9999 - val_accuracy: 0.4822\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9537 - val_loss: 7.0215 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9546 - val_loss: 8.9796 - val_accuracy: 0.5178\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9500 - val_loss: 6.7537 - val_accuracy: 0.5022\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9565 - val_loss: 9.0058 - val_accuracy: 0.4333\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9602 - val_loss: 8.8589 - val_accuracy: 0.5178\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9537 - val_loss: 7.6320 - val_accuracy: 0.4711\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9616 - val_loss: 9.9089 - val_accuracy: 0.4844\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9551 - val_loss: 13.3958 - val_accuracy: 0.4378\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9620 - val_loss: 8.3713 - val_accuracy: 0.4756\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9602 - val_loss: 8.7066 - val_accuracy: 0.4867\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9634 - val_loss: 6.9263 - val_accuracy: 0.4889\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9704 - val_loss: 7.7945 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9671 - val_loss: 14.3967 - val_accuracy: 0.4600\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9611 - val_loss: 9.5415 - val_accuracy: 0.4822\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9690 - val_loss: 10.5356 - val_accuracy: 0.4956\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9662 - val_loss: 11.3309 - val_accuracy: 0.4400\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9690 - val_loss: 10.1729 - val_accuracy: 0.5244\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9634 - val_loss: 10.2543 - val_accuracy: 0.4467\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9616 - val_loss: 12.2531 - val_accuracy: 0.4956\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9620 - val_loss: 8.3766 - val_accuracy: 0.5089\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9755 - val_loss: 12.1245 - val_accuracy: 0.4822\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9620 - val_loss: 7.7282 - val_accuracy: 0.5044\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9667 - val_loss: 12.1460 - val_accuracy: 0.4978\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9657 - val_loss: 7.8300 - val_accuracy: 0.4889\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_164 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_164 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_165 (Conv2D)          (None, 25, 25, 10)        2170      \n",
      "_________________________________________________________________\n",
      "batch_normalization_161 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_165 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_82 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 256)               368896    \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 372,645\n",
      "Trainable params: 372,577\n",
      "Non-trainable params: 68\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.3818 - accuracy: 0.4356 - val_loss: 1.0937 - val_accuracy: 0.3444\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8943 - accuracy: 0.5667 - val_loss: 1.0648 - val_accuracy: 0.3800\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7828 - accuracy: 0.6292 - val_loss: 1.0600 - val_accuracy: 0.4578\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.6880 - val_loss: 1.0610 - val_accuracy: 0.4133\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.7144 - val_loss: 1.4184 - val_accuracy: 0.4867\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7653 - val_loss: 1.6032 - val_accuracy: 0.3911\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7870 - val_loss: 2.9775 - val_accuracy: 0.4378\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8023 - val_loss: 1.5706 - val_accuracy: 0.4622\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8088 - val_loss: 1.7900 - val_accuracy: 0.4778\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8255 - val_loss: 4.1852 - val_accuracy: 0.4133\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8444 - val_loss: 2.3428 - val_accuracy: 0.4111\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8537 - val_loss: 4.2459 - val_accuracy: 0.4200\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8560 - val_loss: 2.5331 - val_accuracy: 0.4089\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8676 - val_loss: 4.3791 - val_accuracy: 0.3800\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.8644 - val_loss: 5.7256 - val_accuracy: 0.3444\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.8880 - val_loss: 2.6202 - val_accuracy: 0.4711\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.8921 - val_loss: 2.9878 - val_accuracy: 0.5067\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.9005 - val_loss: 3.2559 - val_accuracy: 0.4889\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2338 - accuracy: 0.8972 - val_loss: 2.0190 - val_accuracy: 0.4978\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.9079 - val_loss: 2.7379 - val_accuracy: 0.5200\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2137 - accuracy: 0.9116 - val_loss: 2.6904 - val_accuracy: 0.5289\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.9032 - val_loss: 5.4040 - val_accuracy: 0.4489\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9028 - val_loss: 2.9868 - val_accuracy: 0.4267\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9241 - val_loss: 4.6448 - val_accuracy: 0.4578\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.9255 - val_loss: 4.7254 - val_accuracy: 0.4333\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9338 - val_loss: 2.7675 - val_accuracy: 0.5756\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1512 - accuracy: 0.9380 - val_loss: 2.5533 - val_accuracy: 0.5156\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9431 - val_loss: 3.3267 - val_accuracy: 0.4778\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9394 - val_loss: 8.6748 - val_accuracy: 0.3511\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.9403 - val_loss: 6.1731 - val_accuracy: 0.4533\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1515 - accuracy: 0.9356 - val_loss: 2.2057 - val_accuracy: 0.6156\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9347 - val_loss: 3.1082 - val_accuracy: 0.4978\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9431 - val_loss: 5.2706 - val_accuracy: 0.5022\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9440 - val_loss: 4.3591 - val_accuracy: 0.4689\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.9394 - val_loss: 7.1869 - val_accuracy: 0.4733\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9500 - val_loss: 4.6408 - val_accuracy: 0.5067\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9486 - val_loss: 5.2858 - val_accuracy: 0.3644\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9435 - val_loss: 5.8371 - val_accuracy: 0.4200\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9491 - val_loss: 4.8909 - val_accuracy: 0.4711\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9634 - val_loss: 8.6470 - val_accuracy: 0.4689\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9556 - val_loss: 5.3344 - val_accuracy: 0.4422\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9597 - val_loss: 3.0876 - val_accuracy: 0.5956\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9593 - val_loss: 4.7506 - val_accuracy: 0.4378\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9537 - val_loss: 5.2770 - val_accuracy: 0.5133\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9611 - val_loss: 8.1128 - val_accuracy: 0.4333\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9694 - val_loss: 5.3386 - val_accuracy: 0.5067\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9667 - val_loss: 3.6293 - val_accuracy: 0.5489\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9588 - val_loss: 4.6230 - val_accuracy: 0.5511\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9662 - val_loss: 8.4499 - val_accuracy: 0.4022\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9736 - val_loss: 5.0326 - val_accuracy: 0.5067\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9657 - val_loss: 4.5383 - val_accuracy: 0.5467\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9699 - val_loss: 6.9562 - val_accuracy: 0.4867\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9583 - val_loss: 13.8322 - val_accuracy: 0.3600\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9681 - val_loss: 5.7465 - val_accuracy: 0.5111\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9708 - val_loss: 6.6329 - val_accuracy: 0.4578\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9667 - val_loss: 6.3284 - val_accuracy: 0.4911\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9676 - val_loss: 8.5662 - val_accuracy: 0.3889\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9731 - val_loss: 6.1802 - val_accuracy: 0.5622\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9750 - val_loss: 4.0630 - val_accuracy: 0.5489\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9625 - val_loss: 4.0111 - val_accuracy: 0.5222\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9685 - val_loss: 4.9421 - val_accuracy: 0.4911\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9653 - val_loss: 11.4784 - val_accuracy: 0.3667\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0785 - accuracy: 0.9718 - val_loss: 9.4274 - val_accuracy: 0.4089\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9759 - val_loss: 6.5462 - val_accuracy: 0.5222\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9755 - val_loss: 9.7903 - val_accuracy: 0.4644\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9806 - val_loss: 5.6806 - val_accuracy: 0.5511\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9727 - val_loss: 5.1117 - val_accuracy: 0.4867\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9773 - val_loss: 5.8872 - val_accuracy: 0.5667\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9801 - val_loss: 5.7493 - val_accuracy: 0.5578\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9778 - val_loss: 12.6394 - val_accuracy: 0.4067\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9764 - val_loss: 3.8966 - val_accuracy: 0.5578\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9824 - val_loss: 5.5359 - val_accuracy: 0.5378\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9796 - val_loss: 9.2281 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9750 - val_loss: 8.6912 - val_accuracy: 0.5133\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9796 - val_loss: 6.5041 - val_accuracy: 0.5956\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9856 - val_loss: 6.8104 - val_accuracy: 0.4533\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9787 - val_loss: 6.8085 - val_accuracy: 0.5600\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9801 - val_loss: 8.3508 - val_accuracy: 0.5689\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9759 - val_loss: 7.4961 - val_accuracy: 0.5733\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9759 - val_loss: 7.6646 - val_accuracy: 0.5956\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9792 - val_loss: 7.5389 - val_accuracy: 0.4756\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9787 - val_loss: 5.8554 - val_accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9889 - val_loss: 7.2001 - val_accuracy: 0.5556\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 8.4785 - val_accuracy: 0.5511\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9847 - val_loss: 9.5611 - val_accuracy: 0.4911\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 22.9596 - val_accuracy: 0.3911\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9801 - val_loss: 7.7383 - val_accuracy: 0.5778\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9801 - val_loss: 7.5228 - val_accuracy: 0.4622\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9801 - val_loss: 9.1280 - val_accuracy: 0.5933\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9829 - val_loss: 10.4229 - val_accuracy: 0.5356\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9870 - val_loss: 8.6252 - val_accuracy: 0.5378\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9866 - val_loss: 16.6758 - val_accuracy: 0.3311\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9819 - val_loss: 6.6497 - val_accuracy: 0.5378\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 8.1208 - val_accuracy: 0.5933\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9856 - val_loss: 4.7050 - val_accuracy: 0.5200\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9843 - val_loss: 11.0512 - val_accuracy: 0.5022\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9838 - val_loss: 6.3169 - val_accuracy: 0.6356\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9801 - val_loss: 5.9214 - val_accuracy: 0.5933\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9866 - val_loss: 9.6925 - val_accuracy: 0.4600\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 9.2343 - val_accuracy: 0.4889\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_166 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_162 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_166 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 25, 25, 12)        2604      \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_167 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 32)                55328     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 58,847\n",
      "Trainable params: 58,775\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1395 - accuracy: 0.3403 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0789 - accuracy: 0.3704 - val_loss: 1.0927 - val_accuracy: 0.2889\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0654 - accuracy: 0.3815 - val_loss: 1.0827 - val_accuracy: 0.4978\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0527 - accuracy: 0.3991 - val_loss: 1.0929 - val_accuracy: 0.3644\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0474 - accuracy: 0.4032 - val_loss: 1.2134 - val_accuracy: 0.3911\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0355 - accuracy: 0.4171 - val_loss: 1.2859 - val_accuracy: 0.3511\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0298 - accuracy: 0.4144 - val_loss: 1.1241 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0251 - accuracy: 0.4171 - val_loss: 1.1490 - val_accuracy: 0.3711\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0129 - accuracy: 0.4250 - val_loss: 1.1482 - val_accuracy: 0.3600\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0152 - accuracy: 0.4282 - val_loss: 1.1596 - val_accuracy: 0.3644\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9866 - accuracy: 0.4491 - val_loss: 1.1834 - val_accuracy: 0.3822\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9929 - accuracy: 0.4435 - val_loss: 2.1105 - val_accuracy: 0.3289\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9866 - accuracy: 0.4495 - val_loss: 1.3223 - val_accuracy: 0.4444\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9823 - accuracy: 0.4477 - val_loss: 1.2312 - val_accuracy: 0.4489\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9779 - accuracy: 0.4477 - val_loss: 1.0961 - val_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9790 - accuracy: 0.4509 - val_loss: 1.2214 - val_accuracy: 0.4511\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.4509 - val_loss: 1.1467 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9638 - accuracy: 0.4542 - val_loss: 1.2750 - val_accuracy: 0.4400\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9786 - accuracy: 0.4468 - val_loss: 1.1500 - val_accuracy: 0.4178\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9497 - accuracy: 0.4644 - val_loss: 1.4507 - val_accuracy: 0.4044\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9368 - accuracy: 0.4690 - val_loss: 1.2083 - val_accuracy: 0.5022\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9439 - accuracy: 0.4662 - val_loss: 1.1233 - val_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9686 - accuracy: 0.4537 - val_loss: 1.4121 - val_accuracy: 0.4556\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9384 - accuracy: 0.4667 - val_loss: 1.1168 - val_accuracy: 0.4267\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9422 - accuracy: 0.4681 - val_loss: 1.0772 - val_accuracy: 0.4022\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9233 - accuracy: 0.4713 - val_loss: 1.0541 - val_accuracy: 0.4422\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9342 - accuracy: 0.4736 - val_loss: 1.3415 - val_accuracy: 0.4022\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9385 - accuracy: 0.4667 - val_loss: 1.1259 - val_accuracy: 0.4667\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9179 - accuracy: 0.4815 - val_loss: 1.1828 - val_accuracy: 0.4778\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9315 - accuracy: 0.4741 - val_loss: 1.0504 - val_accuracy: 0.4822\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9295 - accuracy: 0.4593 - val_loss: 1.0678 - val_accuracy: 0.4089\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9326 - accuracy: 0.4759 - val_loss: 1.3252 - val_accuracy: 0.4533\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9267 - accuracy: 0.4755 - val_loss: 1.1112 - val_accuracy: 0.4978\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9493 - accuracy: 0.4431 - val_loss: 1.3357 - val_accuracy: 0.4778\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9446 - accuracy: 0.4528 - val_loss: 1.0644 - val_accuracy: 0.5044\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.4523 - val_loss: 1.0111 - val_accuracy: 0.4978\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9382 - accuracy: 0.4532 - val_loss: 1.0275 - val_accuracy: 0.4556\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9414 - accuracy: 0.4625 - val_loss: 1.1450 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9180 - accuracy: 0.4796 - val_loss: 1.0231 - val_accuracy: 0.4711\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9496 - accuracy: 0.4588 - val_loss: 1.0609 - val_accuracy: 0.4156\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9278 - accuracy: 0.4704 - val_loss: 1.3239 - val_accuracy: 0.4778\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9094 - accuracy: 0.4685 - val_loss: 0.9875 - val_accuracy: 0.4711\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9268 - accuracy: 0.4718 - val_loss: 1.0287 - val_accuracy: 0.4133\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9070 - accuracy: 0.4880 - val_loss: 1.0675 - val_accuracy: 0.4511\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9221 - accuracy: 0.4750 - val_loss: 1.2458 - val_accuracy: 0.4244\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9081 - accuracy: 0.4880 - val_loss: 1.1703 - val_accuracy: 0.4200\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9058 - accuracy: 0.4977 - val_loss: 1.2406 - val_accuracy: 0.4622\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8949 - accuracy: 0.4991 - val_loss: 1.1339 - val_accuracy: 0.5467\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8942 - accuracy: 0.5009 - val_loss: 1.0575 - val_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9036 - accuracy: 0.4898 - val_loss: 1.0897 - val_accuracy: 0.5311\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8872 - accuracy: 0.5056 - val_loss: 1.0390 - val_accuracy: 0.4333\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9129 - accuracy: 0.4866 - val_loss: 1.5738 - val_accuracy: 0.4867\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9114 - accuracy: 0.4944 - val_loss: 1.1723 - val_accuracy: 0.4333\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9023 - accuracy: 0.4986 - val_loss: 1.4339 - val_accuracy: 0.4489\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8882 - accuracy: 0.5069 - val_loss: 1.1457 - val_accuracy: 0.4467\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9261 - accuracy: 0.4792 - val_loss: 1.0479 - val_accuracy: 0.4533\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9105 - accuracy: 0.4870 - val_loss: 1.3199 - val_accuracy: 0.5200\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8941 - accuracy: 0.5005 - val_loss: 1.9563 - val_accuracy: 0.4333\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8879 - accuracy: 0.5074 - val_loss: 1.1869 - val_accuracy: 0.5600\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9026 - accuracy: 0.4968 - val_loss: 1.4113 - val_accuracy: 0.5289\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8981 - accuracy: 0.4991 - val_loss: 1.0839 - val_accuracy: 0.4956\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8958 - accuracy: 0.5028 - val_loss: 1.6778 - val_accuracy: 0.5511\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8878 - accuracy: 0.5069 - val_loss: 1.1892 - val_accuracy: 0.5556\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8821 - accuracy: 0.5088 - val_loss: 1.5145 - val_accuracy: 0.5667\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8785 - accuracy: 0.5093 - val_loss: 1.3046 - val_accuracy: 0.5044\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8835 - accuracy: 0.5083 - val_loss: 1.1452 - val_accuracy: 0.5067\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8950 - accuracy: 0.5023 - val_loss: 1.3689 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9058 - accuracy: 0.4963 - val_loss: 1.4641 - val_accuracy: 0.5556\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8757 - accuracy: 0.5171 - val_loss: 1.6633 - val_accuracy: 0.5467\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9012 - accuracy: 0.4977 - val_loss: 1.3657 - val_accuracy: 0.4867\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8818 - accuracy: 0.5120 - val_loss: 1.6925 - val_accuracy: 0.5022\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8681 - accuracy: 0.5199 - val_loss: 1.6346 - val_accuracy: 0.4844\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8560 - accuracy: 0.5245 - val_loss: 1.0065 - val_accuracy: 0.4556\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8709 - accuracy: 0.5148 - val_loss: 1.1863 - val_accuracy: 0.5467\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8538 - accuracy: 0.5259 - val_loss: 3.7829 - val_accuracy: 0.3644\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8627 - accuracy: 0.5190 - val_loss: 1.4338 - val_accuracy: 0.5111\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8473 - accuracy: 0.5306 - val_loss: 1.4085 - val_accuracy: 0.4400\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8484 - accuracy: 0.5269 - val_loss: 1.6556 - val_accuracy: 0.4467\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8680 - accuracy: 0.5181 - val_loss: 1.1831 - val_accuracy: 0.4556\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8552 - accuracy: 0.5259 - val_loss: 1.3777 - val_accuracy: 0.4267\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8545 - accuracy: 0.5301 - val_loss: 2.1245 - val_accuracy: 0.4311\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8746 - accuracy: 0.5171 - val_loss: 1.2865 - val_accuracy: 0.4222\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.5366 - val_loss: 1.1755 - val_accuracy: 0.5289\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.5273 - val_loss: 1.7058 - val_accuracy: 0.4822\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8301 - accuracy: 0.5361 - val_loss: 1.5530 - val_accuracy: 0.5622\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8498 - accuracy: 0.5264 - val_loss: 1.4624 - val_accuracy: 0.4911\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8341 - accuracy: 0.5389 - val_loss: 1.4821 - val_accuracy: 0.5600\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8148 - accuracy: 0.5435 - val_loss: 1.7099 - val_accuracy: 0.5400\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8495 - accuracy: 0.5287 - val_loss: 1.1617 - val_accuracy: 0.5422\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8552 - accuracy: 0.5273 - val_loss: 1.0734 - val_accuracy: 0.5044\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.5384 - val_loss: 1.0877 - val_accuracy: 0.5378\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8290 - accuracy: 0.5412 - val_loss: 1.5119 - val_accuracy: 0.5533\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8139 - accuracy: 0.5449 - val_loss: 1.2341 - val_accuracy: 0.5800\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8169 - accuracy: 0.5421 - val_loss: 1.3923 - val_accuracy: 0.5111\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.5403 - val_loss: 2.0287 - val_accuracy: 0.4778\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.5329 - val_loss: 1.1727 - val_accuracy: 0.5533\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8308 - accuracy: 0.5315 - val_loss: 1.0829 - val_accuracy: 0.5644\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8079 - accuracy: 0.5403 - val_loss: 2.3102 - val_accuracy: 0.5133\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8196 - accuracy: 0.5324 - val_loss: 2.7821 - val_accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8161 - accuracy: 0.5398 - val_loss: 1.6075 - val_accuracy: 0.5489\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_168 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_164 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_168 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_169 (Conv2D)          (None, 25, 25, 12)        2604      \n",
      "_________________________________________________________________\n",
      "batch_normalization_165 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_84 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 114,271\n",
      "Trainable params: 114,199\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2402 - accuracy: 0.3769 - val_loss: 1.0983 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0375 - accuracy: 0.4148 - val_loss: 1.0929 - val_accuracy: 0.5133\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9958 - accuracy: 0.4565 - val_loss: 1.0801 - val_accuracy: 0.4867\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9718 - accuracy: 0.4676 - val_loss: 1.1242 - val_accuracy: 0.4778\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9494 - accuracy: 0.5000 - val_loss: 1.1412 - val_accuracy: 0.4556\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9171 - accuracy: 0.5065 - val_loss: 1.3844 - val_accuracy: 0.5156\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8753 - accuracy: 0.5241 - val_loss: 1.1800 - val_accuracy: 0.4956\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8254 - accuracy: 0.5894 - val_loss: 1.8268 - val_accuracy: 0.3644\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8113 - accuracy: 0.5935 - val_loss: 1.1773 - val_accuracy: 0.5178\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.6000 - val_loss: 1.7320 - val_accuracy: 0.4444\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7585 - accuracy: 0.6273 - val_loss: 1.3852 - val_accuracy: 0.4556\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.6292 - val_loss: 1.7010 - val_accuracy: 0.4400\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7314 - accuracy: 0.6440 - val_loss: 1.3865 - val_accuracy: 0.5489\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.6347 - val_loss: 1.2214 - val_accuracy: 0.5156\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6958 - accuracy: 0.6588 - val_loss: 1.2700 - val_accuracy: 0.4844\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.6616 - val_loss: 3.0349 - val_accuracy: 0.4044\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6699 - val_loss: 2.3324 - val_accuracy: 0.4089\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.6667 - val_loss: 2.6408 - val_accuracy: 0.4044\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6972 - val_loss: 3.3186 - val_accuracy: 0.3978\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6847 - val_loss: 2.3090 - val_accuracy: 0.4667\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6931 - val_loss: 2.6658 - val_accuracy: 0.4467\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6968 - val_loss: 2.2471 - val_accuracy: 0.4156\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6963 - val_loss: 2.5912 - val_accuracy: 0.5111\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6912 - val_loss: 1.5651 - val_accuracy: 0.5667\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.6972 - val_loss: 2.4156 - val_accuracy: 0.4311\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7111 - val_loss: 6.2764 - val_accuracy: 0.3778\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7028 - val_loss: 5.5924 - val_accuracy: 0.4600\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7125 - val_loss: 3.4438 - val_accuracy: 0.4889\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7255 - val_loss: 2.2348 - val_accuracy: 0.4556\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7282 - val_loss: 1.8234 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7407 - val_loss: 3.3523 - val_accuracy: 0.4067\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7134 - val_loss: 3.7720 - val_accuracy: 0.4156\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7398 - val_loss: 5.6107 - val_accuracy: 0.3978\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7273 - val_loss: 3.1917 - val_accuracy: 0.5244\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7255 - val_loss: 2.7137 - val_accuracy: 0.4533\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7278 - val_loss: 2.9488 - val_accuracy: 0.4978\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7329 - val_loss: 2.2867 - val_accuracy: 0.4444\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7083 - val_loss: 3.5938 - val_accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7301 - val_loss: 3.6512 - val_accuracy: 0.4911\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7292 - val_loss: 4.4370 - val_accuracy: 0.4356\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7213 - val_loss: 3.9639 - val_accuracy: 0.4978\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7356 - val_loss: 2.8100 - val_accuracy: 0.4733\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7523 - val_loss: 6.0864 - val_accuracy: 0.4289\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7556 - val_loss: 4.8056 - val_accuracy: 0.4711\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7583 - val_loss: 2.9075 - val_accuracy: 0.5667\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7569 - val_loss: 5.0006 - val_accuracy: 0.4022\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7565 - val_loss: 2.9908 - val_accuracy: 0.4400\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7644 - val_loss: 4.2345 - val_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7588 - val_loss: 2.6061 - val_accuracy: 0.4756\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7583 - val_loss: 3.4279 - val_accuracy: 0.4444\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7454 - val_loss: 4.0384 - val_accuracy: 0.5200\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7653 - val_loss: 3.6001 - val_accuracy: 0.4244\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7727 - val_loss: 2.8299 - val_accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7764 - val_loss: 3.0436 - val_accuracy: 0.5422\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7704 - val_loss: 3.9515 - val_accuracy: 0.4044\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7875 - val_loss: 4.7731 - val_accuracy: 0.4200\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7861 - val_loss: 4.1985 - val_accuracy: 0.4578\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8069 - val_loss: 3.4657 - val_accuracy: 0.5800\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3984 - accuracy: 0.8093 - val_loss: 6.0374 - val_accuracy: 0.4422\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8009 - val_loss: 5.4690 - val_accuracy: 0.4533\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3916 - accuracy: 0.8185 - val_loss: 5.0868 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7889 - val_loss: 2.6219 - val_accuracy: 0.5578\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8088 - val_loss: 3.2177 - val_accuracy: 0.5422\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8079 - val_loss: 7.2380 - val_accuracy: 0.3978\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8023 - val_loss: 2.5436 - val_accuracy: 0.5667\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8097 - val_loss: 4.3554 - val_accuracy: 0.4867\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8120 - val_loss: 6.9999 - val_accuracy: 0.4244\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8065 - val_loss: 4.4661 - val_accuracy: 0.5422\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8204 - val_loss: 3.3480 - val_accuracy: 0.5311\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8227 - val_loss: 3.1220 - val_accuracy: 0.4533\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8361 - val_loss: 7.0260 - val_accuracy: 0.4022\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8352 - val_loss: 3.9482 - val_accuracy: 0.5489\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8162 - val_loss: 9.2270 - val_accuracy: 0.3822\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8292 - val_loss: 5.4726 - val_accuracy: 0.4756\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8389 - val_loss: 5.8494 - val_accuracy: 0.5044\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8565 - val_loss: 4.0264 - val_accuracy: 0.5133\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8495 - val_loss: 3.8410 - val_accuracy: 0.4822\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3154 - accuracy: 0.8458 - val_loss: 5.4654 - val_accuracy: 0.5089\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8468 - val_loss: 5.4323 - val_accuracy: 0.4933\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8394 - val_loss: 4.8792 - val_accuracy: 0.4467\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8481 - val_loss: 5.2691 - val_accuracy: 0.4867\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8532 - val_loss: 4.4236 - val_accuracy: 0.5511\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8454 - val_loss: 4.6778 - val_accuracy: 0.5556\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8486 - val_loss: 5.4648 - val_accuracy: 0.4289\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8523 - val_loss: 6.9074 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8569 - val_loss: 5.1033 - val_accuracy: 0.4933\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8583 - val_loss: 4.1456 - val_accuracy: 0.5933\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.8611 - val_loss: 5.1245 - val_accuracy: 0.5200\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8565 - val_loss: 7.5272 - val_accuracy: 0.4889\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8579 - val_loss: 4.8261 - val_accuracy: 0.6222\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8634 - val_loss: 4.5170 - val_accuracy: 0.5711\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8713 - val_loss: 5.3020 - val_accuracy: 0.5222\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.8694 - val_loss: 3.6947 - val_accuracy: 0.6111\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.8792 - val_loss: 4.4548 - val_accuracy: 0.6244\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8569 - val_loss: 6.7721 - val_accuracy: 0.4689\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8588 - val_loss: 5.1787 - val_accuracy: 0.5089\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.8634 - val_loss: 5.9614 - val_accuracy: 0.5311\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8648 - val_loss: 8.2653 - val_accuracy: 0.3422\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.8676 - val_loss: 6.7851 - val_accuracy: 0.5156\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8764 - val_loss: 7.7909 - val_accuracy: 0.4911\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_170 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_171 (Conv2D)          (None, 25, 25, 12)        2604      \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_171 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_85 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 225,119\n",
      "Trainable params: 225,047\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2126 - accuracy: 0.4375 - val_loss: 1.0966 - val_accuracy: 0.3867\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9490 - accuracy: 0.4912 - val_loss: 1.1342 - val_accuracy: 0.3400\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9009 - accuracy: 0.5148 - val_loss: 1.1086 - val_accuracy: 0.4200\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8208 - accuracy: 0.5384 - val_loss: 1.2524 - val_accuracy: 0.4978\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7845 - accuracy: 0.5625 - val_loss: 1.2909 - val_accuracy: 0.5289\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.6079 - val_loss: 1.1394 - val_accuracy: 0.4511\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.6236 - val_loss: 1.6093 - val_accuracy: 0.4444\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.6394 - val_loss: 1.9422 - val_accuracy: 0.4244\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.6532 - val_loss: 1.2219 - val_accuracy: 0.5711\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6676 - val_loss: 2.2846 - val_accuracy: 0.4911\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6769 - val_loss: 1.7956 - val_accuracy: 0.5133\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6958 - val_loss: 2.9077 - val_accuracy: 0.4489\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5780 - accuracy: 0.7051 - val_loss: 2.3535 - val_accuracy: 0.5156\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7245 - val_loss: 2.6093 - val_accuracy: 0.4533\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7310 - val_loss: 2.0674 - val_accuracy: 0.4778\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7329 - val_loss: 4.5244 - val_accuracy: 0.4267\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7583 - val_loss: 2.3962 - val_accuracy: 0.5600\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7676 - val_loss: 2.9785 - val_accuracy: 0.4689\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7639 - val_loss: 6.2212 - val_accuracy: 0.3622\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7676 - val_loss: 5.2099 - val_accuracy: 0.3689\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7755 - val_loss: 2.7233 - val_accuracy: 0.5022\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7944 - val_loss: 4.7547 - val_accuracy: 0.4067\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7829 - val_loss: 7.1020 - val_accuracy: 0.3622\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7931 - val_loss: 2.3175 - val_accuracy: 0.5644\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8028 - val_loss: 5.2004 - val_accuracy: 0.4622\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7995 - val_loss: 3.4149 - val_accuracy: 0.5022\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8236 - val_loss: 4.4563 - val_accuracy: 0.4578\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8227 - val_loss: 3.3208 - val_accuracy: 0.5644\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8259 - val_loss: 6.2710 - val_accuracy: 0.4356\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8384 - val_loss: 8.4471 - val_accuracy: 0.3244\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8231 - val_loss: 4.5262 - val_accuracy: 0.4933\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8343 - val_loss: 3.8336 - val_accuracy: 0.4578\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8426 - val_loss: 3.1627 - val_accuracy: 0.5822\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8343 - val_loss: 3.0179 - val_accuracy: 0.4867\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8560 - val_loss: 5.8017 - val_accuracy: 0.4644\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.8694 - val_loss: 4.3498 - val_accuracy: 0.5267\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8616 - val_loss: 3.4209 - val_accuracy: 0.4733\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8560 - val_loss: 3.6509 - val_accuracy: 0.5800\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.8875 - val_loss: 4.9143 - val_accuracy: 0.5422\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8852 - val_loss: 4.0182 - val_accuracy: 0.5022\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.8843 - val_loss: 5.7779 - val_accuracy: 0.4244\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.8639 - val_loss: 4.1216 - val_accuracy: 0.5289\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.8968 - val_loss: 4.1515 - val_accuracy: 0.5578\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8778 - val_loss: 4.2558 - val_accuracy: 0.5533\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2413 - accuracy: 0.8958 - val_loss: 6.5069 - val_accuracy: 0.5444\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8903 - val_loss: 4.1756 - val_accuracy: 0.5756\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.8995 - val_loss: 11.4313 - val_accuracy: 0.3978\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9125 - val_loss: 4.7807 - val_accuracy: 0.5422\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2242 - accuracy: 0.9120 - val_loss: 3.8124 - val_accuracy: 0.5600\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2244 - accuracy: 0.9005 - val_loss: 5.5255 - val_accuracy: 0.5444\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9120 - val_loss: 4.4716 - val_accuracy: 0.5800\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9162 - val_loss: 5.8245 - val_accuracy: 0.5489\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9259 - val_loss: 3.9822 - val_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9181 - val_loss: 5.0966 - val_accuracy: 0.4822\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2128 - accuracy: 0.9111 - val_loss: 7.2556 - val_accuracy: 0.4800\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9185 - val_loss: 3.9479 - val_accuracy: 0.5044\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9282 - val_loss: 9.7228 - val_accuracy: 0.4422\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 0.9204 - val_loss: 4.2834 - val_accuracy: 0.5778\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9208 - val_loss: 9.5296 - val_accuracy: 0.4111\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9213 - val_loss: 4.8180 - val_accuracy: 0.5156\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9301 - val_loss: 5.5284 - val_accuracy: 0.5267\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9361 - val_loss: 6.3155 - val_accuracy: 0.4822\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1848 - accuracy: 0.9208 - val_loss: 14.8338 - val_accuracy: 0.3756\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9287 - val_loss: 6.6980 - val_accuracy: 0.4911\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9407 - val_loss: 5.1478 - val_accuracy: 0.5133\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9218 - val_loss: 4.3404 - val_accuracy: 0.5178\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9380 - val_loss: 7.9433 - val_accuracy: 0.4956\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9389 - val_loss: 6.3608 - val_accuracy: 0.5044\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9366 - val_loss: 5.2300 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9426 - val_loss: 6.2322 - val_accuracy: 0.4800\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.9245 - val_loss: 4.5811 - val_accuracy: 0.5311\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9394 - val_loss: 5.4275 - val_accuracy: 0.5556\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9509 - val_loss: 7.0178 - val_accuracy: 0.4867\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9500 - val_loss: 7.8814 - val_accuracy: 0.5044\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9556 - val_loss: 7.1438 - val_accuracy: 0.5489\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1624 - accuracy: 0.9370 - val_loss: 5.2511 - val_accuracy: 0.4822\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9468 - val_loss: 5.8040 - val_accuracy: 0.5822\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9356 - val_loss: 15.2970 - val_accuracy: 0.4489\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9463 - val_loss: 5.7161 - val_accuracy: 0.5889\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9486 - val_loss: 6.7901 - val_accuracy: 0.5600\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9449 - val_loss: 6.9069 - val_accuracy: 0.5289\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9486 - val_loss: 6.1675 - val_accuracy: 0.5467\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9509 - val_loss: 7.4907 - val_accuracy: 0.5022\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9495 - val_loss: 8.3922 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9481 - val_loss: 5.8039 - val_accuracy: 0.5822\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9560 - val_loss: 9.5573 - val_accuracy: 0.4578\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9574 - val_loss: 6.6555 - val_accuracy: 0.5422\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9542 - val_loss: 7.5208 - val_accuracy: 0.5400\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9639 - val_loss: 7.7811 - val_accuracy: 0.5756\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9625 - val_loss: 7.8733 - val_accuracy: 0.5356\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9574 - val_loss: 8.3264 - val_accuracy: 0.5422\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9639 - val_loss: 7.5944 - val_accuracy: 0.5778\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1103 - accuracy: 0.9542 - val_loss: 7.8005 - val_accuracy: 0.5133\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9611 - val_loss: 8.5224 - val_accuracy: 0.5444\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9620 - val_loss: 11.4999 - val_accuracy: 0.4644\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9583 - val_loss: 7.2969 - val_accuracy: 0.4822\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9579 - val_loss: 10.1164 - val_accuracy: 0.4822\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9602 - val_loss: 11.1007 - val_accuracy: 0.4733\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9616 - val_loss: 9.4728 - val_accuracy: 0.4933\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9597 - val_loss: 8.0973 - val_accuracy: 0.5467\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_172 (Conv2D)          (None, 54, 54, 24)        672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 54, 54, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 54, 54, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_172 (MaxPoolin (None, 27, 27, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_173 (Conv2D)          (None, 25, 25, 12)        2604      \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_173 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_86 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 256)               442624    \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 446,815\n",
      "Trainable params: 446,743\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.3085 - accuracy: 0.4463 - val_loss: 1.0873 - val_accuracy: 0.3844\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8721 - accuracy: 0.5718 - val_loss: 1.0723 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.6227 - val_loss: 0.9718 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7040 - accuracy: 0.6704 - val_loss: 1.1701 - val_accuracy: 0.4289\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6852 - val_loss: 1.5713 - val_accuracy: 0.5800\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7421 - val_loss: 1.9443 - val_accuracy: 0.4089\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7583 - val_loss: 1.1669 - val_accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7634 - val_loss: 1.7581 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7921 - val_loss: 1.4771 - val_accuracy: 0.4778\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7972 - val_loss: 2.5968 - val_accuracy: 0.4733\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8176 - val_loss: 3.4307 - val_accuracy: 0.3889\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8273 - val_loss: 1.5393 - val_accuracy: 0.5111\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8255 - val_loss: 1.4256 - val_accuracy: 0.4956\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8468 - val_loss: 1.9945 - val_accuracy: 0.4911\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8449 - val_loss: 4.2643 - val_accuracy: 0.4133\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8458 - val_loss: 1.9279 - val_accuracy: 0.5511\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.8597 - val_loss: 1.9469 - val_accuracy: 0.5133\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8699 - val_loss: 4.9151 - val_accuracy: 0.3911\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8745 - val_loss: 3.0851 - val_accuracy: 0.4911\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.8755 - val_loss: 3.0639 - val_accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.8861 - val_loss: 3.3876 - val_accuracy: 0.4356\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.8921 - val_loss: 6.9954 - val_accuracy: 0.4311\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.8940 - val_loss: 3.0227 - val_accuracy: 0.5156\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9065 - val_loss: 2.5448 - val_accuracy: 0.5067\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.9134 - val_loss: 2.8576 - val_accuracy: 0.5267\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9083 - val_loss: 2.9420 - val_accuracy: 0.5089\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9106 - val_loss: 2.0392 - val_accuracy: 0.6111\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9181 - val_loss: 2.7254 - val_accuracy: 0.5289\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.9190 - val_loss: 10.1102 - val_accuracy: 0.3533\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9255 - val_loss: 8.0590 - val_accuracy: 0.4022\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9273 - val_loss: 4.0560 - val_accuracy: 0.4844\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9259 - val_loss: 5.1109 - val_accuracy: 0.4889\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9333 - val_loss: 3.2027 - val_accuracy: 0.5889\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9315 - val_loss: 4.1642 - val_accuracy: 0.5311\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9412 - val_loss: 5.3615 - val_accuracy: 0.5244\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9356 - val_loss: 4.0057 - val_accuracy: 0.5089\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9431 - val_loss: 2.8301 - val_accuracy: 0.5733\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9333 - val_loss: 4.6768 - val_accuracy: 0.4933\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9380 - val_loss: 4.8570 - val_accuracy: 0.4689\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9481 - val_loss: 6.0653 - val_accuracy: 0.4933\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9421 - val_loss: 6.5247 - val_accuracy: 0.4711\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9431 - val_loss: 4.1525 - val_accuracy: 0.6200\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9468 - val_loss: 5.9271 - val_accuracy: 0.4489\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9509 - val_loss: 5.5367 - val_accuracy: 0.4956\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9583 - val_loss: 3.7077 - val_accuracy: 0.6822\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9639 - val_loss: 6.3925 - val_accuracy: 0.4489\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9583 - val_loss: 6.8435 - val_accuracy: 0.4600\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9514 - val_loss: 3.9565 - val_accuracy: 0.5844\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9588 - val_loss: 4.4187 - val_accuracy: 0.4800\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9616 - val_loss: 3.6267 - val_accuracy: 0.5133\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9634 - val_loss: 3.7031 - val_accuracy: 0.5578\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9611 - val_loss: 8.8264 - val_accuracy: 0.5133\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9611 - val_loss: 4.7879 - val_accuracy: 0.5244\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9704 - val_loss: 9.4578 - val_accuracy: 0.4244\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9704 - val_loss: 4.8204 - val_accuracy: 0.5778\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9625 - val_loss: 3.4130 - val_accuracy: 0.5867\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9620 - val_loss: 7.8942 - val_accuracy: 0.5022\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9606 - val_loss: 5.4089 - val_accuracy: 0.4711\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9671 - val_loss: 3.5997 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9676 - val_loss: 6.0547 - val_accuracy: 0.5133\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9671 - val_loss: 5.2379 - val_accuracy: 0.5289\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9653 - val_loss: 6.6045 - val_accuracy: 0.5222\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9597 - val_loss: 7.2275 - val_accuracy: 0.5267\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9667 - val_loss: 4.3401 - val_accuracy: 0.6111\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9694 - val_loss: 8.2599 - val_accuracy: 0.4978\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9699 - val_loss: 6.2832 - val_accuracy: 0.5089\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9741 - val_loss: 5.7981 - val_accuracy: 0.5556\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9694 - val_loss: 4.3407 - val_accuracy: 0.5600\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9782 - val_loss: 4.8245 - val_accuracy: 0.5622\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9759 - val_loss: 7.7135 - val_accuracy: 0.5311\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9755 - val_loss: 6.9760 - val_accuracy: 0.4867\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9639 - val_loss: 11.6467 - val_accuracy: 0.4378\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9718 - val_loss: 6.8065 - val_accuracy: 0.5600\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9755 - val_loss: 7.0209 - val_accuracy: 0.5467\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9810 - val_loss: 4.7798 - val_accuracy: 0.6533\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9796 - val_loss: 5.8809 - val_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9750 - val_loss: 7.2326 - val_accuracy: 0.5111\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9778 - val_loss: 10.7527 - val_accuracy: 0.4578\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9787 - val_loss: 5.6237 - val_accuracy: 0.5244\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9759 - val_loss: 4.6378 - val_accuracy: 0.6200\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9819 - val_loss: 6.6909 - val_accuracy: 0.5578\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9833 - val_loss: 6.4183 - val_accuracy: 0.6178\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 8.1598 - val_accuracy: 0.5156\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9819 - val_loss: 10.1773 - val_accuracy: 0.4200\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9745 - val_loss: 6.1675 - val_accuracy: 0.5556\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 5.6553 - val_accuracy: 0.5956\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9833 - val_loss: 5.7903 - val_accuracy: 0.5489\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 5.0991 - val_accuracy: 0.5733\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0399 - accuracy: 0.9843 - val_loss: 6.9876 - val_accuracy: 0.5622\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9852 - val_loss: 12.0989 - val_accuracy: 0.4222\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9806 - val_loss: 9.1646 - val_accuracy: 0.5044\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9815 - val_loss: 5.8625 - val_accuracy: 0.5933\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 9.3133 - val_accuracy: 0.5222\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9833 - val_loss: 18.8424 - val_accuracy: 0.3578\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 8.9572 - val_accuracy: 0.4489\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9847 - val_loss: 6.1925 - val_accuracy: 0.5689\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9870 - val_loss: 11.5485 - val_accuracy: 0.5267\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 10.1617 - val_accuracy: 0.4689\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 7.8960 - val_accuracy: 0.5889\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 7.5380 - val_accuracy: 0.4889\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_174 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_170 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_174 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_175 (Conv2D)          (None, 25, 25, 8)         1952      \n",
      "_________________________________________________________________\n",
      "batch_normalization_171 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_175 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_87 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 39,843\n",
      "Trainable params: 39,773\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1606 - accuracy: 0.3546 - val_loss: 1.1006 - val_accuracy: 0.3178\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0667 - accuracy: 0.3509 - val_loss: 1.1139 - val_accuracy: 0.3467\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0564 - accuracy: 0.3648 - val_loss: 1.1389 - val_accuracy: 0.3956\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0403 - accuracy: 0.3833 - val_loss: 1.1421 - val_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0343 - accuracy: 0.3755 - val_loss: 1.1027 - val_accuracy: 0.4511\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.3898 - val_loss: 1.0098 - val_accuracy: 0.4867\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0102 - accuracy: 0.4083 - val_loss: 1.1683 - val_accuracy: 0.5089\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.4106 - val_loss: 0.9828 - val_accuracy: 0.5067\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0103 - accuracy: 0.4162 - val_loss: 1.2070 - val_accuracy: 0.5444\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9908 - accuracy: 0.4310 - val_loss: 1.0676 - val_accuracy: 0.3911\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9834 - accuracy: 0.4329 - val_loss: 0.9568 - val_accuracy: 0.5200\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9664 - accuracy: 0.4472 - val_loss: 0.9879 - val_accuracy: 0.4756\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9559 - accuracy: 0.4551 - val_loss: 0.8678 - val_accuracy: 0.5933\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9523 - accuracy: 0.4593 - val_loss: 0.9033 - val_accuracy: 0.5978\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9301 - accuracy: 0.4755 - val_loss: 1.0156 - val_accuracy: 0.5822\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9152 - accuracy: 0.4796 - val_loss: 1.0164 - val_accuracy: 0.5422\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9080 - accuracy: 0.4903 - val_loss: 1.0304 - val_accuracy: 0.4622\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8947 - accuracy: 0.4954 - val_loss: 0.9669 - val_accuracy: 0.6067\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8830 - accuracy: 0.5111 - val_loss: 0.9513 - val_accuracy: 0.5133\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8648 - accuracy: 0.5065 - val_loss: 0.9864 - val_accuracy: 0.4511\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8732 - accuracy: 0.5181 - val_loss: 1.0907 - val_accuracy: 0.5911\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8705 - accuracy: 0.5088 - val_loss: 1.3710 - val_accuracy: 0.4444\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8422 - accuracy: 0.5468 - val_loss: 0.9196 - val_accuracy: 0.5400\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8427 - accuracy: 0.5324 - val_loss: 0.8785 - val_accuracy: 0.5556\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8410 - accuracy: 0.5366 - val_loss: 0.8999 - val_accuracy: 0.5978\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8401 - accuracy: 0.5444 - val_loss: 0.9132 - val_accuracy: 0.5289\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8362 - accuracy: 0.5509 - val_loss: 1.1302 - val_accuracy: 0.5156\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8132 - accuracy: 0.5486 - val_loss: 1.0677 - val_accuracy: 0.4956\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8180 - accuracy: 0.5500 - val_loss: 1.0529 - val_accuracy: 0.6044\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 0.5745 - val_loss: 1.1252 - val_accuracy: 0.5667\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7823 - accuracy: 0.5708 - val_loss: 1.0205 - val_accuracy: 0.5267\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7805 - accuracy: 0.5833 - val_loss: 1.3577 - val_accuracy: 0.5467\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.5870 - val_loss: 0.8967 - val_accuracy: 0.6444\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7490 - accuracy: 0.5968 - val_loss: 1.2099 - val_accuracy: 0.4800\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7776 - accuracy: 0.5648 - val_loss: 1.1281 - val_accuracy: 0.4600\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7566 - accuracy: 0.5866 - val_loss: 1.1326 - val_accuracy: 0.5244\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.5931 - val_loss: 1.1228 - val_accuracy: 0.5956\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.6051 - val_loss: 1.0991 - val_accuracy: 0.5533\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.6194 - val_loss: 1.1310 - val_accuracy: 0.6356\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.6065 - val_loss: 1.1452 - val_accuracy: 0.5778\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.6144 - val_loss: 1.0099 - val_accuracy: 0.6578\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.6264 - val_loss: 1.0766 - val_accuracy: 0.6622\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.6194 - val_loss: 1.5049 - val_accuracy: 0.5667\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.6296 - val_loss: 1.3533 - val_accuracy: 0.5089\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.6380 - val_loss: 1.1431 - val_accuracy: 0.6222\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.6421 - val_loss: 1.2832 - val_accuracy: 0.5244\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6449 - val_loss: 1.6861 - val_accuracy: 0.4133\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6556 - val_loss: 1.3516 - val_accuracy: 0.6333\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6389 - val_loss: 1.3266 - val_accuracy: 0.6222\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6528 - val_loss: 1.4826 - val_accuracy: 0.6222\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6671 - val_loss: 2.5742 - val_accuracy: 0.3867\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6546 - val_loss: 1.5120 - val_accuracy: 0.5689\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6727 - val_loss: 1.4719 - val_accuracy: 0.5378\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.6796 - val_loss: 1.5553 - val_accuracy: 0.5111\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6755 - val_loss: 2.1205 - val_accuracy: 0.4711\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6634 - val_loss: 1.5152 - val_accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6819 - val_loss: 1.5461 - val_accuracy: 0.5822\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.6769 - val_loss: 1.4459 - val_accuracy: 0.5711\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6606 - val_loss: 1.6005 - val_accuracy: 0.5956\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6861 - val_loss: 1.4751 - val_accuracy: 0.6756\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6894 - val_loss: 1.6794 - val_accuracy: 0.5644\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6838 - val_loss: 1.4823 - val_accuracy: 0.5422\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6792 - val_loss: 1.7058 - val_accuracy: 0.6467\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5975 - accuracy: 0.6884 - val_loss: 1.8212 - val_accuracy: 0.6311\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6889 - val_loss: 1.6701 - val_accuracy: 0.6044\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7111 - val_loss: 2.0625 - val_accuracy: 0.5889\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6968 - val_loss: 1.7685 - val_accuracy: 0.5511\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6981 - val_loss: 1.6262 - val_accuracy: 0.6267\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7106 - val_loss: 1.8782 - val_accuracy: 0.5800\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7199 - val_loss: 1.9006 - val_accuracy: 0.5689\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7171 - val_loss: 2.0557 - val_accuracy: 0.6044\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7157 - val_loss: 1.8534 - val_accuracy: 0.5689\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7250 - val_loss: 1.8483 - val_accuracy: 0.6333\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7259 - val_loss: 2.4193 - val_accuracy: 0.5356\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7236 - val_loss: 1.9166 - val_accuracy: 0.6578\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7356 - val_loss: 2.2696 - val_accuracy: 0.5156\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7375 - val_loss: 2.5933 - val_accuracy: 0.5978\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7384 - val_loss: 2.2088 - val_accuracy: 0.5578\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7389 - val_loss: 2.8276 - val_accuracy: 0.6422\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7204 - val_loss: 2.6882 - val_accuracy: 0.5156\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7458 - val_loss: 2.6131 - val_accuracy: 0.6044\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7398 - val_loss: 2.2718 - val_accuracy: 0.5044\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 2.5224 - val_accuracy: 0.5133\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7440 - val_loss: 2.5287 - val_accuracy: 0.4689\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7588 - val_loss: 2.4369 - val_accuracy: 0.5044\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7532 - val_loss: 2.3912 - val_accuracy: 0.5222\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7611 - val_loss: 2.1794 - val_accuracy: 0.5200\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7435 - val_loss: 2.6908 - val_accuracy: 0.5222\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7546 - val_loss: 3.0374 - val_accuracy: 0.4933\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7477 - val_loss: 2.4117 - val_accuracy: 0.5444\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7532 - val_loss: 2.4335 - val_accuracy: 0.5178\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7495 - val_loss: 2.4920 - val_accuracy: 0.5311\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7514 - val_loss: 2.4131 - val_accuracy: 0.4667\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7463 - val_loss: 2.5830 - val_accuracy: 0.5444\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7602 - val_loss: 2.7964 - val_accuracy: 0.4911\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7653 - val_loss: 3.1122 - val_accuracy: 0.5156\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7560 - val_loss: 3.0099 - val_accuracy: 0.5244\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7588 - val_loss: 2.9391 - val_accuracy: 0.5111\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7574 - val_loss: 2.8661 - val_accuracy: 0.5222\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7662 - val_loss: 3.2893 - val_accuracy: 0.4800\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_176 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_172 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_176 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 25, 25, 8)         1952      \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_177 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_88 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 76,835\n",
      "Trainable params: 76,765\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1902 - accuracy: 0.3880 - val_loss: 1.1060 - val_accuracy: 0.3556\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9859 - accuracy: 0.4449 - val_loss: 1.0955 - val_accuracy: 0.3578\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9448 - accuracy: 0.4940 - val_loss: 1.0600 - val_accuracy: 0.4467\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8733 - accuracy: 0.5227 - val_loss: 1.3920 - val_accuracy: 0.4600\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.5361 - val_loss: 3.6494 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7905 - accuracy: 0.5639 - val_loss: 2.2571 - val_accuracy: 0.4133\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.5894 - val_loss: 2.5805 - val_accuracy: 0.4356\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.6009 - val_loss: 2.1315 - val_accuracy: 0.4156\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6296 - val_loss: 1.8828 - val_accuracy: 0.4733\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6602 - val_loss: 2.1212 - val_accuracy: 0.4511\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6588 - val_loss: 1.7425 - val_accuracy: 0.5533\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6699 - val_loss: 1.9628 - val_accuracy: 0.5133\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6745 - val_loss: 3.4999 - val_accuracy: 0.4556\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.6815 - val_loss: 4.6918 - val_accuracy: 0.4222\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.6833 - val_loss: 5.0630 - val_accuracy: 0.4333\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7023 - val_loss: 4.9115 - val_accuracy: 0.3978\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7065 - val_loss: 2.3401 - val_accuracy: 0.4800\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7213 - val_loss: 2.5545 - val_accuracy: 0.5200\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7102 - val_loss: 4.8226 - val_accuracy: 0.4689\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7264 - val_loss: 4.5033 - val_accuracy: 0.4778\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7338 - val_loss: 5.2231 - val_accuracy: 0.4889\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7468 - val_loss: 2.8945 - val_accuracy: 0.5111\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7324 - val_loss: 3.8757 - val_accuracy: 0.5111\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7435 - val_loss: 8.1109 - val_accuracy: 0.3822\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7491 - val_loss: 4.3049 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7616 - val_loss: 3.9344 - val_accuracy: 0.5267\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7731 - val_loss: 4.0660 - val_accuracy: 0.5667\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7500 - val_loss: 5.5548 - val_accuracy: 0.4733\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7532 - val_loss: 4.7336 - val_accuracy: 0.5178\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7495 - val_loss: 3.1363 - val_accuracy: 0.5467\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.7699 - val_loss: 7.3499 - val_accuracy: 0.3844\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.7852 - val_loss: 10.2283 - val_accuracy: 0.3689\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7653 - val_loss: 4.5383 - val_accuracy: 0.4756\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.7852 - val_loss: 6.6343 - val_accuracy: 0.4956\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.7944 - val_loss: 6.4316 - val_accuracy: 0.4733\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7810 - val_loss: 5.5350 - val_accuracy: 0.5156\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.7838 - val_loss: 4.7321 - val_accuracy: 0.4933\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.7995 - val_loss: 7.5530 - val_accuracy: 0.4622\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.7940 - val_loss: 9.9571 - val_accuracy: 0.3689\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.7931 - val_loss: 5.8575 - val_accuracy: 0.6044\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.7745 - val_loss: 6.4314 - val_accuracy: 0.5133\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.7824 - val_loss: 5.8082 - val_accuracy: 0.5533\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.7977 - val_loss: 6.6865 - val_accuracy: 0.5289\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.7954 - val_loss: 5.2047 - val_accuracy: 0.4756\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.7963 - val_loss: 5.3061 - val_accuracy: 0.4800\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8111 - val_loss: 6.7094 - val_accuracy: 0.4911\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8083 - val_loss: 8.6710 - val_accuracy: 0.4978\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8083 - val_loss: 16.0354 - val_accuracy: 0.3556\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8171 - val_loss: 11.4198 - val_accuracy: 0.4400\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8088 - val_loss: 7.2090 - val_accuracy: 0.4978\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8185 - val_loss: 7.7063 - val_accuracy: 0.4978\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8287 - val_loss: 5.9234 - val_accuracy: 0.5156\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8213 - val_loss: 6.4598 - val_accuracy: 0.4733\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8227 - val_loss: 15.8372 - val_accuracy: 0.3533\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8426 - val_loss: 6.0167 - val_accuracy: 0.4622\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8310 - val_loss: 6.3044 - val_accuracy: 0.5178\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8319 - val_loss: 8.5109 - val_accuracy: 0.5222\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8472 - val_loss: 7.6138 - val_accuracy: 0.5089\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8463 - val_loss: 8.8326 - val_accuracy: 0.5222\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8412 - val_loss: 9.7927 - val_accuracy: 0.5067\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.8532 - val_loss: 11.5404 - val_accuracy: 0.4600\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.8361 - val_loss: 5.4119 - val_accuracy: 0.5356\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2881 - accuracy: 0.8426 - val_loss: 8.4097 - val_accuracy: 0.4911\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8468 - val_loss: 11.5145 - val_accuracy: 0.4622\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8477 - val_loss: 9.9047 - val_accuracy: 0.4778\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8620 - val_loss: 9.2562 - val_accuracy: 0.5156\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8454 - val_loss: 11.3370 - val_accuracy: 0.4244\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8532 - val_loss: 8.2211 - val_accuracy: 0.5667\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8556 - val_loss: 12.1494 - val_accuracy: 0.4333\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.8639 - val_loss: 11.1400 - val_accuracy: 0.4711\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8588 - val_loss: 11.6598 - val_accuracy: 0.4489\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2545 - accuracy: 0.8639 - val_loss: 23.1581 - val_accuracy: 0.3289\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.8657 - val_loss: 17.6668 - val_accuracy: 0.3889\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8671 - val_loss: 10.2497 - val_accuracy: 0.4867\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.8708 - val_loss: 7.2824 - val_accuracy: 0.5267\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.8736 - val_loss: 10.5248 - val_accuracy: 0.5089\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.8778 - val_loss: 9.2184 - val_accuracy: 0.5156\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.8843 - val_loss: 9.8685 - val_accuracy: 0.5222\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2439 - accuracy: 0.8796 - val_loss: 8.6816 - val_accuracy: 0.4800\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.8880 - val_loss: 12.2646 - val_accuracy: 0.4267\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.8829 - val_loss: 8.4992 - val_accuracy: 0.5089\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.8926 - val_loss: 11.3339 - val_accuracy: 0.5111\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.8875 - val_loss: 12.3128 - val_accuracy: 0.4711\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.8856 - val_loss: 9.6840 - val_accuracy: 0.5267\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.8912 - val_loss: 11.3381 - val_accuracy: 0.5267\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 9.5164 - val_accuracy: 0.5044\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.8986 - val_loss: 16.7035 - val_accuracy: 0.4156\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2214 - accuracy: 0.8912 - val_loss: 16.5476 - val_accuracy: 0.4000\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.8944 - val_loss: 13.2088 - val_accuracy: 0.4622\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.8889 - val_loss: 9.1307 - val_accuracy: 0.5533\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.8995 - val_loss: 5.6112 - val_accuracy: 0.5422\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9009 - val_loss: 10.1505 - val_accuracy: 0.5356\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9046 - val_loss: 12.1465 - val_accuracy: 0.4889\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9056 - val_loss: 21.1349 - val_accuracy: 0.4022\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9102 - val_loss: 14.5828 - val_accuracy: 0.4733\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9065 - val_loss: 12.3898 - val_accuracy: 0.5044\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9037 - val_loss: 11.3395 - val_accuracy: 0.4889\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 12.9715 - val_accuracy: 0.4911\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9051 - val_loss: 33.4880 - val_accuracy: 0.3556\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9000 - val_loss: 12.0918 - val_accuracy: 0.4578\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_178 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_178 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 25, 25, 8)         1952      \n",
      "_________________________________________________________________\n",
      "batch_normalization_175 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_179 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_89 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 150,819\n",
      "Trainable params: 150,749\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2465 - accuracy: 0.4306 - val_loss: 1.1057 - val_accuracy: 0.3111\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9462 - accuracy: 0.5037 - val_loss: 1.0854 - val_accuracy: 0.4133\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8811 - accuracy: 0.5319 - val_loss: 1.0688 - val_accuracy: 0.4511\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7654 - accuracy: 0.6310 - val_loss: 1.8959 - val_accuracy: 0.3133\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7205 - accuracy: 0.6458 - val_loss: 1.5156 - val_accuracy: 0.4089\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6787 - val_loss: 3.5454 - val_accuracy: 0.3533\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7157 - val_loss: 1.4044 - val_accuracy: 0.5311\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7292 - val_loss: 8.1926 - val_accuracy: 0.3000\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7366 - val_loss: 1.4984 - val_accuracy: 0.4978\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7495 - val_loss: 2.1498 - val_accuracy: 0.4556\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7713 - val_loss: 2.1022 - val_accuracy: 0.4844\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7745 - val_loss: 2.5769 - val_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4303 - accuracy: 0.7829 - val_loss: 6.1035 - val_accuracy: 0.3511\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7958 - val_loss: 3.4036 - val_accuracy: 0.5089\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8005 - val_loss: 3.5384 - val_accuracy: 0.4489\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8181 - val_loss: 2.3550 - val_accuracy: 0.4844\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8278 - val_loss: 4.4754 - val_accuracy: 0.4133\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8222 - val_loss: 3.1011 - val_accuracy: 0.3578\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8389 - val_loss: 4.0232 - val_accuracy: 0.4444\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.8495 - val_loss: 1.9112 - val_accuracy: 0.5378\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8551 - val_loss: 1.8804 - val_accuracy: 0.5533\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8495 - val_loss: 4.0575 - val_accuracy: 0.4422\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8583 - val_loss: 2.0924 - val_accuracy: 0.5511\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8653 - val_loss: 3.7837 - val_accuracy: 0.3933\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8750 - val_loss: 2.5998 - val_accuracy: 0.5244\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8796 - val_loss: 8.7223 - val_accuracy: 0.3222\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8583 - val_loss: 3.4952 - val_accuracy: 0.4644\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.8829 - val_loss: 4.8232 - val_accuracy: 0.3978\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.8727 - val_loss: 3.3197 - val_accuracy: 0.4644\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8648 - val_loss: 3.7006 - val_accuracy: 0.5244\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.8852 - val_loss: 2.0303 - val_accuracy: 0.5889\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.8926 - val_loss: 5.3347 - val_accuracy: 0.5156\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.8833 - val_loss: 5.8135 - val_accuracy: 0.4289\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2173 - accuracy: 0.9028 - val_loss: 5.7183 - val_accuracy: 0.4644\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 3.5172 - val_accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9037 - val_loss: 4.0191 - val_accuracy: 0.4444\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9093 - val_loss: 5.1575 - val_accuracy: 0.4400\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9167 - val_loss: 5.5684 - val_accuracy: 0.4333\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.9083 - val_loss: 3.2702 - val_accuracy: 0.5244\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9190 - val_loss: 9.5609 - val_accuracy: 0.3822\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1982 - accuracy: 0.9074 - val_loss: 4.8349 - val_accuracy: 0.4844\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.8977 - val_loss: 2.7416 - val_accuracy: 0.6089\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.8991 - val_loss: 6.1373 - val_accuracy: 0.4356\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9074 - val_loss: 10.0690 - val_accuracy: 0.3867\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9282 - val_loss: 7.2930 - val_accuracy: 0.4222\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1855 - accuracy: 0.9083 - val_loss: 10.7125 - val_accuracy: 0.3733\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1700 - accuracy: 0.9204 - val_loss: 7.8209 - val_accuracy: 0.4356\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9245 - val_loss: 3.9789 - val_accuracy: 0.5044\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9255 - val_loss: 8.8893 - val_accuracy: 0.4156\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9329 - val_loss: 5.3176 - val_accuracy: 0.5022\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9269 - val_loss: 5.4539 - val_accuracy: 0.4933\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9361 - val_loss: 4.0784 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1338 - accuracy: 0.9407 - val_loss: 11.2940 - val_accuracy: 0.3978\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9347 - val_loss: 4.5248 - val_accuracy: 0.5289\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9310 - val_loss: 5.2437 - val_accuracy: 0.5178\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.9352 - val_loss: 21.0010 - val_accuracy: 0.3311\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9356 - val_loss: 7.0096 - val_accuracy: 0.4533\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9477 - val_loss: 5.2797 - val_accuracy: 0.5133\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9347 - val_loss: 5.3922 - val_accuracy: 0.4889\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9361 - val_loss: 4.1853 - val_accuracy: 0.5200\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9403 - val_loss: 8.2257 - val_accuracy: 0.4267\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9440 - val_loss: 7.3654 - val_accuracy: 0.4822\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9431 - val_loss: 6.1467 - val_accuracy: 0.4733\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9380 - val_loss: 11.7177 - val_accuracy: 0.3956\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9269 - val_loss: 7.5337 - val_accuracy: 0.4444\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9343 - val_loss: 7.4551 - val_accuracy: 0.4200\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9505 - val_loss: 8.9176 - val_accuracy: 0.4022\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9537 - val_loss: 11.0299 - val_accuracy: 0.4467\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9454 - val_loss: 12.0311 - val_accuracy: 0.3978\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9500 - val_loss: 10.9611 - val_accuracy: 0.4178\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9597 - val_loss: 9.5542 - val_accuracy: 0.4222\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9583 - val_loss: 9.3652 - val_accuracy: 0.4222\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9444 - val_loss: 5.3012 - val_accuracy: 0.5222\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9514 - val_loss: 11.3159 - val_accuracy: 0.3844\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9583 - val_loss: 19.3138 - val_accuracy: 0.3800\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9454 - val_loss: 8.0631 - val_accuracy: 0.4644\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9583 - val_loss: 9.5494 - val_accuracy: 0.4289\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.9505 - val_loss: 6.1996 - val_accuracy: 0.5844\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9593 - val_loss: 8.5789 - val_accuracy: 0.4489\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9505 - val_loss: 10.2456 - val_accuracy: 0.4067\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9569 - val_loss: 5.5606 - val_accuracy: 0.5111\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9583 - val_loss: 17.9345 - val_accuracy: 0.3400\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9551 - val_loss: 7.7499 - val_accuracy: 0.4111\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9597 - val_loss: 8.9058 - val_accuracy: 0.4311\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9593 - val_loss: 9.3994 - val_accuracy: 0.4333\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9574 - val_loss: 9.1516 - val_accuracy: 0.4489\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9616 - val_loss: 22.9315 - val_accuracy: 0.3600\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9588 - val_loss: 7.6384 - val_accuracy: 0.4289\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9630 - val_loss: 6.2665 - val_accuracy: 0.4889\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9741 - val_loss: 11.3546 - val_accuracy: 0.3933\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9685 - val_loss: 33.9754 - val_accuracy: 0.3200\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9574 - val_loss: 5.8257 - val_accuracy: 0.4911\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9625 - val_loss: 8.5914 - val_accuracy: 0.4711\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9639 - val_loss: 12.9879 - val_accuracy: 0.3978\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9750 - val_loss: 9.7642 - val_accuracy: 0.4911\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.9597 - val_loss: 6.9293 - val_accuracy: 0.5311\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9644 - val_loss: 10.8425 - val_accuracy: 0.3844\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0745 - accuracy: 0.9685 - val_loss: 11.4010 - val_accuracy: 0.4600\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9727 - val_loss: 13.0237 - val_accuracy: 0.4178\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9662 - val_loss: 9.0340 - val_accuracy: 0.4822\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_180 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_180 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_181 (Conv2D)          (None, 25, 25, 8)         1952      \n",
      "_________________________________________________________________\n",
      "batch_normalization_177 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_181 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_90 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 298,787\n",
      "Trainable params: 298,717\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2511 - accuracy: 0.4644 - val_loss: 1.1150 - val_accuracy: 0.2822\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8595 - accuracy: 0.5843 - val_loss: 1.1045 - val_accuracy: 0.3978\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7458 - accuracy: 0.6546 - val_loss: 1.0333 - val_accuracy: 0.5267\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.7176 - val_loss: 1.0828 - val_accuracy: 0.5089\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7495 - val_loss: 1.5496 - val_accuracy: 0.4822\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7889 - val_loss: 1.7959 - val_accuracy: 0.5356\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8106 - val_loss: 1.2494 - val_accuracy: 0.4756\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8185 - val_loss: 3.7308 - val_accuracy: 0.4133\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8421 - val_loss: 2.2729 - val_accuracy: 0.4289\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8523 - val_loss: 5.8567 - val_accuracy: 0.4289\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8606 - val_loss: 3.5824 - val_accuracy: 0.4244\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8653 - val_loss: 3.3303 - val_accuracy: 0.3889\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2943 - accuracy: 0.8792 - val_loss: 3.8861 - val_accuracy: 0.4511\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8856 - val_loss: 2.2325 - val_accuracy: 0.4689\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8866 - val_loss: 2.0501 - val_accuracy: 0.4378\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.8898 - val_loss: 2.7703 - val_accuracy: 0.4578\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.8949 - val_loss: 3.4179 - val_accuracy: 0.3933\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9134 - val_loss: 3.5562 - val_accuracy: 0.4022\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2049 - accuracy: 0.9130 - val_loss: 6.4874 - val_accuracy: 0.4200\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9157 - val_loss: 4.5560 - val_accuracy: 0.4511\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9227 - val_loss: 4.4415 - val_accuracy: 0.5311\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9255 - val_loss: 6.2039 - val_accuracy: 0.4444\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9278 - val_loss: 7.4989 - val_accuracy: 0.4244\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.9273 - val_loss: 3.3634 - val_accuracy: 0.4467\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9306 - val_loss: 4.4304 - val_accuracy: 0.4489\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9319 - val_loss: 4.6825 - val_accuracy: 0.4600\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9528 - val_loss: 6.7094 - val_accuracy: 0.4578\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.9343 - val_loss: 5.2649 - val_accuracy: 0.4311\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9389 - val_loss: 5.5921 - val_accuracy: 0.4311\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9500 - val_loss: 5.4776 - val_accuracy: 0.4911\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9546 - val_loss: 5.0458 - val_accuracy: 0.4600\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9509 - val_loss: 4.4106 - val_accuracy: 0.4733\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9583 - val_loss: 7.8353 - val_accuracy: 0.4400\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9546 - val_loss: 6.4556 - val_accuracy: 0.4622\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9481 - val_loss: 5.8048 - val_accuracy: 0.4422\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1296 - accuracy: 0.9514 - val_loss: 4.4262 - val_accuracy: 0.4644\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9579 - val_loss: 4.7147 - val_accuracy: 0.4956\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9662 - val_loss: 6.5628 - val_accuracy: 0.4800\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9606 - val_loss: 6.8566 - val_accuracy: 0.4578\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.9593 - val_loss: 4.1833 - val_accuracy: 0.4711\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9639 - val_loss: 6.5389 - val_accuracy: 0.4756\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9694 - val_loss: 5.1970 - val_accuracy: 0.4689\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0841 - accuracy: 0.9685 - val_loss: 4.5528 - val_accuracy: 0.4622\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 6.8810 - val_accuracy: 0.4356\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9676 - val_loss: 6.3494 - val_accuracy: 0.4800\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9787 - val_loss: 6.3493 - val_accuracy: 0.3956\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9671 - val_loss: 6.2194 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9625 - val_loss: 9.8300 - val_accuracy: 0.4156\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 11.1813 - val_accuracy: 0.4378\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9722 - val_loss: 10.3225 - val_accuracy: 0.4378\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9741 - val_loss: 7.1644 - val_accuracy: 0.5378\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9750 - val_loss: 9.8663 - val_accuracy: 0.4356\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9690 - val_loss: 7.4312 - val_accuracy: 0.4311\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9764 - val_loss: 6.4139 - val_accuracy: 0.5178\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9736 - val_loss: 5.2628 - val_accuracy: 0.5356\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9750 - val_loss: 11.0086 - val_accuracy: 0.4356\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9736 - val_loss: 6.7050 - val_accuracy: 0.4667\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 5.3272 - val_accuracy: 0.4622\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9750 - val_loss: 7.8130 - val_accuracy: 0.4644\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9806 - val_loss: 10.7642 - val_accuracy: 0.4289\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 5.7280 - val_accuracy: 0.5289\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9759 - val_loss: 11.3476 - val_accuracy: 0.4467\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9722 - val_loss: 10.1941 - val_accuracy: 0.4267\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9727 - val_loss: 6.3532 - val_accuracy: 0.4867\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9801 - val_loss: 8.9484 - val_accuracy: 0.4378\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9796 - val_loss: 7.6209 - val_accuracy: 0.4578\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9769 - val_loss: 7.6364 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9801 - val_loss: 14.2163 - val_accuracy: 0.4111\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9866 - val_loss: 8.5595 - val_accuracy: 0.5067\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 6.9496 - val_accuracy: 0.5444\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9838 - val_loss: 10.5437 - val_accuracy: 0.4622\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9824 - val_loss: 8.2592 - val_accuracy: 0.4956\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9843 - val_loss: 6.7243 - val_accuracy: 0.4889\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 7.9236 - val_accuracy: 0.4511\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 10.0551 - val_accuracy: 0.4489\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9833 - val_loss: 16.6493 - val_accuracy: 0.4400\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9750 - val_loss: 12.1761 - val_accuracy: 0.4422\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9741 - val_loss: 11.0056 - val_accuracy: 0.4422\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9815 - val_loss: 8.5794 - val_accuracy: 0.4178\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9843 - val_loss: 9.2827 - val_accuracy: 0.5378\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9861 - val_loss: 15.8336 - val_accuracy: 0.4400\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9866 - val_loss: 8.2335 - val_accuracy: 0.4978\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9861 - val_loss: 6.9085 - val_accuracy: 0.5111\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9856 - val_loss: 10.7411 - val_accuracy: 0.4644\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 9.5253 - val_accuracy: 0.4444\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 11.5499 - val_accuracy: 0.4711\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 13.4975 - val_accuracy: 0.4489\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9833 - val_loss: 10.1797 - val_accuracy: 0.4267\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 13.2873 - val_accuracy: 0.5044\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9838 - val_loss: 10.3886 - val_accuracy: 0.4844\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9875 - val_loss: 6.8906 - val_accuracy: 0.4978\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9801 - val_loss: 12.3936 - val_accuracy: 0.4733\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9829 - val_loss: 8.9488 - val_accuracy: 0.5022\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 11.1613 - val_accuracy: 0.4667\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9847 - val_loss: 8.1530 - val_accuracy: 0.4422\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9880 - val_loss: 10.8498 - val_accuracy: 0.5022\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9935 - val_loss: 17.6377 - val_accuracy: 0.4311\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 8.9296 - val_accuracy: 0.5178\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 9.0557 - val_accuracy: 0.4956\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9819 - val_loss: 7.9592 - val_accuracy: 0.4511\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_182 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_178 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_182 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_183 (Conv2D)          (None, 25, 25, 10)        2440      \n",
      "_________________________________________________________________\n",
      "batch_normalization_179 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_183 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_91 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 49,555\n",
      "Trainable params: 49,481\n",
      "Non-trainable params: 74\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1808 - accuracy: 0.3352 - val_loss: 1.0984 - val_accuracy: 0.3400\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0648 - accuracy: 0.3755 - val_loss: 1.0853 - val_accuracy: 0.2978\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0362 - accuracy: 0.4106 - val_loss: 1.0932 - val_accuracy: 0.3244\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.4204 - val_loss: 1.0318 - val_accuracy: 0.4111\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0215 - accuracy: 0.4111 - val_loss: 1.0017 - val_accuracy: 0.5467\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9816 - accuracy: 0.4417 - val_loss: 1.5070 - val_accuracy: 0.3822\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9661 - accuracy: 0.4491 - val_loss: 1.0648 - val_accuracy: 0.4533\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 0.4630 - val_loss: 1.2643 - val_accuracy: 0.3311\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9307 - accuracy: 0.4676 - val_loss: 1.0835 - val_accuracy: 0.4933\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9233 - accuracy: 0.4755 - val_loss: 1.0724 - val_accuracy: 0.5222\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9251 - accuracy: 0.4704 - val_loss: 1.0772 - val_accuracy: 0.4222\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9411 - accuracy: 0.4685 - val_loss: 1.1497 - val_accuracy: 0.4667\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9085 - accuracy: 0.4801 - val_loss: 1.0328 - val_accuracy: 0.5200\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8969 - accuracy: 0.5019 - val_loss: 1.0969 - val_accuracy: 0.5533\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8773 - accuracy: 0.5005 - val_loss: 1.2068 - val_accuracy: 0.4689\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8807 - accuracy: 0.4931 - val_loss: 1.3898 - val_accuracy: 0.4089\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8900 - accuracy: 0.4722 - val_loss: 2.2239 - val_accuracy: 0.4889\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8728 - accuracy: 0.5093 - val_loss: 1.0706 - val_accuracy: 0.5089\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8448 - accuracy: 0.5222 - val_loss: 1.0279 - val_accuracy: 0.4667\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8482 - accuracy: 0.5310 - val_loss: 1.1345 - val_accuracy: 0.5556\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8278 - accuracy: 0.5440 - val_loss: 1.3479 - val_accuracy: 0.4644\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.5532 - val_loss: 1.5643 - val_accuracy: 0.5178\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8416 - accuracy: 0.5380 - val_loss: 1.3286 - val_accuracy: 0.4889\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8061 - accuracy: 0.5560 - val_loss: 2.9508 - val_accuracy: 0.3600\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8016 - accuracy: 0.5593 - val_loss: 1.0595 - val_accuracy: 0.4867\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8030 - accuracy: 0.5657 - val_loss: 1.2852 - val_accuracy: 0.4911\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7993 - accuracy: 0.5588 - val_loss: 1.4915 - val_accuracy: 0.4111\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7954 - accuracy: 0.5773 - val_loss: 1.2263 - val_accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.5653 - val_loss: 1.5132 - val_accuracy: 0.4733\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8041 - accuracy: 0.5667 - val_loss: 1.3211 - val_accuracy: 0.4933\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7667 - accuracy: 0.5884 - val_loss: 1.3054 - val_accuracy: 0.4778\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7577 - accuracy: 0.5870 - val_loss: 1.0964 - val_accuracy: 0.5089\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7710 - accuracy: 0.5819 - val_loss: 1.1433 - val_accuracy: 0.5933\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7618 - accuracy: 0.5861 - val_loss: 1.1439 - val_accuracy: 0.5400\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.5870 - val_loss: 1.2119 - val_accuracy: 0.5800\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.5991 - val_loss: 1.1124 - val_accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7649 - accuracy: 0.5907 - val_loss: 1.3092 - val_accuracy: 0.5178\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.5954 - val_loss: 1.4095 - val_accuracy: 0.4222\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.6176 - val_loss: 1.1712 - val_accuracy: 0.5356\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7206 - accuracy: 0.6046 - val_loss: 1.3811 - val_accuracy: 0.5289\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.6111 - val_loss: 1.8849 - val_accuracy: 0.4378\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.6190 - val_loss: 1.1935 - val_accuracy: 0.5267\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6458 - val_loss: 1.3513 - val_accuracy: 0.5711\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7127 - accuracy: 0.6199 - val_loss: 1.3195 - val_accuracy: 0.4778\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.6153 - val_loss: 1.7892 - val_accuracy: 0.5089\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.6444 - val_loss: 1.4716 - val_accuracy: 0.5356\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6431 - val_loss: 3.2593 - val_accuracy: 0.4311\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6542 - val_loss: 1.5507 - val_accuracy: 0.5889\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6380 - val_loss: 1.2903 - val_accuracy: 0.4844\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6500 - val_loss: 1.2210 - val_accuracy: 0.5689\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.6509 - val_loss: 1.6610 - val_accuracy: 0.4889\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6556 - val_loss: 1.3437 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6574 - val_loss: 1.8397 - val_accuracy: 0.5200\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6579 - val_loss: 1.4882 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6449 - val_loss: 1.9830 - val_accuracy: 0.4578\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6639 - val_loss: 1.3047 - val_accuracy: 0.5022\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6389 - val_loss: 1.8155 - val_accuracy: 0.4933\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6588 - val_loss: 1.8679 - val_accuracy: 0.5289\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6569 - val_loss: 1.4813 - val_accuracy: 0.5911\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6722 - val_loss: 1.6336 - val_accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6759 - val_loss: 1.7830 - val_accuracy: 0.5822\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6648 - val_loss: 2.9639 - val_accuracy: 0.4467\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6718 - val_loss: 3.7431 - val_accuracy: 0.3911\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6657 - val_loss: 2.3120 - val_accuracy: 0.5378\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6685 - val_loss: 1.7324 - val_accuracy: 0.5222\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.6727 - val_loss: 1.6961 - val_accuracy: 0.5178\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.6875 - val_loss: 2.7380 - val_accuracy: 0.5111\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6676 - val_loss: 2.1356 - val_accuracy: 0.5533\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6782 - val_loss: 2.9192 - val_accuracy: 0.4889\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.6731 - val_loss: 2.3751 - val_accuracy: 0.5222\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6694 - val_loss: 2.6607 - val_accuracy: 0.4756\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6727 - val_loss: 2.6336 - val_accuracy: 0.4711\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.6759 - val_loss: 8.7379 - val_accuracy: 0.3400\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.6764 - val_loss: 2.6074 - val_accuracy: 0.5378\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6657 - val_loss: 2.2577 - val_accuracy: 0.5089\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6750 - val_loss: 4.2784 - val_accuracy: 0.4578\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6694 - val_loss: 2.4779 - val_accuracy: 0.5178\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.6829 - val_loss: 2.2242 - val_accuracy: 0.5578\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.6875 - val_loss: 4.7848 - val_accuracy: 0.4222\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.6912 - val_loss: 2.4193 - val_accuracy: 0.6067\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7116 - val_loss: 2.9846 - val_accuracy: 0.4800\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.6926 - val_loss: 3.1716 - val_accuracy: 0.5156\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7134 - val_loss: 4.3990 - val_accuracy: 0.4200\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7069 - val_loss: 2.0739 - val_accuracy: 0.4933\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7315 - val_loss: 2.2436 - val_accuracy: 0.5422\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7255 - val_loss: 2.5506 - val_accuracy: 0.5289\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7273 - val_loss: 2.0220 - val_accuracy: 0.5111\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7278 - val_loss: 2.9441 - val_accuracy: 0.4844\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7241 - val_loss: 3.2540 - val_accuracy: 0.5311\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7310 - val_loss: 3.3568 - val_accuracy: 0.5089\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7509 - val_loss: 2.2459 - val_accuracy: 0.5556\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4877 - accuracy: 0.7407 - val_loss: 3.1397 - val_accuracy: 0.4378\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7421 - val_loss: 3.5354 - val_accuracy: 0.5178\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7458 - val_loss: 3.8973 - val_accuracy: 0.5156\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7310 - val_loss: 3.5235 - val_accuracy: 0.4378\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7292 - val_loss: 2.4156 - val_accuracy: 0.4933\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7481 - val_loss: 2.4011 - val_accuracy: 0.5244\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7329 - val_loss: 2.9158 - val_accuracy: 0.5267\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7574 - val_loss: 3.0001 - val_accuracy: 0.5067\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7394 - val_loss: 2.8401 - val_accuracy: 0.5378\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_184 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_180 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_180 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_184 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_185 (Conv2D)          (None, 25, 25, 10)        2440      \n",
      "_________________________________________________________________\n",
      "batch_normalization_181 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_181 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_185 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_92 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 95,763\n",
      "Trainable params: 95,689\n",
      "Non-trainable params: 74\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2203 - accuracy: 0.3648 - val_loss: 1.0942 - val_accuracy: 0.4711\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0568 - accuracy: 0.3866 - val_loss: 1.0988 - val_accuracy: 0.4133\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0370 - accuracy: 0.4181 - val_loss: 1.1000 - val_accuracy: 0.5467\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9983 - accuracy: 0.4269 - val_loss: 1.0959 - val_accuracy: 0.5311\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.4551 - val_loss: 1.2017 - val_accuracy: 0.4400\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.4884 - val_loss: 1.1593 - val_accuracy: 0.5289\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9165 - accuracy: 0.4917 - val_loss: 3.5842 - val_accuracy: 0.3222\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9064 - accuracy: 0.4907 - val_loss: 1.5963 - val_accuracy: 0.5044\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8925 - accuracy: 0.5102 - val_loss: 1.6456 - val_accuracy: 0.4378\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.5213 - val_loss: 1.7835 - val_accuracy: 0.5156\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8650 - accuracy: 0.5366 - val_loss: 1.2313 - val_accuracy: 0.5711\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8374 - accuracy: 0.5491 - val_loss: 1.6702 - val_accuracy: 0.5644\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8030 - accuracy: 0.5750 - val_loss: 2.3284 - val_accuracy: 0.4600\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.6023 - val_loss: 1.3037 - val_accuracy: 0.5022\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.5889 - val_loss: 7.0715 - val_accuracy: 0.3311\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7656 - accuracy: 0.5880 - val_loss: 1.5180 - val_accuracy: 0.4933\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.6148 - val_loss: 1.5027 - val_accuracy: 0.5511\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.6370 - val_loss: 1.9225 - val_accuracy: 0.6422\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7271 - accuracy: 0.6380 - val_loss: 4.3041 - val_accuracy: 0.3756\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7175 - accuracy: 0.6426 - val_loss: 1.6978 - val_accuracy: 0.5600\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.6417 - val_loss: 5.0697 - val_accuracy: 0.3733\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.6606 - val_loss: 1.6472 - val_accuracy: 0.5756\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6713 - val_loss: 4.9893 - val_accuracy: 0.4400\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6847 - val_loss: 3.4762 - val_accuracy: 0.5511\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6815 - val_loss: 5.6435 - val_accuracy: 0.3533\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6773 - val_loss: 3.0127 - val_accuracy: 0.5956\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6256 - accuracy: 0.6866 - val_loss: 2.8822 - val_accuracy: 0.4867\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6801 - val_loss: 5.0827 - val_accuracy: 0.3511\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6861 - val_loss: 3.5332 - val_accuracy: 0.4556\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7093 - val_loss: 2.4759 - val_accuracy: 0.4778\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7190 - val_loss: 3.2196 - val_accuracy: 0.5578\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7324 - val_loss: 1.6327 - val_accuracy: 0.5200\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7241 - val_loss: 9.4222 - val_accuracy: 0.3267\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7375 - val_loss: 2.8331 - val_accuracy: 0.6022\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7509 - val_loss: 3.6521 - val_accuracy: 0.4689\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7431 - val_loss: 1.9969 - val_accuracy: 0.5244\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7537 - val_loss: 2.2997 - val_accuracy: 0.5956\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7556 - val_loss: 2.4844 - val_accuracy: 0.5956\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7773 - val_loss: 3.6864 - val_accuracy: 0.5400\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7745 - val_loss: 7.7420 - val_accuracy: 0.3800\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7912 - val_loss: 2.4424 - val_accuracy: 0.5400\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7954 - val_loss: 3.2682 - val_accuracy: 0.6022\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7977 - val_loss: 5.0422 - val_accuracy: 0.4333\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8176 - val_loss: 3.3910 - val_accuracy: 0.5178\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8134 - val_loss: 2.8365 - val_accuracy: 0.4822\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8065 - val_loss: 1.9454 - val_accuracy: 0.5956\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8236 - val_loss: 3.5705 - val_accuracy: 0.6022\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8269 - val_loss: 3.9886 - val_accuracy: 0.5067\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8204 - val_loss: 6.5761 - val_accuracy: 0.4289\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8125 - val_loss: 3.0216 - val_accuracy: 0.5311\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8361 - val_loss: 9.8164 - val_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8264 - val_loss: 3.7756 - val_accuracy: 0.5400\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8375 - val_loss: 3.9067 - val_accuracy: 0.4200\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8375 - val_loss: 3.0816 - val_accuracy: 0.5733\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8481 - val_loss: 4.0484 - val_accuracy: 0.5778\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8426 - val_loss: 4.6362 - val_accuracy: 0.5933\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8542 - val_loss: 3.0472 - val_accuracy: 0.5622\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8500 - val_loss: 3.2544 - val_accuracy: 0.5956\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8625 - val_loss: 3.4313 - val_accuracy: 0.5867\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8630 - val_loss: 5.2961 - val_accuracy: 0.4956\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8644 - val_loss: 4.0811 - val_accuracy: 0.4867\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8648 - val_loss: 3.7061 - val_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8542 - val_loss: 4.5312 - val_accuracy: 0.5956\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8495 - val_loss: 8.1126 - val_accuracy: 0.4178\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8653 - val_loss: 6.8350 - val_accuracy: 0.5311\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8755 - val_loss: 4.0772 - val_accuracy: 0.5667\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.8787 - val_loss: 8.4601 - val_accuracy: 0.4867\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.8787 - val_loss: 4.0883 - val_accuracy: 0.5933\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.8787 - val_loss: 3.7226 - val_accuracy: 0.5533\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8773 - val_loss: 13.0187 - val_accuracy: 0.3911\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8759 - val_loss: 4.8815 - val_accuracy: 0.5111\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2721 - accuracy: 0.8838 - val_loss: 3.5379 - val_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8778 - val_loss: 3.4636 - val_accuracy: 0.4756\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8755 - val_loss: 3.1625 - val_accuracy: 0.6556\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2702 - accuracy: 0.8894 - val_loss: 8.3032 - val_accuracy: 0.4089\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8764 - val_loss: 4.5703 - val_accuracy: 0.5133\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.8931 - val_loss: 7.8383 - val_accuracy: 0.5178\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8819 - val_loss: 4.3787 - val_accuracy: 0.5978\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8870 - val_loss: 8.0640 - val_accuracy: 0.4311\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9074 - val_loss: 4.3819 - val_accuracy: 0.5400\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8995 - val_loss: 9.1897 - val_accuracy: 0.5111\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.9028 - val_loss: 4.8280 - val_accuracy: 0.6067\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9014 - val_loss: 4.6910 - val_accuracy: 0.5733\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2610 - accuracy: 0.8968 - val_loss: 3.5933 - val_accuracy: 0.5978\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9000 - val_loss: 4.7399 - val_accuracy: 0.5867\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.8995 - val_loss: 34.5822 - val_accuracy: 0.3333\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9046 - val_loss: 4.1394 - val_accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.9042 - val_loss: 3.9548 - val_accuracy: 0.5489\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9088 - val_loss: 7.9659 - val_accuracy: 0.4800\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9190 - val_loss: 8.1389 - val_accuracy: 0.4933\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9181 - val_loss: 6.7889 - val_accuracy: 0.5867\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9065 - val_loss: 4.7340 - val_accuracy: 0.5133\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9056 - val_loss: 11.7979 - val_accuracy: 0.4822\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9120 - val_loss: 6.6305 - val_accuracy: 0.5089\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9056 - val_loss: 9.9373 - val_accuracy: 0.4356\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6750 - val_loss: 1.4055 - val_accuracy: 0.5156\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6806 - val_loss: 1.6982 - val_accuracy: 0.3822\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.7005 - val_loss: 2.4247 - val_accuracy: 0.4089\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7111 - val_loss: 2.5729 - val_accuracy: 0.4911\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7208 - val_loss: 3.5001 - val_accuracy: 0.3956\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7458 - val_loss: 2.6179 - val_accuracy: 0.4289\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7634 - val_loss: 5.2131 - val_accuracy: 0.4022\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7514 - val_loss: 6.6116 - val_accuracy: 0.3644\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4690 - accuracy: 0.7708 - val_loss: 2.1132 - val_accuracy: 0.4556\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7806 - val_loss: 2.0155 - val_accuracy: 0.4422\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7750 - val_loss: 2.8558 - val_accuracy: 0.4400\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7861 - val_loss: 3.3336 - val_accuracy: 0.4156\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7903 - val_loss: 3.1750 - val_accuracy: 0.4556\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7949 - val_loss: 4.7522 - val_accuracy: 0.4356\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.7972 - val_loss: 5.5180 - val_accuracy: 0.3822\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8014 - val_loss: 2.4326 - val_accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8231 - val_loss: 4.5826 - val_accuracy: 0.4244\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8255 - val_loss: 7.8238 - val_accuracy: 0.3622\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8255 - val_loss: 5.3640 - val_accuracy: 0.4222\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8273 - val_loss: 3.6577 - val_accuracy: 0.5067\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8412 - val_loss: 4.8800 - val_accuracy: 0.4444\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8394 - val_loss: 4.3378 - val_accuracy: 0.4489\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8394 - val_loss: 2.4289 - val_accuracy: 0.4889\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8352 - val_loss: 4.1654 - val_accuracy: 0.4133\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.8574 - val_loss: 4.0414 - val_accuracy: 0.4133\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8579 - val_loss: 3.2373 - val_accuracy: 0.5067\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8648 - val_loss: 7.4233 - val_accuracy: 0.4089\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8495 - val_loss: 2.6909 - val_accuracy: 0.5378\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8699 - val_loss: 4.0310 - val_accuracy: 0.5044\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8778 - val_loss: 5.1698 - val_accuracy: 0.4222\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.8787 - val_loss: 7.6302 - val_accuracy: 0.3889\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8773 - val_loss: 3.2393 - val_accuracy: 0.5356\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8727 - val_loss: 3.3174 - val_accuracy: 0.4600\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.8736 - val_loss: 3.3670 - val_accuracy: 0.4956\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.8861 - val_loss: 5.9517 - val_accuracy: 0.4267\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.8833 - val_loss: 4.0935 - val_accuracy: 0.5067\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.8847 - val_loss: 11.9942 - val_accuracy: 0.3578\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.8866 - val_loss: 8.2390 - val_accuracy: 0.3956\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2265 - accuracy: 0.8963 - val_loss: 2.9848 - val_accuracy: 0.6267\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.8995 - val_loss: 12.5429 - val_accuracy: 0.3978\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2311 - accuracy: 0.8907 - val_loss: 7.1208 - val_accuracy: 0.4200\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9083 - val_loss: 4.3732 - val_accuracy: 0.4956\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9162 - val_loss: 6.3399 - val_accuracy: 0.4422\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9037 - val_loss: 4.5378 - val_accuracy: 0.5200\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.9139 - val_loss: 7.0508 - val_accuracy: 0.4556\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9014 - val_loss: 6.9146 - val_accuracy: 0.4600\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9111 - val_loss: 5.0989 - val_accuracy: 0.4844\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9032 - val_loss: 4.3063 - val_accuracy: 0.5289\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2006 - accuracy: 0.9171 - val_loss: 8.1455 - val_accuracy: 0.4044\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9208 - val_loss: 12.1473 - val_accuracy: 0.3711\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9199 - val_loss: 7.2790 - val_accuracy: 0.4311\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1530 - accuracy: 0.9282 - val_loss: 5.6489 - val_accuracy: 0.4956\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9236 - val_loss: 5.3527 - val_accuracy: 0.5289\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9278 - val_loss: 10.9807 - val_accuracy: 0.4067\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9222 - val_loss: 6.1034 - val_accuracy: 0.4911\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9315 - val_loss: 6.9756 - val_accuracy: 0.4644\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9171 - val_loss: 5.1518 - val_accuracy: 0.4733\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9194 - val_loss: 10.0037 - val_accuracy: 0.4533\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9333 - val_loss: 4.8194 - val_accuracy: 0.4489\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9306 - val_loss: 7.2399 - val_accuracy: 0.4578\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.9338 - val_loss: 5.1495 - val_accuracy: 0.4978\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9361 - val_loss: 5.4942 - val_accuracy: 0.5378\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1561 - accuracy: 0.9347 - val_loss: 9.0587 - val_accuracy: 0.4400\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9394 - val_loss: 4.2066 - val_accuracy: 0.5044\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.9296 - val_loss: 4.4453 - val_accuracy: 0.5911\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9449 - val_loss: 9.3127 - val_accuracy: 0.4222\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9333 - val_loss: 7.7043 - val_accuracy: 0.4933\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9417 - val_loss: 6.3578 - val_accuracy: 0.5467\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9491 - val_loss: 5.1896 - val_accuracy: 0.5533\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9546 - val_loss: 6.1694 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9463 - val_loss: 16.2147 - val_accuracy: 0.3511\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9403 - val_loss: 13.3115 - val_accuracy: 0.4156\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9523 - val_loss: 6.8214 - val_accuracy: 0.5156\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9523 - val_loss: 8.1914 - val_accuracy: 0.4622\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9491 - val_loss: 6.8455 - val_accuracy: 0.5111\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9514 - val_loss: 5.0396 - val_accuracy: 0.5711\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9583 - val_loss: 5.5251 - val_accuracy: 0.5667\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9421 - val_loss: 6.5385 - val_accuracy: 0.5444\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9551 - val_loss: 6.7371 - val_accuracy: 0.5156\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9611 - val_loss: 5.5022 - val_accuracy: 0.5356\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9569 - val_loss: 12.9337 - val_accuracy: 0.4333\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9574 - val_loss: 11.7715 - val_accuracy: 0.4244\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9602 - val_loss: 6.4840 - val_accuracy: 0.5200\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9583 - val_loss: 7.3075 - val_accuracy: 0.5222\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9560 - val_loss: 8.4128 - val_accuracy: 0.5200\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9519 - val_loss: 8.5329 - val_accuracy: 0.4911\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9602 - val_loss: 7.2428 - val_accuracy: 0.5289\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9611 - val_loss: 7.4931 - val_accuracy: 0.5178\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9597 - val_loss: 7.0272 - val_accuracy: 0.5156\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0792 - accuracy: 0.9630 - val_loss: 8.3285 - val_accuracy: 0.4889\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9671 - val_loss: 8.4666 - val_accuracy: 0.5022\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9653 - val_loss: 9.2353 - val_accuracy: 0.5111\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9657 - val_loss: 7.4172 - val_accuracy: 0.5444\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_188 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_184 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_188 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 25, 25, 10)        2440      \n",
      "_________________________________________________________________\n",
      "batch_normalization_185 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_189 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_94 (Flatten)         (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 256)               368896    \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 373,011\n",
      "Trainable params: 372,937\n",
      "Non-trainable params: 74\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2900 - accuracy: 0.4519 - val_loss: 1.1198 - val_accuracy: 0.3044\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9208 - accuracy: 0.5528 - val_loss: 1.1102 - val_accuracy: 0.3467\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7604 - accuracy: 0.6435 - val_loss: 1.1363 - val_accuracy: 0.3444\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.7074 - val_loss: 1.1954 - val_accuracy: 0.3511\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.7310 - val_loss: 1.2524 - val_accuracy: 0.4689\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7630 - val_loss: 1.6231 - val_accuracy: 0.5200\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7963 - val_loss: 1.7593 - val_accuracy: 0.4178\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7977 - val_loss: 1.4850 - val_accuracy: 0.4822\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8134 - val_loss: 1.7833 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8222 - val_loss: 2.8965 - val_accuracy: 0.4111\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8347 - val_loss: 2.3186 - val_accuracy: 0.5178\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8468 - val_loss: 2.0417 - val_accuracy: 0.4467\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8597 - val_loss: 3.7824 - val_accuracy: 0.4133\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8676 - val_loss: 1.6202 - val_accuracy: 0.5489\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8708 - val_loss: 2.9771 - val_accuracy: 0.3933\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8745 - val_loss: 2.6439 - val_accuracy: 0.4244\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.8838 - val_loss: 2.7625 - val_accuracy: 0.4600\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2562 - accuracy: 0.8907 - val_loss: 4.7472 - val_accuracy: 0.3889\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2605 - accuracy: 0.8870 - val_loss: 2.7892 - val_accuracy: 0.4333\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.8949 - val_loss: 2.0761 - val_accuracy: 0.4844\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9019 - val_loss: 2.2761 - val_accuracy: 0.5911\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2048 - accuracy: 0.9106 - val_loss: 2.5884 - val_accuracy: 0.4333\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2159 - accuracy: 0.9069 - val_loss: 2.9438 - val_accuracy: 0.4511\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9181 - val_loss: 5.3859 - val_accuracy: 0.3978\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9153 - val_loss: 2.5358 - val_accuracy: 0.4733\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2014 - accuracy: 0.9162 - val_loss: 2.8738 - val_accuracy: 0.4533\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9162 - val_loss: 2.8286 - val_accuracy: 0.4844\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9185 - val_loss: 3.9629 - val_accuracy: 0.3978\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9296 - val_loss: 3.6601 - val_accuracy: 0.4467\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9315 - val_loss: 5.2876 - val_accuracy: 0.4622\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9278 - val_loss: 3.7054 - val_accuracy: 0.5511\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9324 - val_loss: 6.0628 - val_accuracy: 0.3733\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9398 - val_loss: 5.2564 - val_accuracy: 0.4489\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9310 - val_loss: 12.6630 - val_accuracy: 0.3156\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9481 - val_loss: 5.4810 - val_accuracy: 0.4356\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9472 - val_loss: 3.9764 - val_accuracy: 0.5378\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9491 - val_loss: 3.8288 - val_accuracy: 0.4267\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9468 - val_loss: 8.8372 - val_accuracy: 0.4111\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9477 - val_loss: 3.9163 - val_accuracy: 0.4022\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9468 - val_loss: 6.4715 - val_accuracy: 0.4311\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9519 - val_loss: 5.0280 - val_accuracy: 0.3844\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9588 - val_loss: 4.5747 - val_accuracy: 0.5689\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9611 - val_loss: 4.3905 - val_accuracy: 0.5644\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9546 - val_loss: 5.6471 - val_accuracy: 0.4289\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9616 - val_loss: 5.2074 - val_accuracy: 0.4244\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9574 - val_loss: 4.1183 - val_accuracy: 0.4089\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9704 - val_loss: 6.8001 - val_accuracy: 0.4200\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9644 - val_loss: 13.0623 - val_accuracy: 0.3689\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9667 - val_loss: 6.1906 - val_accuracy: 0.4356\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9634 - val_loss: 7.4898 - val_accuracy: 0.4244\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9681 - val_loss: 5.0091 - val_accuracy: 0.4178\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9653 - val_loss: 8.5328 - val_accuracy: 0.4111\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9657 - val_loss: 11.3141 - val_accuracy: 0.4178\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9671 - val_loss: 6.0739 - val_accuracy: 0.5222\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9708 - val_loss: 6.4165 - val_accuracy: 0.5600\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9671 - val_loss: 4.9511 - val_accuracy: 0.5667\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9704 - val_loss: 5.9286 - val_accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9694 - val_loss: 4.9548 - val_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0762 - accuracy: 0.9704 - val_loss: 4.7727 - val_accuracy: 0.5378\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9676 - val_loss: 8.5308 - val_accuracy: 0.3778\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9685 - val_loss: 6.5099 - val_accuracy: 0.4822\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9722 - val_loss: 6.8362 - val_accuracy: 0.4333\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9829 - val_loss: 6.7863 - val_accuracy: 0.5244\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 10.9692 - val_accuracy: 0.3844\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9778 - val_loss: 6.1656 - val_accuracy: 0.4578\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9750 - val_loss: 5.6291 - val_accuracy: 0.5444\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9736 - val_loss: 10.7464 - val_accuracy: 0.3956\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9759 - val_loss: 5.8271 - val_accuracy: 0.5689\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 7.7093 - val_accuracy: 0.4733\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9750 - val_loss: 6.0951 - val_accuracy: 0.4600\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9745 - val_loss: 8.2485 - val_accuracy: 0.4511\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9769 - val_loss: 10.5870 - val_accuracy: 0.4311\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9755 - val_loss: 8.6435 - val_accuracy: 0.4178\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9787 - val_loss: 8.1301 - val_accuracy: 0.5400\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9769 - val_loss: 7.0431 - val_accuracy: 0.4489\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9690 - val_loss: 9.8718 - val_accuracy: 0.3956\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9759 - val_loss: 5.4672 - val_accuracy: 0.4933\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9764 - val_loss: 5.3169 - val_accuracy: 0.5422\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9796 - val_loss: 12.7583 - val_accuracy: 0.3956\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9824 - val_loss: 8.0025 - val_accuracy: 0.5756\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9819 - val_loss: 8.1296 - val_accuracy: 0.5156\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9773 - val_loss: 8.0894 - val_accuracy: 0.4622\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9792 - val_loss: 6.7990 - val_accuracy: 0.4533\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9856 - val_loss: 7.4825 - val_accuracy: 0.4533\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9819 - val_loss: 7.4715 - val_accuracy: 0.4711\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0531 - accuracy: 0.9787 - val_loss: 7.4463 - val_accuracy: 0.4822\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9866 - val_loss: 17.1222 - val_accuracy: 0.4667\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9787 - val_loss: 8.7191 - val_accuracy: 0.5622\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9819 - val_loss: 7.5980 - val_accuracy: 0.4378\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 8.9347 - val_accuracy: 0.5533\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9875 - val_loss: 7.7833 - val_accuracy: 0.4889\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 11.6735 - val_accuracy: 0.4622\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9824 - val_loss: 12.0848 - val_accuracy: 0.4333\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9829 - val_loss: 5.7564 - val_accuracy: 0.5289\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9852 - val_loss: 9.5875 - val_accuracy: 0.6044\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9852 - val_loss: 8.3237 - val_accuracy: 0.4711\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9875 - val_loss: 7.6042 - val_accuracy: 0.5378\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9889 - val_loss: 7.7570 - val_accuracy: 0.5511\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9875 - val_loss: 6.4949 - val_accuracy: 0.5289\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9866 - val_loss: 10.4169 - val_accuracy: 0.5578\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_190 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_186 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_190 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 25, 25, 12)        2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_187 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_191 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_95 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 32)                55328     \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 59,267\n",
      "Trainable params: 59,189\n",
      "Non-trainable params: 78\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1417 - accuracy: 0.3495 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0714 - accuracy: 0.3574 - val_loss: 1.0978 - val_accuracy: 0.3489\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0593 - accuracy: 0.3648 - val_loss: 1.1051 - val_accuracy: 0.3578\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0489 - accuracy: 0.3852 - val_loss: 1.1551 - val_accuracy: 0.3622\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0336 - accuracy: 0.3815 - val_loss: 1.1889 - val_accuracy: 0.3644\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0352 - accuracy: 0.3898 - val_loss: 1.4189 - val_accuracy: 0.4756\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0195 - accuracy: 0.4023 - val_loss: 1.2449 - val_accuracy: 0.3667\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0060 - accuracy: 0.4116 - val_loss: 1.2587 - val_accuracy: 0.3711\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9962 - accuracy: 0.4306 - val_loss: 1.1837 - val_accuracy: 0.3289\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9907 - accuracy: 0.4361 - val_loss: 1.2437 - val_accuracy: 0.4378\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9900 - accuracy: 0.4523 - val_loss: 1.1766 - val_accuracy: 0.4644\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9792 - accuracy: 0.4444 - val_loss: 2.1027 - val_accuracy: 0.3622\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9581 - accuracy: 0.4620 - val_loss: 1.3687 - val_accuracy: 0.4911\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9531 - accuracy: 0.4708 - val_loss: 1.6583 - val_accuracy: 0.4267\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9449 - accuracy: 0.4889 - val_loss: 1.6781 - val_accuracy: 0.4778\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9292 - accuracy: 0.4782 - val_loss: 1.3643 - val_accuracy: 0.4356\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9193 - accuracy: 0.4884 - val_loss: 1.7325 - val_accuracy: 0.3756\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9234 - accuracy: 0.4898 - val_loss: 1.7865 - val_accuracy: 0.4489\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9123 - accuracy: 0.5093 - val_loss: 1.5849 - val_accuracy: 0.3756\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9267 - accuracy: 0.4991 - val_loss: 1.4567 - val_accuracy: 0.3667\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9260 - accuracy: 0.4991 - val_loss: 2.4543 - val_accuracy: 0.3933\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8977 - accuracy: 0.5157 - val_loss: 1.5787 - val_accuracy: 0.3511\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8599 - accuracy: 0.5389 - val_loss: 1.2747 - val_accuracy: 0.4267\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8622 - accuracy: 0.5481 - val_loss: 1.5929 - val_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8552 - accuracy: 0.5458 - val_loss: 1.4442 - val_accuracy: 0.3756\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8459 - accuracy: 0.5468 - val_loss: 2.2799 - val_accuracy: 0.3956\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.5481 - val_loss: 1.3528 - val_accuracy: 0.3733\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8246 - accuracy: 0.5694 - val_loss: 2.7376 - val_accuracy: 0.4867\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.5653 - val_loss: 1.4443 - val_accuracy: 0.4067\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8325 - accuracy: 0.5616 - val_loss: 1.6652 - val_accuracy: 0.4089\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8283 - accuracy: 0.5639 - val_loss: 1.3900 - val_accuracy: 0.3978\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8090 - accuracy: 0.5741 - val_loss: 3.7505 - val_accuracy: 0.4844\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8112 - accuracy: 0.5722 - val_loss: 1.4019 - val_accuracy: 0.4644\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8065 - accuracy: 0.5769 - val_loss: 2.3872 - val_accuracy: 0.4400\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7757 - accuracy: 0.5898 - val_loss: 2.2942 - val_accuracy: 0.4378\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7699 - accuracy: 0.5991 - val_loss: 3.7419 - val_accuracy: 0.4444\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.5963 - val_loss: 1.9296 - val_accuracy: 0.3733\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7741 - accuracy: 0.5931 - val_loss: 3.7459 - val_accuracy: 0.3467\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.5782 - val_loss: 3.2008 - val_accuracy: 0.5156\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7710 - accuracy: 0.5889 - val_loss: 1.4958 - val_accuracy: 0.4911\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7627 - accuracy: 0.5931 - val_loss: 2.1221 - val_accuracy: 0.4600\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.5875 - val_loss: 2.6629 - val_accuracy: 0.4289\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.5806 - val_loss: 1.9350 - val_accuracy: 0.4711\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7642 - accuracy: 0.5968 - val_loss: 4.0836 - val_accuracy: 0.4644\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7731 - accuracy: 0.5894 - val_loss: 1.9116 - val_accuracy: 0.4356\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.6051 - val_loss: 2.4700 - val_accuracy: 0.4778\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7772 - accuracy: 0.5829 - val_loss: 2.8929 - val_accuracy: 0.4467\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.5884 - val_loss: 1.7190 - val_accuracy: 0.4667\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.6065 - val_loss: 1.5198 - val_accuracy: 0.4578\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.6028 - val_loss: 1.8073 - val_accuracy: 0.4644\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.5875 - val_loss: 2.0207 - val_accuracy: 0.3756\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.5949 - val_loss: 1.5461 - val_accuracy: 0.4378\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.5958 - val_loss: 2.3643 - val_accuracy: 0.4711\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.5884 - val_loss: 1.6522 - val_accuracy: 0.4533\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7275 - accuracy: 0.6056 - val_loss: 1.6407 - val_accuracy: 0.4178\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7100 - accuracy: 0.6171 - val_loss: 3.5995 - val_accuracy: 0.4622\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7293 - accuracy: 0.5954 - val_loss: 2.4377 - val_accuracy: 0.4156\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.6056 - val_loss: 2.0703 - val_accuracy: 0.4644\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.5991 - val_loss: 3.5215 - val_accuracy: 0.4956\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.6134 - val_loss: 1.5604 - val_accuracy: 0.4556\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.5944 - val_loss: 3.1053 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.5991 - val_loss: 1.6259 - val_accuracy: 0.5222\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7312 - accuracy: 0.5935 - val_loss: 1.6534 - val_accuracy: 0.5178\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7130 - accuracy: 0.6060 - val_loss: 2.1583 - val_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7302 - accuracy: 0.5991 - val_loss: 3.3267 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.6079 - val_loss: 1.9120 - val_accuracy: 0.5067\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.5963 - val_loss: 1.5312 - val_accuracy: 0.4978\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.6097 - val_loss: 2.6598 - val_accuracy: 0.5511\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.6051 - val_loss: 2.6095 - val_accuracy: 0.4067\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.6157 - val_loss: 1.9366 - val_accuracy: 0.4333\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.6005 - val_loss: 2.3174 - val_accuracy: 0.4533\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7205 - accuracy: 0.6093 - val_loss: 3.7184 - val_accuracy: 0.4333\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.6157 - val_loss: 3.1004 - val_accuracy: 0.4133\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7095 - accuracy: 0.6130 - val_loss: 2.0971 - val_accuracy: 0.4244\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.6144 - val_loss: 3.7280 - val_accuracy: 0.4444\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.6222 - val_loss: 7.7523 - val_accuracy: 0.3933\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.6278 - val_loss: 2.0192 - val_accuracy: 0.4244\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.6190 - val_loss: 2.3270 - val_accuracy: 0.4600\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.6301 - val_loss: 6.0507 - val_accuracy: 0.4244\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.6204 - val_loss: 2.4168 - val_accuracy: 0.4956\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.6130 - val_loss: 3.9823 - val_accuracy: 0.4156\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.6329 - val_loss: 4.9785 - val_accuracy: 0.4600\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.6264 - val_loss: 3.6065 - val_accuracy: 0.4889\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.6259 - val_loss: 4.3196 - val_accuracy: 0.4733\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.6296 - val_loss: 5.4098 - val_accuracy: 0.5378\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.6236 - val_loss: 3.5199 - val_accuracy: 0.4467\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6356 - val_loss: 4.7185 - val_accuracy: 0.4400\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6472 - val_loss: 4.3645 - val_accuracy: 0.4422\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6370 - val_loss: 4.8937 - val_accuracy: 0.4133\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6296 - val_loss: 4.1376 - val_accuracy: 0.4467\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6366 - val_loss: 3.8827 - val_accuracy: 0.4356\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6394 - val_loss: 3.3669 - val_accuracy: 0.4378\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6574 - val_loss: 4.5522 - val_accuracy: 0.4600\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6315 - val_loss: 3.2269 - val_accuracy: 0.5089\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.6361 - val_loss: 6.6037 - val_accuracy: 0.4422\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6435 - val_loss: 4.1572 - val_accuracy: 0.4400\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6551 - val_loss: 4.8384 - val_accuracy: 0.4378\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6565 - val_loss: 6.3631 - val_accuracy: 0.4933\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6468 - val_loss: 3.9868 - val_accuracy: 0.4778\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6667 - val_loss: 4.3719 - val_accuracy: 0.5156\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_192 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_188 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_192 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 25, 25, 12)        2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_189 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_193 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_96 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 114,691\n",
      "Trainable params: 114,613\n",
      "Non-trainable params: 78\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1995 - accuracy: 0.3787 - val_loss: 1.1007 - val_accuracy: 0.3622\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0454 - accuracy: 0.3995 - val_loss: 1.1032 - val_accuracy: 0.3000\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9985 - accuracy: 0.4282 - val_loss: 1.1228 - val_accuracy: 0.3578\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9826 - accuracy: 0.4375 - val_loss: 1.1075 - val_accuracy: 0.4044\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9489 - accuracy: 0.4477 - val_loss: 1.1310 - val_accuracy: 0.4489\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9443 - accuracy: 0.4625 - val_loss: 1.8026 - val_accuracy: 0.3644\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9289 - accuracy: 0.4731 - val_loss: 1.1183 - val_accuracy: 0.4689\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9056 - accuracy: 0.5051 - val_loss: 1.0607 - val_accuracy: 0.4111\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8770 - accuracy: 0.4968 - val_loss: 1.8315 - val_accuracy: 0.3400\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8609 - accuracy: 0.5245 - val_loss: 1.5172 - val_accuracy: 0.4778\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8408 - accuracy: 0.5380 - val_loss: 2.9875 - val_accuracy: 0.3156\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8231 - accuracy: 0.5491 - val_loss: 1.3589 - val_accuracy: 0.4533\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7922 - accuracy: 0.5606 - val_loss: 1.6537 - val_accuracy: 0.4578\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 0.5583 - val_loss: 1.4250 - val_accuracy: 0.4422\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.6028 - val_loss: 1.3125 - val_accuracy: 0.4289\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7302 - accuracy: 0.6139 - val_loss: 1.5561 - val_accuracy: 0.4556\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.6069 - val_loss: 3.8203 - val_accuracy: 0.3333\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.6134 - val_loss: 2.4196 - val_accuracy: 0.4022\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.6417 - val_loss: 2.5331 - val_accuracy: 0.3667\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.6292 - val_loss: 2.0593 - val_accuracy: 0.4178\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.6463 - val_loss: 1.6252 - val_accuracy: 0.4756\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.6551 - val_loss: 5.5903 - val_accuracy: 0.3222\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.6389 - val_loss: 2.4829 - val_accuracy: 0.4578\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.6560 - val_loss: 6.6701 - val_accuracy: 0.3556\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6560 - val_loss: 4.0439 - val_accuracy: 0.4067\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6616 - val_loss: 4.4927 - val_accuracy: 0.4156\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6620 - val_loss: 2.3918 - val_accuracy: 0.4289\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.6685 - val_loss: 3.2255 - val_accuracy: 0.4778\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6843 - val_loss: 3.9064 - val_accuracy: 0.4289\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6949 - val_loss: 2.4783 - val_accuracy: 0.4622\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7042 - val_loss: 2.6919 - val_accuracy: 0.4444\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.6843 - val_loss: 2.1891 - val_accuracy: 0.5178\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7032 - val_loss: 4.5489 - val_accuracy: 0.3889\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7227 - val_loss: 3.4422 - val_accuracy: 0.4422\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7014 - val_loss: 1.8282 - val_accuracy: 0.4711\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7074 - val_loss: 1.9633 - val_accuracy: 0.5244\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7273 - val_loss: 2.7398 - val_accuracy: 0.4844\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7338 - val_loss: 4.3390 - val_accuracy: 0.4556\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7190 - val_loss: 2.7387 - val_accuracy: 0.4244\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7264 - val_loss: 3.6139 - val_accuracy: 0.4200\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7463 - val_loss: 4.6365 - val_accuracy: 0.4533\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7375 - val_loss: 2.9031 - val_accuracy: 0.4311\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7315 - val_loss: 6.5733 - val_accuracy: 0.3822\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7394 - val_loss: 5.8095 - val_accuracy: 0.4222\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7546 - val_loss: 5.7669 - val_accuracy: 0.4600\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7398 - val_loss: 3.8215 - val_accuracy: 0.4778\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7681 - val_loss: 2.3643 - val_accuracy: 0.4467\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7611 - val_loss: 2.6899 - val_accuracy: 0.4556\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7625 - val_loss: 5.5677 - val_accuracy: 0.3933\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7606 - val_loss: 3.6678 - val_accuracy: 0.4511\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7606 - val_loss: 3.3351 - val_accuracy: 0.5067\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7704 - val_loss: 2.7920 - val_accuracy: 0.4622\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7759 - val_loss: 7.0510 - val_accuracy: 0.4511\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7574 - val_loss: 2.8321 - val_accuracy: 0.4733\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7769 - val_loss: 4.3463 - val_accuracy: 0.4467\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7639 - val_loss: 2.6331 - val_accuracy: 0.4844\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7713 - val_loss: 4.7731 - val_accuracy: 0.4600\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7630 - val_loss: 8.3074 - val_accuracy: 0.4178\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7759 - val_loss: 3.9407 - val_accuracy: 0.4844\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7792 - val_loss: 4.4971 - val_accuracy: 0.4667\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7718 - val_loss: 2.8036 - val_accuracy: 0.4289\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7843 - val_loss: 2.7363 - val_accuracy: 0.4844\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.7926 - val_loss: 3.7497 - val_accuracy: 0.4756\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.7944 - val_loss: 3.3657 - val_accuracy: 0.4844\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7833 - val_loss: 3.3590 - val_accuracy: 0.4600\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8120 - val_loss: 3.9087 - val_accuracy: 0.4711\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.7968 - val_loss: 3.1953 - val_accuracy: 0.4600\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.7968 - val_loss: 6.4868 - val_accuracy: 0.4289\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.7981 - val_loss: 4.5140 - val_accuracy: 0.4289\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.7847 - val_loss: 3.1372 - val_accuracy: 0.5111\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8028 - val_loss: 2.9993 - val_accuracy: 0.5533\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.7986 - val_loss: 9.5207 - val_accuracy: 0.3422\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.7898 - val_loss: 3.7452 - val_accuracy: 0.5267\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8162 - val_loss: 4.5610 - val_accuracy: 0.4178\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8060 - val_loss: 4.2469 - val_accuracy: 0.4444\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8028 - val_loss: 4.1472 - val_accuracy: 0.4356\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8185 - val_loss: 6.7734 - val_accuracy: 0.4622\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8176 - val_loss: 5.8073 - val_accuracy: 0.4444\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8130 - val_loss: 4.2377 - val_accuracy: 0.4933\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8037 - val_loss: 3.2057 - val_accuracy: 0.5200\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8181 - val_loss: 6.8605 - val_accuracy: 0.4533\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8000 - val_loss: 3.8168 - val_accuracy: 0.5556\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8106 - val_loss: 5.6286 - val_accuracy: 0.4533\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8069 - val_loss: 5.9952 - val_accuracy: 0.4711\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8181 - val_loss: 4.9298 - val_accuracy: 0.4933\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.8282 - val_loss: 2.9029 - val_accuracy: 0.5711\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.7921 - val_loss: 5.8787 - val_accuracy: 0.4333\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.8347 - val_loss: 4.5472 - val_accuracy: 0.4511\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8245 - val_loss: 5.3712 - val_accuracy: 0.4356\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8250 - val_loss: 4.8812 - val_accuracy: 0.5267\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8278 - val_loss: 7.8274 - val_accuracy: 0.4933\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3402 - accuracy: 0.8148 - val_loss: 4.7137 - val_accuracy: 0.5244\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8250 - val_loss: 6.3930 - val_accuracy: 0.5156\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3005 - accuracy: 0.8324 - val_loss: 5.6880 - val_accuracy: 0.5111\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3471 - accuracy: 0.8079 - val_loss: 4.9149 - val_accuracy: 0.4667\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8319 - val_loss: 5.1777 - val_accuracy: 0.5089\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8144 - val_loss: 6.0929 - val_accuracy: 0.4644\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8301 - val_loss: 4.0981 - val_accuracy: 0.5533\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8213 - val_loss: 5.1504 - val_accuracy: 0.4467\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8287 - val_loss: 7.7023 - val_accuracy: 0.4533\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_194 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_190 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_194 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_195 (Conv2D)          (None, 25, 25, 12)        2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_191 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_195 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_97 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 225,539\n",
      "Trainable params: 225,461\n",
      "Non-trainable params: 78\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2898 - accuracy: 0.4028 - val_loss: 1.0935 - val_accuracy: 0.4089\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9650 - accuracy: 0.4718 - val_loss: 1.0922 - val_accuracy: 0.3956\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8610 - accuracy: 0.5449 - val_loss: 1.1006 - val_accuracy: 0.3800\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8012 - accuracy: 0.5921 - val_loss: 1.0062 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7481 - accuracy: 0.6190 - val_loss: 1.0094 - val_accuracy: 0.5311\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6412 - val_loss: 1.7240 - val_accuracy: 0.4689\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6468 - accuracy: 0.6731 - val_loss: 1.1848 - val_accuracy: 0.4844\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7111 - val_loss: 1.6928 - val_accuracy: 0.5044\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7106 - val_loss: 2.0963 - val_accuracy: 0.4378\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5404 - accuracy: 0.7287 - val_loss: 2.3395 - val_accuracy: 0.4111\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7583 - val_loss: 1.5035 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7417 - val_loss: 1.4673 - val_accuracy: 0.5511\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7556 - val_loss: 2.4138 - val_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7819 - val_loss: 2.0253 - val_accuracy: 0.5044\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.7829 - val_loss: 2.2980 - val_accuracy: 0.3978\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7815 - val_loss: 3.0431 - val_accuracy: 0.4533\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8028 - val_loss: 2.9969 - val_accuracy: 0.4733\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8171 - val_loss: 2.2191 - val_accuracy: 0.4600\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8009 - val_loss: 2.8122 - val_accuracy: 0.4778\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8167 - val_loss: 2.9386 - val_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8069 - val_loss: 3.8276 - val_accuracy: 0.4222\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8278 - val_loss: 2.7127 - val_accuracy: 0.4556\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.8069 - val_loss: 2.3821 - val_accuracy: 0.4422\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8190 - val_loss: 2.3910 - val_accuracy: 0.4289\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8296 - val_loss: 2.6235 - val_accuracy: 0.4578\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8472 - val_loss: 3.1152 - val_accuracy: 0.5422\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8426 - val_loss: 2.9350 - val_accuracy: 0.5222\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8352 - val_loss: 4.8113 - val_accuracy: 0.4244\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2911 - accuracy: 0.8546 - val_loss: 2.2565 - val_accuracy: 0.5178\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8500 - val_loss: 2.8561 - val_accuracy: 0.5089\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2529 - accuracy: 0.8671 - val_loss: 3.2473 - val_accuracy: 0.4822\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8741 - val_loss: 4.9908 - val_accuracy: 0.4622\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.8671 - val_loss: 3.1876 - val_accuracy: 0.4911\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8722 - val_loss: 3.6282 - val_accuracy: 0.4933\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.8685 - val_loss: 5.1429 - val_accuracy: 0.4067\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.8731 - val_loss: 4.3828 - val_accuracy: 0.4844\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8681 - val_loss: 4.3078 - val_accuracy: 0.4956\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.8773 - val_loss: 3.4947 - val_accuracy: 0.4533\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.8782 - val_loss: 7.0357 - val_accuracy: 0.4289\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.8824 - val_loss: 7.1342 - val_accuracy: 0.4422\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.8972 - val_loss: 4.2503 - val_accuracy: 0.4156\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.8801 - val_loss: 5.1646 - val_accuracy: 0.4911\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.8926 - val_loss: 4.5233 - val_accuracy: 0.5044\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2132 - accuracy: 0.8912 - val_loss: 4.3736 - val_accuracy: 0.4867\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9023 - val_loss: 6.7288 - val_accuracy: 0.4489\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9051 - val_loss: 7.3741 - val_accuracy: 0.4556\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2078 - accuracy: 0.8986 - val_loss: 5.2293 - val_accuracy: 0.4956\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.8995 - val_loss: 6.1976 - val_accuracy: 0.5022\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9102 - val_loss: 5.9353 - val_accuracy: 0.4822\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.9083 - val_loss: 5.6818 - val_accuracy: 0.4822\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9093 - val_loss: 6.2090 - val_accuracy: 0.4711\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1855 - accuracy: 0.9097 - val_loss: 7.9487 - val_accuracy: 0.4400\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9148 - val_loss: 5.2220 - val_accuracy: 0.4778\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9032 - val_loss: 15.6385 - val_accuracy: 0.3400\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9023 - val_loss: 8.5718 - val_accuracy: 0.4089\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9139 - val_loss: 7.4611 - val_accuracy: 0.4822\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1732 - accuracy: 0.9144 - val_loss: 6.0872 - val_accuracy: 0.4956\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9130 - val_loss: 5.6299 - val_accuracy: 0.5467\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9176 - val_loss: 6.0583 - val_accuracy: 0.4356\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.9222 - val_loss: 6.3954 - val_accuracy: 0.5156\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1661 - accuracy: 0.9185 - val_loss: 5.4360 - val_accuracy: 0.4711\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9222 - val_loss: 5.8573 - val_accuracy: 0.4844\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9329 - val_loss: 6.7277 - val_accuracy: 0.4356\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9306 - val_loss: 7.0015 - val_accuracy: 0.4711\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9338 - val_loss: 7.5591 - val_accuracy: 0.5267\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9356 - val_loss: 7.1175 - val_accuracy: 0.4800\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9264 - val_loss: 5.7632 - val_accuracy: 0.5867\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9366 - val_loss: 9.8429 - val_accuracy: 0.4644\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9245 - val_loss: 6.6046 - val_accuracy: 0.5089\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9394 - val_loss: 6.7988 - val_accuracy: 0.4533\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9273 - val_loss: 6.7435 - val_accuracy: 0.5644\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9417 - val_loss: 8.6548 - val_accuracy: 0.3844\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9384 - val_loss: 7.3708 - val_accuracy: 0.5289\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9389 - val_loss: 6.4194 - val_accuracy: 0.5267\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9477 - val_loss: 7.9682 - val_accuracy: 0.5289\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9519 - val_loss: 8.6970 - val_accuracy: 0.4489\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9458 - val_loss: 8.1739 - val_accuracy: 0.4933\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9412 - val_loss: 8.7536 - val_accuracy: 0.4978\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9523 - val_loss: 9.1887 - val_accuracy: 0.4267\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9440 - val_loss: 7.5864 - val_accuracy: 0.5244\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9444 - val_loss: 8.9824 - val_accuracy: 0.4689\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9472 - val_loss: 11.9825 - val_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9458 - val_loss: 6.4544 - val_accuracy: 0.5200\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9500 - val_loss: 7.0071 - val_accuracy: 0.4844\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9523 - val_loss: 10.5460 - val_accuracy: 0.4444\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9546 - val_loss: 9.2893 - val_accuracy: 0.5222\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9528 - val_loss: 9.6265 - val_accuracy: 0.4400\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9574 - val_loss: 8.4425 - val_accuracy: 0.4600\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9509 - val_loss: 7.3039 - val_accuracy: 0.5511\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9542 - val_loss: 7.4540 - val_accuracy: 0.4867\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.9532 - val_loss: 8.4971 - val_accuracy: 0.4933\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 0.9657 - val_loss: 11.4663 - val_accuracy: 0.4356\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9556 - val_loss: 12.7146 - val_accuracy: 0.4578\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0826 - accuracy: 0.9611 - val_loss: 8.4505 - val_accuracy: 0.4533\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9694 - val_loss: 8.5505 - val_accuracy: 0.5289\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9602 - val_loss: 8.4039 - val_accuracy: 0.5133\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9588 - val_loss: 31.3924 - val_accuracy: 0.3311\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9662 - val_loss: 8.5958 - val_accuracy: 0.4289\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9630 - val_loss: 12.1182 - val_accuracy: 0.3956\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9616 - val_loss: 8.8476 - val_accuracy: 0.4822\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_196 (Conv2D)          (None, 54, 54, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_192 (Bat (None, 54, 54, 27)        108       \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 54, 54, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_196 (MaxPoolin (None, 27, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_197 (Conv2D)          (None, 25, 25, 12)        2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_193 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_197 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_98 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 256)               442624    \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 447,235\n",
      "Trainable params: 447,157\n",
      "Non-trainable params: 78\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 2s 10ms/step - loss: 1.3151 - accuracy: 0.4588 - val_loss: 1.0898 - val_accuracy: 0.3022\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8625 - accuracy: 0.5736 - val_loss: 1.0912 - val_accuracy: 0.4244\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.6440 - val_loss: 1.1589 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6944 - val_loss: 1.2118 - val_accuracy: 0.4978\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6027 - accuracy: 0.7181 - val_loss: 1.3898 - val_accuracy: 0.5067\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7444 - val_loss: 1.9046 - val_accuracy: 0.4289\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7694 - val_loss: 1.7503 - val_accuracy: 0.4756\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7745 - val_loss: 2.5346 - val_accuracy: 0.4244\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8102 - val_loss: 3.4102 - val_accuracy: 0.4178\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8171 - val_loss: 4.5860 - val_accuracy: 0.4089\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8259 - val_loss: 3.1532 - val_accuracy: 0.3956\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8449 - val_loss: 3.1368 - val_accuracy: 0.4222\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8449 - val_loss: 8.4012 - val_accuracy: 0.3533\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8602 - val_loss: 3.6911 - val_accuracy: 0.3956\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8588 - val_loss: 2.9678 - val_accuracy: 0.4533\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8630 - val_loss: 2.3699 - val_accuracy: 0.4378\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8750 - val_loss: 5.4692 - val_accuracy: 0.4111\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8731 - val_loss: 3.8440 - val_accuracy: 0.4044\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8769 - val_loss: 2.5018 - val_accuracy: 0.4756\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2520 - accuracy: 0.8782 - val_loss: 2.2127 - val_accuracy: 0.5289\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.8940 - val_loss: 6.0742 - val_accuracy: 0.4444\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.8815 - val_loss: 2.3760 - val_accuracy: 0.5156\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2170 - accuracy: 0.9005 - val_loss: 4.8157 - val_accuracy: 0.4444\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.9032 - val_loss: 3.3879 - val_accuracy: 0.4156\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2150 - accuracy: 0.9083 - val_loss: 6.6072 - val_accuracy: 0.4333\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9037 - val_loss: 4.5123 - val_accuracy: 0.4378\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2088 - accuracy: 0.9106 - val_loss: 5.1118 - val_accuracy: 0.4822\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2027 - accuracy: 0.9042 - val_loss: 3.8281 - val_accuracy: 0.6244\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.9037 - val_loss: 5.0467 - val_accuracy: 0.4578\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9236 - val_loss: 6.0366 - val_accuracy: 0.4289\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9273 - val_loss: 4.7978 - val_accuracy: 0.5089\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9190 - val_loss: 3.9616 - val_accuracy: 0.5022\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1550 - accuracy: 0.9338 - val_loss: 4.1958 - val_accuracy: 0.4689\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9236 - val_loss: 5.7224 - val_accuracy: 0.4578\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.9421 - val_loss: 5.0152 - val_accuracy: 0.5178\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9287 - val_loss: 9.4422 - val_accuracy: 0.4244\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9370 - val_loss: 7.7862 - val_accuracy: 0.4333\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9407 - val_loss: 3.6870 - val_accuracy: 0.5622\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9412 - val_loss: 3.9390 - val_accuracy: 0.5156\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9542 - val_loss: 5.8103 - val_accuracy: 0.4933\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9546 - val_loss: 3.9684 - val_accuracy: 0.5511\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9463 - val_loss: 4.5132 - val_accuracy: 0.5711\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9338 - val_loss: 4.4844 - val_accuracy: 0.4689\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9412 - val_loss: 4.5538 - val_accuracy: 0.5978\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9431 - val_loss: 10.9227 - val_accuracy: 0.4467\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9560 - val_loss: 5.3509 - val_accuracy: 0.5778\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9509 - val_loss: 4.1146 - val_accuracy: 0.5511\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9634 - val_loss: 5.0720 - val_accuracy: 0.4667\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9597 - val_loss: 4.7398 - val_accuracy: 0.5467\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9657 - val_loss: 4.1059 - val_accuracy: 0.6044\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9486 - val_loss: 4.1595 - val_accuracy: 0.5089\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9583 - val_loss: 9.1130 - val_accuracy: 0.4622\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 6.0086 - val_accuracy: 0.4822\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9593 - val_loss: 8.1460 - val_accuracy: 0.4444\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9648 - val_loss: 4.6799 - val_accuracy: 0.6178\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9625 - val_loss: 8.7404 - val_accuracy: 0.5022\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9644 - val_loss: 8.0313 - val_accuracy: 0.4711\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9620 - val_loss: 24.9721 - val_accuracy: 0.3400\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9681 - val_loss: 5.7392 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9667 - val_loss: 5.0963 - val_accuracy: 0.4778\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9713 - val_loss: 6.2985 - val_accuracy: 0.5133\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9750 - val_loss: 6.4469 - val_accuracy: 0.5378\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9773 - val_loss: 6.9214 - val_accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9560 - val_loss: 6.3592 - val_accuracy: 0.4622\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9681 - val_loss: 5.7638 - val_accuracy: 0.5600\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9685 - val_loss: 10.2487 - val_accuracy: 0.4667\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9694 - val_loss: 7.9430 - val_accuracy: 0.4978\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0637 - accuracy: 0.9741 - val_loss: 8.2613 - val_accuracy: 0.5089\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9704 - val_loss: 9.2327 - val_accuracy: 0.5867\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9653 - val_loss: 5.2781 - val_accuracy: 0.5667\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9745 - val_loss: 9.4358 - val_accuracy: 0.4133\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9644 - val_loss: 4.8282 - val_accuracy: 0.6022\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9727 - val_loss: 14.0424 - val_accuracy: 0.4600\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9778 - val_loss: 5.9549 - val_accuracy: 0.5978\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9759 - val_loss: 4.7601 - val_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9829 - val_loss: 5.0792 - val_accuracy: 0.5956\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9667 - val_loss: 9.0871 - val_accuracy: 0.5622\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9769 - val_loss: 6.4080 - val_accuracy: 0.5533\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9806 - val_loss: 9.2013 - val_accuracy: 0.4844\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9806 - val_loss: 7.1435 - val_accuracy: 0.5356\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9870 - val_loss: 5.6597 - val_accuracy: 0.5511\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9755 - val_loss: 10.7841 - val_accuracy: 0.5111\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9810 - val_loss: 7.3899 - val_accuracy: 0.6467\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9778 - val_loss: 7.0156 - val_accuracy: 0.5489\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9801 - val_loss: 6.8864 - val_accuracy: 0.5089\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9819 - val_loss: 7.6689 - val_accuracy: 0.5444\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 9.4279 - val_accuracy: 0.4800\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9727 - val_loss: 8.2549 - val_accuracy: 0.5600\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9829 - val_loss: 7.3925 - val_accuracy: 0.6200\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9829 - val_loss: 6.5329 - val_accuracy: 0.5044\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9824 - val_loss: 10.7968 - val_accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9847 - val_loss: 15.3981 - val_accuracy: 0.3978\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9824 - val_loss: 6.8056 - val_accuracy: 0.5244\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9782 - val_loss: 7.1986 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9819 - val_loss: 10.4480 - val_accuracy: 0.4711\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9824 - val_loss: 8.7384 - val_accuracy: 0.5489\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9815 - val_loss: 9.5190 - val_accuracy: 0.5578\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 10.8567 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9870 - val_loss: 8.4794 - val_accuracy: 0.5378\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9843 - val_loss: 8.2230 - val_accuracy: 0.4822\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_198 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_194 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_198 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_199 (Conv2D)          (None, 25, 25, 8)         2168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_195 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_199 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_99 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 40,155\n",
      "Trainable params: 40,079\n",
      "Non-trainable params: 76\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1650 - accuracy: 0.3671 - val_loss: 1.0997 - val_accuracy: 0.3489\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0750 - accuracy: 0.3792 - val_loss: 1.0992 - val_accuracy: 0.3822\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0550 - accuracy: 0.4005 - val_loss: 1.1086 - val_accuracy: 0.3778\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0219 - accuracy: 0.4255 - val_loss: 1.1298 - val_accuracy: 0.5511\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9897 - accuracy: 0.4449 - val_loss: 1.1995 - val_accuracy: 0.4111\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9845 - accuracy: 0.4602 - val_loss: 1.3498 - val_accuracy: 0.4667\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9647 - accuracy: 0.4569 - val_loss: 1.3302 - val_accuracy: 0.4911\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9525 - accuracy: 0.4676 - val_loss: 1.2767 - val_accuracy: 0.4644\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9400 - accuracy: 0.4685 - val_loss: 1.4222 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9569 - accuracy: 0.4722 - val_loss: 1.6174 - val_accuracy: 0.4111\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9346 - accuracy: 0.4782 - val_loss: 1.7040 - val_accuracy: 0.5444\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9304 - accuracy: 0.4792 - val_loss: 1.4500 - val_accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9260 - accuracy: 0.4866 - val_loss: 1.2990 - val_accuracy: 0.5933\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9046 - accuracy: 0.4958 - val_loss: 1.1870 - val_accuracy: 0.5356\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9164 - accuracy: 0.4894 - val_loss: 1.2222 - val_accuracy: 0.5244\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9011 - accuracy: 0.5083 - val_loss: 1.5971 - val_accuracy: 0.4822\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8985 - accuracy: 0.5079 - val_loss: 1.1715 - val_accuracy: 0.5378\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8916 - accuracy: 0.4968 - val_loss: 1.1576 - val_accuracy: 0.5844\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8585 - accuracy: 0.5236 - val_loss: 1.2968 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8708 - accuracy: 0.5181 - val_loss: 1.5046 - val_accuracy: 0.3467\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8686 - accuracy: 0.5120 - val_loss: 1.3935 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8684 - accuracy: 0.5162 - val_loss: 1.3867 - val_accuracy: 0.4578\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8580 - accuracy: 0.5347 - val_loss: 1.1149 - val_accuracy: 0.5533\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8317 - accuracy: 0.5296 - val_loss: 1.2365 - val_accuracy: 0.5222\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8423 - accuracy: 0.5292 - val_loss: 1.1381 - val_accuracy: 0.5356\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8165 - accuracy: 0.5426 - val_loss: 1.1938 - val_accuracy: 0.5356\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8088 - accuracy: 0.5583 - val_loss: 1.4026 - val_accuracy: 0.5356\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8204 - accuracy: 0.5347 - val_loss: 1.3787 - val_accuracy: 0.4822\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8027 - accuracy: 0.5542 - val_loss: 1.3467 - val_accuracy: 0.5044\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7957 - accuracy: 0.5699 - val_loss: 1.4635 - val_accuracy: 0.4822\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8041 - accuracy: 0.5606 - val_loss: 1.0528 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7782 - accuracy: 0.5704 - val_loss: 1.3236 - val_accuracy: 0.4556\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7650 - accuracy: 0.5759 - val_loss: 1.1486 - val_accuracy: 0.5667\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.5898 - val_loss: 1.6691 - val_accuracy: 0.5111\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.6042 - val_loss: 2.2287 - val_accuracy: 0.4289\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.6019 - val_loss: 1.4917 - val_accuracy: 0.4422\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7263 - accuracy: 0.6111 - val_loss: 2.9187 - val_accuracy: 0.3689\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.6264 - val_loss: 1.4146 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.6231 - val_loss: 1.3263 - val_accuracy: 0.6178\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.6282 - val_loss: 3.0023 - val_accuracy: 0.4222\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7164 - accuracy: 0.6329 - val_loss: 1.9584 - val_accuracy: 0.5644\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.6417 - val_loss: 2.2803 - val_accuracy: 0.4511\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.6505 - val_loss: 2.2792 - val_accuracy: 0.4978\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6542 - val_loss: 2.2779 - val_accuracy: 0.4733\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6546 - val_loss: 2.9553 - val_accuracy: 0.4689\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6597 - val_loss: 1.6034 - val_accuracy: 0.5089\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6579 - val_loss: 3.7929 - val_accuracy: 0.3600\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6764 - val_loss: 2.4379 - val_accuracy: 0.5089\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6579 - val_loss: 2.9724 - val_accuracy: 0.3889\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6699 - val_loss: 3.6551 - val_accuracy: 0.3733\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6838 - val_loss: 2.6866 - val_accuracy: 0.4600\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6616 - val_loss: 2.5501 - val_accuracy: 0.4444\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6718 - val_loss: 1.8080 - val_accuracy: 0.4844\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6750 - val_loss: 4.4132 - val_accuracy: 0.3867\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6769 - val_loss: 3.5060 - val_accuracy: 0.4556\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6778 - val_loss: 6.0298 - val_accuracy: 0.3867\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6681 - val_loss: 3.4413 - val_accuracy: 0.4022\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6907 - val_loss: 1.6198 - val_accuracy: 0.6378\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6981 - val_loss: 4.3976 - val_accuracy: 0.3978\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6991 - val_loss: 2.2984 - val_accuracy: 0.5356\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.7023 - val_loss: 2.4186 - val_accuracy: 0.5400\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7130 - val_loss: 1.9680 - val_accuracy: 0.5200\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7051 - val_loss: 1.6401 - val_accuracy: 0.6333\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6894 - val_loss: 3.5938 - val_accuracy: 0.4222\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7157 - val_loss: 4.1110 - val_accuracy: 0.4889\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6968 - val_loss: 3.6968 - val_accuracy: 0.4844\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7023 - val_loss: 8.3785 - val_accuracy: 0.3556\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7088 - val_loss: 3.9998 - val_accuracy: 0.3711\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7162 - val_loss: 1.4547 - val_accuracy: 0.5667\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6958 - val_loss: 4.2845 - val_accuracy: 0.3911\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7218 - val_loss: 3.4331 - val_accuracy: 0.3911\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7028 - val_loss: 2.5060 - val_accuracy: 0.5044\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5451 - accuracy: 0.7204 - val_loss: 3.6482 - val_accuracy: 0.5022\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7148 - val_loss: 3.0573 - val_accuracy: 0.4778\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7310 - val_loss: 3.1002 - val_accuracy: 0.5244\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7218 - val_loss: 3.7938 - val_accuracy: 0.4800\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7269 - val_loss: 1.7594 - val_accuracy: 0.6378\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7199 - val_loss: 5.3063 - val_accuracy: 0.3667\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7417 - val_loss: 2.6384 - val_accuracy: 0.5156\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7352 - val_loss: 3.4721 - val_accuracy: 0.5311\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7356 - val_loss: 1.7717 - val_accuracy: 0.5467\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7463 - val_loss: 1.5617 - val_accuracy: 0.5400\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7417 - val_loss: 3.2260 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7477 - val_loss: 2.5837 - val_accuracy: 0.5444\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7296 - val_loss: 1.5250 - val_accuracy: 0.5778\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7472 - val_loss: 3.0516 - val_accuracy: 0.5311\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7287 - val_loss: 2.7197 - val_accuracy: 0.5244\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7468 - val_loss: 4.1356 - val_accuracy: 0.4156\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7338 - val_loss: 2.7574 - val_accuracy: 0.5822\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7366 - val_loss: 2.2930 - val_accuracy: 0.5533\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7315 - val_loss: 3.9730 - val_accuracy: 0.4867\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7653 - val_loss: 4.4975 - val_accuracy: 0.4911\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7477 - val_loss: 1.7578 - val_accuracy: 0.5711\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7384 - val_loss: 3.8243 - val_accuracy: 0.4889\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7389 - val_loss: 3.6114 - val_accuracy: 0.4578\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7421 - val_loss: 2.4507 - val_accuracy: 0.5467\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7486 - val_loss: 3.3896 - val_accuracy: 0.5489\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7551 - val_loss: 3.3284 - val_accuracy: 0.5133\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7579 - val_loss: 3.3988 - val_accuracy: 0.5244\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7824 - val_loss: 4.9431 - val_accuracy: 0.5000\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_200 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_196 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_200 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 25, 25, 8)         2168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_197 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_197 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_201 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_100 (Flatten)        (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 77,147\n",
      "Trainable params: 77,071\n",
      "Non-trainable params: 76\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1892 - accuracy: 0.4236 - val_loss: 1.0859 - val_accuracy: 0.3622\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0030 - accuracy: 0.4611 - val_loss: 1.1304 - val_accuracy: 0.5422\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8899 - accuracy: 0.5194 - val_loss: 1.2452 - val_accuracy: 0.5978\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8585 - accuracy: 0.5495 - val_loss: 1.3735 - val_accuracy: 0.6533\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7946 - accuracy: 0.5713 - val_loss: 1.6096 - val_accuracy: 0.6267\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7812 - accuracy: 0.5968 - val_loss: 1.2075 - val_accuracy: 0.6133\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.6273 - val_loss: 0.9665 - val_accuracy: 0.7044\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7074 - accuracy: 0.6278 - val_loss: 2.4869 - val_accuracy: 0.6244\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6731 - val_loss: 2.7096 - val_accuracy: 0.5667\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6764 - val_loss: 1.5005 - val_accuracy: 0.6378\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6921 - val_loss: 1.4057 - val_accuracy: 0.6244\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7065 - val_loss: 4.8562 - val_accuracy: 0.4044\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7278 - val_loss: 2.0293 - val_accuracy: 0.6489\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7361 - val_loss: 3.0050 - val_accuracy: 0.4178\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7227 - val_loss: 2.4252 - val_accuracy: 0.5756\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7366 - val_loss: 2.3639 - val_accuracy: 0.6378\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7468 - val_loss: 7.7021 - val_accuracy: 0.3533\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7463 - val_loss: 1.7211 - val_accuracy: 0.5156\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7713 - val_loss: 2.8178 - val_accuracy: 0.5822\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7731 - val_loss: 2.5752 - val_accuracy: 0.5244\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7894 - val_loss: 4.7849 - val_accuracy: 0.5067\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7940 - val_loss: 6.6534 - val_accuracy: 0.5600\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7782 - val_loss: 2.3909 - val_accuracy: 0.4978\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.7926 - val_loss: 2.4277 - val_accuracy: 0.5222\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.7894 - val_loss: 2.8662 - val_accuracy: 0.5756\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8028 - val_loss: 6.2402 - val_accuracy: 0.4267\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8056 - val_loss: 2.8049 - val_accuracy: 0.5622\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8171 - val_loss: 3.5901 - val_accuracy: 0.5644\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8144 - val_loss: 2.3180 - val_accuracy: 0.5222\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8199 - val_loss: 3.5278 - val_accuracy: 0.5289\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8185 - val_loss: 3.1461 - val_accuracy: 0.5778\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8148 - val_loss: 3.6669 - val_accuracy: 0.5267\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8343 - val_loss: 4.8866 - val_accuracy: 0.4956\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8236 - val_loss: 3.5177 - val_accuracy: 0.4956\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8264 - val_loss: 2.5765 - val_accuracy: 0.5533\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8398 - val_loss: 5.1398 - val_accuracy: 0.5222\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8500 - val_loss: 6.9469 - val_accuracy: 0.4844\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8324 - val_loss: 10.3678 - val_accuracy: 0.3933\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.8505 - val_loss: 7.2124 - val_accuracy: 0.5156\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3107 - accuracy: 0.8468 - val_loss: 2.8614 - val_accuracy: 0.5111\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8620 - val_loss: 4.0535 - val_accuracy: 0.4600\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8407 - val_loss: 5.8117 - val_accuracy: 0.4511\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8620 - val_loss: 7.0258 - val_accuracy: 0.4622\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8509 - val_loss: 7.2934 - val_accuracy: 0.4622\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8528 - val_loss: 3.4201 - val_accuracy: 0.5822\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8579 - val_loss: 3.7535 - val_accuracy: 0.5644\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8606 - val_loss: 4.0210 - val_accuracy: 0.6044\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.8579 - val_loss: 5.0692 - val_accuracy: 0.4467\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8593 - val_loss: 3.9335 - val_accuracy: 0.5978\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.8764 - val_loss: 6.8781 - val_accuracy: 0.4111\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2568 - accuracy: 0.8690 - val_loss: 5.0988 - val_accuracy: 0.4867\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.8870 - val_loss: 4.3374 - val_accuracy: 0.5111\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.8856 - val_loss: 5.3535 - val_accuracy: 0.4956\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8764 - val_loss: 3.5634 - val_accuracy: 0.5111\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8764 - val_loss: 3.6517 - val_accuracy: 0.5111\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8713 - val_loss: 4.8162 - val_accuracy: 0.5356\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2393 - accuracy: 0.8889 - val_loss: 7.1595 - val_accuracy: 0.4622\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.8852 - val_loss: 5.7123 - val_accuracy: 0.4756\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.8870 - val_loss: 4.4556 - val_accuracy: 0.5267\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.8935 - val_loss: 5.5300 - val_accuracy: 0.6200\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9042 - val_loss: 4.3749 - val_accuracy: 0.5667\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.8977 - val_loss: 5.2838 - val_accuracy: 0.4600\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.8949 - val_loss: 4.7436 - val_accuracy: 0.5578\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.8917 - val_loss: 5.8891 - val_accuracy: 0.4778\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.8995 - val_loss: 5.3613 - val_accuracy: 0.5267\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9037 - val_loss: 9.2434 - val_accuracy: 0.4311\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.8907 - val_loss: 5.3749 - val_accuracy: 0.4533\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9065 - val_loss: 6.2103 - val_accuracy: 0.5067\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9014 - val_loss: 7.4876 - val_accuracy: 0.4933\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9051 - val_loss: 11.5159 - val_accuracy: 0.4400\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9181 - val_loss: 4.8656 - val_accuracy: 0.5733\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9139 - val_loss: 7.6875 - val_accuracy: 0.5022\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9069 - val_loss: 5.0181 - val_accuracy: 0.5111\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9278 - val_loss: 6.1378 - val_accuracy: 0.5222\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9153 - val_loss: 8.2508 - val_accuracy: 0.4667\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9106 - val_loss: 11.3317 - val_accuracy: 0.3689\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9153 - val_loss: 7.3267 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9181 - val_loss: 4.9371 - val_accuracy: 0.5133\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9278 - val_loss: 5.5819 - val_accuracy: 0.4822\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9222 - val_loss: 10.6401 - val_accuracy: 0.5444\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9153 - val_loss: 5.6354 - val_accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9245 - val_loss: 5.0162 - val_accuracy: 0.6178\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9287 - val_loss: 5.7795 - val_accuracy: 0.5533\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9278 - val_loss: 15.4507 - val_accuracy: 0.3644\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9315 - val_loss: 8.7512 - val_accuracy: 0.5067\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9176 - val_loss: 6.9863 - val_accuracy: 0.5511\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9245 - val_loss: 7.0369 - val_accuracy: 0.4800\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9171 - val_loss: 6.2583 - val_accuracy: 0.5911\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9384 - val_loss: 6.7127 - val_accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9375 - val_loss: 11.2070 - val_accuracy: 0.5622\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9329 - val_loss: 7.1132 - val_accuracy: 0.5178\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.9361 - val_loss: 7.2374 - val_accuracy: 0.4400\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9310 - val_loss: 7.0520 - val_accuracy: 0.5689\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9389 - val_loss: 7.1261 - val_accuracy: 0.5756\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9463 - val_loss: 5.5017 - val_accuracy: 0.5644\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1431 - accuracy: 0.9356 - val_loss: 7.9974 - val_accuracy: 0.5422\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9426 - val_loss: 8.3194 - val_accuracy: 0.5311\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9449 - val_loss: 7.8075 - val_accuracy: 0.5422\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9625 - val_loss: 7.8426 - val_accuracy: 0.5822\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9491 - val_loss: 11.6987 - val_accuracy: 0.4444\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_202 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_198 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_198 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_202 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 25, 25, 8)         2168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_199 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_203 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_101 (Flatten)        (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 151,131\n",
      "Trainable params: 151,055\n",
      "Non-trainable params: 76\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1748 - accuracy: 0.4245 - val_loss: 1.1007 - val_accuracy: 0.3156\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9306 - accuracy: 0.5000 - val_loss: 1.1054 - val_accuracy: 0.3556\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8642 - accuracy: 0.5519 - val_loss: 1.1802 - val_accuracy: 0.5156\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7844 - accuracy: 0.6000 - val_loss: 1.1053 - val_accuracy: 0.4689\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7309 - accuracy: 0.6273 - val_loss: 3.9635 - val_accuracy: 0.3089\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.6648 - val_loss: 2.8560 - val_accuracy: 0.5133\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6949 - val_loss: 1.5233 - val_accuracy: 0.5267\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.7171 - val_loss: 2.0418 - val_accuracy: 0.4756\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7218 - val_loss: 2.1523 - val_accuracy: 0.4556\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7574 - val_loss: 2.6215 - val_accuracy: 0.4911\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7856 - val_loss: 3.5904 - val_accuracy: 0.4356\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7889 - val_loss: 3.6017 - val_accuracy: 0.5244\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7991 - val_loss: 2.2041 - val_accuracy: 0.5711\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 2.2667 - val_accuracy: 0.5622\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8199 - val_loss: 4.3524 - val_accuracy: 0.4111\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8347 - val_loss: 3.9921 - val_accuracy: 0.4956\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8398 - val_loss: 2.2818 - val_accuracy: 0.5711\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8560 - val_loss: 3.1926 - val_accuracy: 0.5244\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8523 - val_loss: 3.2682 - val_accuracy: 0.5689\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8532 - val_loss: 3.3192 - val_accuracy: 0.5733\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.8653 - val_loss: 3.8813 - val_accuracy: 0.5156\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.8792 - val_loss: 4.2169 - val_accuracy: 0.5667\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.8815 - val_loss: 3.0728 - val_accuracy: 0.5533\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8981 - val_loss: 3.5807 - val_accuracy: 0.4867\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.8894 - val_loss: 3.6263 - val_accuracy: 0.5644\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.8981 - val_loss: 6.4002 - val_accuracy: 0.4889\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.8995 - val_loss: 8.4176 - val_accuracy: 0.3800\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.8963 - val_loss: 8.6947 - val_accuracy: 0.3844\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9139 - val_loss: 3.7449 - val_accuracy: 0.5422\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9116 - val_loss: 6.2977 - val_accuracy: 0.5222\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9106 - val_loss: 4.1545 - val_accuracy: 0.5533\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1914 - accuracy: 0.9144 - val_loss: 4.7351 - val_accuracy: 0.5467\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9361 - val_loss: 5.3007 - val_accuracy: 0.5533\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9231 - val_loss: 5.2697 - val_accuracy: 0.5356\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9236 - val_loss: 4.9489 - val_accuracy: 0.5778\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9301 - val_loss: 4.8763 - val_accuracy: 0.5289\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9338 - val_loss: 4.5289 - val_accuracy: 0.6044\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9366 - val_loss: 5.4385 - val_accuracy: 0.5044\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9394 - val_loss: 6.4548 - val_accuracy: 0.5022\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9375 - val_loss: 5.6022 - val_accuracy: 0.5378\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9343 - val_loss: 6.2684 - val_accuracy: 0.5378\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9468 - val_loss: 5.9908 - val_accuracy: 0.5711\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9500 - val_loss: 8.7630 - val_accuracy: 0.4689\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9491 - val_loss: 6.9502 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9463 - val_loss: 6.8161 - val_accuracy: 0.5156\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9486 - val_loss: 6.8682 - val_accuracy: 0.4956\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9556 - val_loss: 6.6711 - val_accuracy: 0.5644\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9574 - val_loss: 5.9049 - val_accuracy: 0.5867\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9352 - val_loss: 13.7202 - val_accuracy: 0.3600\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9519 - val_loss: 8.1638 - val_accuracy: 0.4711\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9500 - val_loss: 6.9184 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9579 - val_loss: 5.8529 - val_accuracy: 0.5889\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9620 - val_loss: 8.6599 - val_accuracy: 0.5222\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9444 - val_loss: 7.4079 - val_accuracy: 0.5756\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9523 - val_loss: 6.6622 - val_accuracy: 0.5200\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9667 - val_loss: 6.6626 - val_accuracy: 0.5689\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9602 - val_loss: 8.8813 - val_accuracy: 0.5511\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 0.9523 - val_loss: 6.3390 - val_accuracy: 0.5689\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9620 - val_loss: 5.7486 - val_accuracy: 0.6244\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9583 - val_loss: 10.9018 - val_accuracy: 0.4978\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9532 - val_loss: 6.9730 - val_accuracy: 0.5978\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9667 - val_loss: 8.8851 - val_accuracy: 0.5311\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9620 - val_loss: 8.3945 - val_accuracy: 0.5711\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0814 - accuracy: 0.9653 - val_loss: 8.0889 - val_accuracy: 0.5778\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9630 - val_loss: 6.4805 - val_accuracy: 0.5444\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0808 - accuracy: 0.9657 - val_loss: 6.4908 - val_accuracy: 0.4689\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9653 - val_loss: 7.9269 - val_accuracy: 0.4933\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9639 - val_loss: 8.5814 - val_accuracy: 0.5222\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9685 - val_loss: 8.0109 - val_accuracy: 0.6222\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9685 - val_loss: 8.4812 - val_accuracy: 0.6200\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9718 - val_loss: 9.5426 - val_accuracy: 0.5489\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9713 - val_loss: 8.3103 - val_accuracy: 0.5311\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9694 - val_loss: 8.7097 - val_accuracy: 0.5378\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9718 - val_loss: 9.2636 - val_accuracy: 0.5356\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9699 - val_loss: 11.0202 - val_accuracy: 0.4933\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9819 - val_loss: 10.6654 - val_accuracy: 0.4978\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9731 - val_loss: 9.7708 - val_accuracy: 0.5822\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9727 - val_loss: 9.9445 - val_accuracy: 0.6511\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9750 - val_loss: 11.2022 - val_accuracy: 0.4733\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9718 - val_loss: 8.6919 - val_accuracy: 0.6600\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9718 - val_loss: 8.0046 - val_accuracy: 0.5511\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9681 - val_loss: 9.7593 - val_accuracy: 0.4933\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9773 - val_loss: 7.3273 - val_accuracy: 0.5133\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9782 - val_loss: 8.0877 - val_accuracy: 0.6422\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9722 - val_loss: 9.7184 - val_accuracy: 0.5711\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9713 - val_loss: 10.1275 - val_accuracy: 0.5600\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9750 - val_loss: 10.5554 - val_accuracy: 0.5244\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9847 - val_loss: 12.4684 - val_accuracy: 0.6311\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9824 - val_loss: 10.6009 - val_accuracy: 0.5733\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9644 - val_loss: 7.6634 - val_accuracy: 0.5400\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9773 - val_loss: 9.2307 - val_accuracy: 0.5822\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9852 - val_loss: 10.3786 - val_accuracy: 0.5800\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9708 - val_loss: 10.6982 - val_accuracy: 0.6289\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9722 - val_loss: 12.0700 - val_accuracy: 0.5022\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 9.7558 - val_accuracy: 0.4733\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9727 - val_loss: 12.1008 - val_accuracy: 0.4889\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9764 - val_loss: 9.7405 - val_accuracy: 0.4733\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9755 - val_loss: 10.2592 - val_accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9778 - val_loss: 14.9775 - val_accuracy: 0.4533\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9755 - val_loss: 12.1866 - val_accuracy: 0.6289\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_204 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_204 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 25, 25, 8)         2168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_205 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_102 (Flatten)        (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 299,099\n",
      "Trainable params: 299,023\n",
      "Non-trainable params: 76\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2575 - accuracy: 0.4667 - val_loss: 1.0933 - val_accuracy: 0.3178\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8560 - accuracy: 0.5806 - val_loss: 1.0900 - val_accuracy: 0.4844\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.6542 - val_loss: 1.0948 - val_accuracy: 0.4333\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.7120 - val_loss: 1.1503 - val_accuracy: 0.4200\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7574 - val_loss: 1.8048 - val_accuracy: 0.4756\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7718 - val_loss: 1.5391 - val_accuracy: 0.6178\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.8102 - val_loss: 1.5263 - val_accuracy: 0.4556\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8148 - val_loss: 2.2444 - val_accuracy: 0.4467\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8380 - val_loss: 2.6760 - val_accuracy: 0.4822\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8509 - val_loss: 1.9973 - val_accuracy: 0.4244\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8597 - val_loss: 2.5183 - val_accuracy: 0.4511\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8611 - val_loss: 2.2788 - val_accuracy: 0.5444\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.8815 - val_loss: 2.7206 - val_accuracy: 0.5067\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8806 - val_loss: 2.3704 - val_accuracy: 0.5711\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.8954 - val_loss: 2.3341 - val_accuracy: 0.4444\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2580 - accuracy: 0.8838 - val_loss: 2.0153 - val_accuracy: 0.5022\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9005 - val_loss: 2.3299 - val_accuracy: 0.5133\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1953 - accuracy: 0.9185 - val_loss: 3.7733 - val_accuracy: 0.4511\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1991 - accuracy: 0.9199 - val_loss: 3.3832 - val_accuracy: 0.4422\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9315 - val_loss: 2.7066 - val_accuracy: 0.5133\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9273 - val_loss: 2.9921 - val_accuracy: 0.5578\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9199 - val_loss: 2.9593 - val_accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9236 - val_loss: 3.2922 - val_accuracy: 0.5511\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9324 - val_loss: 3.8826 - val_accuracy: 0.5489\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1637 - accuracy: 0.9287 - val_loss: 3.4066 - val_accuracy: 0.4956\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1992 - accuracy: 0.9199 - val_loss: 4.6259 - val_accuracy: 0.4378\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9431 - val_loss: 3.3306 - val_accuracy: 0.5422\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9458 - val_loss: 3.3489 - val_accuracy: 0.5489\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9509 - val_loss: 3.7470 - val_accuracy: 0.5844\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9505 - val_loss: 4.3746 - val_accuracy: 0.4356\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9542 - val_loss: 4.0768 - val_accuracy: 0.4756\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9551 - val_loss: 3.8229 - val_accuracy: 0.5178\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9565 - val_loss: 3.2530 - val_accuracy: 0.5489\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9630 - val_loss: 3.8456 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9495 - val_loss: 3.0428 - val_accuracy: 0.5667\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9532 - val_loss: 4.0320 - val_accuracy: 0.5089\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9491 - val_loss: 4.0358 - val_accuracy: 0.5311\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.9653 - val_loss: 3.7297 - val_accuracy: 0.5933\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9588 - val_loss: 4.9233 - val_accuracy: 0.5267\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9565 - val_loss: 6.6871 - val_accuracy: 0.4600\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9551 - val_loss: 3.3029 - val_accuracy: 0.5867\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9727 - val_loss: 6.1213 - val_accuracy: 0.4067\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9634 - val_loss: 3.9465 - val_accuracy: 0.4778\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9657 - val_loss: 4.1152 - val_accuracy: 0.5289\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9662 - val_loss: 5.2779 - val_accuracy: 0.4867\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9676 - val_loss: 4.4282 - val_accuracy: 0.5689\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9722 - val_loss: 4.6253 - val_accuracy: 0.5289\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9662 - val_loss: 6.6155 - val_accuracy: 0.4333\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9667 - val_loss: 3.4796 - val_accuracy: 0.5867\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9690 - val_loss: 12.6485 - val_accuracy: 0.3756\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9801 - val_loss: 4.7534 - val_accuracy: 0.5200\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9778 - val_loss: 5.0105 - val_accuracy: 0.5222\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9662 - val_loss: 4.8660 - val_accuracy: 0.5400\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9750 - val_loss: 6.9741 - val_accuracy: 0.4511\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9745 - val_loss: 8.2017 - val_accuracy: 0.4356\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9750 - val_loss: 4.8121 - val_accuracy: 0.5311\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9778 - val_loss: 6.5560 - val_accuracy: 0.5933\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9769 - val_loss: 5.3399 - val_accuracy: 0.5133\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9773 - val_loss: 8.3730 - val_accuracy: 0.4356\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9773 - val_loss: 5.0038 - val_accuracy: 0.5689\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9731 - val_loss: 13.4650 - val_accuracy: 0.3711\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9764 - val_loss: 7.3050 - val_accuracy: 0.4511\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9778 - val_loss: 4.9378 - val_accuracy: 0.5311\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9815 - val_loss: 6.3086 - val_accuracy: 0.5489\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9796 - val_loss: 7.1299 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 5.8263 - val_accuracy: 0.5089\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9819 - val_loss: 8.7334 - val_accuracy: 0.4778\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9819 - val_loss: 11.6680 - val_accuracy: 0.4689\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9773 - val_loss: 6.5674 - val_accuracy: 0.4689\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9824 - val_loss: 8.0140 - val_accuracy: 0.4378\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9847 - val_loss: 6.9112 - val_accuracy: 0.5511\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 6.3463 - val_accuracy: 0.5244\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9815 - val_loss: 11.8465 - val_accuracy: 0.3667\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9778 - val_loss: 6.5508 - val_accuracy: 0.5022\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9796 - val_loss: 5.4679 - val_accuracy: 0.5956\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9773 - val_loss: 9.8530 - val_accuracy: 0.4911\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9829 - val_loss: 7.8572 - val_accuracy: 0.5844\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 5.5820 - val_accuracy: 0.5067\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 5.5224 - val_accuracy: 0.5756\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 14.5390 - val_accuracy: 0.3867\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9856 - val_loss: 6.8515 - val_accuracy: 0.5578\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9833 - val_loss: 5.3025 - val_accuracy: 0.5667\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 7.9507 - val_accuracy: 0.4911\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9852 - val_loss: 6.3592 - val_accuracy: 0.5778\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9838 - val_loss: 7.0931 - val_accuracy: 0.5533\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 6.8119 - val_accuracy: 0.5022\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9870 - val_loss: 6.6794 - val_accuracy: 0.5200\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9787 - val_loss: 9.1525 - val_accuracy: 0.5200\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0469 - accuracy: 0.9806 - val_loss: 6.5506 - val_accuracy: 0.5689\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 7.6658 - val_accuracy: 0.5422\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9847 - val_loss: 12.3547 - val_accuracy: 0.4267\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9824 - val_loss: 7.3424 - val_accuracy: 0.5911\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9847 - val_loss: 6.7944 - val_accuracy: 0.6133\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9907 - val_loss: 7.2408 - val_accuracy: 0.5578\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9856 - val_loss: 8.7627 - val_accuracy: 0.5178\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9815 - val_loss: 7.0622 - val_accuracy: 0.5267\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9856 - val_loss: 13.8036 - val_accuracy: 0.3844\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9847 - val_loss: 5.9924 - val_accuracy: 0.5267\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9824 - val_loss: 7.3604 - val_accuracy: 0.5133\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 9.9303 - val_accuracy: 0.4578\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_206 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_206 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 25, 25, 10)        2710      \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_207 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_103 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 49,921\n",
      "Trainable params: 49,841\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1783 - accuracy: 0.3324 - val_loss: 1.0971 - val_accuracy: 0.3267\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0958 - accuracy: 0.3407 - val_loss: 1.0940 - val_accuracy: 0.3644\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0907 - accuracy: 0.3532 - val_loss: 1.0968 - val_accuracy: 0.3911\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0856 - accuracy: 0.3662 - val_loss: 1.1042 - val_accuracy: 0.3644\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0780 - accuracy: 0.3690 - val_loss: 1.1411 - val_accuracy: 0.3956\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0773 - accuracy: 0.3681 - val_loss: 1.1557 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0726 - accuracy: 0.3708 - val_loss: 1.2202 - val_accuracy: 0.3556\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0719 - accuracy: 0.3796 - val_loss: 1.2503 - val_accuracy: 0.3400\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0623 - accuracy: 0.3829 - val_loss: 1.1395 - val_accuracy: 0.3489\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0684 - accuracy: 0.3833 - val_loss: 1.2260 - val_accuracy: 0.4244\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0618 - accuracy: 0.3806 - val_loss: 1.2066 - val_accuracy: 0.3511\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0676 - accuracy: 0.3699 - val_loss: 1.1035 - val_accuracy: 0.3444\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0615 - accuracy: 0.3759 - val_loss: 1.2136 - val_accuracy: 0.3489\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0552 - accuracy: 0.3792 - val_loss: 1.1467 - val_accuracy: 0.3467\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0604 - accuracy: 0.3755 - val_loss: 1.3142 - val_accuracy: 0.3689\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0462 - accuracy: 0.3926 - val_loss: 1.2863 - val_accuracy: 0.4267\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0528 - accuracy: 0.3838 - val_loss: 1.1994 - val_accuracy: 0.3756\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0466 - accuracy: 0.3889 - val_loss: 1.1831 - val_accuracy: 0.3422\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0553 - accuracy: 0.3815 - val_loss: 1.1596 - val_accuracy: 0.3556\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0489 - accuracy: 0.3894 - val_loss: 1.4110 - val_accuracy: 0.4178\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.3884 - val_loss: 1.3952 - val_accuracy: 0.3822\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0596 - accuracy: 0.3764 - val_loss: 1.1244 - val_accuracy: 0.3200\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0491 - accuracy: 0.3847 - val_loss: 1.2963 - val_accuracy: 0.3600\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.0330 - accuracy: 0.3972 - val_loss: 1.3693 - val_accuracy: 0.3933\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0504 - accuracy: 0.3856 - val_loss: 1.1827 - val_accuracy: 0.3533\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0519 - accuracy: 0.3810 - val_loss: 1.2242 - val_accuracy: 0.3333\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0383 - accuracy: 0.3917 - val_loss: 1.3369 - val_accuracy: 0.3533\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0477 - accuracy: 0.3880 - val_loss: 1.3030 - val_accuracy: 0.4156\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0352 - accuracy: 0.3917 - val_loss: 1.4764 - val_accuracy: 0.4333\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0423 - accuracy: 0.3875 - val_loss: 1.3348 - val_accuracy: 0.3667\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0384 - accuracy: 0.3949 - val_loss: 1.3185 - val_accuracy: 0.3711\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0436 - accuracy: 0.3921 - val_loss: 1.7213 - val_accuracy: 0.3978\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0639 - accuracy: 0.3838 - val_loss: 1.1382 - val_accuracy: 0.3178\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0601 - accuracy: 0.3745 - val_loss: 1.2397 - val_accuracy: 0.3311\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0383 - accuracy: 0.3815 - val_loss: 1.3519 - val_accuracy: 0.3867\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0335 - accuracy: 0.3713 - val_loss: 1.2535 - val_accuracy: 0.3556\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0457 - accuracy: 0.3843 - val_loss: 1.4174 - val_accuracy: 0.3711\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0271 - accuracy: 0.3852 - val_loss: 1.1644 - val_accuracy: 0.3844\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0227 - accuracy: 0.3954 - val_loss: 1.2830 - val_accuracy: 0.3800\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0355 - accuracy: 0.3648 - val_loss: 1.3074 - val_accuracy: 0.3600\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0278 - accuracy: 0.3801 - val_loss: 1.2242 - val_accuracy: 0.3911\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.3958 - val_loss: 1.2454 - val_accuracy: 0.3689\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.3741 - val_loss: 1.2642 - val_accuracy: 0.4178\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.3903 - val_loss: 2.0897 - val_accuracy: 0.4156\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0184 - accuracy: 0.4009 - val_loss: 1.5776 - val_accuracy: 0.3844\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0114 - accuracy: 0.3995 - val_loss: 1.5810 - val_accuracy: 0.4156\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0231 - accuracy: 0.3745 - val_loss: 1.7296 - val_accuracy: 0.3667\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0230 - accuracy: 0.3884 - val_loss: 1.6971 - val_accuracy: 0.3644\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0092 - accuracy: 0.4032 - val_loss: 1.0954 - val_accuracy: 0.4022\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0236 - accuracy: 0.3778 - val_loss: 1.4429 - val_accuracy: 0.4222\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0232 - accuracy: 0.3880 - val_loss: 1.7137 - val_accuracy: 0.3844\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0266 - accuracy: 0.3935 - val_loss: 1.3824 - val_accuracy: 0.3689\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0156 - accuracy: 0.4009 - val_loss: 1.2963 - val_accuracy: 0.3533\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0017 - accuracy: 0.4102 - val_loss: 1.2677 - val_accuracy: 0.4156\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0181 - accuracy: 0.3981 - val_loss: 1.5603 - val_accuracy: 0.3889\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.3898 - val_loss: 1.6358 - val_accuracy: 0.3756\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0127 - accuracy: 0.4046 - val_loss: 1.5041 - val_accuracy: 0.4133\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0103 - accuracy: 0.4060 - val_loss: 1.1667 - val_accuracy: 0.4067\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9995 - accuracy: 0.4176 - val_loss: 1.4830 - val_accuracy: 0.4244\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0080 - accuracy: 0.4125 - val_loss: 1.2751 - val_accuracy: 0.4089\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0068 - accuracy: 0.4102 - val_loss: 1.4695 - val_accuracy: 0.3756\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.4028 - val_loss: 2.7369 - val_accuracy: 0.3156\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9953 - accuracy: 0.4273 - val_loss: 1.8700 - val_accuracy: 0.4178\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9728 - accuracy: 0.4435 - val_loss: 1.6697 - val_accuracy: 0.4378\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9584 - accuracy: 0.4551 - val_loss: 1.2391 - val_accuracy: 0.4200\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9733 - accuracy: 0.4343 - val_loss: 1.5993 - val_accuracy: 0.4533\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9636 - accuracy: 0.4398 - val_loss: 2.1116 - val_accuracy: 0.3644\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9559 - accuracy: 0.4546 - val_loss: 1.7451 - val_accuracy: 0.4222\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9320 - accuracy: 0.4667 - val_loss: 2.7818 - val_accuracy: 0.3333\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9511 - accuracy: 0.4528 - val_loss: 1.4459 - val_accuracy: 0.3844\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9316 - accuracy: 0.4602 - val_loss: 3.5768 - val_accuracy: 0.3778\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9297 - accuracy: 0.4782 - val_loss: 1.8509 - val_accuracy: 0.3911\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9140 - accuracy: 0.4810 - val_loss: 1.4742 - val_accuracy: 0.4200\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9303 - accuracy: 0.4704 - val_loss: 2.0206 - val_accuracy: 0.4044\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9029 - accuracy: 0.4861 - val_loss: 3.2232 - val_accuracy: 0.3933\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8928 - accuracy: 0.4954 - val_loss: 2.7124 - val_accuracy: 0.4000\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9011 - accuracy: 0.4819 - val_loss: 2.3683 - val_accuracy: 0.4222\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9132 - accuracy: 0.4787 - val_loss: 1.5777 - val_accuracy: 0.4467\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9024 - accuracy: 0.4741 - val_loss: 1.7608 - val_accuracy: 0.4311\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8883 - accuracy: 0.5023 - val_loss: 1.5515 - val_accuracy: 0.4244\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9071 - accuracy: 0.4954 - val_loss: 1.9515 - val_accuracy: 0.4489\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8753 - accuracy: 0.5125 - val_loss: 2.4124 - val_accuracy: 0.4778\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8821 - accuracy: 0.5097 - val_loss: 1.7743 - val_accuracy: 0.4511\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9078 - accuracy: 0.4898 - val_loss: 2.1012 - val_accuracy: 0.4356\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8753 - accuracy: 0.5019 - val_loss: 2.6377 - val_accuracy: 0.4533\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8859 - accuracy: 0.5009 - val_loss: 2.1816 - val_accuracy: 0.4556\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9053 - accuracy: 0.4912 - val_loss: 1.4153 - val_accuracy: 0.4356\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8789 - accuracy: 0.5051 - val_loss: 2.2624 - val_accuracy: 0.4267\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8819 - accuracy: 0.5000 - val_loss: 2.2221 - val_accuracy: 0.4467\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8565 - accuracy: 0.5255 - val_loss: 2.1654 - val_accuracy: 0.4244\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8705 - accuracy: 0.5083 - val_loss: 1.9828 - val_accuracy: 0.4511\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8703 - accuracy: 0.5023 - val_loss: 1.6161 - val_accuracy: 0.4267\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.5208 - val_loss: 2.8271 - val_accuracy: 0.4111\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8726 - accuracy: 0.5046 - val_loss: 2.1579 - val_accuracy: 0.4489\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8770 - accuracy: 0.5042 - val_loss: 1.5151 - val_accuracy: 0.4489\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8650 - accuracy: 0.5111 - val_loss: 2.2669 - val_accuracy: 0.3556\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8711 - accuracy: 0.5097 - val_loss: 3.1750 - val_accuracy: 0.4000\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8637 - accuracy: 0.5153 - val_loss: 2.6515 - val_accuracy: 0.4333\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8659 - accuracy: 0.5088 - val_loss: 1.6611 - val_accuracy: 0.4356\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8649 - accuracy: 0.5060 - val_loss: 2.1629 - val_accuracy: 0.4333\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_208 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_204 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_208 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_209 (Conv2D)          (None, 25, 25, 10)        2710      \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_209 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_104 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 96,129\n",
      "Trainable params: 96,049\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1847 - accuracy: 0.3468 - val_loss: 1.0994 - val_accuracy: 0.3444\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0536 - accuracy: 0.3968 - val_loss: 1.1123 - val_accuracy: 0.3622\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.4005 - val_loss: 1.1229 - val_accuracy: 0.4067\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9728 - accuracy: 0.4167 - val_loss: 1.3057 - val_accuracy: 0.3178\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9544 - accuracy: 0.4671 - val_loss: 1.6462 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9167 - accuracy: 0.4773 - val_loss: 1.3895 - val_accuracy: 0.3733\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8868 - accuracy: 0.4810 - val_loss: 1.0892 - val_accuracy: 0.5556\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8714 - accuracy: 0.4856 - val_loss: 1.3110 - val_accuracy: 0.3800\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8468 - accuracy: 0.5056 - val_loss: 1.2804 - val_accuracy: 0.3911\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8322 - accuracy: 0.5287 - val_loss: 1.1959 - val_accuracy: 0.5022\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8034 - accuracy: 0.5444 - val_loss: 1.6633 - val_accuracy: 0.4467\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.5722 - val_loss: 1.4294 - val_accuracy: 0.5489\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.5653 - val_loss: 1.3018 - val_accuracy: 0.4578\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7439 - accuracy: 0.5514 - val_loss: 2.2027 - val_accuracy: 0.3556\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7203 - accuracy: 0.5898 - val_loss: 2.9240 - val_accuracy: 0.3511\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5926 - val_loss: 1.4294 - val_accuracy: 0.6067\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.6065 - val_loss: 1.2117 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.6120 - val_loss: 1.4205 - val_accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6148 - val_loss: 3.2011 - val_accuracy: 0.3578\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.6194 - val_loss: 1.4213 - val_accuracy: 0.5156\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6366 - val_loss: 1.4017 - val_accuracy: 0.6133\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6463 - val_loss: 1.2204 - val_accuracy: 0.6644\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6444 - val_loss: 4.2702 - val_accuracy: 0.3200\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6319 - val_loss: 1.5960 - val_accuracy: 0.6022\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.6583 - val_loss: 1.6015 - val_accuracy: 0.5578\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.6676 - val_loss: 2.4906 - val_accuracy: 0.4867\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6611 - val_loss: 3.7050 - val_accuracy: 0.3911\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.6852 - val_loss: 1.9574 - val_accuracy: 0.5778\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.6949 - val_loss: 2.0274 - val_accuracy: 0.5978\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7144 - val_loss: 1.5404 - val_accuracy: 0.6111\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.6875 - val_loss: 8.7560 - val_accuracy: 0.3533\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.6843 - val_loss: 3.2068 - val_accuracy: 0.4422\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7037 - val_loss: 5.2862 - val_accuracy: 0.3778\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7060 - val_loss: 4.9609 - val_accuracy: 0.4044\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7181 - val_loss: 1.5956 - val_accuracy: 0.6267\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7329 - val_loss: 2.2621 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7116 - val_loss: 7.5326 - val_accuracy: 0.3800\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7264 - val_loss: 2.5035 - val_accuracy: 0.5756\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7403 - val_loss: 5.7323 - val_accuracy: 0.4200\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7394 - val_loss: 6.8126 - val_accuracy: 0.3889\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7481 - val_loss: 3.5982 - val_accuracy: 0.4733\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7472 - val_loss: 3.4597 - val_accuracy: 0.5400\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7509 - val_loss: 3.1401 - val_accuracy: 0.5489\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7625 - val_loss: 2.6804 - val_accuracy: 0.5933\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7449 - val_loss: 2.4213 - val_accuracy: 0.5467\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7463 - val_loss: 3.3148 - val_accuracy: 0.4956\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7569 - val_loss: 5.9340 - val_accuracy: 0.4067\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7574 - val_loss: 2.4210 - val_accuracy: 0.5911\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.7796 - val_loss: 6.2465 - val_accuracy: 0.4089\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.7764 - val_loss: 2.6373 - val_accuracy: 0.6333\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.7833 - val_loss: 4.4811 - val_accuracy: 0.4956\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.7875 - val_loss: 14.3112 - val_accuracy: 0.3267\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7579 - val_loss: 4.8083 - val_accuracy: 0.5044\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.7704 - val_loss: 2.1398 - val_accuracy: 0.6356\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.7694 - val_loss: 2.4355 - val_accuracy: 0.6133\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.7917 - val_loss: 3.7254 - val_accuracy: 0.5022\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.7926 - val_loss: 3.1655 - val_accuracy: 0.5911\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.7889 - val_loss: 2.8153 - val_accuracy: 0.5844\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.7847 - val_loss: 8.5415 - val_accuracy: 0.4067\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.7829 - val_loss: 3.8001 - val_accuracy: 0.5489\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.7931 - val_loss: 3.7113 - val_accuracy: 0.5689\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.7815 - val_loss: 2.8652 - val_accuracy: 0.6089\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.7898 - val_loss: 5.3045 - val_accuracy: 0.4533\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8032 - val_loss: 5.5373 - val_accuracy: 0.4400\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.7773 - val_loss: 4.3239 - val_accuracy: 0.4867\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8005 - val_loss: 4.1321 - val_accuracy: 0.5378\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8162 - val_loss: 3.8329 - val_accuracy: 0.5911\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.7963 - val_loss: 3.4838 - val_accuracy: 0.5467\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8005 - val_loss: 3.3510 - val_accuracy: 0.6044\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8056 - val_loss: 2.6154 - val_accuracy: 0.6178\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8019 - val_loss: 6.9723 - val_accuracy: 0.4333\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8051 - val_loss: 6.4892 - val_accuracy: 0.4178\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8144 - val_loss: 3.5947 - val_accuracy: 0.5022\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8120 - val_loss: 3.7131 - val_accuracy: 0.5200\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8176 - val_loss: 3.7849 - val_accuracy: 0.5844\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8116 - val_loss: 13.0092 - val_accuracy: 0.3800\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8185 - val_loss: 3.0907 - val_accuracy: 0.6089\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8384 - val_loss: 4.7029 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8477 - val_loss: 6.3328 - val_accuracy: 0.5222\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8370 - val_loss: 4.7364 - val_accuracy: 0.6089\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.8514 - val_loss: 5.0922 - val_accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8444 - val_loss: 7.4205 - val_accuracy: 0.4244\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8630 - val_loss: 3.5984 - val_accuracy: 0.5600\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8602 - val_loss: 5.6515 - val_accuracy: 0.5156\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8718 - val_loss: 5.7684 - val_accuracy: 0.5644\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.8713 - val_loss: 5.2231 - val_accuracy: 0.5689\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.8639 - val_loss: 7.8419 - val_accuracy: 0.4178\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.8750 - val_loss: 4.5914 - val_accuracy: 0.6422\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8630 - val_loss: 6.6484 - val_accuracy: 0.6044\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.8667 - val_loss: 5.5316 - val_accuracy: 0.4889\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8833 - val_loss: 4.4399 - val_accuracy: 0.5844\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.8681 - val_loss: 4.2034 - val_accuracy: 0.5200\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.8639 - val_loss: 5.1697 - val_accuracy: 0.5778\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.8699 - val_loss: 5.1218 - val_accuracy: 0.5600\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.8685 - val_loss: 7.1523 - val_accuracy: 0.4889\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.8745 - val_loss: 12.0992 - val_accuracy: 0.3822\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.8685 - val_loss: 4.2809 - val_accuracy: 0.6089\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.8824 - val_loss: 7.1833 - val_accuracy: 0.4622\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.8796 - val_loss: 5.2915 - val_accuracy: 0.5711\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.8801 - val_loss: 9.2787 - val_accuracy: 0.5067\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_210 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_210 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_211 (Conv2D)          (None, 25, 25, 10)        2710      \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_211 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_105 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 128)               184448    \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 188,545\n",
      "Trainable params: 188,465\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2316 - accuracy: 0.4227 - val_loss: 1.0901 - val_accuracy: 0.3867\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.4963 - val_loss: 1.0695 - val_accuracy: 0.5200\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8651 - accuracy: 0.5352 - val_loss: 1.1055 - val_accuracy: 0.4378\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8043 - accuracy: 0.5722 - val_loss: 1.0446 - val_accuracy: 0.4867\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7651 - accuracy: 0.5903 - val_loss: 1.1939 - val_accuracy: 0.3756\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.6384 - val_loss: 1.1180 - val_accuracy: 0.4467\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.6431 - val_loss: 2.3618 - val_accuracy: 0.3800\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6342 - accuracy: 0.6843 - val_loss: 1.0582 - val_accuracy: 0.4356\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6819 - val_loss: 1.3572 - val_accuracy: 0.4844\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5465 - accuracy: 0.7176 - val_loss: 1.5321 - val_accuracy: 0.4933\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7171 - val_loss: 1.4589 - val_accuracy: 0.3733\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7208 - val_loss: 1.2519 - val_accuracy: 0.4667\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7380 - val_loss: 4.8909 - val_accuracy: 0.3378\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7500 - val_loss: 1.5678 - val_accuracy: 0.4867\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7625 - val_loss: 2.1764 - val_accuracy: 0.4644\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7676 - val_loss: 1.3357 - val_accuracy: 0.4400\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7690 - val_loss: 1.9812 - val_accuracy: 0.5733\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7875 - val_loss: 12.8310 - val_accuracy: 0.3311\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7810 - val_loss: 1.7342 - val_accuracy: 0.5156\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7912 - val_loss: 1.8671 - val_accuracy: 0.4867\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8194 - val_loss: 2.0918 - val_accuracy: 0.4644\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8106 - val_loss: 2.1570 - val_accuracy: 0.4644\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8162 - val_loss: 2.3284 - val_accuracy: 0.4489\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8306 - val_loss: 2.8412 - val_accuracy: 0.5044\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8380 - val_loss: 4.4819 - val_accuracy: 0.4089\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8380 - val_loss: 2.5776 - val_accuracy: 0.5022\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8282 - val_loss: 2.4064 - val_accuracy: 0.4133\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8426 - val_loss: 3.2475 - val_accuracy: 0.4022\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8394 - val_loss: 2.9260 - val_accuracy: 0.5289\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8472 - val_loss: 3.9667 - val_accuracy: 0.4200\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8245 - val_loss: 3.4412 - val_accuracy: 0.4111\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8606 - val_loss: 3.1143 - val_accuracy: 0.4489\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2882 - accuracy: 0.8676 - val_loss: 2.5514 - val_accuracy: 0.4911\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.8690 - val_loss: 4.1728 - val_accuracy: 0.4311\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2872 - accuracy: 0.8648 - val_loss: 6.1413 - val_accuracy: 0.4111\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8745 - val_loss: 4.0316 - val_accuracy: 0.4511\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.8889 - val_loss: 2.8975 - val_accuracy: 0.4978\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.8852 - val_loss: 3.3859 - val_accuracy: 0.5133\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.8759 - val_loss: 4.0530 - val_accuracy: 0.4356\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2340 - accuracy: 0.8907 - val_loss: 3.9732 - val_accuracy: 0.4667\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8810 - val_loss: 3.3708 - val_accuracy: 0.4289\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2344 - accuracy: 0.8898 - val_loss: 3.0888 - val_accuracy: 0.4356\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.8944 - val_loss: 3.4820 - val_accuracy: 0.4667\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.8944 - val_loss: 3.0148 - val_accuracy: 0.4556\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.8903 - val_loss: 4.4050 - val_accuracy: 0.4422\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.8894 - val_loss: 4.2348 - val_accuracy: 0.4867\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 0.9130 - val_loss: 7.5018 - val_accuracy: 0.3889\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9023 - val_loss: 6.1320 - val_accuracy: 0.4511\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9111 - val_loss: 5.3107 - val_accuracy: 0.4711\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9120 - val_loss: 4.2476 - val_accuracy: 0.5022\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.9069 - val_loss: 5.5598 - val_accuracy: 0.4400\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.9116 - val_loss: 4.7275 - val_accuracy: 0.4844\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9134 - val_loss: 4.0799 - val_accuracy: 0.5489\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1674 - accuracy: 0.9255 - val_loss: 4.2816 - val_accuracy: 0.4867\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9185 - val_loss: 5.7869 - val_accuracy: 0.5044\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9199 - val_loss: 4.9787 - val_accuracy: 0.4756\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9227 - val_loss: 5.4802 - val_accuracy: 0.4578\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1590 - accuracy: 0.9241 - val_loss: 5.4291 - val_accuracy: 0.4644\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9269 - val_loss: 5.2057 - val_accuracy: 0.5244\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9241 - val_loss: 7.2479 - val_accuracy: 0.4311\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9194 - val_loss: 4.5040 - val_accuracy: 0.4933\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1770 - accuracy: 0.9236 - val_loss: 4.3317 - val_accuracy: 0.4778\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9273 - val_loss: 5.8250 - val_accuracy: 0.5022\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9361 - val_loss: 5.2884 - val_accuracy: 0.4711\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9454 - val_loss: 6.4620 - val_accuracy: 0.5156\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9157 - val_loss: 4.1523 - val_accuracy: 0.5267\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9315 - val_loss: 4.9007 - val_accuracy: 0.5222\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9412 - val_loss: 5.4445 - val_accuracy: 0.4711\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9245 - val_loss: 3.8571 - val_accuracy: 0.5156\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9495 - val_loss: 5.2135 - val_accuracy: 0.5600\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9306 - val_loss: 10.5559 - val_accuracy: 0.3733\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9472 - val_loss: 5.3626 - val_accuracy: 0.4467\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9407 - val_loss: 5.5886 - val_accuracy: 0.5289\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9426 - val_loss: 11.2431 - val_accuracy: 0.3911\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9472 - val_loss: 5.6431 - val_accuracy: 0.4489\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9435 - val_loss: 5.0662 - val_accuracy: 0.5022\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1294 - accuracy: 0.9431 - val_loss: 6.4691 - val_accuracy: 0.4667\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9509 - val_loss: 8.7269 - val_accuracy: 0.4333\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9398 - val_loss: 7.4453 - val_accuracy: 0.5044\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9606 - val_loss: 6.6546 - val_accuracy: 0.4889\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9426 - val_loss: 7.0103 - val_accuracy: 0.4844\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9421 - val_loss: 6.8282 - val_accuracy: 0.4800\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9407 - val_loss: 7.9466 - val_accuracy: 0.4511\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9528 - val_loss: 6.3541 - val_accuracy: 0.4933\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9579 - val_loss: 10.0275 - val_accuracy: 0.4267\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9611 - val_loss: 7.6471 - val_accuracy: 0.4822\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9597 - val_loss: 8.2681 - val_accuracy: 0.4378\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9583 - val_loss: 9.5989 - val_accuracy: 0.5067\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9528 - val_loss: 7.2942 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9523 - val_loss: 9.0653 - val_accuracy: 0.4222\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1054 - accuracy: 0.9560 - val_loss: 7.5914 - val_accuracy: 0.4733\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9579 - val_loss: 8.2654 - val_accuracy: 0.4956\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9653 - val_loss: 6.6743 - val_accuracy: 0.5200\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9625 - val_loss: 6.2754 - val_accuracy: 0.4956\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9500 - val_loss: 7.0966 - val_accuracy: 0.4578\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9685 - val_loss: 10.6157 - val_accuracy: 0.5022\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9736 - val_loss: 10.7689 - val_accuracy: 0.4778\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9620 - val_loss: 6.6503 - val_accuracy: 0.4711\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9606 - val_loss: 7.5657 - val_accuracy: 0.4667\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9630 - val_loss: 7.7282 - val_accuracy: 0.5156\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_212 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_212 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_213 (Conv2D)          (None, 25, 25, 10)        2710      \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_213 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_106 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 256)               368896    \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 373,377\n",
      "Trainable params: 373,297\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.3197 - accuracy: 0.4597 - val_loss: 1.0853 - val_accuracy: 0.4489\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8504 - accuracy: 0.6000 - val_loss: 1.1001 - val_accuracy: 0.3467\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7486 - accuracy: 0.6574 - val_loss: 1.1405 - val_accuracy: 0.4022\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7051 - val_loss: 1.2810 - val_accuracy: 0.4956\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7509 - val_loss: 2.4433 - val_accuracy: 0.5267\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7741 - val_loss: 1.1818 - val_accuracy: 0.4644\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7903 - val_loss: 1.5490 - val_accuracy: 0.5400\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.8014 - val_loss: 4.2727 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8301 - val_loss: 3.3728 - val_accuracy: 0.4844\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8319 - val_loss: 5.1463 - val_accuracy: 0.3667\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8593 - val_loss: 2.6867 - val_accuracy: 0.4022\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8699 - val_loss: 4.5310 - val_accuracy: 0.4511\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8667 - val_loss: 3.0092 - val_accuracy: 0.4311\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.8884 - val_loss: 3.6715 - val_accuracy: 0.4422\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.8977 - val_loss: 2.6711 - val_accuracy: 0.5178\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8708 - val_loss: 8.9459 - val_accuracy: 0.3556\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.8815 - val_loss: 3.7141 - val_accuracy: 0.4200\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.9083 - val_loss: 6.7385 - val_accuracy: 0.4089\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9019 - val_loss: 4.3098 - val_accuracy: 0.4244\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.9093 - val_loss: 2.5331 - val_accuracy: 0.5022\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2059 - accuracy: 0.9181 - val_loss: 6.1488 - val_accuracy: 0.4289\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1908 - accuracy: 0.9213 - val_loss: 4.7419 - val_accuracy: 0.4467\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9273 - val_loss: 4.0055 - val_accuracy: 0.5489\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9292 - val_loss: 7.4975 - val_accuracy: 0.4222\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9167 - val_loss: 2.7770 - val_accuracy: 0.4644\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9347 - val_loss: 5.5328 - val_accuracy: 0.4667\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9319 - val_loss: 4.7067 - val_accuracy: 0.4356\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9375 - val_loss: 3.5890 - val_accuracy: 0.4911\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9519 - val_loss: 6.0799 - val_accuracy: 0.4244\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9384 - val_loss: 3.9213 - val_accuracy: 0.5400\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9463 - val_loss: 6.7906 - val_accuracy: 0.4422\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9435 - val_loss: 3.2919 - val_accuracy: 0.4422\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9495 - val_loss: 9.9158 - val_accuracy: 0.4289\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9468 - val_loss: 7.9600 - val_accuracy: 0.4578\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9481 - val_loss: 6.3217 - val_accuracy: 0.4867\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9486 - val_loss: 6.6628 - val_accuracy: 0.4400\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9588 - val_loss: 6.1925 - val_accuracy: 0.4756\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9574 - val_loss: 7.4609 - val_accuracy: 0.4467\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9648 - val_loss: 4.7335 - val_accuracy: 0.5200\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9537 - val_loss: 4.5212 - val_accuracy: 0.5022\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9537 - val_loss: 11.3849 - val_accuracy: 0.4356\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9588 - val_loss: 7.9129 - val_accuracy: 0.4556\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9662 - val_loss: 7.9443 - val_accuracy: 0.4889\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0858 - accuracy: 0.9676 - val_loss: 6.4577 - val_accuracy: 0.4600\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9653 - val_loss: 4.0033 - val_accuracy: 0.5489\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9565 - val_loss: 4.7673 - val_accuracy: 0.5111\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9708 - val_loss: 6.4866 - val_accuracy: 0.5022\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9731 - val_loss: 7.8825 - val_accuracy: 0.4311\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9616 - val_loss: 4.1981 - val_accuracy: 0.5400\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9606 - val_loss: 4.8228 - val_accuracy: 0.5467\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9708 - val_loss: 7.6071 - val_accuracy: 0.4378\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9708 - val_loss: 5.3472 - val_accuracy: 0.4956\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9648 - val_loss: 6.0179 - val_accuracy: 0.4844\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0879 - accuracy: 0.9681 - val_loss: 5.7124 - val_accuracy: 0.5044\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9667 - val_loss: 7.4205 - val_accuracy: 0.4778\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9755 - val_loss: 6.6641 - val_accuracy: 0.4489\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9727 - val_loss: 9.6952 - val_accuracy: 0.4578\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9736 - val_loss: 9.9998 - val_accuracy: 0.4511\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9690 - val_loss: 7.1496 - val_accuracy: 0.4800\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9769 - val_loss: 9.1831 - val_accuracy: 0.4556\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9625 - val_loss: 12.5910 - val_accuracy: 0.3867\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9759 - val_loss: 4.8558 - val_accuracy: 0.5778\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9741 - val_loss: 4.3226 - val_accuracy: 0.5578\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9722 - val_loss: 6.1635 - val_accuracy: 0.4911\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9787 - val_loss: 18.3291 - val_accuracy: 0.4378\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9750 - val_loss: 8.6698 - val_accuracy: 0.4644\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9750 - val_loss: 8.0736 - val_accuracy: 0.4533\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9713 - val_loss: 9.8872 - val_accuracy: 0.4711\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9792 - val_loss: 6.1184 - val_accuracy: 0.5089\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9750 - val_loss: 4.8306 - val_accuracy: 0.5644\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9769 - val_loss: 8.0801 - val_accuracy: 0.5133\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9806 - val_loss: 4.7185 - val_accuracy: 0.5622\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9778 - val_loss: 4.2257 - val_accuracy: 0.5533\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9764 - val_loss: 6.3140 - val_accuracy: 0.5311\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9736 - val_loss: 6.9039 - val_accuracy: 0.4378\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 9.8061 - val_accuracy: 0.4800\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9778 - val_loss: 10.1138 - val_accuracy: 0.4489\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9782 - val_loss: 8.1329 - val_accuracy: 0.4844\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9838 - val_loss: 8.9303 - val_accuracy: 0.5044\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9792 - val_loss: 7.6332 - val_accuracy: 0.5111\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 8.9549 - val_accuracy: 0.5178\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9773 - val_loss: 6.9151 - val_accuracy: 0.5644\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9796 - val_loss: 8.6843 - val_accuracy: 0.5689\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9824 - val_loss: 8.1276 - val_accuracy: 0.5067\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9861 - val_loss: 7.3957 - val_accuracy: 0.5822\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9778 - val_loss: 8.2131 - val_accuracy: 0.5133\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9815 - val_loss: 5.9727 - val_accuracy: 0.5578\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 10.0365 - val_accuracy: 0.4889\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 7.9870 - val_accuracy: 0.5467\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9769 - val_loss: 7.3656 - val_accuracy: 0.5156\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 11.6003 - val_accuracy: 0.4867\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 8.6218 - val_accuracy: 0.4844\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 9.8059 - val_accuracy: 0.4578\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 11.3160 - val_accuracy: 0.4756\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9870 - val_loss: 8.3569 - val_accuracy: 0.5200\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9866 - val_loss: 22.4515 - val_accuracy: 0.4333\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9875 - val_loss: 13.5376 - val_accuracy: 0.4556\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9861 - val_loss: 10.3024 - val_accuracy: 0.5111\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9856 - val_loss: 16.9115 - val_accuracy: 0.4400\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 12.7644 - val_accuracy: 0.4311\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_214 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_214 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_215 (Conv2D)          (None, 25, 25, 12)        3252      \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_215 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_107 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 32)                55328     \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 59,687\n",
      "Trainable params: 59,603\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1679 - accuracy: 0.3417 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0810 - accuracy: 0.3398 - val_loss: 1.0947 - val_accuracy: 0.3644\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0865 - accuracy: 0.3329 - val_loss: 1.1328 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0818 - accuracy: 0.3556 - val_loss: 1.0964 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0792 - accuracy: 0.3241 - val_loss: 1.0667 - val_accuracy: 0.3911\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0589 - accuracy: 0.3583 - val_loss: 1.0932 - val_accuracy: 0.3533\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0394 - accuracy: 0.3806 - val_loss: 1.0517 - val_accuracy: 0.3844\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0147 - accuracy: 0.3968 - val_loss: 1.1438 - val_accuracy: 0.4089\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0010 - accuracy: 0.4167 - val_loss: 1.2131 - val_accuracy: 0.3933\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.4306 - val_loss: 1.0743 - val_accuracy: 0.4911\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0047 - accuracy: 0.4329 - val_loss: 1.4816 - val_accuracy: 0.4178\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9968 - accuracy: 0.4329 - val_loss: 1.1896 - val_accuracy: 0.3578\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9757 - accuracy: 0.4426 - val_loss: 1.1183 - val_accuracy: 0.3778\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9811 - accuracy: 0.4329 - val_loss: 1.1600 - val_accuracy: 0.4978\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9621 - accuracy: 0.4426 - val_loss: 1.3042 - val_accuracy: 0.4800\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9435 - accuracy: 0.4565 - val_loss: 1.2240 - val_accuracy: 0.3844\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9448 - accuracy: 0.4574 - val_loss: 1.3069 - val_accuracy: 0.4111\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9451 - accuracy: 0.4606 - val_loss: 1.1353 - val_accuracy: 0.4111\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9393 - accuracy: 0.4718 - val_loss: 0.9951 - val_accuracy: 0.5200\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9443 - accuracy: 0.4685 - val_loss: 1.1655 - val_accuracy: 0.5044\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9298 - accuracy: 0.4731 - val_loss: 1.0373 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9377 - accuracy: 0.4671 - val_loss: 1.2766 - val_accuracy: 0.3933\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9138 - accuracy: 0.4810 - val_loss: 1.5274 - val_accuracy: 0.4467\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9252 - accuracy: 0.4870 - val_loss: 1.5617 - val_accuracy: 0.3511\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9072 - accuracy: 0.4903 - val_loss: 1.4735 - val_accuracy: 0.4933\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8952 - accuracy: 0.4981 - val_loss: 2.2881 - val_accuracy: 0.4644\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8710 - accuracy: 0.5190 - val_loss: 1.4882 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8833 - accuracy: 0.5222 - val_loss: 2.5046 - val_accuracy: 0.4244\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8807 - accuracy: 0.5106 - val_loss: 1.2643 - val_accuracy: 0.5200\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8791 - accuracy: 0.5194 - val_loss: 1.6628 - val_accuracy: 0.4822\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8844 - accuracy: 0.5282 - val_loss: 1.4519 - val_accuracy: 0.4667\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8547 - accuracy: 0.5292 - val_loss: 2.0673 - val_accuracy: 0.4200\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8351 - accuracy: 0.5528 - val_loss: 1.6012 - val_accuracy: 0.4756\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8170 - accuracy: 0.5537 - val_loss: 1.2922 - val_accuracy: 0.4644\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8144 - accuracy: 0.5616 - val_loss: 1.4085 - val_accuracy: 0.5133\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.5602 - val_loss: 1.4056 - val_accuracy: 0.4489\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.5731 - val_loss: 1.2700 - val_accuracy: 0.4356\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8013 - accuracy: 0.5583 - val_loss: 1.7765 - val_accuracy: 0.5022\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7920 - accuracy: 0.5671 - val_loss: 2.4261 - val_accuracy: 0.4867\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7850 - accuracy: 0.5736 - val_loss: 1.3256 - val_accuracy: 0.4489\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7743 - accuracy: 0.5778 - val_loss: 3.4026 - val_accuracy: 0.4111\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7476 - accuracy: 0.6056 - val_loss: 1.6784 - val_accuracy: 0.4289\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.5935 - val_loss: 1.3803 - val_accuracy: 0.4711\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7486 - accuracy: 0.5968 - val_loss: 2.6823 - val_accuracy: 0.4333\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.6069 - val_loss: 1.9605 - val_accuracy: 0.4844\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.5977 - val_loss: 2.5908 - val_accuracy: 0.3978\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 0.6130 - val_loss: 1.6244 - val_accuracy: 0.4711\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.6222 - val_loss: 1.7166 - val_accuracy: 0.4333\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.6282 - val_loss: 1.2333 - val_accuracy: 0.4511\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.6134 - val_loss: 3.1152 - val_accuracy: 0.4356\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7041 - accuracy: 0.6190 - val_loss: 2.3597 - val_accuracy: 0.4578\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.6125 - val_loss: 3.5628 - val_accuracy: 0.4067\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.6199 - val_loss: 1.6300 - val_accuracy: 0.4756\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.6269 - val_loss: 1.9282 - val_accuracy: 0.4600\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.6319 - val_loss: 1.9625 - val_accuracy: 0.4444\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6241 - val_loss: 1.8446 - val_accuracy: 0.4578\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6356 - val_loss: 3.4689 - val_accuracy: 0.3956\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6417 - val_loss: 2.1002 - val_accuracy: 0.4400\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.6505 - val_loss: 2.0932 - val_accuracy: 0.4044\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6477 - val_loss: 3.1216 - val_accuracy: 0.4400\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6625 - val_loss: 2.2382 - val_accuracy: 0.4333\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6361 - val_loss: 1.5661 - val_accuracy: 0.4911\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6616 - val_loss: 2.1080 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6667 - val_loss: 7.9784 - val_accuracy: 0.3867\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6551 - val_loss: 3.2688 - val_accuracy: 0.4356\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.6824 - val_loss: 2.5277 - val_accuracy: 0.3867\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6644 - val_loss: 2.6848 - val_accuracy: 0.4889\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6671 - val_loss: 1.8577 - val_accuracy: 0.4511\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6657 - val_loss: 4.3567 - val_accuracy: 0.4244\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6699 - val_loss: 3.5421 - val_accuracy: 0.4022\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6639 - val_loss: 1.6739 - val_accuracy: 0.4711\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6870 - val_loss: 2.2259 - val_accuracy: 0.5244\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6889 - val_loss: 3.4101 - val_accuracy: 0.4733\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.6792 - val_loss: 3.3084 - val_accuracy: 0.4133\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.6819 - val_loss: 3.3078 - val_accuracy: 0.4333\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6833 - val_loss: 4.6876 - val_accuracy: 0.3533\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.6875 - val_loss: 3.1001 - val_accuracy: 0.4689\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7074 - val_loss: 2.7906 - val_accuracy: 0.4533\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7042 - val_loss: 3.3301 - val_accuracy: 0.4356\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7005 - val_loss: 3.0393 - val_accuracy: 0.4489\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7069 - val_loss: 3.2263 - val_accuracy: 0.4467\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7310 - val_loss: 4.0076 - val_accuracy: 0.4444\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5279 - accuracy: 0.7324 - val_loss: 6.2869 - val_accuracy: 0.4000\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7171 - val_loss: 2.6290 - val_accuracy: 0.4711\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7162 - val_loss: 4.2781 - val_accuracy: 0.3889\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7171 - val_loss: 2.8237 - val_accuracy: 0.4778\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7204 - val_loss: 4.2051 - val_accuracy: 0.4800\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7282 - val_loss: 2.7189 - val_accuracy: 0.4200\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7403 - val_loss: 11.2414 - val_accuracy: 0.3578\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7384 - val_loss: 3.5966 - val_accuracy: 0.4667\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7449 - val_loss: 3.1018 - val_accuracy: 0.4933\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7426 - val_loss: 5.0677 - val_accuracy: 0.4444\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7417 - val_loss: 4.3127 - val_accuracy: 0.4978\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7412 - val_loss: 3.0525 - val_accuracy: 0.4422\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7542 - val_loss: 2.2133 - val_accuracy: 0.4956\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7500 - val_loss: 4.4601 - val_accuracy: 0.4600\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7602 - val_loss: 3.1643 - val_accuracy: 0.5200\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7565 - val_loss: 3.1193 - val_accuracy: 0.4756\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7875 - val_loss: 9.7104 - val_accuracy: 0.3667\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7477 - val_loss: 5.3414 - val_accuracy: 0.4289\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_216 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_216 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_217 (Conv2D)          (None, 25, 25, 12)        3252      \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_217 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_108 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 115,111\n",
      "Trainable params: 115,027\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2150 - accuracy: 0.3606 - val_loss: 1.0961 - val_accuracy: 0.3622\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0664 - accuracy: 0.3778 - val_loss: 1.0983 - val_accuracy: 0.3778\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0181 - accuracy: 0.4204 - val_loss: 1.0844 - val_accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.4218 - val_loss: 1.0821 - val_accuracy: 0.4356\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9856 - accuracy: 0.4380 - val_loss: 1.0637 - val_accuracy: 0.4022\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9513 - accuracy: 0.4699 - val_loss: 1.1062 - val_accuracy: 0.3867\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9596 - accuracy: 0.4602 - val_loss: 1.0794 - val_accuracy: 0.4222\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9218 - accuracy: 0.4866 - val_loss: 1.1248 - val_accuracy: 0.4356\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9190 - accuracy: 0.4968 - val_loss: 1.2287 - val_accuracy: 0.3667\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.5051 - val_loss: 1.2472 - val_accuracy: 0.4556\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8998 - accuracy: 0.5139 - val_loss: 1.1152 - val_accuracy: 0.4356\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8948 - accuracy: 0.5162 - val_loss: 1.3299 - val_accuracy: 0.4467\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8795 - accuracy: 0.5431 - val_loss: 1.2941 - val_accuracy: 0.4467\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8592 - accuracy: 0.5491 - val_loss: 1.9162 - val_accuracy: 0.5133\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8542 - accuracy: 0.5583 - val_loss: 1.1116 - val_accuracy: 0.3467\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8744 - accuracy: 0.5435 - val_loss: 1.8119 - val_accuracy: 0.5067\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8225 - accuracy: 0.5741 - val_loss: 1.1735 - val_accuracy: 0.4933\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8111 - accuracy: 0.5843 - val_loss: 1.6031 - val_accuracy: 0.3978\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7998 - accuracy: 0.6051 - val_loss: 1.3805 - val_accuracy: 0.4556\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7680 - accuracy: 0.6176 - val_loss: 1.3416 - val_accuracy: 0.4289\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7587 - accuracy: 0.6333 - val_loss: 1.7651 - val_accuracy: 0.3733\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.6259 - val_loss: 1.5124 - val_accuracy: 0.4533\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.6440 - val_loss: 1.1177 - val_accuracy: 0.5600\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7100 - accuracy: 0.6602 - val_loss: 3.1961 - val_accuracy: 0.3822\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7014 - accuracy: 0.6620 - val_loss: 1.6377 - val_accuracy: 0.5067\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6939 - accuracy: 0.6546 - val_loss: 1.7056 - val_accuracy: 0.4156\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6750 - val_loss: 2.3878 - val_accuracy: 0.4089\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6819 - val_loss: 1.1041 - val_accuracy: 0.4622\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.6657 - val_loss: 4.2101 - val_accuracy: 0.4356\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.6639 - val_loss: 2.2630 - val_accuracy: 0.4578\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6981 - val_loss: 2.5381 - val_accuracy: 0.4911\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6935 - val_loss: 1.9431 - val_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6750 - val_loss: 1.5689 - val_accuracy: 0.4378\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6921 - val_loss: 1.2698 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6935 - val_loss: 3.4436 - val_accuracy: 0.4689\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7093 - val_loss: 2.1958 - val_accuracy: 0.4800\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7097 - val_loss: 1.5504 - val_accuracy: 0.4978\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7065 - val_loss: 2.4051 - val_accuracy: 0.5133\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5515 - accuracy: 0.7315 - val_loss: 2.6995 - val_accuracy: 0.5200\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7245 - val_loss: 3.5591 - val_accuracy: 0.4911\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7250 - val_loss: 2.3744 - val_accuracy: 0.4600\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7255 - val_loss: 1.5344 - val_accuracy: 0.4800\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7310 - val_loss: 2.8657 - val_accuracy: 0.3978\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7426 - val_loss: 3.2394 - val_accuracy: 0.4711\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7537 - val_loss: 2.0825 - val_accuracy: 0.5844\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7639 - val_loss: 3.4589 - val_accuracy: 0.4756\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7560 - val_loss: 2.4855 - val_accuracy: 0.4311\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7699 - val_loss: 3.4680 - val_accuracy: 0.4600\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7690 - val_loss: 4.4043 - val_accuracy: 0.4822\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7759 - val_loss: 2.0105 - val_accuracy: 0.3556\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7750 - val_loss: 3.2461 - val_accuracy: 0.5356\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7889 - val_loss: 2.9502 - val_accuracy: 0.4533\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7963 - val_loss: 3.9625 - val_accuracy: 0.5111\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8019 - val_loss: 4.3271 - val_accuracy: 0.5467\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7958 - val_loss: 3.5250 - val_accuracy: 0.5400\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8023 - val_loss: 3.0641 - val_accuracy: 0.5644\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8046 - val_loss: 5.6490 - val_accuracy: 0.4711\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8037 - val_loss: 3.6271 - val_accuracy: 0.4822\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8014 - val_loss: 2.9314 - val_accuracy: 0.4622\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7968 - val_loss: 2.9358 - val_accuracy: 0.4622\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7954 - val_loss: 5.9598 - val_accuracy: 0.4689\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8139 - val_loss: 9.4731 - val_accuracy: 0.3800\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8139 - val_loss: 3.4917 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8097 - val_loss: 3.3432 - val_accuracy: 0.5356\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8250 - val_loss: 4.6011 - val_accuracy: 0.4889\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8315 - val_loss: 4.8952 - val_accuracy: 0.5044\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8287 - val_loss: 4.6729 - val_accuracy: 0.4467\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8120 - val_loss: 6.4560 - val_accuracy: 0.4600\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8255 - val_loss: 5.4650 - val_accuracy: 0.4778\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3664 - accuracy: 0.8269 - val_loss: 4.5322 - val_accuracy: 0.5756\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8338 - val_loss: 5.4628 - val_accuracy: 0.5533\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8347 - val_loss: 4.3262 - val_accuracy: 0.4889\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8199 - val_loss: 8.4233 - val_accuracy: 0.4711\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8287 - val_loss: 3.8550 - val_accuracy: 0.4778\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8370 - val_loss: 3.7422 - val_accuracy: 0.5244\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8282 - val_loss: 6.6643 - val_accuracy: 0.4800\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8375 - val_loss: 7.3246 - val_accuracy: 0.5378\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8324 - val_loss: 3.7208 - val_accuracy: 0.4733\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8389 - val_loss: 4.8322 - val_accuracy: 0.4200\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8287 - val_loss: 5.0155 - val_accuracy: 0.5089\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8412 - val_loss: 5.7223 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8384 - val_loss: 5.0708 - val_accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8366 - val_loss: 4.5750 - val_accuracy: 0.4556\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.8454 - val_loss: 9.1107 - val_accuracy: 0.4133\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8389 - val_loss: 3.9473 - val_accuracy: 0.5178\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8431 - val_loss: 4.7935 - val_accuracy: 0.5622\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.8514 - val_loss: 4.8591 - val_accuracy: 0.4956\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8519 - val_loss: 4.3445 - val_accuracy: 0.5044\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8551 - val_loss: 4.6324 - val_accuracy: 0.4822\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.8519 - val_loss: 11.5976 - val_accuracy: 0.4711\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8620 - val_loss: 6.7172 - val_accuracy: 0.5133\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.8481 - val_loss: 6.0918 - val_accuracy: 0.5022\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8644 - val_loss: 5.5056 - val_accuracy: 0.5200\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8579 - val_loss: 9.3571 - val_accuracy: 0.4711\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.8634 - val_loss: 5.2867 - val_accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.8755 - val_loss: 8.6862 - val_accuracy: 0.5356\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.8704 - val_loss: 5.9453 - val_accuracy: 0.5400\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.8694 - val_loss: 7.2026 - val_accuracy: 0.5111\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8704 - val_loss: 3.1436 - val_accuracy: 0.5378\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8731 - val_loss: 6.8655 - val_accuracy: 0.5067\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_218 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_218 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_219 (Conv2D)          (None, 25, 25, 12)        3252      \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_219 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_109 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 225,959\n",
      "Trainable params: 225,875\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2181 - accuracy: 0.4282 - val_loss: 1.1018 - val_accuracy: 0.3356\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9384 - accuracy: 0.5060 - val_loss: 1.1026 - val_accuracy: 0.4711\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8452 - accuracy: 0.5750 - val_loss: 1.0356 - val_accuracy: 0.4022\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7841 - accuracy: 0.6046 - val_loss: 0.9779 - val_accuracy: 0.5889\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.6412 - val_loss: 1.1221 - val_accuracy: 0.4511\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6653 - val_loss: 1.3557 - val_accuracy: 0.5200\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6898 - val_loss: 1.1309 - val_accuracy: 0.6022\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7153 - val_loss: 1.3068 - val_accuracy: 0.5178\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7329 - val_loss: 2.0406 - val_accuracy: 0.5444\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7440 - val_loss: 1.9753 - val_accuracy: 0.4089\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7394 - val_loss: 2.1343 - val_accuracy: 0.4800\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7394 - val_loss: 1.7377 - val_accuracy: 0.4800\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7764 - val_loss: 2.0037 - val_accuracy: 0.4511\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7671 - val_loss: 2.2397 - val_accuracy: 0.4022\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4409 - accuracy: 0.7833 - val_loss: 2.1023 - val_accuracy: 0.4800\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7764 - val_loss: 2.4607 - val_accuracy: 0.4778\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7931 - val_loss: 3.9716 - val_accuracy: 0.4311\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.7926 - val_loss: 3.2369 - val_accuracy: 0.3978\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8028 - val_loss: 3.1240 - val_accuracy: 0.4533\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8111 - val_loss: 2.2145 - val_accuracy: 0.5067\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8097 - val_loss: 3.7310 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8102 - val_loss: 3.5106 - val_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8111 - val_loss: 4.9770 - val_accuracy: 0.4022\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8167 - val_loss: 3.3194 - val_accuracy: 0.4356\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8236 - val_loss: 2.3119 - val_accuracy: 0.4244\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8347 - val_loss: 2.6175 - val_accuracy: 0.4422\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8255 - val_loss: 4.3456 - val_accuracy: 0.3933\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8343 - val_loss: 3.1264 - val_accuracy: 0.4289\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8468 - val_loss: 3.4988 - val_accuracy: 0.4844\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8519 - val_loss: 12.3995 - val_accuracy: 0.3311\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3130 - accuracy: 0.8495 - val_loss: 2.9298 - val_accuracy: 0.4578\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8495 - val_loss: 4.0407 - val_accuracy: 0.4422\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8551 - val_loss: 4.7275 - val_accuracy: 0.4467\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8602 - val_loss: 4.1365 - val_accuracy: 0.4444\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8657 - val_loss: 3.4465 - val_accuracy: 0.5067\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.8704 - val_loss: 4.3474 - val_accuracy: 0.4333\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.8801 - val_loss: 7.8828 - val_accuracy: 0.3733\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.8708 - val_loss: 4.4448 - val_accuracy: 0.5178\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.8745 - val_loss: 3.8803 - val_accuracy: 0.5111\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 2.6909 - val_accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.8843 - val_loss: 3.5570 - val_accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.8782 - val_loss: 7.3692 - val_accuracy: 0.4556\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.8866 - val_loss: 3.9030 - val_accuracy: 0.5244\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8806 - val_loss: 4.6159 - val_accuracy: 0.4867\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2142 - accuracy: 0.9009 - val_loss: 6.7168 - val_accuracy: 0.4578\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.8903 - val_loss: 2.9320 - val_accuracy: 0.4889\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9019 - val_loss: 7.7406 - val_accuracy: 0.4156\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.9083 - val_loss: 3.6461 - val_accuracy: 0.5489\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.8894 - val_loss: 7.1201 - val_accuracy: 0.4267\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9125 - val_loss: 5.8324 - val_accuracy: 0.5267\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2082 - accuracy: 0.9005 - val_loss: 4.4926 - val_accuracy: 0.5444\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.8991 - val_loss: 3.0569 - val_accuracy: 0.6156\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9019 - val_loss: 6.4333 - val_accuracy: 0.4333\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.8935 - val_loss: 8.5781 - val_accuracy: 0.4600\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1908 - accuracy: 0.9106 - val_loss: 6.2732 - val_accuracy: 0.4978\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9167 - val_loss: 7.1638 - val_accuracy: 0.4400\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9208 - val_loss: 6.0594 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9120 - val_loss: 9.3106 - val_accuracy: 0.4444\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9213 - val_loss: 5.7317 - val_accuracy: 0.5178\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9181 - val_loss: 7.4925 - val_accuracy: 0.3956\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1685 - accuracy: 0.9204 - val_loss: 5.6933 - val_accuracy: 0.4622\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9227 - val_loss: 9.3080 - val_accuracy: 0.4156\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9264 - val_loss: 9.7139 - val_accuracy: 0.3600\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9218 - val_loss: 9.0164 - val_accuracy: 0.3267\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9204 - val_loss: 5.2839 - val_accuracy: 0.5222\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9338 - val_loss: 4.2438 - val_accuracy: 0.6356\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9245 - val_loss: 6.5976 - val_accuracy: 0.4578\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9315 - val_loss: 7.1644 - val_accuracy: 0.4867\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9329 - val_loss: 7.0779 - val_accuracy: 0.5267\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9347 - val_loss: 5.8451 - val_accuracy: 0.4956\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9403 - val_loss: 8.2754 - val_accuracy: 0.4889\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9329 - val_loss: 5.5443 - val_accuracy: 0.5800\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9352 - val_loss: 4.5540 - val_accuracy: 0.6444\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9495 - val_loss: 6.3933 - val_accuracy: 0.4778\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9417 - val_loss: 4.8541 - val_accuracy: 0.5933\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9481 - val_loss: 13.3888 - val_accuracy: 0.3778\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.9417 - val_loss: 8.7385 - val_accuracy: 0.4400\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9468 - val_loss: 12.2834 - val_accuracy: 0.3756\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9347 - val_loss: 7.0905 - val_accuracy: 0.5178\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9403 - val_loss: 9.1217 - val_accuracy: 0.4267\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9412 - val_loss: 5.6446 - val_accuracy: 0.6444\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9505 - val_loss: 7.4234 - val_accuracy: 0.5444\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9468 - val_loss: 9.2401 - val_accuracy: 0.5111\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9519 - val_loss: 12.4457 - val_accuracy: 0.3933\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.9384 - val_loss: 6.5871 - val_accuracy: 0.5222\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9505 - val_loss: 18.1235 - val_accuracy: 0.4178\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9481 - val_loss: 8.6484 - val_accuracy: 0.4778\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9546 - val_loss: 9.4640 - val_accuracy: 0.5044\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9528 - val_loss: 6.0011 - val_accuracy: 0.5467\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9579 - val_loss: 8.4527 - val_accuracy: 0.4933\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9486 - val_loss: 8.4937 - val_accuracy: 0.4778\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9546 - val_loss: 9.3580 - val_accuracy: 0.5022\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9509 - val_loss: 19.2303 - val_accuracy: 0.3200\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9495 - val_loss: 8.9212 - val_accuracy: 0.4511\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9556 - val_loss: 6.6918 - val_accuracy: 0.5867\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9574 - val_loss: 9.7163 - val_accuracy: 0.4711\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9565 - val_loss: 10.6068 - val_accuracy: 0.4822\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9569 - val_loss: 10.7254 - val_accuracy: 0.4800\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9509 - val_loss: 8.5935 - val_accuracy: 0.4622\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9597 - val_loss: 9.5927 - val_accuracy: 0.4800\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_220 (Conv2D)          (None, 54, 54, 30)        840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 54, 54, 30)        120       \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 54, 54, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_220 (MaxPoolin (None, 27, 27, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_221 (Conv2D)          (None, 25, 25, 12)        3252      \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_221 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_110 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 256)               442624    \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 447,655\n",
      "Trainable params: 447,571\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.4573 - accuracy: 0.4472 - val_loss: 1.0905 - val_accuracy: 0.4822\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8927 - accuracy: 0.5606 - val_loss: 1.1068 - val_accuracy: 0.4822\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8049 - accuracy: 0.6051 - val_loss: 1.1309 - val_accuracy: 0.3400\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.6764 - val_loss: 1.1026 - val_accuracy: 0.5067\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6949 - val_loss: 0.8984 - val_accuracy: 0.6044\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7236 - val_loss: 1.2534 - val_accuracy: 0.4889\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7500 - val_loss: 0.9679 - val_accuracy: 0.5622\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7907 - val_loss: 1.8533 - val_accuracy: 0.4422\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8005 - val_loss: 1.9549 - val_accuracy: 0.4267\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.8056 - val_loss: 1.4486 - val_accuracy: 0.5111\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8144 - val_loss: 1.5743 - val_accuracy: 0.4867\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8352 - val_loss: 1.4418 - val_accuracy: 0.5133\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8551 - val_loss: 2.8012 - val_accuracy: 0.4422\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8588 - val_loss: 1.8997 - val_accuracy: 0.4978\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8694 - val_loss: 4.0105 - val_accuracy: 0.3867\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.8866 - val_loss: 3.5461 - val_accuracy: 0.4467\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8676 - val_loss: 1.5874 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8856 - val_loss: 1.9307 - val_accuracy: 0.5378\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2339 - accuracy: 0.8954 - val_loss: 5.9617 - val_accuracy: 0.4200\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.8991 - val_loss: 3.8349 - val_accuracy: 0.4556\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2197 - accuracy: 0.9028 - val_loss: 1.9058 - val_accuracy: 0.5556\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9088 - val_loss: 1.8886 - val_accuracy: 0.5733\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9079 - val_loss: 3.4863 - val_accuracy: 0.5200\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9167 - val_loss: 5.2311 - val_accuracy: 0.4289\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.9181 - val_loss: 3.0489 - val_accuracy: 0.5267\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1962 - accuracy: 0.9153 - val_loss: 3.2947 - val_accuracy: 0.5933\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9250 - val_loss: 4.0367 - val_accuracy: 0.4800\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9208 - val_loss: 2.4247 - val_accuracy: 0.5156\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9324 - val_loss: 2.9482 - val_accuracy: 0.6067\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1419 - accuracy: 0.9370 - val_loss: 3.8716 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9435 - val_loss: 3.3890 - val_accuracy: 0.5844\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9366 - val_loss: 2.9091 - val_accuracy: 0.5533\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9426 - val_loss: 5.5794 - val_accuracy: 0.4778\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9310 - val_loss: 3.2459 - val_accuracy: 0.5622\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9366 - val_loss: 2.9437 - val_accuracy: 0.5156\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9551 - val_loss: 3.6249 - val_accuracy: 0.5578\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9523 - val_loss: 3.9663 - val_accuracy: 0.5311\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9509 - val_loss: 3.4045 - val_accuracy: 0.5622\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9486 - val_loss: 8.3676 - val_accuracy: 0.4044\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9505 - val_loss: 5.3037 - val_accuracy: 0.4800\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9523 - val_loss: 5.6678 - val_accuracy: 0.4467\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9500 - val_loss: 2.8644 - val_accuracy: 0.5578\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9583 - val_loss: 13.2153 - val_accuracy: 0.3489\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9468 - val_loss: 8.2887 - val_accuracy: 0.4622\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9593 - val_loss: 6.0690 - val_accuracy: 0.4689\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9454 - val_loss: 9.7792 - val_accuracy: 0.4356\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0879 - accuracy: 0.9648 - val_loss: 6.2608 - val_accuracy: 0.5156\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9690 - val_loss: 7.8458 - val_accuracy: 0.4578\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9602 - val_loss: 4.0298 - val_accuracy: 0.5489\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9602 - val_loss: 7.6342 - val_accuracy: 0.4733\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9560 - val_loss: 4.4399 - val_accuracy: 0.5289\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9708 - val_loss: 7.7136 - val_accuracy: 0.4400\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9653 - val_loss: 6.1522 - val_accuracy: 0.4956\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9690 - val_loss: 8.1841 - val_accuracy: 0.4200\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9699 - val_loss: 13.4662 - val_accuracy: 0.3200\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9750 - val_loss: 8.2587 - val_accuracy: 0.5311\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9625 - val_loss: 4.7069 - val_accuracy: 0.5644\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9718 - val_loss: 5.2429 - val_accuracy: 0.5511\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0629 - accuracy: 0.9769 - val_loss: 6.4918 - val_accuracy: 0.5133\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9727 - val_loss: 5.6134 - val_accuracy: 0.4889\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 5.9880 - val_accuracy: 0.5622\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 5.9634 - val_accuracy: 0.5556\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9773 - val_loss: 9.1198 - val_accuracy: 0.4911\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9764 - val_loss: 8.0233 - val_accuracy: 0.4711\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9796 - val_loss: 10.3077 - val_accuracy: 0.3444\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9708 - val_loss: 5.0364 - val_accuracy: 0.5844\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9690 - val_loss: 6.9569 - val_accuracy: 0.5644\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9769 - val_loss: 12.9674 - val_accuracy: 0.3889\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9745 - val_loss: 8.4157 - val_accuracy: 0.4533\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9718 - val_loss: 6.6885 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9819 - val_loss: 18.0068 - val_accuracy: 0.3711\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9815 - val_loss: 10.1218 - val_accuracy: 0.5022\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9806 - val_loss: 8.5130 - val_accuracy: 0.5311\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9708 - val_loss: 4.5369 - val_accuracy: 0.5200\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9755 - val_loss: 7.2376 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 5.4284 - val_accuracy: 0.5778\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9792 - val_loss: 7.3733 - val_accuracy: 0.4978\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9769 - val_loss: 8.6401 - val_accuracy: 0.4800\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9819 - val_loss: 9.4933 - val_accuracy: 0.4578\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9773 - val_loss: 7.7992 - val_accuracy: 0.4333\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9838 - val_loss: 10.7450 - val_accuracy: 0.4800\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 5.7121 - val_accuracy: 0.6022\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9815 - val_loss: 8.8845 - val_accuracy: 0.4311\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9824 - val_loss: 6.8920 - val_accuracy: 0.4911\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9833 - val_loss: 23.7393 - val_accuracy: 0.3244\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 6.8850 - val_accuracy: 0.5244\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9806 - val_loss: 9.0603 - val_accuracy: 0.4400\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9824 - val_loss: 8.0600 - val_accuracy: 0.4911\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 7.0327 - val_accuracy: 0.5378\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9866 - val_loss: 8.6041 - val_accuracy: 0.5467\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9880 - val_loss: 9.3591 - val_accuracy: 0.5267\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9819 - val_loss: 7.9167 - val_accuracy: 0.5156\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 8.4725 - val_accuracy: 0.5089\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9819 - val_loss: 8.1939 - val_accuracy: 0.5111\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9778 - val_loss: 7.2974 - val_accuracy: 0.5644\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 10.3977 - val_accuracy: 0.4822\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 9.8088 - val_accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 16.3109 - val_accuracy: 0.4400\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9866 - val_loss: 18.7869 - val_accuracy: 0.3556\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9838 - val_loss: 13.4338 - val_accuracy: 0.4822\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_222 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_222 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_223 (Conv2D)          (None, 25, 25, 8)         2384      \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_219 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_223 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_111 (Flatten)        (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 40,467\n",
      "Trainable params: 40,385\n",
      "Non-trainable params: 82\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1726 - accuracy: 0.3565 - val_loss: 1.1081 - val_accuracy: 0.3933\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0455 - accuracy: 0.3981 - val_loss: 1.1018 - val_accuracy: 0.4467\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0181 - accuracy: 0.4255 - val_loss: 1.0999 - val_accuracy: 0.4511\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9895 - accuracy: 0.4370 - val_loss: 1.2138 - val_accuracy: 0.5133\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9706 - accuracy: 0.4574 - val_loss: 1.3063 - val_accuracy: 0.5133\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9489 - accuracy: 0.4801 - val_loss: 1.6436 - val_accuracy: 0.4333\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9399 - accuracy: 0.4648 - val_loss: 1.6190 - val_accuracy: 0.4911\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9327 - accuracy: 0.4759 - val_loss: 1.5981 - val_accuracy: 0.4867\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9156 - accuracy: 0.4856 - val_loss: 1.4998 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9197 - accuracy: 0.4898 - val_loss: 1.8825 - val_accuracy: 0.5044\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9059 - accuracy: 0.4944 - val_loss: 1.6745 - val_accuracy: 0.4911\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8806 - accuracy: 0.5227 - val_loss: 1.8547 - val_accuracy: 0.5267\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8849 - accuracy: 0.5167 - val_loss: 1.4976 - val_accuracy: 0.5089\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8778 - accuracy: 0.5157 - val_loss: 2.2079 - val_accuracy: 0.4422\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8808 - accuracy: 0.5190 - val_loss: 1.6962 - val_accuracy: 0.4511\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8423 - accuracy: 0.5394 - val_loss: 2.1266 - val_accuracy: 0.4489\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8330 - accuracy: 0.5417 - val_loss: 3.7760 - val_accuracy: 0.3844\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8441 - accuracy: 0.5361 - val_loss: 2.2436 - val_accuracy: 0.4400\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8209 - accuracy: 0.5537 - val_loss: 1.4378 - val_accuracy: 0.5311\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8004 - accuracy: 0.5597 - val_loss: 1.6420 - val_accuracy: 0.4933\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8181 - accuracy: 0.5542 - val_loss: 1.3888 - val_accuracy: 0.5244\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8128 - accuracy: 0.5537 - val_loss: 1.8007 - val_accuracy: 0.4356\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7815 - accuracy: 0.5829 - val_loss: 2.6999 - val_accuracy: 0.4356\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7915 - accuracy: 0.5764 - val_loss: 2.6628 - val_accuracy: 0.4511\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.5764 - val_loss: 3.7807 - val_accuracy: 0.4467\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.5852 - val_loss: 2.0954 - val_accuracy: 0.4822\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.5731 - val_loss: 1.7336 - val_accuracy: 0.4933\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7711 - accuracy: 0.5833 - val_loss: 5.8765 - val_accuracy: 0.3600\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7593 - accuracy: 0.5866 - val_loss: 1.9582 - val_accuracy: 0.4600\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7279 - accuracy: 0.6000 - val_loss: 2.5465 - val_accuracy: 0.4156\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.6069 - val_loss: 6.2981 - val_accuracy: 0.3511\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7041 - accuracy: 0.6236 - val_loss: 1.5200 - val_accuracy: 0.4756\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.6236 - val_loss: 1.8445 - val_accuracy: 0.4422\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.6204 - val_loss: 4.5206 - val_accuracy: 0.4044\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.6458 - val_loss: 2.6776 - val_accuracy: 0.4889\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.6361 - val_loss: 2.1061 - val_accuracy: 0.4711\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.6296 - val_loss: 2.9849 - val_accuracy: 0.4622\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.6532 - val_loss: 3.0464 - val_accuracy: 0.5178\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6495 - val_loss: 3.5397 - val_accuracy: 0.4133\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6579 - val_loss: 5.0671 - val_accuracy: 0.4200\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6444 - val_loss: 6.7523 - val_accuracy: 0.4356\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6537 - val_loss: 6.0516 - val_accuracy: 0.4422\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6653 - val_loss: 3.5515 - val_accuracy: 0.4489\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.6759 - val_loss: 3.5041 - val_accuracy: 0.4667\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6741 - val_loss: 3.8590 - val_accuracy: 0.4978\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6671 - val_loss: 5.5373 - val_accuracy: 0.4400\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.6778 - val_loss: 6.1683 - val_accuracy: 0.4156\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6782 - val_loss: 3.8857 - val_accuracy: 0.4333\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6699 - val_loss: 2.6692 - val_accuracy: 0.5156\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6875 - val_loss: 3.2326 - val_accuracy: 0.4467\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7120 - val_loss: 5.3908 - val_accuracy: 0.4200\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.6736 - val_loss: 3.3679 - val_accuracy: 0.5378\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6903 - val_loss: 3.8581 - val_accuracy: 0.4600\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6782 - val_loss: 3.7999 - val_accuracy: 0.4267\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6884 - val_loss: 5.6151 - val_accuracy: 0.4200\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6935 - val_loss: 5.2771 - val_accuracy: 0.4467\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6870 - val_loss: 9.2564 - val_accuracy: 0.3822\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7065 - val_loss: 5.8373 - val_accuracy: 0.4644\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7176 - val_loss: 6.1896 - val_accuracy: 0.4600\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7181 - val_loss: 11.2615 - val_accuracy: 0.3578\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7139 - val_loss: 5.0822 - val_accuracy: 0.4133\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.7046 - val_loss: 7.6061 - val_accuracy: 0.4244\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5448 - accuracy: 0.7218 - val_loss: 5.4796 - val_accuracy: 0.4489\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7463 - val_loss: 6.2611 - val_accuracy: 0.4600\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7162 - val_loss: 7.9622 - val_accuracy: 0.4156\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7144 - val_loss: 4.0529 - val_accuracy: 0.4822\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7315 - val_loss: 5.4299 - val_accuracy: 0.4689\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7236 - val_loss: 5.9167 - val_accuracy: 0.4822\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7255 - val_loss: 4.9491 - val_accuracy: 0.5356\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7292 - val_loss: 7.6894 - val_accuracy: 0.4378\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7486 - val_loss: 5.5714 - val_accuracy: 0.4356\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7269 - val_loss: 7.1541 - val_accuracy: 0.4711\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7310 - val_loss: 7.0205 - val_accuracy: 0.4911\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7542 - val_loss: 7.1038 - val_accuracy: 0.4933\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7477 - val_loss: 9.0753 - val_accuracy: 0.4533\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7565 - val_loss: 16.7196 - val_accuracy: 0.3467\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7528 - val_loss: 6.4005 - val_accuracy: 0.4200\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7477 - val_loss: 7.2284 - val_accuracy: 0.4644\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7597 - val_loss: 7.5133 - val_accuracy: 0.4644\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7491 - val_loss: 6.3852 - val_accuracy: 0.4578\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7505 - val_loss: 7.3952 - val_accuracy: 0.4644\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7449 - val_loss: 5.7162 - val_accuracy: 0.4600\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7579 - val_loss: 6.8612 - val_accuracy: 0.5489\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7583 - val_loss: 5.0458 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7509 - val_loss: 5.8677 - val_accuracy: 0.4867\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7523 - val_loss: 9.0163 - val_accuracy: 0.5133\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7542 - val_loss: 7.2469 - val_accuracy: 0.4844\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7699 - val_loss: 6.2011 - val_accuracy: 0.5022\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7481 - val_loss: 6.6379 - val_accuracy: 0.5200\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7667 - val_loss: 7.2415 - val_accuracy: 0.5178\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7546 - val_loss: 9.0284 - val_accuracy: 0.4867\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7630 - val_loss: 8.1329 - val_accuracy: 0.4933\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7750 - val_loss: 6.2780 - val_accuracy: 0.5044\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7667 - val_loss: 7.3486 - val_accuracy: 0.5422\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7616 - val_loss: 6.5431 - val_accuracy: 0.5422\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7755 - val_loss: 5.4849 - val_accuracy: 0.5533\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7704 - val_loss: 12.0918 - val_accuracy: 0.4356\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7769 - val_loss: 6.1107 - val_accuracy: 0.5511\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7727 - val_loss: 6.1398 - val_accuracy: 0.5200\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7949 - val_loss: 5.9210 - val_accuracy: 0.4933\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_224 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_220 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_224 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_225 (Conv2D)          (None, 25, 25, 8)         2384      \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_221 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_225 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_112 (Flatten)        (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 77,459\n",
      "Trainable params: 77,377\n",
      "Non-trainable params: 82\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1565 - accuracy: 0.3755 - val_loss: 1.0957 - val_accuracy: 0.3978\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.3847 - val_loss: 1.1040 - val_accuracy: 0.3733\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9975 - accuracy: 0.4412 - val_loss: 1.0735 - val_accuracy: 0.4044\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9603 - accuracy: 0.4532 - val_loss: 1.1287 - val_accuracy: 0.4089\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9049 - accuracy: 0.5060 - val_loss: 1.1024 - val_accuracy: 0.3800\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.5296 - val_loss: 1.0703 - val_accuracy: 0.4444\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.5398 - val_loss: 1.2666 - val_accuracy: 0.4733\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7944 - accuracy: 0.5718 - val_loss: 1.1890 - val_accuracy: 0.4200\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7858 - accuracy: 0.5903 - val_loss: 1.1571 - val_accuracy: 0.5200\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7825 - accuracy: 0.5944 - val_loss: 1.5210 - val_accuracy: 0.5533\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.6306 - val_loss: 1.2100 - val_accuracy: 0.4733\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.6259 - val_loss: 1.3979 - val_accuracy: 0.5156\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6421 - val_loss: 1.1483 - val_accuracy: 0.5644\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6583 - val_loss: 3.5862 - val_accuracy: 0.3889\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6838 - val_loss: 1.6168 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6759 - val_loss: 1.4997 - val_accuracy: 0.5133\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6662 - val_loss: 1.8005 - val_accuracy: 0.4400\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6755 - val_loss: 2.3068 - val_accuracy: 0.4222\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6875 - val_loss: 1.3785 - val_accuracy: 0.4956\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6931 - val_loss: 1.3713 - val_accuracy: 0.5911\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7167 - val_loss: 1.7343 - val_accuracy: 0.5044\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7134 - val_loss: 2.9108 - val_accuracy: 0.4733\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7273 - val_loss: 1.7237 - val_accuracy: 0.5489\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7319 - val_loss: 2.3333 - val_accuracy: 0.4911\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7449 - val_loss: 2.0636 - val_accuracy: 0.5022\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7588 - val_loss: 1.5580 - val_accuracy: 0.5289\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7616 - val_loss: 4.0231 - val_accuracy: 0.4578\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7625 - val_loss: 3.9147 - val_accuracy: 0.4200\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7690 - val_loss: 2.2820 - val_accuracy: 0.4822\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7657 - val_loss: 4.6243 - val_accuracy: 0.4400\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7722 - val_loss: 1.9010 - val_accuracy: 0.5444\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7824 - val_loss: 3.3543 - val_accuracy: 0.5111\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.7986 - val_loss: 2.3162 - val_accuracy: 0.4733\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7958 - val_loss: 1.8108 - val_accuracy: 0.5222\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7856 - val_loss: 1.6615 - val_accuracy: 0.6267\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7866 - val_loss: 3.6645 - val_accuracy: 0.4822\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.7944 - val_loss: 2.5510 - val_accuracy: 0.5356\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8060 - val_loss: 5.5400 - val_accuracy: 0.4511\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8148 - val_loss: 1.8931 - val_accuracy: 0.5733\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8069 - val_loss: 2.2765 - val_accuracy: 0.6089\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8060 - val_loss: 3.3955 - val_accuracy: 0.4467\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8389 - val_loss: 2.4720 - val_accuracy: 0.5956\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8417 - val_loss: 3.4444 - val_accuracy: 0.4867\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8282 - val_loss: 2.3979 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8356 - val_loss: 2.1498 - val_accuracy: 0.4867\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8329 - val_loss: 3.2277 - val_accuracy: 0.5022\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8551 - val_loss: 3.7314 - val_accuracy: 0.5956\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8352 - val_loss: 3.9098 - val_accuracy: 0.5778\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8417 - val_loss: 3.3960 - val_accuracy: 0.4978\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8537 - val_loss: 3.7929 - val_accuracy: 0.5067\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8574 - val_loss: 4.2675 - val_accuracy: 0.5156\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8616 - val_loss: 3.4058 - val_accuracy: 0.4889\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8560 - val_loss: 3.7452 - val_accuracy: 0.5267\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.8718 - val_loss: 3.4384 - val_accuracy: 0.5511\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8718 - val_loss: 9.0625 - val_accuracy: 0.3956\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8639 - val_loss: 3.9754 - val_accuracy: 0.5533\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8727 - val_loss: 6.9214 - val_accuracy: 0.4689\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8657 - val_loss: 4.1106 - val_accuracy: 0.5378\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.8769 - val_loss: 3.8821 - val_accuracy: 0.5311\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8741 - val_loss: 3.9080 - val_accuracy: 0.5556\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.8852 - val_loss: 4.8965 - val_accuracy: 0.5511\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.8838 - val_loss: 7.5654 - val_accuracy: 0.4622\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.8875 - val_loss: 5.4654 - val_accuracy: 0.5133\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.8981 - val_loss: 6.5836 - val_accuracy: 0.4867\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.8769 - val_loss: 6.5965 - val_accuracy: 0.4889\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2565 - accuracy: 0.8764 - val_loss: 4.7384 - val_accuracy: 0.5622\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.8833 - val_loss: 4.8524 - val_accuracy: 0.4911\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2149 - accuracy: 0.9051 - val_loss: 10.8349 - val_accuracy: 0.4156\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2305 - accuracy: 0.8944 - val_loss: 5.9140 - val_accuracy: 0.5867\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.8917 - val_loss: 4.4225 - val_accuracy: 0.5200\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2377 - accuracy: 0.8940 - val_loss: 5.2671 - val_accuracy: 0.5200\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.8981 - val_loss: 4.5516 - val_accuracy: 0.4822\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.8875 - val_loss: 4.6488 - val_accuracy: 0.4956\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.8958 - val_loss: 6.4108 - val_accuracy: 0.5044\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.8986 - val_loss: 6.2571 - val_accuracy: 0.5156\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9042 - val_loss: 8.7573 - val_accuracy: 0.5022\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.8995 - val_loss: 4.8101 - val_accuracy: 0.5778\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9134 - val_loss: 9.5030 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9139 - val_loss: 5.2683 - val_accuracy: 0.5356\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9088 - val_loss: 4.7120 - val_accuracy: 0.5289\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9162 - val_loss: 4.8579 - val_accuracy: 0.5756\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9134 - val_loss: 4.4428 - val_accuracy: 0.5422\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9167 - val_loss: 4.6635 - val_accuracy: 0.5511\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9144 - val_loss: 4.4874 - val_accuracy: 0.5711\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9218 - val_loss: 4.5326 - val_accuracy: 0.5600\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9236 - val_loss: 9.1385 - val_accuracy: 0.5089\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9269 - val_loss: 5.8688 - val_accuracy: 0.5622\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1858 - accuracy: 0.9204 - val_loss: 5.5917 - val_accuracy: 0.4622\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9236 - val_loss: 10.3520 - val_accuracy: 0.4356\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9282 - val_loss: 4.9648 - val_accuracy: 0.5200\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1852 - accuracy: 0.9148 - val_loss: 9.3680 - val_accuracy: 0.4711\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9319 - val_loss: 5.4139 - val_accuracy: 0.5356\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9329 - val_loss: 5.1627 - val_accuracy: 0.5533\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9264 - val_loss: 11.3126 - val_accuracy: 0.4667\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9181 - val_loss: 6.0144 - val_accuracy: 0.5044\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9352 - val_loss: 6.3734 - val_accuracy: 0.4844\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9329 - val_loss: 8.7641 - val_accuracy: 0.5422\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9356 - val_loss: 6.7427 - val_accuracy: 0.4956\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9324 - val_loss: 5.8845 - val_accuracy: 0.4978\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9301 - val_loss: 7.2002 - val_accuracy: 0.5422\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_226 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_226 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_227 (Conv2D)          (None, 25, 25, 8)         2384      \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_227 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_113 (Flatten)        (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 151,443\n",
      "Trainable params: 151,361\n",
      "Non-trainable params: 82\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2533 - accuracy: 0.4060 - val_loss: 1.1121 - val_accuracy: 0.3289\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9759 - accuracy: 0.4787 - val_loss: 1.1282 - val_accuracy: 0.3822\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9235 - accuracy: 0.5347 - val_loss: 1.0715 - val_accuracy: 0.5533\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8034 - accuracy: 0.5981 - val_loss: 1.2235 - val_accuracy: 0.5111\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7339 - accuracy: 0.6310 - val_loss: 3.2334 - val_accuracy: 0.3133\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6704 - val_loss: 1.7067 - val_accuracy: 0.4778\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7019 - val_loss: 1.8329 - val_accuracy: 0.4089\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.7005 - val_loss: 4.5452 - val_accuracy: 0.3933\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5353 - accuracy: 0.7458 - val_loss: 3.4758 - val_accuracy: 0.4467\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7500 - val_loss: 4.6986 - val_accuracy: 0.4200\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7583 - val_loss: 2.5010 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7861 - val_loss: 4.5335 - val_accuracy: 0.4267\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8037 - val_loss: 2.8279 - val_accuracy: 0.5067\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8125 - val_loss: 2.0684 - val_accuracy: 0.5356\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8079 - val_loss: 3.3823 - val_accuracy: 0.4489\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8384 - val_loss: 2.5861 - val_accuracy: 0.4400\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8486 - val_loss: 4.0389 - val_accuracy: 0.4644\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8407 - val_loss: 4.0208 - val_accuracy: 0.4378\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8569 - val_loss: 2.6799 - val_accuracy: 0.5356\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8620 - val_loss: 5.5208 - val_accuracy: 0.4200\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8782 - val_loss: 9.4337 - val_accuracy: 0.4044\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8769 - val_loss: 4.6599 - val_accuracy: 0.4178\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8606 - val_loss: 3.8510 - val_accuracy: 0.5200\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8755 - val_loss: 7.8634 - val_accuracy: 0.3978\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2660 - accuracy: 0.8838 - val_loss: 11.2404 - val_accuracy: 0.3844\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.8898 - val_loss: 5.4546 - val_accuracy: 0.4667\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.8931 - val_loss: 4.7119 - val_accuracy: 0.4778\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.8935 - val_loss: 5.0535 - val_accuracy: 0.4756\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9088 - val_loss: 5.1301 - val_accuracy: 0.4511\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9060 - val_loss: 6.4836 - val_accuracy: 0.4267\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2045 - accuracy: 0.9069 - val_loss: 4.0178 - val_accuracy: 0.5244\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.8991 - val_loss: 6.6529 - val_accuracy: 0.4467\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9125 - val_loss: 5.7189 - val_accuracy: 0.4622\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9227 - val_loss: 6.6934 - val_accuracy: 0.4644\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9176 - val_loss: 3.7536 - val_accuracy: 0.5622\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9079 - val_loss: 6.1913 - val_accuracy: 0.4800\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9130 - val_loss: 8.2388 - val_accuracy: 0.4711\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9162 - val_loss: 4.7593 - val_accuracy: 0.4822\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9241 - val_loss: 10.3249 - val_accuracy: 0.4089\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9199 - val_loss: 7.0694 - val_accuracy: 0.4578\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9255 - val_loss: 4.7737 - val_accuracy: 0.4889\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9329 - val_loss: 3.4022 - val_accuracy: 0.5644\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9310 - val_loss: 4.2378 - val_accuracy: 0.4778\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9394 - val_loss: 5.1825 - val_accuracy: 0.4933\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9417 - val_loss: 4.5395 - val_accuracy: 0.5178\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9366 - val_loss: 5.3109 - val_accuracy: 0.5467\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9472 - val_loss: 6.4639 - val_accuracy: 0.4733\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9449 - val_loss: 7.1152 - val_accuracy: 0.5067\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9319 - val_loss: 6.6094 - val_accuracy: 0.4556\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9449 - val_loss: 10.9277 - val_accuracy: 0.4778\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9431 - val_loss: 12.0620 - val_accuracy: 0.4222\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9454 - val_loss: 6.8497 - val_accuracy: 0.4333\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9449 - val_loss: 10.5255 - val_accuracy: 0.4267\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9444 - val_loss: 10.5521 - val_accuracy: 0.4511\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9523 - val_loss: 12.1893 - val_accuracy: 0.3800\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9486 - val_loss: 8.8996 - val_accuracy: 0.4267\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9560 - val_loss: 8.0762 - val_accuracy: 0.4867\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9491 - val_loss: 6.7292 - val_accuracy: 0.4489\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9495 - val_loss: 12.4968 - val_accuracy: 0.4133\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9514 - val_loss: 8.4892 - val_accuracy: 0.4378\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9583 - val_loss: 24.9243 - val_accuracy: 0.3733\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9532 - val_loss: 6.2859 - val_accuracy: 0.4733\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9569 - val_loss: 6.2667 - val_accuracy: 0.4756\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9634 - val_loss: 7.2696 - val_accuracy: 0.5067\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9560 - val_loss: 20.1219 - val_accuracy: 0.4089\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9514 - val_loss: 8.9778 - val_accuracy: 0.4333\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9644 - val_loss: 8.2692 - val_accuracy: 0.4578\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9685 - val_loss: 10.4189 - val_accuracy: 0.4356\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9560 - val_loss: 13.1771 - val_accuracy: 0.4444\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9671 - val_loss: 14.7600 - val_accuracy: 0.4422\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9602 - val_loss: 15.6270 - val_accuracy: 0.4867\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0975 - accuracy: 0.9662 - val_loss: 6.6317 - val_accuracy: 0.5600\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9593 - val_loss: 10.9134 - val_accuracy: 0.4800\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9630 - val_loss: 11.2912 - val_accuracy: 0.4667\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9602 - val_loss: 10.5069 - val_accuracy: 0.4644\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9718 - val_loss: 8.2765 - val_accuracy: 0.4933\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9667 - val_loss: 8.1585 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9569 - val_loss: 14.7122 - val_accuracy: 0.4311\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9648 - val_loss: 12.3380 - val_accuracy: 0.4533\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9727 - val_loss: 9.3906 - val_accuracy: 0.4644\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9722 - val_loss: 8.5874 - val_accuracy: 0.4756\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9708 - val_loss: 10.2947 - val_accuracy: 0.5133\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9787 - val_loss: 14.5424 - val_accuracy: 0.4667\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9694 - val_loss: 19.3015 - val_accuracy: 0.4044\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9736 - val_loss: 25.5648 - val_accuracy: 0.4556\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9731 - val_loss: 11.3575 - val_accuracy: 0.4267\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9764 - val_loss: 10.7992 - val_accuracy: 0.4600\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9731 - val_loss: 12.4491 - val_accuracy: 0.4756\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9736 - val_loss: 8.3473 - val_accuracy: 0.5400\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9741 - val_loss: 18.8586 - val_accuracy: 0.4400\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9810 - val_loss: 11.6281 - val_accuracy: 0.4956\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9787 - val_loss: 10.5389 - val_accuracy: 0.4600\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9667 - val_loss: 9.8741 - val_accuracy: 0.4467\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9764 - val_loss: 10.1662 - val_accuracy: 0.4578\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9773 - val_loss: 15.6371 - val_accuracy: 0.4089\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9769 - val_loss: 16.8955 - val_accuracy: 0.4689\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9685 - val_loss: 11.4975 - val_accuracy: 0.4311\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9750 - val_loss: 8.6355 - val_accuracy: 0.5022\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9787 - val_loss: 12.0855 - val_accuracy: 0.4356\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9806 - val_loss: 14.9112 - val_accuracy: 0.4644\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_228 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_228 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_229 (Conv2D)          (None, 25, 25, 8)         2384      \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 25, 25, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_229 (MaxPoolin (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_114 (Flatten)        (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 299,411\n",
      "Trainable params: 299,329\n",
      "Non-trainable params: 82\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2826 - accuracy: 0.4588 - val_loss: 1.0979 - val_accuracy: 0.4956\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.5769 - val_loss: 1.0893 - val_accuracy: 0.3111\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7663 - accuracy: 0.6343 - val_loss: 1.1280 - val_accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7051 - val_loss: 1.2640 - val_accuracy: 0.4444\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7282 - val_loss: 1.3584 - val_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7718 - val_loss: 1.3700 - val_accuracy: 0.4044\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7866 - val_loss: 1.6024 - val_accuracy: 0.3822\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7958 - val_loss: 1.4163 - val_accuracy: 0.4289\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8241 - val_loss: 1.3547 - val_accuracy: 0.5022\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8523 - val_loss: 2.4145 - val_accuracy: 0.4556\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8611 - val_loss: 2.2243 - val_accuracy: 0.4044\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8727 - val_loss: 2.1454 - val_accuracy: 0.4489\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3065 - accuracy: 0.8778 - val_loss: 2.1280 - val_accuracy: 0.4778\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.8995 - val_loss: 3.1746 - val_accuracy: 0.5556\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.8931 - val_loss: 3.0550 - val_accuracy: 0.4756\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2140 - accuracy: 0.9134 - val_loss: 5.7145 - val_accuracy: 0.3844\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.8894 - val_loss: 3.0220 - val_accuracy: 0.5044\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9060 - val_loss: 2.3830 - val_accuracy: 0.4556\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1824 - accuracy: 0.9250 - val_loss: 2.9253 - val_accuracy: 0.4400\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.9241 - val_loss: 3.6609 - val_accuracy: 0.4556\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9245 - val_loss: 3.1979 - val_accuracy: 0.4600\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9185 - val_loss: 2.8581 - val_accuracy: 0.4378\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9208 - val_loss: 2.6450 - val_accuracy: 0.4889\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9407 - val_loss: 3.8639 - val_accuracy: 0.4822\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9407 - val_loss: 3.3051 - val_accuracy: 0.4644\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9412 - val_loss: 3.9146 - val_accuracy: 0.5244\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9514 - val_loss: 4.4752 - val_accuracy: 0.5756\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9505 - val_loss: 3.6936 - val_accuracy: 0.5022\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9449 - val_loss: 3.6267 - val_accuracy: 0.4356\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9574 - val_loss: 3.9887 - val_accuracy: 0.4556\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9532 - val_loss: 4.1935 - val_accuracy: 0.4511\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9574 - val_loss: 4.0720 - val_accuracy: 0.4622\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9569 - val_loss: 3.9540 - val_accuracy: 0.5200\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9597 - val_loss: 7.6739 - val_accuracy: 0.4044\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9574 - val_loss: 4.7285 - val_accuracy: 0.4400\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9532 - val_loss: 3.5565 - val_accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9662 - val_loss: 4.7895 - val_accuracy: 0.4644\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1042 - accuracy: 0.9579 - val_loss: 5.2071 - val_accuracy: 0.5200\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9602 - val_loss: 5.7104 - val_accuracy: 0.5044\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0896 - accuracy: 0.9648 - val_loss: 5.3365 - val_accuracy: 0.4800\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9644 - val_loss: 4.8095 - val_accuracy: 0.4756\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9708 - val_loss: 5.5574 - val_accuracy: 0.5022\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9620 - val_loss: 5.9289 - val_accuracy: 0.5089\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9620 - val_loss: 6.3105 - val_accuracy: 0.4378\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9648 - val_loss: 9.0215 - val_accuracy: 0.4600\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 0.9593 - val_loss: 7.4038 - val_accuracy: 0.4711\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 5.0042 - val_accuracy: 0.5178\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9713 - val_loss: 4.6384 - val_accuracy: 0.4600\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9731 - val_loss: 4.5788 - val_accuracy: 0.5422\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9736 - val_loss: 5.7140 - val_accuracy: 0.5244\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9736 - val_loss: 4.5659 - val_accuracy: 0.5422\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9639 - val_loss: 5.1624 - val_accuracy: 0.5156\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9731 - val_loss: 8.0575 - val_accuracy: 0.5044\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9745 - val_loss: 6.4674 - val_accuracy: 0.5044\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 9.4662 - val_accuracy: 0.5267\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9722 - val_loss: 7.2620 - val_accuracy: 0.4978\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9787 - val_loss: 11.6517 - val_accuracy: 0.3533\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9787 - val_loss: 6.5994 - val_accuracy: 0.5689\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9806 - val_loss: 6.5828 - val_accuracy: 0.4911\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9815 - val_loss: 6.3026 - val_accuracy: 0.4956\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9801 - val_loss: 6.3001 - val_accuracy: 0.5444\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9773 - val_loss: 9.5470 - val_accuracy: 0.4511\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9764 - val_loss: 14.7528 - val_accuracy: 0.3889\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9778 - val_loss: 5.8429 - val_accuracy: 0.5244\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 6.4078 - val_accuracy: 0.5489\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9815 - val_loss: 8.6399 - val_accuracy: 0.4578\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9764 - val_loss: 7.0347 - val_accuracy: 0.5511\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9833 - val_loss: 8.4285 - val_accuracy: 0.4933\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9792 - val_loss: 6.9347 - val_accuracy: 0.4822\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 7.3630 - val_accuracy: 0.4756\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9801 - val_loss: 7.2793 - val_accuracy: 0.4622\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9778 - val_loss: 6.9572 - val_accuracy: 0.5244\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9773 - val_loss: 8.4195 - val_accuracy: 0.4333\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9824 - val_loss: 8.6057 - val_accuracy: 0.4422\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9787 - val_loss: 6.4549 - val_accuracy: 0.4822\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9852 - val_loss: 9.0907 - val_accuracy: 0.3933\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9829 - val_loss: 7.7742 - val_accuracy: 0.4467\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9880 - val_loss: 8.4593 - val_accuracy: 0.4867\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9792 - val_loss: 8.3394 - val_accuracy: 0.4867\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9856 - val_loss: 6.3026 - val_accuracy: 0.5111\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9736 - val_loss: 11.4217 - val_accuracy: 0.4956\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9829 - val_loss: 6.0166 - val_accuracy: 0.5178\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9824 - val_loss: 11.1295 - val_accuracy: 0.4422\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 9.3097 - val_accuracy: 0.4600\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9870 - val_loss: 8.0284 - val_accuracy: 0.4844\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9861 - val_loss: 7.6121 - val_accuracy: 0.5422\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 9.9864 - val_accuracy: 0.4867\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 7.0112 - val_accuracy: 0.5089\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9866 - val_loss: 6.6574 - val_accuracy: 0.4956\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 6.9603 - val_accuracy: 0.5044\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 8.5807 - val_accuracy: 0.5044\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 10.7150 - val_accuracy: 0.4378\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9847 - val_loss: 10.5230 - val_accuracy: 0.4533\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9833 - val_loss: 11.1961 - val_accuracy: 0.4400\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9880 - val_loss: 8.3097 - val_accuracy: 0.5467\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9838 - val_loss: 7.5224 - val_accuracy: 0.4911\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9907 - val_loss: 10.3398 - val_accuracy: 0.4844\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 7.7175 - val_accuracy: 0.5156\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9870 - val_loss: 8.0904 - val_accuracy: 0.5356\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9903 - val_loss: 8.8220 - val_accuracy: 0.5200\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_230 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_226 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_230 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_231 (Conv2D)          (None, 25, 25, 10)        2980      \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_227 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_231 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_115 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 50,287\n",
      "Trainable params: 50,201\n",
      "Non-trainable params: 86\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1610 - accuracy: 0.3542 - val_loss: 1.0985 - val_accuracy: 0.3356\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0625 - accuracy: 0.3787 - val_loss: 1.0970 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.4231 - val_loss: 1.1309 - val_accuracy: 0.4311\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9965 - accuracy: 0.4269 - val_loss: 1.0791 - val_accuracy: 0.4911\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9860 - accuracy: 0.4338 - val_loss: 1.1171 - val_accuracy: 0.4800\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9955 - accuracy: 0.4171 - val_loss: 1.1874 - val_accuracy: 0.4733\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9828 - accuracy: 0.4157 - val_loss: 1.1676 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9968 - accuracy: 0.4380 - val_loss: 1.4837 - val_accuracy: 0.3200\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9493 - accuracy: 0.4546 - val_loss: 1.1776 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9514 - accuracy: 0.4435 - val_loss: 1.9515 - val_accuracy: 0.4244\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9411 - accuracy: 0.4644 - val_loss: 1.4402 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9502 - accuracy: 0.4690 - val_loss: 1.0986 - val_accuracy: 0.4733\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9202 - accuracy: 0.4815 - val_loss: 1.3816 - val_accuracy: 0.3600\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9046 - accuracy: 0.4819 - val_loss: 1.8499 - val_accuracy: 0.4022\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9292 - accuracy: 0.4806 - val_loss: 1.9347 - val_accuracy: 0.4556\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9122 - accuracy: 0.4759 - val_loss: 1.7959 - val_accuracy: 0.3978\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9047 - accuracy: 0.4912 - val_loss: 1.1558 - val_accuracy: 0.4422\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9130 - accuracy: 0.4852 - val_loss: 1.2594 - val_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8999 - accuracy: 0.4972 - val_loss: 1.0933 - val_accuracy: 0.4022\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9039 - accuracy: 0.5009 - val_loss: 1.2650 - val_accuracy: 0.4800\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8907 - accuracy: 0.5181 - val_loss: 1.3960 - val_accuracy: 0.4200\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9030 - accuracy: 0.5083 - val_loss: 1.0794 - val_accuracy: 0.4667\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8772 - accuracy: 0.5287 - val_loss: 2.4346 - val_accuracy: 0.3689\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8860 - accuracy: 0.5259 - val_loss: 1.2344 - val_accuracy: 0.4756\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8607 - accuracy: 0.5421 - val_loss: 1.1158 - val_accuracy: 0.4733\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8702 - accuracy: 0.5269 - val_loss: 1.7395 - val_accuracy: 0.4422\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8898 - accuracy: 0.5130 - val_loss: 1.2803 - val_accuracy: 0.4733\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8601 - accuracy: 0.5398 - val_loss: 1.4086 - val_accuracy: 0.4644\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8599 - accuracy: 0.5403 - val_loss: 1.5732 - val_accuracy: 0.4444\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8672 - accuracy: 0.5389 - val_loss: 1.3654 - val_accuracy: 0.3889\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8644 - accuracy: 0.5426 - val_loss: 2.8510 - val_accuracy: 0.3978\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8596 - accuracy: 0.5389 - val_loss: 1.1773 - val_accuracy: 0.4667\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8558 - accuracy: 0.5468 - val_loss: 4.0855 - val_accuracy: 0.4067\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.3767 - val_accuracy: 0.4711\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8330 - accuracy: 0.5593 - val_loss: 1.8200 - val_accuracy: 0.4600\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8392 - accuracy: 0.5556 - val_loss: 2.2893 - val_accuracy: 0.4711\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8165 - accuracy: 0.5815 - val_loss: 1.7070 - val_accuracy: 0.4644\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7938 - accuracy: 0.5931 - val_loss: 1.2580 - val_accuracy: 0.4200\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7946 - accuracy: 0.5926 - val_loss: 1.4128 - val_accuracy: 0.4356\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7963 - accuracy: 0.5866 - val_loss: 1.5844 - val_accuracy: 0.4733\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8009 - accuracy: 0.5829 - val_loss: 1.5539 - val_accuracy: 0.4467\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7888 - accuracy: 0.5880 - val_loss: 2.0873 - val_accuracy: 0.4978\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8042 - accuracy: 0.5838 - val_loss: 1.5575 - val_accuracy: 0.4600\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8029 - accuracy: 0.5843 - val_loss: 1.3874 - val_accuracy: 0.4689\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7757 - accuracy: 0.6069 - val_loss: 1.5597 - val_accuracy: 0.4556\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7869 - accuracy: 0.5944 - val_loss: 2.2119 - val_accuracy: 0.4267\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.6019 - val_loss: 2.3672 - val_accuracy: 0.4667\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7643 - accuracy: 0.6069 - val_loss: 5.0479 - val_accuracy: 0.3733\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.6051 - val_loss: 4.8580 - val_accuracy: 0.3556\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.6255 - val_loss: 2.7958 - val_accuracy: 0.4711\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.6194 - val_loss: 1.9198 - val_accuracy: 0.4200\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.6176 - val_loss: 1.8820 - val_accuracy: 0.5133\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.6190 - val_loss: 1.9249 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.6116 - val_loss: 2.2119 - val_accuracy: 0.4778\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.6380 - val_loss: 3.1434 - val_accuracy: 0.3756\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.6245 - val_loss: 3.5533 - val_accuracy: 0.4244\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.6218 - val_loss: 1.6545 - val_accuracy: 0.5067\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7182 - accuracy: 0.6306 - val_loss: 2.0207 - val_accuracy: 0.5133\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.6264 - val_loss: 2.3977 - val_accuracy: 0.4622\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.6208 - val_loss: 3.5557 - val_accuracy: 0.4556\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.6375 - val_loss: 1.6999 - val_accuracy: 0.5556\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.6259 - val_loss: 2.1315 - val_accuracy: 0.4778\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.6343 - val_loss: 2.2080 - val_accuracy: 0.5178\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.6495 - val_loss: 1.6713 - val_accuracy: 0.4778\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.6394 - val_loss: 4.5590 - val_accuracy: 0.4044\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.6417 - val_loss: 1.5765 - val_accuracy: 0.4933\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.6426 - val_loss: 2.3885 - val_accuracy: 0.4867\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.6343 - val_loss: 1.3917 - val_accuracy: 0.4511\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.6454 - val_loss: 2.5949 - val_accuracy: 0.5044\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6593 - val_loss: 2.6500 - val_accuracy: 0.4933\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6560 - val_loss: 1.7325 - val_accuracy: 0.5467\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.6486 - val_loss: 2.2661 - val_accuracy: 0.4933\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.6597 - val_loss: 1.7641 - val_accuracy: 0.4800\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.6729 - accuracy: 0.6472 - val_loss: 1.3645 - val_accuracy: 0.4667\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6606 - val_loss: 9.1869 - val_accuracy: 0.3444\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.6361 - val_loss: 1.8630 - val_accuracy: 0.5556\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.6472 - val_loss: 4.7527 - val_accuracy: 0.3978\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6625 - val_loss: 2.7622 - val_accuracy: 0.4889\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6745 - val_loss: 9.1540 - val_accuracy: 0.3800\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6694 - val_loss: 2.2399 - val_accuracy: 0.5778\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6611 - val_loss: 1.7440 - val_accuracy: 0.5422\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6773 - val_loss: 1.5975 - val_accuracy: 0.5289\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6792 - val_loss: 3.0397 - val_accuracy: 0.5111\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6597 - val_loss: 2.2708 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6648 - val_loss: 2.1551 - val_accuracy: 0.4489\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.6759 - val_loss: 2.7165 - val_accuracy: 0.4133\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6819 - val_loss: 2.3596 - val_accuracy: 0.5711\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6676 - val_loss: 6.5695 - val_accuracy: 0.3956\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6870 - val_loss: 2.1705 - val_accuracy: 0.5578\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.6847 - val_loss: 2.0369 - val_accuracy: 0.4911\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6773 - val_loss: 3.7537 - val_accuracy: 0.4844\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.6644 - val_loss: 2.6881 - val_accuracy: 0.5400\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6787 - val_loss: 6.4905 - val_accuracy: 0.4111\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6778 - val_loss: 1.6686 - val_accuracy: 0.5533\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.6796 - val_loss: 2.3556 - val_accuracy: 0.5467\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6801 - val_loss: 3.1840 - val_accuracy: 0.4844\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.6917 - val_loss: 3.4676 - val_accuracy: 0.4778\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.6889 - val_loss: 2.2436 - val_accuracy: 0.5067\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6815 - val_loss: 3.3216 - val_accuracy: 0.4689\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.6694 - val_loss: 2.9862 - val_accuracy: 0.5178\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_232 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_228 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_232 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_233 (Conv2D)          (None, 25, 25, 10)        2980      \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_229 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_233 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_116 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 64)                92224     \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 96,495\n",
      "Trainable params: 96,409\n",
      "Non-trainable params: 86\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.1667 - accuracy: 0.3764 - val_loss: 1.0990 - val_accuracy: 0.3733\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0123 - accuracy: 0.4338 - val_loss: 1.0800 - val_accuracy: 0.4511\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9661 - accuracy: 0.4630 - val_loss: 1.1046 - val_accuracy: 0.4667\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9094 - accuracy: 0.5000 - val_loss: 1.0900 - val_accuracy: 0.4911\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8659 - accuracy: 0.5148 - val_loss: 1.0972 - val_accuracy: 0.4333\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8474 - accuracy: 0.5338 - val_loss: 1.2996 - val_accuracy: 0.4133\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8128 - accuracy: 0.5671 - val_loss: 1.0188 - val_accuracy: 0.4956\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7732 - accuracy: 0.5727 - val_loss: 1.9724 - val_accuracy: 0.4711\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7879 - accuracy: 0.5718 - val_loss: 1.5052 - val_accuracy: 0.4889\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7436 - accuracy: 0.6097 - val_loss: 2.2932 - val_accuracy: 0.4644\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.6088 - val_loss: 1.9704 - val_accuracy: 0.5089\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.6056 - val_loss: 1.5396 - val_accuracy: 0.4800\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7023 - accuracy: 0.6222 - val_loss: 1.3968 - val_accuracy: 0.4689\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.6167 - val_loss: 1.4760 - val_accuracy: 0.4289\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6329 - val_loss: 1.8932 - val_accuracy: 0.5467\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6532 - val_loss: 1.5719 - val_accuracy: 0.4756\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.6667 - val_loss: 2.5096 - val_accuracy: 0.5356\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6671 - val_loss: 2.7865 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.6718 - val_loss: 2.6010 - val_accuracy: 0.5311\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6662 - val_loss: 1.5042 - val_accuracy: 0.4378\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6843 - val_loss: 1.9811 - val_accuracy: 0.5289\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6958 - val_loss: 2.2541 - val_accuracy: 0.5133\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7014 - val_loss: 3.8582 - val_accuracy: 0.4911\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7069 - val_loss: 3.0965 - val_accuracy: 0.5489\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7125 - val_loss: 2.2061 - val_accuracy: 0.5244\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7083 - val_loss: 3.0217 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7292 - val_loss: 1.6532 - val_accuracy: 0.5756\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7454 - val_loss: 2.9380 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7292 - val_loss: 2.4210 - val_accuracy: 0.5156\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7407 - val_loss: 2.1583 - val_accuracy: 0.5578\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7352 - val_loss: 3.6710 - val_accuracy: 0.5378\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7468 - val_loss: 2.9932 - val_accuracy: 0.5756\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7718 - val_loss: 4.1931 - val_accuracy: 0.5311\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7481 - val_loss: 2.7155 - val_accuracy: 0.5867\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7801 - val_loss: 2.8721 - val_accuracy: 0.5200\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7861 - val_loss: 2.2877 - val_accuracy: 0.5444\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7755 - val_loss: 2.7789 - val_accuracy: 0.5267\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7792 - val_loss: 3.0496 - val_accuracy: 0.5178\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7815 - val_loss: 3.3339 - val_accuracy: 0.4556\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7819 - val_loss: 4.3520 - val_accuracy: 0.5111\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7875 - val_loss: 5.4344 - val_accuracy: 0.4978\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8000 - val_loss: 8.4485 - val_accuracy: 0.3489\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8028 - val_loss: 4.2517 - val_accuracy: 0.4444\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.7995 - val_loss: 3.6402 - val_accuracy: 0.5356\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8037 - val_loss: 3.1554 - val_accuracy: 0.5400\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8181 - val_loss: 4.9930 - val_accuracy: 0.5444\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8125 - val_loss: 3.0986 - val_accuracy: 0.5244\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8208 - val_loss: 4.6473 - val_accuracy: 0.5667\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8213 - val_loss: 5.5826 - val_accuracy: 0.5156\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8148 - val_loss: 10.9810 - val_accuracy: 0.3911\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8218 - val_loss: 4.4231 - val_accuracy: 0.4956\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8245 - val_loss: 4.1615 - val_accuracy: 0.5311\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8468 - val_loss: 4.8050 - val_accuracy: 0.5089\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8278 - val_loss: 3.5062 - val_accuracy: 0.5022\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8338 - val_loss: 3.5438 - val_accuracy: 0.4889\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8227 - val_loss: 4.8892 - val_accuracy: 0.5556\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8449 - val_loss: 5.2398 - val_accuracy: 0.5156\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8343 - val_loss: 6.6759 - val_accuracy: 0.5422\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.8426 - val_loss: 8.4737 - val_accuracy: 0.4289\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8287 - val_loss: 6.9173 - val_accuracy: 0.5133\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8301 - val_loss: 7.2324 - val_accuracy: 0.5178\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8403 - val_loss: 6.1163 - val_accuracy: 0.4756\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8528 - val_loss: 9.2139 - val_accuracy: 0.4289\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8491 - val_loss: 6.8870 - val_accuracy: 0.4022\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8500 - val_loss: 5.2057 - val_accuracy: 0.4978\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8319 - val_loss: 9.9095 - val_accuracy: 0.4511\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8542 - val_loss: 5.0982 - val_accuracy: 0.4867\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8468 - val_loss: 4.2840 - val_accuracy: 0.5133\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8630 - val_loss: 5.6274 - val_accuracy: 0.5178\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8551 - val_loss: 4.8589 - val_accuracy: 0.4778\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8745 - val_loss: 4.3422 - val_accuracy: 0.5533\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8648 - val_loss: 4.7122 - val_accuracy: 0.4889\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8685 - val_loss: 5.0739 - val_accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8639 - val_loss: 5.6209 - val_accuracy: 0.5400\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8671 - val_loss: 4.2166 - val_accuracy: 0.5711\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8630 - val_loss: 4.2946 - val_accuracy: 0.5044\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2605 - accuracy: 0.8685 - val_loss: 6.4127 - val_accuracy: 0.5044\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8634 - val_loss: 5.7140 - val_accuracy: 0.5133\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.8745 - val_loss: 5.9272 - val_accuracy: 0.5111\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2397 - accuracy: 0.8810 - val_loss: 5.7929 - val_accuracy: 0.4956\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2422 - accuracy: 0.8880 - val_loss: 6.9483 - val_accuracy: 0.5311\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.8824 - val_loss: 7.0231 - val_accuracy: 0.5489\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.8824 - val_loss: 6.4419 - val_accuracy: 0.5200\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.8884 - val_loss: 5.7499 - val_accuracy: 0.5022\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.8894 - val_loss: 5.8550 - val_accuracy: 0.4956\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.8884 - val_loss: 5.7937 - val_accuracy: 0.5467\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.8838 - val_loss: 12.9366 - val_accuracy: 0.4089\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.8954 - val_loss: 20.0697 - val_accuracy: 0.3489\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2410 - accuracy: 0.8727 - val_loss: 6.3794 - val_accuracy: 0.5244\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.8898 - val_loss: 7.0105 - val_accuracy: 0.5222\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.8944 - val_loss: 5.9403 - val_accuracy: 0.5200\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.8954 - val_loss: 6.2540 - val_accuracy: 0.5667\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.8898 - val_loss: 5.7326 - val_accuracy: 0.4911\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.8958 - val_loss: 5.8810 - val_accuracy: 0.5289\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9000 - val_loss: 7.3911 - val_accuracy: 0.5444\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9019 - val_loss: 7.6105 - val_accuracy: 0.4867\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.8995 - val_loss: 6.6916 - val_accuracy: 0.5222\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.8921 - val_loss: 7.2241 - val_accuracy: 0.4644\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.8931 - val_loss: 9.7328 - val_accuracy: 0.4333\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.8931 - val_loss: 6.8475 - val_accuracy: 0.5289\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_234 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_230 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_234 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_235 (Conv2D)          (None, 25, 25, 10)        2980      \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_231 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_235 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_117 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 128)               184448    \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 188,911\n",
      "Trainable params: 188,825\n",
      "Non-trainable params: 86\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2303 - accuracy: 0.4593 - val_loss: 1.0906 - val_accuracy: 0.4867\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9029 - accuracy: 0.5389 - val_loss: 1.1130 - val_accuracy: 0.3778\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8179 - accuracy: 0.5935 - val_loss: 1.3179 - val_accuracy: 0.3622\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7640 - accuracy: 0.6292 - val_loss: 1.7373 - val_accuracy: 0.4267\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.6625 - val_loss: 1.4115 - val_accuracy: 0.4689\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6884 - val_loss: 1.6809 - val_accuracy: 0.4022\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6958 - val_loss: 2.7249 - val_accuracy: 0.4289\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7181 - val_loss: 2.1421 - val_accuracy: 0.4533\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7273 - val_loss: 2.4709 - val_accuracy: 0.3667\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7606 - val_loss: 2.6793 - val_accuracy: 0.4378\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7657 - val_loss: 2.1341 - val_accuracy: 0.4089\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7875 - val_loss: 5.2820 - val_accuracy: 0.3622\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8060 - val_loss: 2.6918 - val_accuracy: 0.4822\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8125 - val_loss: 2.4781 - val_accuracy: 0.4822\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3937 - accuracy: 0.8157 - val_loss: 2.9220 - val_accuracy: 0.5156\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8407 - val_loss: 2.8116 - val_accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8338 - val_loss: 2.2671 - val_accuracy: 0.4244\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8333 - val_loss: 2.8017 - val_accuracy: 0.4889\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8412 - val_loss: 2.5104 - val_accuracy: 0.4311\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8565 - val_loss: 2.2587 - val_accuracy: 0.5489\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.8528 - val_loss: 2.7941 - val_accuracy: 0.4533\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.8644 - val_loss: 6.5175 - val_accuracy: 0.4356\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8694 - val_loss: 3.4884 - val_accuracy: 0.4822\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8829 - val_loss: 3.3143 - val_accuracy: 0.5444\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8838 - val_loss: 4.1209 - val_accuracy: 0.4422\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.8838 - val_loss: 7.0258 - val_accuracy: 0.4333\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.8787 - val_loss: 4.9556 - val_accuracy: 0.4822\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.8931 - val_loss: 10.6597 - val_accuracy: 0.3822\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.8880 - val_loss: 3.3148 - val_accuracy: 0.5844\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9037 - val_loss: 6.1532 - val_accuracy: 0.4267\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9005 - val_loss: 4.9936 - val_accuracy: 0.4756\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.8986 - val_loss: 4.8356 - val_accuracy: 0.4778\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9051 - val_loss: 3.8298 - val_accuracy: 0.4867\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.8991 - val_loss: 4.6654 - val_accuracy: 0.5044\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.8931 - val_loss: 3.0836 - val_accuracy: 0.5533\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9190 - val_loss: 5.4204 - val_accuracy: 0.4578\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9176 - val_loss: 8.2757 - val_accuracy: 0.4267\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9144 - val_loss: 5.9905 - val_accuracy: 0.5111\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9181 - val_loss: 6.0065 - val_accuracy: 0.4622\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9208 - val_loss: 7.4300 - val_accuracy: 0.4800\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9194 - val_loss: 7.3421 - val_accuracy: 0.5644\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9264 - val_loss: 3.8442 - val_accuracy: 0.6200\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1773 - accuracy: 0.9199 - val_loss: 5.1328 - val_accuracy: 0.5733\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9315 - val_loss: 8.7314 - val_accuracy: 0.5267\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9319 - val_loss: 9.1948 - val_accuracy: 0.4644\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9306 - val_loss: 4.3461 - val_accuracy: 0.5089\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.9208 - val_loss: 3.6053 - val_accuracy: 0.5400\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9380 - val_loss: 5.4016 - val_accuracy: 0.5822\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9384 - val_loss: 4.4897 - val_accuracy: 0.5556\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9426 - val_loss: 5.2603 - val_accuracy: 0.5733\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9463 - val_loss: 4.9682 - val_accuracy: 0.6067\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1330 - accuracy: 0.9380 - val_loss: 5.0839 - val_accuracy: 0.5289\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9389 - val_loss: 8.0325 - val_accuracy: 0.5133\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9449 - val_loss: 7.9783 - val_accuracy: 0.4311\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9431 - val_loss: 8.1354 - val_accuracy: 0.5089\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.9333 - val_loss: 12.0998 - val_accuracy: 0.3956\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9412 - val_loss: 4.6062 - val_accuracy: 0.5867\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9472 - val_loss: 5.9556 - val_accuracy: 0.5444\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9500 - val_loss: 15.3961 - val_accuracy: 0.3911\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9375 - val_loss: 5.2742 - val_accuracy: 0.5178\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9389 - val_loss: 8.9345 - val_accuracy: 0.4778\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9551 - val_loss: 8.7242 - val_accuracy: 0.5600\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9486 - val_loss: 4.0665 - val_accuracy: 0.6511\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9579 - val_loss: 9.5466 - val_accuracy: 0.4444\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.9472 - val_loss: 6.1011 - val_accuracy: 0.6467\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9556 - val_loss: 4.2792 - val_accuracy: 0.6111\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9509 - val_loss: 7.2148 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9565 - val_loss: 5.2519 - val_accuracy: 0.6067\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9579 - val_loss: 7.0076 - val_accuracy: 0.5133\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9495 - val_loss: 4.0592 - val_accuracy: 0.5978\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9602 - val_loss: 4.8127 - val_accuracy: 0.5978\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9606 - val_loss: 5.4030 - val_accuracy: 0.6022\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9551 - val_loss: 8.1476 - val_accuracy: 0.5156\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9630 - val_loss: 7.4299 - val_accuracy: 0.5400\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9676 - val_loss: 4.4699 - val_accuracy: 0.5956\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9528 - val_loss: 9.9213 - val_accuracy: 0.4778\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9625 - val_loss: 4.4339 - val_accuracy: 0.6133\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9611 - val_loss: 28.7954 - val_accuracy: 0.3689\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9602 - val_loss: 6.6025 - val_accuracy: 0.5356\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9708 - val_loss: 5.5049 - val_accuracy: 0.6422\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9597 - val_loss: 4.2692 - val_accuracy: 0.5889\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9625 - val_loss: 6.6320 - val_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9634 - val_loss: 7.4754 - val_accuracy: 0.5844\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9671 - val_loss: 4.7979 - val_accuracy: 0.4933\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9648 - val_loss: 6.8588 - val_accuracy: 0.5511\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9667 - val_loss: 5.5612 - val_accuracy: 0.6022\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9657 - val_loss: 6.4406 - val_accuracy: 0.4844\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9690 - val_loss: 5.8470 - val_accuracy: 0.6378\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9722 - val_loss: 7.0360 - val_accuracy: 0.5356\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9727 - val_loss: 8.3229 - val_accuracy: 0.4778\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9750 - val_loss: 7.0679 - val_accuracy: 0.5111\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9611 - val_loss: 7.4431 - val_accuracy: 0.5600\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0756 - accuracy: 0.9648 - val_loss: 7.7381 - val_accuracy: 0.5756\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9620 - val_loss: 4.8239 - val_accuracy: 0.5222\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9593 - val_loss: 4.6376 - val_accuracy: 0.6689\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9685 - val_loss: 4.7435 - val_accuracy: 0.6467\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9630 - val_loss: 8.1287 - val_accuracy: 0.4978\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9625 - val_loss: 5.9264 - val_accuracy: 0.6267\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9699 - val_loss: 5.9441 - val_accuracy: 0.5822\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9616 - val_loss: 7.1050 - val_accuracy: 0.5844\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_236 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_236 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_237 (Conv2D)          (None, 25, 25, 10)        2980      \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 25, 25, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 25, 25, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_237 (MaxPoolin (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_118 (Flatten)        (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 256)               368896    \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 373,743\n",
      "Trainable params: 373,657\n",
      "Non-trainable params: 86\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.3203 - accuracy: 0.4481 - val_loss: 1.0949 - val_accuracy: 0.3667\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8703 - accuracy: 0.5718 - val_loss: 1.0764 - val_accuracy: 0.4378\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.6421 - val_loss: 1.2157 - val_accuracy: 0.5756\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6903 - val_loss: 1.1367 - val_accuracy: 0.5533\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5821 - accuracy: 0.7343 - val_loss: 1.1176 - val_accuracy: 0.5800\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5277 - accuracy: 0.7602 - val_loss: 1.4108 - val_accuracy: 0.5933\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4961 - accuracy: 0.7815 - val_loss: 1.2898 - val_accuracy: 0.5378\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4627 - accuracy: 0.8028 - val_loss: 1.5175 - val_accuracy: 0.5800\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4339 - accuracy: 0.8009 - val_loss: 1.9631 - val_accuracy: 0.5200\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3631 - accuracy: 0.8380 - val_loss: 2.5172 - val_accuracy: 0.5556\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8278 - val_loss: 2.1912 - val_accuracy: 0.5689\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3667 - accuracy: 0.8398 - val_loss: 2.3929 - val_accuracy: 0.5911\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8616 - val_loss: 2.7728 - val_accuracy: 0.5244\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8671 - val_loss: 2.1902 - val_accuracy: 0.5378\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2964 - accuracy: 0.8694 - val_loss: 2.3234 - val_accuracy: 0.6178\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2651 - accuracy: 0.8806 - val_loss: 1.6402 - val_accuracy: 0.6267\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2593 - accuracy: 0.8875 - val_loss: 3.4758 - val_accuracy: 0.4778\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.8875 - val_loss: 2.1794 - val_accuracy: 0.5067\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.8903 - val_loss: 2.5801 - val_accuracy: 0.6089\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2113 - accuracy: 0.9111 - val_loss: 3.5280 - val_accuracy: 0.5089\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9157 - val_loss: 2.5209 - val_accuracy: 0.6467\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9074 - val_loss: 1.9766 - val_accuracy: 0.6556\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9097 - val_loss: 3.4844 - val_accuracy: 0.6267\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1958 - accuracy: 0.9185 - val_loss: 4.0472 - val_accuracy: 0.6311\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9231 - val_loss: 3.0335 - val_accuracy: 0.5533\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9227 - val_loss: 3.7699 - val_accuracy: 0.5444\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.9319 - val_loss: 3.9134 - val_accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9213 - val_loss: 2.1428 - val_accuracy: 0.6378\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1563 - accuracy: 0.9366 - val_loss: 3.9921 - val_accuracy: 0.6578\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9454 - val_loss: 2.9191 - val_accuracy: 0.5911\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9481 - val_loss: 3.9735 - val_accuracy: 0.5489\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9440 - val_loss: 2.8912 - val_accuracy: 0.6778\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9477 - val_loss: 4.5460 - val_accuracy: 0.6689\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9481 - val_loss: 8.0654 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9556 - val_loss: 2.4745 - val_accuracy: 0.6733\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9602 - val_loss: 6.0302 - val_accuracy: 0.5067\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9606 - val_loss: 7.1474 - val_accuracy: 0.5578\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9495 - val_loss: 4.2220 - val_accuracy: 0.6711\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9662 - val_loss: 5.7910 - val_accuracy: 0.6556\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9616 - val_loss: 5.3338 - val_accuracy: 0.6400\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9671 - val_loss: 4.8224 - val_accuracy: 0.6489\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9593 - val_loss: 4.0353 - val_accuracy: 0.6133\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9579 - val_loss: 4.6581 - val_accuracy: 0.6200\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9630 - val_loss: 2.9671 - val_accuracy: 0.6844\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9653 - val_loss: 7.7402 - val_accuracy: 0.5356\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9731 - val_loss: 3.5121 - val_accuracy: 0.6822\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9616 - val_loss: 3.1046 - val_accuracy: 0.6978\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9708 - val_loss: 3.4893 - val_accuracy: 0.6689\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9773 - val_loss: 5.8836 - val_accuracy: 0.5711\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.9722 - val_loss: 4.8998 - val_accuracy: 0.5244\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9699 - val_loss: 5.5110 - val_accuracy: 0.5733\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9773 - val_loss: 7.3223 - val_accuracy: 0.5400\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9750 - val_loss: 6.0343 - val_accuracy: 0.6378\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9727 - val_loss: 5.3707 - val_accuracy: 0.6911\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9769 - val_loss: 5.8526 - val_accuracy: 0.7022\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.9773 - val_loss: 3.5860 - val_accuracy: 0.6822\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9727 - val_loss: 7.2231 - val_accuracy: 0.4889\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9681 - val_loss: 4.8465 - val_accuracy: 0.6756\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0625 - accuracy: 0.9750 - val_loss: 5.7964 - val_accuracy: 0.6689\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9759 - val_loss: 6.3859 - val_accuracy: 0.6378\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9778 - val_loss: 6.4038 - val_accuracy: 0.6022\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9782 - val_loss: 4.1332 - val_accuracy: 0.6889\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9810 - val_loss: 6.1418 - val_accuracy: 0.6822\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 7.3681 - val_accuracy: 0.6356\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9778 - val_loss: 8.8784 - val_accuracy: 0.6622\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0616 - accuracy: 0.9773 - val_loss: 6.9393 - val_accuracy: 0.5556\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9741 - val_loss: 5.0061 - val_accuracy: 0.5978\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9778 - val_loss: 6.6092 - val_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9810 - val_loss: 5.1044 - val_accuracy: 0.6844\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0738 - accuracy: 0.9750 - val_loss: 7.6629 - val_accuracy: 0.6911\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.9782 - val_loss: 4.7530 - val_accuracy: 0.5889\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.9778 - val_loss: 8.3069 - val_accuracy: 0.7000\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9847 - val_loss: 7.8512 - val_accuracy: 0.6800\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 8.5388 - val_accuracy: 0.7000\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9787 - val_loss: 5.3624 - val_accuracy: 0.6311\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9824 - val_loss: 5.9878 - val_accuracy: 0.6489\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 6.7457 - val_accuracy: 0.6044\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0451 - accuracy: 0.9815 - val_loss: 6.2390 - val_accuracy: 0.6756\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9847 - val_loss: 9.3037 - val_accuracy: 0.5289\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9819 - val_loss: 6.4170 - val_accuracy: 0.6600\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9866 - val_loss: 7.2221 - val_accuracy: 0.6756\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9787 - val_loss: 8.6049 - val_accuracy: 0.4844\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9778 - val_loss: 6.9303 - val_accuracy: 0.6111\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9870 - val_loss: 10.3533 - val_accuracy: 0.6222\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9861 - val_loss: 5.8819 - val_accuracy: 0.6244\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9829 - val_loss: 6.6972 - val_accuracy: 0.6467\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9824 - val_loss: 8.2559 - val_accuracy: 0.6733\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9866 - val_loss: 7.9741 - val_accuracy: 0.6578\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 5.9349 - val_accuracy: 0.5067\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9866 - val_loss: 4.7517 - val_accuracy: 0.6533\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9843 - val_loss: 6.2378 - val_accuracy: 0.6333\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 5.8650 - val_accuracy: 0.6467\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9889 - val_loss: 7.7407 - val_accuracy: 0.6556\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9856 - val_loss: 12.3405 - val_accuracy: 0.5422\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9880 - val_loss: 6.8422 - val_accuracy: 0.6178\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 5.2957 - val_accuracy: 0.5867\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9819 - val_loss: 6.4186 - val_accuracy: 0.5133\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9889 - val_loss: 10.5245 - val_accuracy: 0.6356\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9843 - val_loss: 6.2257 - val_accuracy: 0.6200\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9875 - val_loss: 12.0979 - val_accuracy: 0.5933\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_238 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_238 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_239 (Conv2D)          (None, 25, 25, 12)        3576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_235 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_239 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_119 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 32)                55328     \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 60,107\n",
      "Trainable params: 60,017\n",
      "Non-trainable params: 90\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.1632 - accuracy: 0.3412 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0979 - accuracy: 0.3264 - val_loss: 1.0992 - val_accuracy: 0.3378\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0955 - accuracy: 0.3310 - val_loss: 1.1114 - val_accuracy: 0.2622\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0925 - accuracy: 0.3421 - val_loss: 1.1160 - val_accuracy: 0.3289\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0898 - accuracy: 0.3403 - val_loss: 1.1062 - val_accuracy: 0.3244\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0879 - accuracy: 0.3389 - val_loss: 1.1466 - val_accuracy: 0.2933\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0852 - accuracy: 0.3440 - val_loss: 1.1778 - val_accuracy: 0.3178\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0832 - accuracy: 0.3514 - val_loss: 1.1802 - val_accuracy: 0.3000\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0921 - accuracy: 0.3454 - val_loss: 1.1358 - val_accuracy: 0.3289\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0824 - accuracy: 0.3523 - val_loss: 1.1134 - val_accuracy: 0.3200\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0813 - accuracy: 0.3440 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0762 - accuracy: 0.3597 - val_loss: 1.1181 - val_accuracy: 0.3067\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0739 - accuracy: 0.3657 - val_loss: 1.1066 - val_accuracy: 0.3222\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0697 - accuracy: 0.3620 - val_loss: 1.1094 - val_accuracy: 0.3578\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0590 - accuracy: 0.3769 - val_loss: 1.6086 - val_accuracy: 0.3667\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0562 - accuracy: 0.3861 - val_loss: 1.1210 - val_accuracy: 0.4022\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0661 - accuracy: 0.3750 - val_loss: 1.0985 - val_accuracy: 0.3311\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.3884 - val_loss: 1.1540 - val_accuracy: 0.3467\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.0444 - accuracy: 0.3815 - val_loss: 1.1243 - val_accuracy: 0.3733\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0240 - accuracy: 0.4167 - val_loss: 1.0896 - val_accuracy: 0.3667\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0405 - accuracy: 0.4148 - val_loss: 2.0490 - val_accuracy: 0.3822\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0313 - accuracy: 0.4190 - val_loss: 1.0816 - val_accuracy: 0.4400\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9943 - accuracy: 0.4301 - val_loss: 1.1952 - val_accuracy: 0.4822\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9948 - accuracy: 0.4352 - val_loss: 1.4022 - val_accuracy: 0.3778\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9932 - accuracy: 0.4361 - val_loss: 1.8037 - val_accuracy: 0.4156\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9831 - accuracy: 0.4468 - val_loss: 1.2045 - val_accuracy: 0.4622\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9707 - accuracy: 0.4593 - val_loss: 1.0882 - val_accuracy: 0.4444\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9531 - accuracy: 0.4648 - val_loss: 1.7681 - val_accuracy: 0.3422\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9554 - accuracy: 0.4750 - val_loss: 1.1696 - val_accuracy: 0.4133\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9325 - accuracy: 0.4778 - val_loss: 1.1428 - val_accuracy: 0.4933\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9042 - accuracy: 0.5009 - val_loss: 1.7464 - val_accuracy: 0.5422\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9571 - accuracy: 0.4657 - val_loss: 1.2845 - val_accuracy: 0.4600\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9157 - accuracy: 0.4958 - val_loss: 1.3404 - val_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9075 - accuracy: 0.5032 - val_loss: 2.0157 - val_accuracy: 0.3778\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9055 - accuracy: 0.5060 - val_loss: 1.1917 - val_accuracy: 0.5844\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9092 - accuracy: 0.5046 - val_loss: 1.5244 - val_accuracy: 0.4667\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8855 - accuracy: 0.5181 - val_loss: 1.2495 - val_accuracy: 0.5489\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8941 - accuracy: 0.5097 - val_loss: 1.9828 - val_accuracy: 0.4800\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8783 - accuracy: 0.5236 - val_loss: 1.3096 - val_accuracy: 0.5267\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8892 - accuracy: 0.5236 - val_loss: 1.2225 - val_accuracy: 0.5578\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8759 - accuracy: 0.5347 - val_loss: 1.7008 - val_accuracy: 0.5089\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8695 - accuracy: 0.5310 - val_loss: 1.7978 - val_accuracy: 0.5156\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8602 - accuracy: 0.5343 - val_loss: 2.2422 - val_accuracy: 0.4533\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8845 - accuracy: 0.5389 - val_loss: 1.4209 - val_accuracy: 0.4933\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8536 - accuracy: 0.5486 - val_loss: 1.2349 - val_accuracy: 0.5267\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8546 - accuracy: 0.5505 - val_loss: 1.3207 - val_accuracy: 0.5356\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8245 - accuracy: 0.5634 - val_loss: 1.4209 - val_accuracy: 0.5111\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8241 - accuracy: 0.5759 - val_loss: 1.1419 - val_accuracy: 0.5067\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8168 - accuracy: 0.5718 - val_loss: 1.3255 - val_accuracy: 0.6089\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.5736 - val_loss: 1.1596 - val_accuracy: 0.5444\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7975 - accuracy: 0.5926 - val_loss: 1.6129 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8069 - accuracy: 0.5829 - val_loss: 1.9417 - val_accuracy: 0.5556\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7914 - accuracy: 0.5912 - val_loss: 1.0388 - val_accuracy: 0.5933\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.5801 - val_loss: 2.7562 - val_accuracy: 0.4756\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8041 - accuracy: 0.5792 - val_loss: 2.1571 - val_accuracy: 0.4911\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7696 - accuracy: 0.6037 - val_loss: 1.6395 - val_accuracy: 0.5889\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7924 - accuracy: 0.5875 - val_loss: 1.0898 - val_accuracy: 0.5689\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8067 - accuracy: 0.5843 - val_loss: 1.8707 - val_accuracy: 0.5622\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7760 - accuracy: 0.6005 - val_loss: 2.6441 - val_accuracy: 0.4489\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7984 - accuracy: 0.5810 - val_loss: 1.1035 - val_accuracy: 0.6244\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7970 - accuracy: 0.5852 - val_loss: 1.2270 - val_accuracy: 0.5867\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7753 - accuracy: 0.6028 - val_loss: 1.1490 - val_accuracy: 0.4956\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7832 - accuracy: 0.5958 - val_loss: 1.9335 - val_accuracy: 0.4667\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7855 - accuracy: 0.5880 - val_loss: 1.2300 - val_accuracy: 0.6133\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7830 - accuracy: 0.5991 - val_loss: 1.3025 - val_accuracy: 0.5444\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7941 - accuracy: 0.5931 - val_loss: 4.5602 - val_accuracy: 0.4111\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7765 - accuracy: 0.5977 - val_loss: 1.7669 - val_accuracy: 0.5578\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7781 - accuracy: 0.5968 - val_loss: 3.2070 - val_accuracy: 0.5244\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7691 - accuracy: 0.6079 - val_loss: 2.4832 - val_accuracy: 0.5311\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7519 - accuracy: 0.6139 - val_loss: 3.1331 - val_accuracy: 0.4778\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7709 - accuracy: 0.6069 - val_loss: 1.9117 - val_accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7597 - accuracy: 0.6139 - val_loss: 1.3941 - val_accuracy: 0.4978\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7703 - accuracy: 0.6079 - val_loss: 1.9507 - val_accuracy: 0.5800\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7743 - accuracy: 0.6037 - val_loss: 1.8168 - val_accuracy: 0.5356\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.6324 - val_loss: 2.2223 - val_accuracy: 0.5422\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7663 - accuracy: 0.6106 - val_loss: 2.2847 - val_accuracy: 0.5467\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7629 - accuracy: 0.6148 - val_loss: 2.4430 - val_accuracy: 0.4822\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7721 - accuracy: 0.6074 - val_loss: 1.8611 - val_accuracy: 0.5444\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7758 - accuracy: 0.6074 - val_loss: 2.8208 - val_accuracy: 0.5289\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7462 - accuracy: 0.6236 - val_loss: 1.8956 - val_accuracy: 0.5356\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7705 - accuracy: 0.6056 - val_loss: 2.8991 - val_accuracy: 0.5022\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7463 - accuracy: 0.6199 - val_loss: 2.1520 - val_accuracy: 0.5667\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7722 - accuracy: 0.6019 - val_loss: 3.2421 - val_accuracy: 0.5200\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7479 - accuracy: 0.6176 - val_loss: 1.7644 - val_accuracy: 0.5733\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.6208 - val_loss: 1.9917 - val_accuracy: 0.5889\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7580 - accuracy: 0.6130 - val_loss: 4.2848 - val_accuracy: 0.5133\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.6264 - val_loss: 3.5085 - val_accuracy: 0.5311\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.6306 - val_loss: 3.7119 - val_accuracy: 0.5067\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7611 - accuracy: 0.6134 - val_loss: 1.7373 - val_accuracy: 0.5467\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.6134 - val_loss: 1.5396 - val_accuracy: 0.6200\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7425 - accuracy: 0.6375 - val_loss: 2.8315 - val_accuracy: 0.5267\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.6194 - val_loss: 2.0809 - val_accuracy: 0.5556\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.6287 - val_loss: 4.3672 - val_accuracy: 0.4911\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.6269 - val_loss: 3.1165 - val_accuracy: 0.5200\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.6282 - val_loss: 1.8559 - val_accuracy: 0.5689\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7334 - accuracy: 0.6296 - val_loss: 1.2963 - val_accuracy: 0.5733\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.6208 - val_loss: 2.8202 - val_accuracy: 0.4622\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.6306 - val_loss: 2.3805 - val_accuracy: 0.5844\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7223 - accuracy: 0.6343 - val_loss: 1.9609 - val_accuracy: 0.5556\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.6241 - val_loss: 2.7404 - val_accuracy: 0.5511\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_240 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_236 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_240 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_241 (Conv2D)          (None, 25, 25, 12)        3576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_237 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_241 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_120 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 115,531\n",
      "Trainable params: 115,441\n",
      "Non-trainable params: 90\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 1.2485 - accuracy: 0.3611 - val_loss: 1.0997 - val_accuracy: 0.4089\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0382 - accuracy: 0.4213 - val_loss: 1.0952 - val_accuracy: 0.4289\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9903 - accuracy: 0.4597 - val_loss: 1.0640 - val_accuracy: 0.4689\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9412 - accuracy: 0.4824 - val_loss: 1.0475 - val_accuracy: 0.5178\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.9056 - accuracy: 0.5060 - val_loss: 1.0838 - val_accuracy: 0.4333\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8604 - accuracy: 0.5176 - val_loss: 1.3495 - val_accuracy: 0.3578\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8353 - accuracy: 0.5380 - val_loss: 1.2165 - val_accuracy: 0.5200\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.5366 - val_loss: 1.1232 - val_accuracy: 0.4267\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7605 - accuracy: 0.5870 - val_loss: 1.2948 - val_accuracy: 0.4867\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7811 - accuracy: 0.5560 - val_loss: 1.3984 - val_accuracy: 0.4867\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.5741 - val_loss: 1.4575 - val_accuracy: 0.4756\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.5958 - val_loss: 1.5218 - val_accuracy: 0.4511\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.6074 - val_loss: 1.0474 - val_accuracy: 0.4889\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7135 - accuracy: 0.6079 - val_loss: 1.4386 - val_accuracy: 0.4689\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7036 - accuracy: 0.6167 - val_loss: 1.8735 - val_accuracy: 0.4133\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6435 - val_loss: 1.6479 - val_accuracy: 0.5444\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.6278 - val_loss: 1.2775 - val_accuracy: 0.4733\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.6250 - val_loss: 2.2002 - val_accuracy: 0.4511\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6519 - val_loss: 1.8620 - val_accuracy: 0.4978\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.6398 - val_loss: 1.7781 - val_accuracy: 0.4622\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6491 - val_loss: 1.5249 - val_accuracy: 0.4822\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6417 - val_loss: 1.5939 - val_accuracy: 0.4822\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6560 - val_loss: 2.8445 - val_accuracy: 0.4267\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6435 - val_loss: 2.6207 - val_accuracy: 0.4556\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6690 - val_loss: 1.9373 - val_accuracy: 0.4156\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6870 - val_loss: 1.8021 - val_accuracy: 0.5156\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6810 - val_loss: 1.9499 - val_accuracy: 0.5400\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6755 - val_loss: 1.6051 - val_accuracy: 0.4422\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6833 - val_loss: 2.5549 - val_accuracy: 0.4289\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.6926 - val_loss: 4.7988 - val_accuracy: 0.3600\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7157 - val_loss: 2.5200 - val_accuracy: 0.4889\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7005 - val_loss: 4.4554 - val_accuracy: 0.4178\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7125 - val_loss: 2.9885 - val_accuracy: 0.4711\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7153 - val_loss: 2.5392 - val_accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7301 - val_loss: 2.1455 - val_accuracy: 0.5111\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7292 - val_loss: 2.2658 - val_accuracy: 0.4733\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7208 - val_loss: 2.5740 - val_accuracy: 0.4667\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7190 - val_loss: 3.2066 - val_accuracy: 0.4333\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7287 - val_loss: 3.1033 - val_accuracy: 0.4778\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7486 - val_loss: 3.2513 - val_accuracy: 0.4600\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7472 - val_loss: 4.0203 - val_accuracy: 0.4444\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7440 - val_loss: 3.9553 - val_accuracy: 0.4533\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7440 - val_loss: 2.9580 - val_accuracy: 0.5778\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7634 - val_loss: 2.5810 - val_accuracy: 0.4933\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7500 - val_loss: 2.9586 - val_accuracy: 0.5133\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4811 - accuracy: 0.7699 - val_loss: 2.8970 - val_accuracy: 0.5556\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7653 - val_loss: 3.2874 - val_accuracy: 0.5644\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7616 - val_loss: 3.6102 - val_accuracy: 0.4956\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7727 - val_loss: 5.8135 - val_accuracy: 0.4400\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7671 - val_loss: 2.8014 - val_accuracy: 0.4867\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7750 - val_loss: 3.1893 - val_accuracy: 0.4978\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7843 - val_loss: 5.4856 - val_accuracy: 0.4044\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8019 - val_loss: 3.5896 - val_accuracy: 0.4800\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7935 - val_loss: 4.5129 - val_accuracy: 0.4622\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8083 - val_loss: 4.9429 - val_accuracy: 0.4489\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7972 - val_loss: 5.0060 - val_accuracy: 0.4489\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7949 - val_loss: 3.7565 - val_accuracy: 0.4867\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8111 - val_loss: 6.2007 - val_accuracy: 0.4444\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8097 - val_loss: 5.3282 - val_accuracy: 0.4289\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8083 - val_loss: 3.5842 - val_accuracy: 0.5044\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8236 - val_loss: 4.2702 - val_accuracy: 0.4444\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8245 - val_loss: 3.4352 - val_accuracy: 0.5178\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8144 - val_loss: 3.8077 - val_accuracy: 0.5444\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8157 - val_loss: 11.9222 - val_accuracy: 0.3667\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8241 - val_loss: 4.0829 - val_accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8426 - val_loss: 3.8230 - val_accuracy: 0.4911\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8440 - val_loss: 3.7192 - val_accuracy: 0.5133\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8241 - val_loss: 3.0865 - val_accuracy: 0.6178\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8208 - val_loss: 14.2614 - val_accuracy: 0.3578\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8347 - val_loss: 4.2352 - val_accuracy: 0.5067\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8468 - val_loss: 3.5503 - val_accuracy: 0.5689\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8426 - val_loss: 4.5827 - val_accuracy: 0.4733\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8472 - val_loss: 6.0816 - val_accuracy: 0.4667\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8519 - val_loss: 4.7898 - val_accuracy: 0.5044\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8472 - val_loss: 4.5568 - val_accuracy: 0.4933\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8495 - val_loss: 5.3862 - val_accuracy: 0.4889\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8625 - val_loss: 5.6184 - val_accuracy: 0.4844\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8569 - val_loss: 4.1146 - val_accuracy: 0.5556\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8690 - val_loss: 7.1380 - val_accuracy: 0.4444\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8588 - val_loss: 5.8326 - val_accuracy: 0.4333\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8532 - val_loss: 6.2119 - val_accuracy: 0.4489\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8569 - val_loss: 5.6628 - val_accuracy: 0.4778\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8694 - val_loss: 5.0666 - val_accuracy: 0.5200\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8764 - val_loss: 8.5397 - val_accuracy: 0.4378\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8884 - val_loss: 10.1430 - val_accuracy: 0.4289\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8838 - val_loss: 5.1165 - val_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2579 - accuracy: 0.8986 - val_loss: 5.3006 - val_accuracy: 0.6000\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8708 - val_loss: 4.4256 - val_accuracy: 0.5244\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8718 - val_loss: 5.9173 - val_accuracy: 0.5444\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8764 - val_loss: 7.1636 - val_accuracy: 0.4822\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8843 - val_loss: 6.6137 - val_accuracy: 0.5378\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8801 - val_loss: 10.2013 - val_accuracy: 0.4200\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.8801 - val_loss: 8.0949 - val_accuracy: 0.4311\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8778 - val_loss: 6.1922 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8917 - val_loss: 8.1334 - val_accuracy: 0.4511\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.8949 - val_loss: 6.9480 - val_accuracy: 0.4933\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8875 - val_loss: 5.1474 - val_accuracy: 0.4778\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.8898 - val_loss: 7.7662 - val_accuracy: 0.4556\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.8741 - val_loss: 8.2546 - val_accuracy: 0.4489\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9083 - val_loss: 6.3140 - val_accuracy: 0.5333\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_242 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_238 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_238 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_242 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_243 (Conv2D)          (None, 25, 25, 12)        3576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_243 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_121 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 226,379\n",
      "Trainable params: 226,289\n",
      "Non-trainable params: 90\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 1.2482 - accuracy: 0.4023 - val_loss: 1.1063 - val_accuracy: 0.2933\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.9666 - accuracy: 0.4806 - val_loss: 1.1082 - val_accuracy: 0.3578\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8778 - accuracy: 0.5366 - val_loss: 1.1350 - val_accuracy: 0.5022\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.5630 - val_loss: 1.1679 - val_accuracy: 0.4422\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7828 - accuracy: 0.5912 - val_loss: 1.8087 - val_accuracy: 0.4356\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.6069 - val_loss: 1.4329 - val_accuracy: 0.4489\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7142 - accuracy: 0.6148 - val_loss: 2.3666 - val_accuracy: 0.3933\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.6338 - val_loss: 1.5538 - val_accuracy: 0.5067\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.6361 - val_loss: 2.1619 - val_accuracy: 0.4756\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6759 - val_loss: 1.8932 - val_accuracy: 0.4600\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6713 - val_loss: 2.2553 - val_accuracy: 0.4956\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.6921 - val_loss: 2.6635 - val_accuracy: 0.3733\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7218 - val_loss: 4.8949 - val_accuracy: 0.4022\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7088 - val_loss: 2.9637 - val_accuracy: 0.4778\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5054 - accuracy: 0.7269 - val_loss: 1.5529 - val_accuracy: 0.4533\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7296 - val_loss: 1.4663 - val_accuracy: 0.5444\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7514 - val_loss: 2.6371 - val_accuracy: 0.4111\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7569 - val_loss: 1.9033 - val_accuracy: 0.5622\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7708 - val_loss: 2.2281 - val_accuracy: 0.4956\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.4266 - accuracy: 0.7810 - val_loss: 2.7985 - val_accuracy: 0.5178\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7815 - val_loss: 4.0472 - val_accuracy: 0.4422\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7838 - val_loss: 11.9055 - val_accuracy: 0.3378\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.7977 - val_loss: 2.5680 - val_accuracy: 0.4978\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8102 - val_loss: 2.9268 - val_accuracy: 0.4978\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8194 - val_loss: 3.5165 - val_accuracy: 0.5067\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8120 - val_loss: 6.7061 - val_accuracy: 0.3933\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8315 - val_loss: 2.6165 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8301 - val_loss: 3.4203 - val_accuracy: 0.4600\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8528 - val_loss: 3.5339 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8333 - val_loss: 4.5266 - val_accuracy: 0.4444\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8551 - val_loss: 3.6069 - val_accuracy: 0.4622\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8491 - val_loss: 4.3053 - val_accuracy: 0.5533\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2445 - accuracy: 0.8722 - val_loss: 9.9905 - val_accuracy: 0.3578\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8537 - val_loss: 3.3124 - val_accuracy: 0.4711\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8583 - val_loss: 3.4574 - val_accuracy: 0.4911\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8514 - val_loss: 6.1110 - val_accuracy: 0.4200\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.8745 - val_loss: 5.6682 - val_accuracy: 0.4956\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.8736 - val_loss: 7.6409 - val_accuracy: 0.4200\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.8819 - val_loss: 6.9543 - val_accuracy: 0.3956\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.8907 - val_loss: 5.0715 - val_accuracy: 0.4867\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2401 - accuracy: 0.8787 - val_loss: 7.6172 - val_accuracy: 0.3933\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.8921 - val_loss: 3.8764 - val_accuracy: 0.5289\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2149 - accuracy: 0.8921 - val_loss: 5.2215 - val_accuracy: 0.4844\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2080 - accuracy: 0.8880 - val_loss: 9.1250 - val_accuracy: 0.3911\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2173 - accuracy: 0.9009 - val_loss: 4.9018 - val_accuracy: 0.4844\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9056 - val_loss: 6.0983 - val_accuracy: 0.4533\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9042 - val_loss: 7.8875 - val_accuracy: 0.4289\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.9120 - val_loss: 5.1082 - val_accuracy: 0.4867\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1669 - accuracy: 0.9185 - val_loss: 5.6334 - val_accuracy: 0.5044\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9116 - val_loss: 11.0809 - val_accuracy: 0.3778\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1611 - accuracy: 0.9194 - val_loss: 5.0404 - val_accuracy: 0.5111\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9167 - val_loss: 8.1467 - val_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9236 - val_loss: 5.8000 - val_accuracy: 0.4778\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9236 - val_loss: 6.6506 - val_accuracy: 0.5022\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1624 - accuracy: 0.9250 - val_loss: 8.4609 - val_accuracy: 0.4733\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9236 - val_loss: 12.7149 - val_accuracy: 0.3644\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9292 - val_loss: 5.4506 - val_accuracy: 0.5178\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9370 - val_loss: 6.4051 - val_accuracy: 0.5089\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9273 - val_loss: 7.4654 - val_accuracy: 0.4844\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9241 - val_loss: 10.1899 - val_accuracy: 0.4289\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9389 - val_loss: 6.6469 - val_accuracy: 0.4956\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.9343 - val_loss: 7.3740 - val_accuracy: 0.5222\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9329 - val_loss: 6.6808 - val_accuracy: 0.5467\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9324 - val_loss: 10.9755 - val_accuracy: 0.4311\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9407 - val_loss: 10.4809 - val_accuracy: 0.4067\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9417 - val_loss: 10.5276 - val_accuracy: 0.4689\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9403 - val_loss: 9.6439 - val_accuracy: 0.5089\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9398 - val_loss: 6.8905 - val_accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9287 - val_loss: 8.4312 - val_accuracy: 0.4267\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9505 - val_loss: 13.1811 - val_accuracy: 0.3600\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1260 - accuracy: 0.9440 - val_loss: 7.0958 - val_accuracy: 0.5467\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1213 - accuracy: 0.9440 - val_loss: 8.4790 - val_accuracy: 0.5267\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9440 - val_loss: 8.1628 - val_accuracy: 0.4978\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9509 - val_loss: 8.1401 - val_accuracy: 0.5200\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9509 - val_loss: 8.8203 - val_accuracy: 0.5289\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1042 - accuracy: 0.9514 - val_loss: 17.0111 - val_accuracy: 0.3600\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9519 - val_loss: 10.5853 - val_accuracy: 0.3978\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1056 - accuracy: 0.9468 - val_loss: 8.4358 - val_accuracy: 0.5244\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9468 - val_loss: 7.2370 - val_accuracy: 0.4778\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9403 - val_loss: 10.2146 - val_accuracy: 0.4711\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9421 - val_loss: 6.9609 - val_accuracy: 0.5644\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9505 - val_loss: 10.8606 - val_accuracy: 0.4422\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9509 - val_loss: 17.2120 - val_accuracy: 0.3533\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9583 - val_loss: 11.7095 - val_accuracy: 0.4911\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9477 - val_loss: 9.9358 - val_accuracy: 0.4956\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9468 - val_loss: 7.7466 - val_accuracy: 0.5511\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9542 - val_loss: 9.2286 - val_accuracy: 0.5067\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9657 - val_loss: 15.1321 - val_accuracy: 0.3689\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9616 - val_loss: 9.9836 - val_accuracy: 0.4533\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9602 - val_loss: 13.1988 - val_accuracy: 0.4689\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9565 - val_loss: 8.7915 - val_accuracy: 0.4822\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9639 - val_loss: 9.5457 - val_accuracy: 0.4489\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9630 - val_loss: 15.3657 - val_accuracy: 0.3956\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0757 - accuracy: 0.9699 - val_loss: 14.3867 - val_accuracy: 0.4022\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0869 - accuracy: 0.9690 - val_loss: 10.3386 - val_accuracy: 0.5289\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0780 - accuracy: 0.9653 - val_loss: 11.9901 - val_accuracy: 0.4556\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9713 - val_loss: 9.7959 - val_accuracy: 0.4622\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9634 - val_loss: 18.9577 - val_accuracy: 0.3911\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9602 - val_loss: 12.2720 - val_accuracy: 0.4356\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9722 - val_loss: 10.8751 - val_accuracy: 0.4444\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_244 (Conv2D)          (None, 54, 54, 33)        924       \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 54, 54, 33)        132       \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 54, 54, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_244 (MaxPoolin (None, 27, 27, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_245 (Conv2D)          (None, 25, 25, 12)        3576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 25, 25, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 25, 25, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_245 (MaxPoolin (None, 12, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_122 (Flatten)        (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 256)               442624    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 448,075\n",
      "Trainable params: 447,985\n",
      "Non-trainable params: 90\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 1.4837 - accuracy: 0.4213 - val_loss: 1.1038 - val_accuracy: 0.3667\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.9285 - accuracy: 0.5444 - val_loss: 1.0967 - val_accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.8208 - accuracy: 0.6042 - val_loss: 1.1064 - val_accuracy: 0.4711\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.6653 - val_loss: 1.1849 - val_accuracy: 0.3956\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.7176 - val_loss: 1.0378 - val_accuracy: 0.4489\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5999 - accuracy: 0.7231 - val_loss: 1.4732 - val_accuracy: 0.4556\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5666 - accuracy: 0.7588 - val_loss: 1.9820 - val_accuracy: 0.4489\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.5034 - accuracy: 0.7778 - val_loss: 1.3767 - val_accuracy: 0.4311\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7907 - val_loss: 1.2660 - val_accuracy: 0.3400\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8116 - val_loss: 1.2706 - val_accuracy: 0.3911\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8148 - val_loss: 2.1847 - val_accuracy: 0.4578\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8449 - val_loss: 1.4765 - val_accuracy: 0.4733\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3549 - accuracy: 0.8463 - val_loss: 1.7216 - val_accuracy: 0.4178\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8477 - val_loss: 1.6297 - val_accuracy: 0.4400\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8657 - val_loss: 1.9148 - val_accuracy: 0.5089\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8722 - val_loss: 2.1247 - val_accuracy: 0.5289\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.8727 - val_loss: 4.0839 - val_accuracy: 0.4489\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8852 - val_loss: 5.5971 - val_accuracy: 0.4111\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.8866 - val_loss: 3.9147 - val_accuracy: 0.4378\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.8991 - val_loss: 10.4027 - val_accuracy: 0.3489\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2411 - accuracy: 0.8991 - val_loss: 2.3448 - val_accuracy: 0.4844\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.8907 - val_loss: 2.4429 - val_accuracy: 0.4378\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9019 - val_loss: 3.7200 - val_accuracy: 0.4089\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9167 - val_loss: 2.2783 - val_accuracy: 0.4222\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9125 - val_loss: 3.0827 - val_accuracy: 0.4644\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2345 - accuracy: 0.9032 - val_loss: 2.5719 - val_accuracy: 0.4511\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9227 - val_loss: 3.5670 - val_accuracy: 0.4378\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1724 - accuracy: 0.9315 - val_loss: 3.5672 - val_accuracy: 0.4222\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9296 - val_loss: 3.3181 - val_accuracy: 0.5289\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9162 - val_loss: 2.9855 - val_accuracy: 0.4067\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.9292 - val_loss: 4.8988 - val_accuracy: 0.4444\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9236 - val_loss: 3.2886 - val_accuracy: 0.4756\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9292 - val_loss: 6.2114 - val_accuracy: 0.4378\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9454 - val_loss: 5.3089 - val_accuracy: 0.4689\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1332 - accuracy: 0.9468 - val_loss: 10.2571 - val_accuracy: 0.3422\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9389 - val_loss: 4.7456 - val_accuracy: 0.3956\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9417 - val_loss: 4.2963 - val_accuracy: 0.4222\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9449 - val_loss: 4.7765 - val_accuracy: 0.5111\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9421 - val_loss: 6.1137 - val_accuracy: 0.4600\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9343 - val_loss: 6.4671 - val_accuracy: 0.4667\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1119 - accuracy: 0.9514 - val_loss: 6.7949 - val_accuracy: 0.4422\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9491 - val_loss: 14.7510 - val_accuracy: 0.3511\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9454 - val_loss: 5.6082 - val_accuracy: 0.4511\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1112 - accuracy: 0.9500 - val_loss: 5.9281 - val_accuracy: 0.4511\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9486 - val_loss: 5.8846 - val_accuracy: 0.4600\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9597 - val_loss: 8.3445 - val_accuracy: 0.4067\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9579 - val_loss: 11.0020 - val_accuracy: 0.3933\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9569 - val_loss: 4.6511 - val_accuracy: 0.4622\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9579 - val_loss: 7.4334 - val_accuracy: 0.5067\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9597 - val_loss: 5.3711 - val_accuracy: 0.4511\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9685 - val_loss: 14.4655 - val_accuracy: 0.3622\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9625 - val_loss: 5.2324 - val_accuracy: 0.5444\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9616 - val_loss: 6.1522 - val_accuracy: 0.4333\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9657 - val_loss: 5.2472 - val_accuracy: 0.4622\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9667 - val_loss: 9.3290 - val_accuracy: 0.4533\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9653 - val_loss: 6.7434 - val_accuracy: 0.3978\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9639 - val_loss: 7.2448 - val_accuracy: 0.4044\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9727 - val_loss: 7.6322 - val_accuracy: 0.4311\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9708 - val_loss: 5.8165 - val_accuracy: 0.4267\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9727 - val_loss: 8.2745 - val_accuracy: 0.4089\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9713 - val_loss: 9.3974 - val_accuracy: 0.4111\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9745 - val_loss: 6.2901 - val_accuracy: 0.4378\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9731 - val_loss: 7.4323 - val_accuracy: 0.4533\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9704 - val_loss: 6.7958 - val_accuracy: 0.4822\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9718 - val_loss: 12.0446 - val_accuracy: 0.3956\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9667 - val_loss: 7.6937 - val_accuracy: 0.4244\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9727 - val_loss: 6.5166 - val_accuracy: 0.4400\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9755 - val_loss: 4.5459 - val_accuracy: 0.4800\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9815 - val_loss: 5.9683 - val_accuracy: 0.4533\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9681 - val_loss: 5.4657 - val_accuracy: 0.5200\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9745 - val_loss: 8.5015 - val_accuracy: 0.4822\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9787 - val_loss: 7.5629 - val_accuracy: 0.4533\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9792 - val_loss: 6.2802 - val_accuracy: 0.4911\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9773 - val_loss: 6.7571 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9676 - val_loss: 14.1717 - val_accuracy: 0.4156\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9731 - val_loss: 6.8199 - val_accuracy: 0.4711\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9755 - val_loss: 7.7570 - val_accuracy: 0.4156\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 6.9469 - val_accuracy: 0.5022\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 7.2930 - val_accuracy: 0.3956\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9727 - val_loss: 8.8213 - val_accuracy: 0.4422\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9773 - val_loss: 8.0170 - val_accuracy: 0.4867\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 7.9000 - val_accuracy: 0.4889\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.0451 - accuracy: 0.9829 - val_loss: 12.4169 - val_accuracy: 0.4356\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 7.2084 - val_accuracy: 0.4556\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9801 - val_loss: 7.1872 - val_accuracy: 0.4311\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9838 - val_loss: 11.3288 - val_accuracy: 0.4444\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.9838 - val_loss: 17.0418 - val_accuracy: 0.3978\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9806 - val_loss: 12.2940 - val_accuracy: 0.4333\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9806 - val_loss: 6.4976 - val_accuracy: 0.5311\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9843 - val_loss: 13.9418 - val_accuracy: 0.4533\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9792 - val_loss: 12.9699 - val_accuracy: 0.4311\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9847 - val_loss: 6.9384 - val_accuracy: 0.4400\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9801 - val_loss: 8.3554 - val_accuracy: 0.4067\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9856 - val_loss: 10.6009 - val_accuracy: 0.4578\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9824 - val_loss: 11.5642 - val_accuracy: 0.4511\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9755 - val_loss: 8.4698 - val_accuracy: 0.4467\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 8.3782 - val_accuracy: 0.4022\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9819 - val_loss: 10.6057 - val_accuracy: 0.4267\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9810 - val_loss: 7.7106 - val_accuracy: 0.4711\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 8.6446 - val_accuracy: 0.5156\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=[3*i for i in range(6,12)]\n",
    "n_channel_2=[2*i for i in range(4,7)]\n",
    "n_dense=[2**i for i in range(5,9)]\n",
    "\n",
    "n_train_epoch=100\n",
    "dropout_rate=0.8\n",
    "lrs=0.001\n",
    "batch_size=16\n",
    "\n",
    "acc_2={}\n",
    "for i in n_channel_1:\n",
    "    for j in n_channel_2:\n",
    "        for k in n_dense: #n_channel_1, n_channel_2, n_dense, dropout_rate,n_train_epoch,batch_size,lr\n",
    "            history=model1(i, j, k, dropout_rate,n_train_epoch,batch_size,lrs)\n",
    "            acc_2[f\"{i}-{j}-{k}\"]=history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc7944c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_ch_1</th>\n",
       "      <th>n_ch_2</th>\n",
       "      <th>n_dense</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.704444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.702222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>256</td>\n",
       "      <td>0.682222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.675556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.671111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.668889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.664444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_ch_1 n_ch_2 n_dense       acc\n",
       "49     30      8      64  0.704444\n",
       "67     33     10     256  0.702222\n",
       "15     21      8     256  0.686667\n",
       "35     24     12     256  0.682222\n",
       "36     27      8      32  0.675556\n",
       "26     24      8     128  0.671111\n",
       "66     33     10     128  0.668889\n",
       "53     30     10      64  0.664444"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_list=[]\n",
    "for i in acc_2.keys():\n",
    "    dict_list.append(find_acc(acc_2,i,(\"n_ch_1\",\"n_ch_2\",\"n_dense\")))\n",
    "    \n",
    "acc2_df=pd.DataFrame(dict_list) \n",
    "acc2_df.loc[acc2_df[\"acc\"]>0.664444].sort_values(\"acc\", ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45019a9",
   "metadata": {},
   "source": [
    "learning rate와 dropout 비율, 배치사이즈를 튜닝한 모델의 최고 성능인 0.664444 비해 최대 0.04가량 accuracy가 올라간 것을 확인 할수 있었다. 사실 처음에 맞추었던 filter의 개수와 은닉층의 노드수는 mnist를 분류할때 사용했던 값들이었다. 그러니까 숫자에 비해 이미지의 디테일이 많은 손 이미지를 학습하기에는 필터의 개수가 부족했던 것이다.  \n",
    "\n",
    "일단 딥러닝 학습에 핵심이 되는 학습율과 배치사이즈를 조절하는 것이 모델의 성능을 판단하는데 중요할 것으로 예상되어 먼저 튜닝을 하였고 이렇게 튜닝한 값이 베이스모델보다 성능이 좋은 정확도들이 __학습율 0.001, 배치 사이즈 16 그리고 dropout 0.8 부근__ 으로 수렴을 한 것을 볼 수 있었다.  \n",
    "\n",
    "- 그래서 이 값을 기준으로 필터의 수와 은닉층의 출력 노드 수를 조절하니까 accuracy가 위에 보는 것처럼 개선이 된 것을 볼 수 있었다.\n",
    "- 다음은 가장 성능이 좋았던 두개의 조합의 loss와 accuracy를 그래프로 그려보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcb56b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first=pd.DataFrame(acc_2[\"30-8-64\"].history)\n",
    "second=pd.DataFrame(acc_2[\"33-10-256\"].history)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(first[\"val_accuracy\"])\n",
    "plt.plot(first[\"accuracy\"])\n",
    "plt.title(\"n_ch_1:30, n_ch_2:8 ,n_dense:64\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(second[\"val_accuracy\"])\n",
    "plt.plot(second[\"accuracy\"])\n",
    "plt.title(\"n_ch_1:33, n_ch_2:10 ,n_dense:256\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(first[\"val_loss\"])\n",
    "plt.plot(first[\"loss\"])\n",
    "plt.title(\"n_ch_1:30, n_ch_2:8 ,n_dense:64\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(second[\"val_loss\"])\n",
    "plt.plot(second[\"loss\"])\n",
    "plt.title(\"n_ch_1:33, n_ch_2:10 ,n_dense:256\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87782eeb",
   "metadata": {},
   "source": [
    "- 베이스 모델의 오버피팅이 심해서 dropout, batch normalization을 적용하고, learning rate, batch size, dropout rate를 튜닝하였으나 오버피팅이 생각만큼 개선되지 않은 것이 다소 실망스러웠으나 그 중에 가장 좋은 하이퍼파라미터 값으로 나머지 하이퍼파라미터 값을 튜닝해보니 그래도 베이스 모델보다는 오버피팅이 개선된 것을 볼 수 있었다. \n",
    "- 다만 테스트 데이터셋의 이미지가 상대적으로 적고, 다양성이 충분하지 않아서 loss와 accuracy가 안정적이지 못한 것이 아쉽다  \n",
    "\n",
    "두 그래프의 왼쪽 모델은 epoch가 6일때 가장 좋은 성능이 나왔고, 오른쪽의 모델은 epoch이 54일때 가장 좋은 성능이 나왔다. 즉 학습을 오래 시킨다고 능사가 아님을 알수 있었다. 학습을 오래 시키면 시킬수록 오히려 성능이 떨어지게 된다는 것을 알 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ac1d843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.728841</td>\n",
       "      <td>0.627315</td>\n",
       "      <td>0.966513</td>\n",
       "      <td>0.704444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "6  0.728841  0.627315  0.966513      0.704444"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=pd.DataFrame(acc_2[\"30-8-64\"].history)\n",
    "f.loc[f[\"val_accuracy\"]>0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97568e9",
   "metadata": {},
   "source": [
    "### 사실 이 과제를 내기 전에 하나의 에피소드가 있었다.\n",
    "\n",
    "- exploration01을 하고 난후 exploration02를 마친 뒤에 이 과제를 시작을 해서 당연하게 validation을 해야한다고 생각하고 다음과 같이 학습데이터셋에서 validation 데이터를 분리해낸 다음 결과를 보니까 다음과 같은 결과가 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72c5418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val= train_test_split(x_train_reshaped, y_train, stratify=y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cd787f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def re_model(n_channel_1, n_channel_2, n_dense, n_train_epoch):\n",
    "\n",
    "    model=keras.models.Sequential() # 시퀀스형 \n",
    "    model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation=\"relu\", input_shape=(56,56,3))) \n",
    "    model.add(keras.layers.MaxPool2D(2,2))\n",
    "    model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # 모델 훈련\n",
    "    history=model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=n_train_epoch)\n",
    "    # 모델 시험\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "021a34df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_250 (Conv2D)          (None, 54, 54, 10)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_250 (MaxPoolin (None, 27, 27, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_251 (Conv2D)          (None, 25, 25, 32)        2912      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_251 (MaxPoolin (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_125 (Flatten)        (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 150,779\n",
      "Trainable params: 150,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "54/54 [==============================] - 1s 6ms/step - loss: 1.0679 - accuracy: 0.4167 - val_loss: 0.9731 - val_accuracy: 0.4954\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9130 - accuracy: 0.5700 - val_loss: 0.8063 - val_accuracy: 0.6736\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.6950 - val_loss: 0.6499 - val_accuracy: 0.7199\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7708 - val_loss: 0.5306 - val_accuracy: 0.7824\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.8044 - val_loss: 0.5521 - val_accuracy: 0.7639\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8333 - val_loss: 0.4290 - val_accuracy: 0.8264\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8547 - val_loss: 0.4247 - val_accuracy: 0.8194\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8692 - val_loss: 0.3537 - val_accuracy: 0.8472\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8999 - val_loss: 0.2873 - val_accuracy: 0.8843\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9144 - val_loss: 0.2986 - val_accuracy: 0.8727\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9306 - val_loss: 0.2437 - val_accuracy: 0.9144\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9323 - val_loss: 0.2330 - val_accuracy: 0.9190\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9525 - val_loss: 0.1913 - val_accuracy: 0.9306\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9624 - val_loss: 0.2022 - val_accuracy: 0.9329\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1213 - accuracy: 0.9606 - val_loss: 0.1725 - val_accuracy: 0.9468\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9711 - val_loss: 0.1961 - val_accuracy: 0.9375\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9728 - val_loss: 0.1658 - val_accuracy: 0.9514\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9809 - val_loss: 0.2297 - val_accuracy: 0.9213\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9757 - val_loss: 0.1694 - val_accuracy: 0.9491\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9850 - val_loss: 0.1751 - val_accuracy: 0.9468\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9844 - val_loss: 0.1409 - val_accuracy: 0.9560\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9890 - val_loss: 0.1650 - val_accuracy: 0.9514\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9919 - val_loss: 0.1319 - val_accuracy: 0.9699\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9959 - val_loss: 0.1547 - val_accuracy: 0.9653\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9931 - val_loss: 0.1341 - val_accuracy: 0.9583\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.1438 - val_accuracy: 0.9583\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9971 - val_loss: 0.1538 - val_accuracy: 0.9653\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9983 - val_loss: 0.1456 - val_accuracy: 0.9653\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9988 - val_loss: 0.1561 - val_accuracy: 0.9653\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 0.1624 - val_accuracy: 0.9653\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9965 - val_loss: 0.1713 - val_accuracy: 0.9583\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9988 - val_loss: 0.1900 - val_accuracy: 0.9653\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.1704 - val_accuracy: 0.9676\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.1533 - val_accuracy: 0.9653\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9699\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9630\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.2083 - val_accuracy: 0.9444\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 0.1833 - val_accuracy: 0.9514\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.1796 - val_accuracy: 0.9583\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9919 - val_loss: 0.2761 - val_accuracy: 0.9421\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.2605 - val_accuracy: 0.9560\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9612 - val_loss: 0.2076 - val_accuracy: 0.9421\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.1981 - val_accuracy: 0.9583\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.1919 - val_accuracy: 0.9653\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9699\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9676\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9699\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9676\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9699\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9676\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=10\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=50\n",
    "\n",
    "model_=re_model(n_channel_1, n_channel_2, n_dense, n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4778a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model_.history.history).plot()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1),loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bdb13957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 12.3820 - accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.381986618041992, 0.5555555820465088]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.evaluate(x_test_reshaped, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c2a5d",
   "metadata": {},
   "source": [
    "__결과__ 적으로 validation set의 성능은 매우 높아서 그대로 테스트 데이터셋에 성능을 비교해보니 0.55의 정확도를 갖는 것을 확인했다. \n",
    "\n",
    "검증데이터셋(validation dataset)이 학습데이터셋에서 나오다보니 같은 사람의 손으로 학습을 해서 같은 사람의 손으로 검증을 하게 되었다. 그래서 베이스모델에서 더 이상 수정할 필요가 없이 성능이 잘 나온 것을 판단된다. 그래서 학습데이터와 다른 이미지인 테스트 데이터셋의 예측성능이 떨어지게 된 것으로 판단된다.  \n",
    "\n",
    "일단 이번 과제를 통해서 __하이퍼파라미터 튜닝__ 을 하여서 모델 성능을 개선 시키는 경험을 하고자 했던 목표가 있었기 때문에 어쩔수 없이 테스트 데이터셋으로 튜닝을 진행했다. \n",
    "\n",
    "\n",
    "----------------------------------------------------------\n",
    "### 3. 회고\n",
    "\n",
    "0. 그 전에 회사에서 데이터를 수집하고 레이블링하는 업무가 주가 되었다.  직접 딥러닝 모델을 구성하고 튜닝하는 것을 경험하고 싶었지만 어디에서 시작해야할지 엄두를 못내고 있다가 아이펠에서 처음으로 딥러닝 모델을 전반적으로 구성하는 경험이었기에 앞으로의 동기부여가 될 경험이라고 생각했다.\n",
    "\n",
    "1. 결과적으로 베이스모델이 0.6 정도의 성능을 보였었는데 다양한 최적화 방법을 사용해서 오버피팅을 방지하여 __성능이 0.7__ 으로 높여보는 경험을 해본 것은 좋았다. 하지만 앞으로 딥러닝 모델을 만들기 위해서는 가급적이면 많은 양의 데이터를 다양하게 수집을 해서 이렇게 검증데이터셋만으로도 모델 튜닝을 할수 있는 환경을 조성하는게 좋은 모델을 만드는데 첫걸음이라는 것을 느꼈다.\n",
    "\n",
    "2. 그리고 모델의 구조를 만드는데 좀 더 중요하다고 생각되어진 학습률, 배치사이즈, 드롭아웃 비율을 튜닝했는데 생각보다 성능이 많이 개선되지 않아서 실망했었지만, 그 중에서도 가장 좋은 것을 갖고 다시 다른 하이퍼파라미터들을 튜닝을 시도한 결과 모델 성능이 개선되는 경험에서 희열이 느껴졌다. 딥러닝 모델은 하이퍼파라미터를 미세하게 조정하는데서 모델성능이 좌우된다는 말은 들어봤지만 실제로 미묘한 차이로 성능이 개선되는 것을 보면서 개념적으로만 이해하고 있던 손실함수가 실체적으로 느껴졌다.\n",
    "3. 구불구불 하게 있는데 여러가지 하이퍼파라미터들을 조합하면서 손실이 가장 낮은 지점을 찾아가는 것 같았다.\n",
    "4. 그리고 일단 과제를 하기 위해서 빠르게 코드를 짜느라고 기존에 익숙했던 코드 방식으로 절차적 프로그래밍 중심으로 코드를 구성했는데 앞으로는 클래스로 이 일련의 과정을 축약할 수 있는 방법을 고민해봐야겠다는 생각을 했다. 반복되는 코드들이 많아서 앞으로 프로젝트를 하면서 유용하게 쓰일 것 같은 코드들이 일종의 자산이 될 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
