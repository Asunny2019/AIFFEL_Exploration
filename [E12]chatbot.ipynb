{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [E12] 트랜스포머로 만드는 대화형 챗봇\n",
    "\n",
    "### 학습목표\n",
    "------------\n",
    "- 트랜스포머의 인코더 디코더 구조 이해하기\n",
    "- 내부 단어 토크나이저 사용하기\n",
    "- 셀프 어텐션 이해하기\n",
    "- 한국어에도 적용해보기\n",
    "\n",
    "\n",
    "### 참고 사이트\n",
    "- 아이펠의 Exploration 12 노드\n",
    "- [고려대학교 산업경영공학부 DSBA연구실|08-2:Transformer](https://www.youtube.com/watch?v=Yk1tV_cXMMU)\n",
    "- [Positional Encoding in NLP](https://inmoonlight.github.io/2020/01/26/Positional-Encoding/)\n",
    "\n",
    "\n",
    "-------------------\n",
    "![](https://jalammar.github.io/images/t/the_transformer_3.png)\n",
    "![](https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png)\n",
    "![](https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모델 구성\n",
    "### 1-1. Positional encoding\n",
    "단어를 임베딩 벡터로 변환하는 벡터화 과정을 거치는데, 트랜스포머의 경우는 임베딩하고 난 이후에 positional encoding을 임베딩 벡터에 더해준다.\n",
    "- RNN은 단어를 문장에 위치하는 순서대로 입력되니까 따로 어순을 알려주지 않아도 되지만, __트랜스포머는 한꺼번에 모든 단어를 문장 단위로 입력하기 때문에 위치정보를 가진 벡터(positinal encoding)를 더해줘서 모델에 입력__ 해준다. \n",
    "\n",
    "- 좋은 Positional encoding scheme은 다음과 같은 두가지 특징을 갖고 있다. \n",
    "    1. 해당하는 encoding vector의 크기 자체는 동일해야한다.      \n",
    "     - word embedding에 똑같은 크기로 더해줘야 동일한 벡터 크기가같은 벡터가 더해져서 모든 word들이 같은 방향 같은 크기로 변화한다는 보장을 할수 있다. \n",
    "    2. input sequence에 포함된 두 단어의 거리가 sequence 안에서 멀어지면, positional encoding vector 사이의 거리도 멀어져야 한다. \n",
    "    \n",
    "    \n",
    "- 여러가지 positional encoding vector가 있지만 \"Attention is all you need\"에서 사용된 PE(혹은 sinusoidal functions)는 sin, cos 함수를 사용하여서 만든다. \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PE_{(pos, 2i)}=sin(pos/10000^{2i/d_{model}})$$\n",
    "$$PE_{(pos, 2i+1)}=cos(pos/10000^{2i/d_{model}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "    \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "        \n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.xlabel(\"embedding\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled dot prodcut attention\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query vector와 key vector의 dot product\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True) \n",
    "    \n",
    "    # 가중치를 정규화 \n",
    "    # key의 dimension\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    # key의 dimension을 루트 씌워서  matmul_pk로 나눠준다.\n",
    "    logits = matmul_qk / tf.math.sqrt(depth) \n",
    "    \n",
    "    # 패딩에 마스크 추가\n",
    "    # encoder에 넣을 때는 마스크 빼고, decoder에 넣을 때는 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "        \n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "    \n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Multi - head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,(batch_size, -1, self.d_model))\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. 패딩 마스킹 (padding masking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 패딩은 문장의 길이가 주어진 문장 길이보다 짧은 문장의 앞 혹은 뒤에 0으로 채워서 모든 문장의 길이를 동일하게 해주는 자연어 전처리이다.\n",
    "- 패딩(0)처리가 된 위치를 표시하여 attention 연산을 실행할때 패딩을 포함 시키지 않는다. 그래서 padding masking 처리를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x): # 패딩마스크\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32) # 의미 없는 0\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 숫자가 0인 곳만 1이 되고 나머지는 0이 된다. \n",
    "# attention 연산할때 1인 부분을 제외하고 연산하게 함.\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5. 룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-6. 인코더\n",
    "-  인코더 블록 및 인코더 생성     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "        'query': inputs,'key': inputs,'value': inputs,'mask': padding_mask})\n",
    "    \n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    \n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    # num_layers만큼 쌓아올린 인코더의 층\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(units=units, d_model=d_model,\n",
    "                                num_heads=num_heads,dropout=dropout,\n",
    "                                name=\"encoder_layer_{}\".format(i),)([outputs, padding_mask])\n",
    "        return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-7. 디코더\n",
    "-  디코더 블록 및 디코더 생성     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "        'query': inputs,'key': inputs,'value': inputs,'mask': look_ahead_mask})\n",
    "    \n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "    \n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "        'query': attention1,'key': enc_outputs,'value': enc_outputs,'mask': padding_mask})\n",
    "    \n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "    \n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    \n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "    \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,num_layers,units,d_model,num_heads,dropout,name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "    \n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    \n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "        \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 챗봇 데이터(cornell movie dialogs Corpus) 다운로드 및 전처리\n",
    "\n",
    "### 2.1 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        id2line[parts[0]] = parts[4]\n",
    "        \n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "        for i in range(len(conversation) - 1):\n",
    "            # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "            \n",
    "            if len(inputs) >= MAX_SAMPLES:\n",
    "                return inputs, outputs\n",
    "            \n",
    "    return inputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_movie_lines, errors='ignore') as file:\n",
    "        lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])\n",
    "print(lines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045', 'u0', 'm0', 'BIANCA', 'They do not!']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].replace('\\n', '').split(' +++$+++ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "        \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 교사강요(Teacher Forcing) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 정의 및 학습\n",
    "\n",
    "### 3-1. 트랜스포머 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "    \n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "    \n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "    \n",
    "    \n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,)(inputs=[inputs, enc_padding_mask])\n",
    "    \n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "    \n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. 손실함수\n",
    "- 레이블이 문장이기 때문에 시퀀스에 패딩이 있다. \n",
    "- loss를 계산하기 위해서 패딩 마스크를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    \n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4.Custom Learning rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-14c2b932eb98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mCustomSchedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCustomSchedule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 커스텀 학습률 스케줄링 계획 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-5. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomSchedule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f17d5ad17eef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomSchedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_MODEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer = tf.keras.optimizers.Adam(\n\u001b[0;32m      4\u001b[0m     learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CustomSchedule' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-6. 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 챗봇 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    \n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        # 현재 예측한 단어의 정수\n",
    "        \n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        \n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "            \n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        \n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "    \n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "    \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('Where have you been?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
