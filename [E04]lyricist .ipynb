{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration 4. 프로젝트: 멋진 작사가 만들기\n",
    "\n",
    "\n",
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob       # 시스템에 접근하는 라이브러리, 파일을 가져오는데 상용한다.\n",
    "import re             # 정규표현식 라이브러리\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__preprocess_sentence__ (문장을 전처리하는 함수)\n",
    "\n",
    "- __소문자로 바꾸기(lower함수 사용)__  \n",
    "    : 대문자가 섞인 단어와 소문자로만 이루어진 단어가 한 단어로 인식되도록 만들어주는 작업이다. 예를들어 Love와 love를 그냥 입력하면 다른 단어로 받아들여지게 되므로 소문자로 바꿔주는 작업을 한다\n",
    "- __문장부호를 단어와 분리하기(정규표현식 함수 re.sub에 정규표현식 r\"([?.!,¿])\", r\" \\1\"사용)__  \n",
    "    : 같은 단어에 하나는 문장부호가 들어있고 한쪽은 없는 경우에도 다른 단어로 인식하기 때문에 문장부호를 단어와 스페이스바로 여백을 주어서 분리한다. 예를 들어 \"How old are you?\"의 you와 \"you are...\" 두 문장에서 you는 같은 you이지만 처음 것은 물음표가 있고 뒤에 것은 물음표가 없지만 같은 you이다. 하지만 물음표가 붙어있으면 컴퓨터에서는 둘을 다른 단어로 인식하게 된다. 그래서 전처리 과정에서 분리한다.\n",
    "- __여러개의 공백을 하나의 공백으로 변환__(정규표현식 함수 re.sub에 정규표현식 r'[\" \"]+', \" \" 사용)\n",
    "    : [\" \"]+ 이 정규표현식은 공백이 둘 이상 있는 경우를 의미하고 이럴 경우 하나의 띄어쓰기로 바꿔준다는 뜻이다   \n",
    "    ex) long-time-ago. (한단어로 인식한다. 띄어쓰기가 아니라 -를 기준으로 단어가 나뉘므로)\n",
    "    \n",
    "\n",
    "\n",
    "자연어처리 분야에서 __모델의 입력문장을 소스문장(Source Sentence)__ , 정답이 되는 __모델의 출력문장을 타겟문장(Target sentence)__ 라고 부른다. X_train, y_train에 해당한다. 그래서 문장의 시작에  start 끝에 end를 넣었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence=sentence.strip().lower() # 문장의 오른쪽 왼쪽의 공백을 지우고 소문자 변환\n",
    "    sentence=re.sub(r\"([?.!,¿])\", r\" \\1\", sentence)  # 문장부호의 양 옆을 각각 한칸 띄운다.\n",
    "    sentence=re.sub(r'[\" \"]+', \" \", sentence) # 여러개의 공백은 하나의 공백으로 바꿉니다.\n",
    "    sentence=re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) \n",
    "    #a-zA-Z?.!,¿가 아닌 모든 특수문자를 하나의 공백으로 바꾼다.\n",
    "    sentence=sentence.strip() # 문자열에 양끝의 공백을 한번 더 삭제\n",
    "    sentence=\" \".join(['<start> ',sentence,' <end>']) # 문장시작은 <start> 끝에는 <end>를 추가한다.\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does pure water have a taste\n"
     ]
    }
   ],
   "source": [
    "#a-zA-Z?.!,¿가 아닌 모든 특수문자를 하나의 공백으로 바꾼다.\n",
    "s=\"Does 100% pure water have a taste\"\n",
    "s=re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \",s) \n",
    "print(s) # 100% 단어가 공백으로 바뀐다. 특수문자와 숫자도 공백으로 바뀐 것을 볼수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __토큰화(tokenize)__\n",
    " - 앞에서 전처리한 문장을 띄어쓰기를 기준으로 잘라내어 토큰으로 만들어낸다.\n",
    "\n",
    "텐서플로우의 Tokenizer 패키지\n",
    "- 위의 정제된 corpus를 토큰화해서 단어사전(vocabulary or dictionary)라고 말하며 숫자로 변환해준다. 이 과정을 벡터화(vectorize)이고, 숫자로 바꾼 데이터를 tensor라고 말한다.\n",
    "\n",
    "tf.keras.preprocessing.text.Tokenizer\n",
    "[참고할 사이트](https://wikidocs.net/31766)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus): \n",
    "    tokenizer=tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 단어장 크기12000\n",
    "        filters=' ',     # preprocessed_sentence\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 사용해서 tokenizer 단어장을 만든다. \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 사용해서 corpus를 Tensor로 만든다.\n",
    "    tensor=tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    # input data의 시퀀스 크기를 \n",
    "    #(길이가 짧은 문장 뒤(post)에 padding을 붙여서) 동일하게 만든다.\n",
    "    # 문장 앞에 패딩을 붙이려면 pre라고 입력하면 됨\n",
    "    tensor=tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    #print(tensor, tokenizer)\n",
    "    return tensor, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스의 LSTM을 사용한 텍스트 생성기 모델(TextGenerator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size): # 단어장 크기, 단어를 임베딩할 사이즈, LSTM의 unit개수\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 마지막으로 가사를 생성시킬 함수(generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])  \n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1. 데이터 다운로드\n",
    "- 아이펠에서 제공한 가사데이터를 다운받는다.\n",
    "\n",
    "### Step2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/lyricist/data/lyrics/*\n",
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "print(txt_file_path)\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3. 데이터 정제\n",
    "\n",
    "\n",
    "- 노드 작성자의 조언대로 문장을 토큰화 했을 때 토큰의 개수가 15개 넘어가는 문장을 제외하였다.  \n",
    "\n",
    "text_to_sequences 메서드를 사용해서 텍스트를 시퀀스형 데이터인 리스트로 만들어낸다. 2차원 리스트의 모양으로 데이터를 반환한다\n",
    "\n",
    "데이터가 preprocess_sentence 함수에 의해 처리되면서 문장의 앞에 start 뒤에 end가 붙게 된다. 모델을 학습시킬 문장에는 end를 빼기 위해서 -1인덱스까지 자르고, 타겟문장에는 start를 잘라내기 위해서 1번 인덱스부터 끝의 문장까지 슬라이싱한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   17 2647 ...    0    0    0]\n",
      " [   2   35    7 ...    0    0    0]\n",
      " ...\n",
      " [   2  130    5 ...    0    0    0]\n",
      " [   2   23   89 ...    0    0    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f97cfd5d820>\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue    # 빈 단어를 corpus에서 뺀다\n",
    "    if sentence[-1] == \":\" : continue  # 문장 끝에 콜론이 있는 경우 제외한다. \n",
    "                                        # 이건 가사라서 연극(이름에 콜론)과 달리 지워도 상관 없을 것 같지만 유지했다.\n",
    "        \n",
    "    # 앞에서 문장부호와 특수문자, 소문자 대문자 처리\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "\n",
    "tensor, tokenizer=tokenize(corpus)\n",
    "\n",
    "tensor_=tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "tensor=[]\n",
    "\n",
    "for i in tensor_:\n",
    "    if len(i)<=15:   # 15개 \n",
    "        tensor.append(i)\n",
    "        \n",
    "tensor=tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "# 마지막토큰은 <end>가 아닌 <pad> 가능성이 높다.\n",
    "src_input=tensor[:,:-1]\n",
    "# t<start> 를 잘라서 타겟문장을 만든다.\n",
    "tgt_input=tensor[:,1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,tgt_input, test_size=0.2) \n",
    "# step3에서 전처리를 완성한 텐서(numpy 배열)를 train_test_split 으로 분할한다.\n",
    "\n",
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256    # 학습시 배치사이즈\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE # 한 에포크가 돌 동안 몇번의 스텝을 가느냐\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)) # 나뉘어진 데이터셋을 텐서플로 데이터셋으로 만든다.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)    # 데이터를 섞어주고\n",
    "val_dataset = val_dataset.shuffle(BUFFER_SIZE)    \n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)  # 학습할때 쓰이는 배치사이즈로 나눠준다.\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 40s 78ms/step - loss: 3.7877 - val_loss: 3.3858\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 3.2852 - val_loss: 3.1982\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 3.0931 - val_loss: 3.0435\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 2.9613 - val_loss: 2.9449\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 2.8604 - val_loss: 2.8748\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 2.7795 - val_loss: 2.8157\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 2.7084 - val_loss: 2.7691\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 2.6433 - val_loss: 2.7284\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 2.5825 - val_loss: 2.6923\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 2.5241 - val_loss: 2.6599\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 95s 186ms/step - loss: 3.4827 - val_loss: 3.1311\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 90s 184ms/step - loss: 3.0102 - val_loss: 2.9489\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 90s 184ms/step - loss: 2.8517 - val_loss: 2.8416\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 90s 184ms/step - loss: 2.7311 - val_loss: 2.7657\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 90s 184ms/step - loss: 2.6281 - val_loss: 2.7075\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 90s 184ms/step - loss: 2.5339 - val_loss: 2.6571\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 90s 184ms/step - loss: 2.4452 - val_loss: 2.6132\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 90s 185ms/step - loss: 2.3613 - val_loss: 2.5742\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 90s 185ms/step - loss: 2.2820 - val_loss: 2.5421\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 90s 185ms/step - loss: 2.2066 - val_loss: 2.5129\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 259s 494ms/step - loss: 3.4437 - val_loss: 3.0473\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 241s 494ms/step - loss: 2.8843 - val_loss: 2.7969\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 242s 496ms/step - loss: 2.6193 - val_loss: 2.6362\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 242s 496ms/step - loss: 2.3749 - val_loss: 2.5102\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 242s 496ms/step - loss: 2.1406 - val_loss: 2.4135\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 243s 497ms/step - loss: 1.9194 - val_loss: 2.3352\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 243s 497ms/step - loss: 1.7142 - val_loss: 2.2798\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 243s 497ms/step - loss: 1.5281 - val_loss: 2.2387\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 242s 496ms/step - loss: 1.3660 - val_loss: 2.2170\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 243s 497ms/step - loss: 1.2312 - val_loss: 2.2122\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 42s 81ms/step - loss: 3.7608 - val_loss: 3.3975\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 39s 80ms/step - loss: 3.2690 - val_loss: 3.1499\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 39s 80ms/step - loss: 3.0470 - val_loss: 3.0054\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 39s 81ms/step - loss: 2.9211 - val_loss: 2.9169\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 40s 81ms/step - loss: 2.8259 - val_loss: 2.8442\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 40s 81ms/step - loss: 2.7451 - val_loss: 2.7842\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 40s 81ms/step - loss: 2.6702 - val_loss: 2.7329\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 40s 81ms/step - loss: 2.5979 - val_loss: 2.6874\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 40s 81ms/step - loss: 2.5275 - val_loss: 2.6466\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 40s 81ms/step - loss: 2.4588 - val_loss: 2.6109\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 98s 193ms/step - loss: 3.4614 - val_loss: 3.1089\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 94s 193ms/step - loss: 2.9884 - val_loss: 2.9235\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 94s 193ms/step - loss: 2.8126 - val_loss: 2.8054\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 95s 194ms/step - loss: 2.6792 - val_loss: 2.7247\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 94s 193ms/step - loss: 2.5636 - val_loss: 2.6561\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 94s 193ms/step - loss: 2.4579 - val_loss: 2.6000\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 95s 194ms/step - loss: 2.3588 - val_loss: 2.5545\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 95s 194ms/step - loss: 2.2653 - val_loss: 2.5155\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 95s 194ms/step - loss: 2.1767 - val_loss: 2.4839\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 95s 194ms/step - loss: 2.0927 - val_loss: 2.4560\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 267s 510ms/step - loss: 3.2855 - val_loss: 2.9227\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 249s 509ms/step - loss: 2.7546 - val_loss: 2.6811\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 249s 510ms/step - loss: 2.4610 - val_loss: 2.5065\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 249s 511ms/step - loss: 2.1731 - val_loss: 2.3716\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 250s 512ms/step - loss: 1.8950 - val_loss: 2.2730\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 250s 513ms/step - loss: 1.6405 - val_loss: 2.2052\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 250s 512ms/step - loss: 1.4232 - val_loss: 2.1622\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 250s 511ms/step - loss: 1.2503 - val_loss: 2.1522\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 250s 511ms/step - loss: 1.1237 - val_loss: 2.1588\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 250s 512ms/step - loss: 1.0437 - val_loss: 2.1768\n"
     ]
    }
   ],
   "source": [
    "#Loss\n",
    "embedding_size=[256,512]     # 임베딩할 차원의 수\n",
    "hidden_size=[512,1024,2048]  # LSTM모델의 hidden\n",
    "acc={}\n",
    "for i in embedding_size:\n",
    "    for j in hidden_size:\n",
    "        model=TextGenerator(12000+1, i, j) # i: embadding_size, j: hidden_size\n",
    "        optimizer=tf.keras.optimizers.Adam()\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        model.compile(loss=loss, optimizer=optimizer)\n",
    "        tg=model.fit(train_dataset, epochs=10, validation_data=(val_dataset))\n",
    "        acc[\"%d-%d\"%(i,j)]=tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>2.152177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding hidden_size  val_loss\n",
       "5       512        2048  2.152177"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_acc(acc, key,hp):\n",
    "    hp1,hp2=key.split(\"-\")\n",
    "    dd=pd.DataFrame(acc[key].history)\n",
    "    return {hp[0]:hp1,hp[1]:hp2,\"val_loss\":dd.min()[1]}\n",
    "\n",
    "dict_list=[]\n",
    "for i in acc.keys():\n",
    "    dict_list.append(find_acc(acc,i,(\"embedding\",\"hidden_size\")))\n",
    "    \n",
    "loss_df=pd.DataFrame(dict_list) # 가장 높은 accuracy는 0.574667\n",
    "loss_df.loc[acc_df[\"val_loss\"]<2.2].sort_values(\"val_loss\", ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_=loss_df.pivot(index=\"embedding\", columns=\"hidden_size\", values=\"val_loss\")\n",
    "\n",
    "loss_=loss_[['512','1024', '2048']]\n",
    "loss_=loss_.reindex([\"512\",\"256\"])\n",
    "\n",
    "font3 = {'color':  'green',\n",
    "      'style': 'italic',\n",
    "      'size': 15}\n",
    "\n",
    "sns.heatmap(loss_)\n",
    "for i in range(loss_.shape[1]):\n",
    "    for j in range(loss_.shape[0]):\n",
    "        plt.text(i+0.5,j+0.5,round(loss_.iloc[j,i],3),ha='center',va='center', fontdict=font3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation loss가 2.2 아래인 2.152가 된 모델은 embedding은 512, hidden_size는 2048개인 모델이었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 264s 505ms/step - loss: 3.2788 - val_loss: 2.9039\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 248s 509ms/step - loss: 2.7189 - val_loss: 2.6363\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 249s 509ms/step - loss: 2.3876 - val_loss: 2.4508\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 249s 510ms/step - loss: 2.0638 - val_loss: 2.3140\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 249s 510ms/step - loss: 1.7637 - val_loss: 2.2172\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 249s 510ms/step - loss: 1.5042 - val_loss: 2.1596\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 249s 511ms/step - loss: 1.2976 - val_loss: 2.1375\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 249s 510ms/step - loss: 1.1485 - val_loss: 2.1427\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 249s 511ms/step - loss: 1.0582 - val_loss: 2.1622\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 249s 510ms/step - loss: 1.0098 - val_loss: 2.1770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9738629af0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model=TextGenerator(12000+1, 512, 2048) # i: embadding_size, j: hidden_size\n",
    "optimizer=tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(train_dataset, epochs=10, validation_data=(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text generator가 작사한 문장들이다.\n",
    "- 간단한 초보 영단어들을 넣어보니,어쩐지 추상적인 느낌이 드는 그럴싸한 가사들이 만들어졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i need you to be here with me <end> '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i need you \", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i said , no , no , no <end> '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i said\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> we live in cities you ll never see on screen <end> '"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> we live \", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> my life s a mess <end> '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> my life \", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you never thought that hip hop would take it this far <end> '"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> you never \", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 언어모델을 돌려본 것 자체가 처음이었다. 물론 지난 프로젝트에 사용했던 가위바위보 모델 만들기도 시간이 오래걸렸지만, 하나의 모델을 만들기 위해서 10epoch를 돌리는데만해도 가장 작은 모델이 한 epoch당 40초 가량 시간이 들었다. 가장 무거운 모델은 한 에폭당 249초가 걸렸다. 학습시간이 오래 걸려서 모델을 돌려놓고 기다리다가 깜빡 졸았는데 너무 푹자버려서 다음날 아침에 일어나보니 LMS가 로그아웃 된 일도 있었고, 구글 colab에 모델을 걸어놓고 외출하고 돌아왔는데 오래 마우스 반응이 없어서 런타임이 종료된 일도 있었다. 이 사건을 계기로 꼭 모델을 만들고 어떻게하면 모델 저장하고 다시 로드해서 쓰는 방법을 꼭 익혀서 자칫 잘못해서 모델이 일부 날라가도 이어서 학습시킬수 있는 환경을 만들고 싶다. \n",
    "- 전반적으로 낯선 파트이라서 어려웠지만 자연어처리 데이터를 전처리하는 방법에 있어서 정규표현식을 자유자제로 다루는 스킬이 중요함을 느꼈다. 코드를 보면 전처리 과정에서 반 정도가 정규표현식의 패턴으로 데이터의 불필요한 정보는 지우는 일이 많았다.\n",
    "- 노드에서 제시된 것처럼 대본의 텍스트를 다룰때는 문장 끝에 콜론이 붙을 경우(극본의 이름을 나타내는 표시) 그 문장을 포함시키지 않는등 NLP가 사용되는 텍스트에 대한 이해도 역시 중요하다는 생각이 들었다.  \n",
    "\n",
    "- 위의 히트맵을 보면 __embedding 사이즈가 높고, hidden의 사이즈가 큰쪽__ 이 loss가 많이 줄어들었음을 알수 있었다. validation loss가 2.2 아래로 떨어진 모델은 embedding은 512, hidden_size는 2048인 모델이다. 이정도면 모델의 복잡도가 큰 모델이라고 생각했었는데 검증데이터셋의 loss가 꾸준히 착착 줄어드는 것을 보고 NLP모델을 충분히 학습하고 결과물을 내기 위해서는 많은 리소스와 시간, 데이터를 필요로 하는 모델이라고 생각했다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
