{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b669658c",
   "metadata": {},
   "source": [
    "# Exploration 4. 프로젝트: 멋진 작사가 만들기\n",
    "\n",
    "\n",
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1984b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae46641",
   "metadata": {},
   "source": [
    "### __preprocess_sentence__ (문장을 전처리하는 함수)\n",
    "\n",
    "- __소문자로 바꾸기(lower함수 사용)__  \n",
    "    : 대문자가 섞인 단어와 소문자로만 이루어진 단어가 한 단어로 인식되도록 만들어주는 작업이다. 예를들어 Love와 love를 그냥 입력하면 다른 단어로 받아들여지게 되므로 소문자로 바꿔주는 작업을 한다\n",
    "- __문장부호를 단어와 분리하기(정규표현식 함수 re.sub에 정규표현식 r\"([?.!,¿])\", r\" \\1\"사용)__  \n",
    "    : 같은 단어에 하나는 문장부호가 들어있고 한쪽은 없는 경우에도 다른 단어로 인식하기 때문에 문장부호를 단어와 스페이스바로 여백을 주어서 분리한다. 예를 들어 \"How old are you?\"의 you와 \"you are...\" 두 문장에서 you는 같은 you이지만 처음 것은 물음표가 있고 뒤에 것은 물음표가 없지만 같은 you이다. 하지만 물음표가 붙어있으면 컴퓨터에서는 둘을 다른 단어로 인식하게 된다. 그래서 전처리 과정에서 분리한다.\n",
    "- __여러개의 공백을 하나의 공백으로 변환__(정규표현식 함수 re.sub에 정규표현식 r'[\" \"]+', \" \" 사용)\n",
    "    : [\" \"]+ 이 정규표현식은 공백이 둘 이상 있는 경우를 의미하고 이럴 경우 하나의 띄어쓰기로 바꿔준다는 뜻이다   \n",
    "    ex) long-time-ago. (한단어로 인식한다. 띄어쓰기가 아니라 -를 기준으로 단어가 나뉘므로)\n",
    "    \n",
    "\n",
    "\n",
    "자연어처리 분야에서 __모델의 입력문장을 소스문장(Source Sentence)__ , 정답이 되는 __모델의 출력문장을 타겟문장(Target sentence)__ 라고 부른다. X_train, y_train에 해당한다. 그래서 문장의 시작에  start 끝에 end를 넣었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180067a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence=sentence.strip().lower() # 문장의 앞뒤 공백을 지우고 소문자 변환\n",
    "    sentence=re.sub(r\"([?.!,¿])\", r\" \\1\", sentence)  # 특수문자의 양 옆을 각각 한칸 띄우고\n",
    "    sentence=re.sub(r'[\" \"]+', \" \", sentence) # 여러개의 공백은 하나의 공백으로 바꿉니다.\n",
    "    sentence=re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) \n",
    "    #특수문자는 하나의 공백으로 바꾼다.\n",
    "    sentence=sentence.strip() # 문자열에 양끝의 공백을 한번 더 삭제\n",
    "    sentence=\" \".join(['<start> ',sentence,' <end>']) # 문장시작은 <start> 끝에는 <end>를 추가한다.\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc85b45",
   "metadata": {},
   "source": [
    "preprocess_sentence 함수 내의 정규표현식 re.sub를 어떻게 쓰는지 궁금해서 테스트를 해보았다.  \n",
    "\n",
    "re.sub(정규표현식, 바꿀 문자, 적용할 문장 )\n",
    "- re.sub 함수는 적용할 문장에 정규표현식에 해당하는 문자를 찾아서 바꿀 문자로 바꿔주는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653ed25f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does pure water have a taste\n"
     ]
    }
   ],
   "source": [
    "#a-zA-Z?.!,¿가 아닌 모든 특수문자를 하나의 공백으로 바꾼다.\n",
    "\n",
    "s=\"Does 100% pure water have a taste\"\n",
    "s=re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \",s) \n",
    "print(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f7e8c",
   "metadata": {},
   "source": [
    "바로 위에 있는 셀의 r\"[^a-zA-Z?.!,¿]+\"는 대괄호 안의 맨 앞에 __메타문자 ^__ 가 있다. 이 메타문자는 __not이라는 의미__ 를 갖고 있다. 그래서 대괄호 안에 있는 __소문자(a-z) 대문자(A-Z) 문장기호 (?.!,¿)가 아닌 문자로 이루어진 것__ 을 삭제하게 된다.  \n",
    "그래서 s에 저장된 문자열에서 100% 단어가 공백으로 바뀐다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160e507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>  hi , my name is sunny  <end>\n"
     ]
    }
   ],
   "source": [
    "# 위의 preprocess_sentence 함수에 문자열을 넣으면 다음과 같이 전처리가 된다.\n",
    "print(preprocess_sentence(\"Hi, My name is sunny 100%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f3fe6",
   "metadata": {},
   "source": [
    "왜 문장의 처음과 끝에 start와 end 넣는 이유는 시퀀스 문장의 시작과 끝이 어디인지를 학습시키기 위해서 태그를 해준다. \n",
    "우리가 구축해야하는 데이터셋의 모양은?\n",
    "- 언어모델 입력문장: \\<start\\> 나는 밥을 먹었다 \n",
    "- 언어모델 출력문장: 나는 밥을 먹었다 \\<end\\>\n",
    "\n",
    "자연어처리 분야에서 __모델의 입력문장을 소스문장(Source Sentence)__ , 정답이 되는 __모델의 출력문장을 타겟문장(Target sentence)__ 라고 부른다. X_train, y_train에 해당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de0cdba",
   "metadata": {},
   "source": [
    "### tokenize(문장을 토큰으로 만드는 함수)\n",
    " - 문장을 토큰화 했을 때 토큰의 개수가 15개 넘어가는 문장을 제외하였다.  \n",
    "\n",
    " - 앞에서 전처리한 문장을 띄어쓰기를 기준으로 잘라내어 토큰으로 만들어서 vectorize 시킨다. \n",
    " 토큰: 단어를 의미를 갖는 가장 짧은 단위로 자르는 것\n",
    " vectorize: 토큰으로 만든 문장을 단어사전의 숫자에 맞게 매칭을 시켜주어서 벡터로 만드는 것.\n",
    "\n",
    "텐서플로우의 Tokenizer 패키지\n",
    "- 위의 정제된 corpus를 토큰화해서 단어사전(vocabulary or dictionary)라고 말하며 숫자로 변환해준다. 이 과정을 벡터화(vectorize)이고, 숫자로 바꾼 데이터를 tensor라고 말한다.\n",
    "\n",
    "tf.keras.preprocessing.text.Tokenizer\n",
    "[참고할 사이트](https://wikidocs.net/31766)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1436de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus): \n",
    "    tokenizer=tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 단어장 크기12000\n",
    "        filters=' ',     # preprocessed_sentence\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 사용해서 tokenizer 단어장을 만든다. \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 사용해서 corpus를 Tensor로 만든다.\n",
    "    tensor=tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    tensor_=[]\n",
    "\n",
    "    for i in tensor:\n",
    "        if len(i)<=15:   # 15개 \n",
    "            tensor_.append(i)\n",
    "    # input data의 시퀀스 크기를 \n",
    "    #(길이가 짧은 문장 뒤(post)에 padding을 붙여서) 동일하게 만든다.\n",
    "    # 문장 앞에 패딩을 붙이려면 pre라고 입력하면 됨\n",
    "    tensor=tf.keras.preprocessing.sequence.pad_sequences(tensor_, padding='post')\n",
    "                \n",
    "    print(tensor, tokenizer)\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4e4bb",
   "metadata": {},
   "source": [
    "### __TextGenerator (케라스의 LSTM을 사용한 텍스트 생성기 모델)__\n",
    "\n",
    "- keras.layers.Embedding(input_dim, output_dim)  \n",
    "> input_dim: 단어사전의 크기+1  \n",
    "> output_dim: 임베딩 차원의 크기\n",
    "\n",
    "- tf.keras.layers.LSTM(units,return_squences=True)\n",
    "> units: 양의 정수, out space의 차원  \n",
    "> activation: 따로 입력하지 않았으므로 기본값인 hyperbolic tangent  \n",
    "> return_sequence: 아웃풋 시퀀스의 마지막 아웃풋을 반환할지, 시퀀스 전체를 반환할지를 정한다. 코드에서는 True가 적혀 있으므로 시퀀스 전체를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac54e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model): # keras의 Model 클래스를 오버라이딩한다.\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4096ba",
   "metadata": {},
   "source": [
    "### __generate_text__ (마지막으로 가사를 생성시킬 함수)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b332fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환.(입력 문장)\n",
    "    \n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence]) # tokenizer를 사용해서 init_sentence를 시퀀스 데이터로 바꿈\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)  # 시퀀스 데이터를 텐서로 바꾼다.\n",
    "    \n",
    "    end_token = tokenizer.word_index[\"<end>\"]  # \"<end>\"에 해당하는 index를 end_token에 반환한다\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "\n",
    "    while True: # 4번 조건에 의해서 while 반복문을 끝내기 전까지 반복해라\n",
    "\n",
    "        # 1 . 입력받은 문장의 텐서를 입력합니다\n",
    "        predict = model(test_tensor)\n",
    "        \n",
    "        # 2 . 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        \n",
    "        # 3 . 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        \n",
    "        # 4 . 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "        if predict_word.numpy()[0] == end_token: break # 예측한 단어가 end에 해당하는 인덱스 번호와 같으면 끝내기\n",
    "        if test_tensor.shape[1] >= max_len: break \n",
    "\n",
    "    generated = \"\"\n",
    "\n",
    "    # while문으로 인해 만들어진 test_tensor를 tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy(): \n",
    "        generated += tokenizer.index_word[word_index] + \" \" \n",
    "\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7976b",
   "metadata": {},
   "source": [
    "### step1. 데이터 다운로드 & Step2. 데이터 읽어오기\n",
    "- 아이펠에서 제공한 가사데이터를 다운받는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c59512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/lyricist/data/lyrics/*\n",
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "print(txt_file_path)\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f402eff0",
   "metadata": {},
   "source": [
    "### step 3. 데이터 정제\n",
    "\n",
    "text_to_sequences 메서드를 사용해서 텍스트를 시퀀스형 데이터인 리스트로 만들어낸다. 2차원 리스트의 모양으로 데이터를 반환한다\n",
    "\n",
    "데이터가 preprocess_sentence 함수에 의해 처리되면서 문장의 앞에 start 뒤에 end가 붙게 된다. 모델을 학습시킬 문장에는 end를 빼기 위해서 -1인덱스까지 자르고, 타겟문장에는 start를 잘라내기 위해서 1번 인덱스부터 끝의 문장까지 슬라이싱한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cb09f8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   17 2643 ...    0    0    0]\n",
      " [   2   35    7 ...   44    3    0]\n",
      " ...\n",
      " [   2    5  107 ...    0    0    0]\n",
      " [   2  261  202 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f62edcacbb0>\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue    # 빈 단어를 corpus에서 뺀다\n",
    "    if sentence[-1] == \":\" : continue  # 끝에 콜론이 있는 다\n",
    "        \n",
    "    # 앞에서 문장부호와 특수문자, 소문자 대문자 처리\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "\n",
    "tensor, tokenizer=tokenize(corpus)     # 전처리가 끝난 corpus를 tokenize 함수를 적용해서 텐서와 tokenizer를 반환받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc78c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156074, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ab391",
   "metadata": {},
   "source": [
    "tokenize 함수 내부의 과정이 궁금해서 조금 뜯어보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79830356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus를 texts_to_sequences를 적용한 결과\n",
      "데이터 타입은  <class 'list'> 이고, 문장의 길이에 따라 리스트의 길이가 제각각이 된다.\n",
      "[[2, 50, 5, 91, 296, 65, 57, 10, 968, 6062, 3], [2, 17, 2643, 872, 4, 8, 11, 6063, 6, 329, 3], [2, 35, 7, 37, 15, 164, 282, 28, 298, 4, 47, 7, 44, 3], [2, 11, 354, 25, 42, 3]]\n",
      "--------------------------------------------------\n",
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   17 2643 ...    0    0    0]\n",
      " [   2   35    7 ...   44    3    0]\n",
      " ...\n",
      " [   2    5  107 ...    0    0    0]\n",
      " [   2  261  202 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f6313e9d7f0>\n"
     ]
    }
   ],
   "source": [
    "tokenizerA=tf.keras.preprocessing.text.Tokenizer(num_words=12000,  # 단어장 크기12000\n",
    "                                                filters=' ',     # preprocessed_sentence\n",
    "                                                oov_token=\"<unk>\") # 사전에 없는 단어를 대신 <unk>로 채워준다.\n",
    "# corpus를 사용해서 tokenizer 단어장을 만든다. \n",
    "tokenizerA.fit_on_texts(corpus)\n",
    "\n",
    "# 준비한 tokenizer를 사용해서 corpus를 Tensor로 만든다. \n",
    "# 2차리스트로 결과물이 나온다. 안쪽 리스트의 길이는 문장의 단어 길이이다.\n",
    "\n",
    "tensor_A=tokenizerA.texts_to_sequences(corpus)\n",
    "\n",
    "print(\"corpus를 texts_to_sequences를 적용한 결과\")\n",
    "print(\"데이터 타입은 \",type(tensor_A),\"이고, 문장의 길이에 따라 리스트의 길이가 제각각이 된다.\")\n",
    "\n",
    "# tokenizer를 통해 텍스트를 시퀀스 데이터를 만든 것은 리스트가 된다\n",
    "print(tensor_A[:4])\n",
    "print(\"--------------------------------------------------\")\n",
    "tensorA=[]\n",
    "\n",
    "for i in tensor_A: # 16미만의 단어로 이루어진 문장만 데이터로 쓰겠다.\n",
    "    if len(i)<16:\n",
    "        tensorA.append(i)\n",
    "\n",
    "tensorA=tf.keras.preprocessing.sequence.pad_sequences(tensorA, padding='post') # 다른 길이의 문장들을 15개의 단어로 통일 시킨다.\n",
    "print(tensorA, tokenizerA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca9278ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156074, 15)\n",
      "<unk>:1 / <start>:2 / <end>:3 / ,:4 / i:5 / the:6 / you:7 / and:8 / to:9 / a:10 / it:11 / me:12 / "
     ]
    }
   ],
   "source": [
    "print(tensorA.shape)\n",
    "for i,j in enumerate(tokenizerA.word_index):\n",
    "    print(\"%s:%d\"%(j,tokenizerA.word_index[j]), end=\" / \")\n",
    "    if i>10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b160be",
   "metadata": {},
   "source": [
    "- 문장의 길이를 15단어 이하로 제한을 하였기에 (156074,15)이다. texts_to_sequences를 적용시켜서 길이가 제각각이었던 문장들의 길이를 15단어 이하(16미만의 단어)의 문장만 골라내어서 pad_sequences를 사용해서 문장 길이를 통일 시킨다.(15미만 토큰을 갖는 문장 뒤에 0\\<pad\\>을 채운다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a98a1",
   "metadata": {},
   "source": [
    "- corpus를 sequences로 바꾸니까 2로 시작해서 3으로 끝나는 것을 알수 있다. 바로 위의 셀에서 본 것 같이 word_index의 \\<start\\>가 2, \\<end\\>가 3 word_index이다. 문장이 preprocess_sentence 함수에 의해 모든 문장이 잘 정리되었다는 것을 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d219cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막토큰은 <end>가 아닌 <pad> 가능성이 높다.\n",
    "src_input=tensor[:,:-1]\n",
    "# t<start> 를 잘라서 타겟문장을 만든다.\n",
    "tgt_input=tensor[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8d665fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156074, 14) (156074, 14)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(src_input.shape, tgt_input.shape)\n",
    "print(type(src_input), type(tgt_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a535820",
   "metadata": {},
   "source": [
    "### Step 4. 평가 데이터셋 분리\n",
    "- src_input과 tgt_input은 numpy array 이므로 사이킷런의 train_test_split으로 학습데이터셋과 검증 데이터셋으로 나눠준다. 그리고 배치사이즈를 적용해서 데이터셋을 준비한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37a186ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,tgt_input, test_size=0.2)\n",
    "# step3에서 전처리를 완성한 텐서(numpy 배열)를 train_test_split 으로 분할한다.\n",
    "\n",
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256    # 학습시 배치사이즈\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE # 한 에포크가 돌 동안 몇번의 스텝을 가느냐\n",
    "\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)# 데이터를 섞어주고    \n",
    "val_dataset = val_dataset.shuffle(BUFFER_SIZE)    \n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)# 학습할때 쓰이는 배치사이즈로 나눠준다.\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1285443",
   "metadata": {},
   "source": [
    "### Step 5. 인공지능 만들기 & Step 6. 더 나은 텍스트 생성기를 만들기 위해서 하이퍼파라미터 튜닝하기\n",
    "- embedding 사이즈와 LSTM의 hidden 사이즈를 바꿔가면서 튜닝을 하였다.  \n",
    "- ex4에서 제시 되었던 embedding 사이즈와 hidden 사이즈로 모델을 돌렸다. \n",
    "- 주어진 것과 같이 사전의 단어는 12000단어로 정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19a9338c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 104s 205ms/step - loss: 3.4966 - val_loss: 3.1284\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 99s 203ms/step - loss: 3.0141 - val_loss: 2.9424\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 99s 202ms/step - loss: 2.8558 - val_loss: 2.8364\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 99s 202ms/step - loss: 2.7338 - val_loss: 2.7577\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 99s 202ms/step - loss: 2.6303 - val_loss: 2.6977\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 99s 203ms/step - loss: 2.5377 - val_loss: 2.6468\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 98s 201ms/step - loss: 2.4518 - val_loss: 2.6016\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 99s 203ms/step - loss: 2.3694 - val_loss: 2.5659\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 99s 203ms/step - loss: 2.2902 - val_loss: 2.5311\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 99s 204ms/step - loss: 2.2144 - val_loss: 2.5030\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 285s 542ms/step - loss: 3.3765 - val_loss: 2.9964\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 265s 542ms/step - loss: 2.8592 - val_loss: 2.7763\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 265s 544ms/step - loss: 2.6170 - val_loss: 2.6201\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 266s 544ms/step - loss: 2.3877 - val_loss: 2.4996\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 265s 544ms/step - loss: 2.1647 - val_loss: 2.3979\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 266s 545ms/step - loss: 1.9484 - val_loss: 2.3179\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 266s 545ms/step - loss: 1.7458 - val_loss: 2.2582\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 266s 545ms/step - loss: 1.5616 - val_loss: 2.2149\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 266s 546ms/step - loss: 1.4012 - val_loss: 2.1872\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 266s 545ms/step - loss: 1.2659 - val_loss: 2.1751\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 108s 213ms/step - loss: 3.5089 - val_loss: 3.1322\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 104s 214ms/step - loss: 3.0058 - val_loss: 2.9197\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 104s 214ms/step - loss: 2.8217 - val_loss: 2.7982\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 105s 214ms/step - loss: 2.6853 - val_loss: 2.7123\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 104s 214ms/step - loss: 2.5657 - val_loss: 2.6407\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 105s 215ms/step - loss: 2.4540 - val_loss: 2.5835\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 105s 215ms/step - loss: 2.3479 - val_loss: 2.5327\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 105s 215ms/step - loss: 2.2461 - val_loss: 2.4869\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 105s 214ms/step - loss: 2.1480 - val_loss: 2.4504\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 105s 215ms/step - loss: 2.0543 - val_loss: 2.4180\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 293s 561ms/step - loss: 3.3151 - val_loss: 2.9438\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 274s 561ms/step - loss: 2.7977 - val_loss: 2.7120\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 274s 561ms/step - loss: 2.5319 - val_loss: 2.5494\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 274s 562ms/step - loss: 2.2770 - val_loss: 2.4221\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 275s 563ms/step - loss: 2.0282 - val_loss: 2.3179\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 275s 563ms/step - loss: 1.7909 - val_loss: 2.2409\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 274s 562ms/step - loss: 1.5737 - val_loss: 2.1845\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 275s 564ms/step - loss: 1.3866 - val_loss: 2.1499\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 275s 564ms/step - loss: 1.2335 - val_loss: 2.1434\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 275s 564ms/step - loss: 1.1188 - val_loss: 2.1486\n"
     ]
    }
   ],
   "source": [
    "#Loss\n",
    "embedding_size=[256,512]\n",
    "hidden_size=[1024,2048]\n",
    "acc={}\n",
    "for i in embedding_size:\n",
    "    for j in hidden_size:\n",
    "        model=TextGenerator(12000+1, i, j) # i: embadding_size, j: hidden_size\n",
    "        optimizer=tf.keras.optimizers.Adam()\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        model.compile(loss=loss, optimizer=optimizer)\n",
    "        tg=model.fit(train_dataset, epochs=10, validation_data=(val_dataset))\n",
    "        acc[\"%d-%d\"%(i,j)]=tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdb12be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def find_acc(acc, key,hp):\n",
    "    hp1,hp2=key.split(\"-\")\n",
    "    dd=pd.DataFrame(acc[key].history)\n",
    "    return {hp[0]:hp1,hp[1]:hp2,\"val_loss\":dd.min()[1]}\n",
    "\n",
    "dict_list=[]\n",
    "for i in acc.keys():\n",
    "    dict_list.append(find_acc(acc,i,(\"embedding\",\"hidden_size\")))\n",
    "    \n",
    "loss_df=pd.DataFrame(dict_list) # 가장 높은 accuracy는 0.574667\n",
    "#loss_df.loc[acc[\"val_loss\"]<2.2].sort_values(\"val_loss\", ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a57a4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.503041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>2048</td>\n",
       "      <td>2.175064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.417997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>2.143438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embedding hidden_size  val_loss\n",
       "0       256        1024  2.503041\n",
       "1       256        2048  2.175064\n",
       "2       512        1024  2.417997\n",
       "3       512        2048  2.143438"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d461b706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_=loss_df.pivot(index=\"embedding\", columns=\"hidden_size\", values=\"val_loss\") \n",
    "\n",
    "loss_=loss_[['1024', '2048']]\n",
    "loss_=loss_.reindex([\"512\",\"256\"])\n",
    "\n",
    "font3 = {'color':  'green',\n",
    "      'style': 'italic',\n",
    "      'size': 15}\n",
    "\n",
    "sns.heatmap(loss_)\n",
    "for i in range(loss_.shape[1]):\n",
    "    for j in range(loss_.shape[0]):\n",
    "        plt.text(i+0.5,j+0.5,round(loss_.iloc[j,i],3),ha='center',va='center', fontdict=font3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf36eb",
   "metadata": {},
   "source": [
    "validation loss가 2.2 이하인 모델은 hidden_size가 2048개인 모델 둘이 었다.  \n",
    "그 중에서도 가장 성능이 좋았던 embedding_size=512, hidden_size=2048인 모델을 선택하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7b81c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 272s 513ms/step - loss: 3.3075 - val_loss: 2.9033\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 272s 557ms/step - loss: 2.7270 - val_loss: 2.6305\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 273s 561ms/step - loss: 2.3960 - val_loss: 2.4448\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 273s 560ms/step - loss: 2.0771 - val_loss: 2.3118\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 273s 559ms/step - loss: 1.7839 - val_loss: 2.2161\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 273s 560ms/step - loss: 1.5290 - val_loss: 2.1521\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 274s 562ms/step - loss: 1.3230 - val_loss: 2.1277\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 274s 562ms/step - loss: 1.1694 - val_loss: 2.1278\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 275s 564ms/step - loss: 1.0700 - val_loss: 2.1454\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 274s 563ms/step - loss: 1.0157 - val_loss: 2.1655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91a3825370>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model=TextGenerator(12000+1, 512, 2048) # i: embedding_size, j: hidden_size\n",
    "optimizer=tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(train_dataset, epochs=10, validation_data=(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94789cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i need you to be here with me <end> '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i need you \", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69a97665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i said i m sorry girl <end> '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i said\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd27212a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> never let me go , keep breathing <end> '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> never let me go\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7ea0af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you never thought kanye would ever got that mad <end> '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> you never \", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03308ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> why not i trying to give when no one gives me a try <end> '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> why not \", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b3547",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 언어모델을 돌려본 것 자체가 처음이었다. 물론 지난 프로젝트에 사용했던 가위바위보 모델 만들기도 시간이 오래걸렸지만, 하나의 모델을 만들기 위해서 10epoch를 돌리는데만해도 가장 작은 모델이 한 epoch당 40초 가량 시간이 들었다. 가장 무거운 모델은 한 에폭당 249초가 걸렸다. 학습시간이 오래 걸려서 모델을 돌려놓고 기다리다가 깜빡 졸았는데 너무 푹자버려서 다음날 아침에 일어나보니 LMS가 로그아웃 된 일도 있었고, 구글 colab에 모델을 걸어놓고 외출하고 돌아왔는데 오래 마우스 반응이 없어서 런타임이 종료된 일도 있었다. 이 사건을 계기로 꼭 모델을 만들고 어떻게하면 모델 저장하고 다시 로드해서 쓰는 방법을 꼭 익혀서 자칫 잘못해서 모델이 일부 날라가도 이어서 학습시킬수 있는 환경을 만들고 싶었다. \n",
    "\n",
    "-  위의 사연을 들은 유현지 퍼실님과 같은 조의 태원님과 대화중 callback기능을 알게 되었다. 다음에 모델을 만들때는 꼭 callback을 넣어서 모델을 만들어서 안전하게 학습을 해야겠다.\n",
    "\n",
    "- 전반적으로 낯선 파트이라서 어려웠지만 자연어처리 데이터를 전처리하는 방법에 있어서 정규표현식을 자유자제로 다루는 스킬이 중요함을 느꼈다. 코드를 보면 전처리 과정에서 반 정도가 정규표현식의 패턴으로 데이터의 불필요한 정보는 지우는 일이 많았다. 정규표현식은 보통 필요할때 메뉴얼을 펼쳐놓고 하나씩 테스트하면서 정규식 표현식 패턴을 만들었는데 여러 케이스에 대해서 연습해서 익숙해져야겠다고 생각했다. 메타문자 '^'이 not을 의미하는지 몰라서 처음에 정규표현식을 잘못 이해했었다. 최소한 정규표현식의 메타표현식이 뭘 의미하는지는 숙지해야겠다고 생각했다.\n",
    "\n",
    "- 노드에서 제시된 것처럼 대본의 텍스트를 다룰때는 문장 끝에 콜론이 붙을 경우(극본의 이름을 나타내는 표시) 그 문장을 포함시키지 않는등 NLP가 사용되는 텍스트에 대한 이해를 안다면 전처리를 더 수월하겠다는 생각을 했다. \n",
    "\n",
    "- 위의 히트맵을 보면 __embedding 사이즈가 높고, hidden의 사이즈가 큰쪽__ 이 loss가 많이 줄어들었음을 알수 있었다. validation loss가 2.2 아래로 떨어진 모델은 embedding은 512, hidden_size는 2048인 모델이다. 이정도면 모델의 복잡도가 큰 모델이라고 생각했었는데 검증데이터셋의 loss가 꾸준히 착착 줄어드는 것을 보고 NLP모델을 충분히 학습하고 결과물을 내기 위해서는 많은 리소스와 시간, 데이터를 필요로 하는 모델이라고 생각했다. \n",
    "\n",
    "- 사실 전처리 코드를 제출일 하루 전에 전처리 코드를 잘못 입력한 것을 발견해서 시간이 부족하여, 맨처음에 시도했던 embedding_size [128,256,512],hidden_size[512,1024,2048]. 총 9가지 케이스를 다시 돌려보지 못해서 아쉽다. 그래도 처음의 9번의 시도를 했던 당시와 같이 embedding_size와 hidden_size가 커질수록 학습의 손실(loss)과 검증데이터셋의 손실(loss)가 착착 줄어드는 것을 확인하였다. 그래서 최종적으로 embeding_size 512, hidden_size 2048인 모델을 선택해서 generate_text를 만들었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
